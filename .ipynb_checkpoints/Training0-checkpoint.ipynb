{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "\n",
    "# ----\n",
    "import glob\n",
    "import pickle\n",
    "# import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_directory = \"../DataX/\"\n",
    "data_directory = \"DataX/\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = 'DataX/Model_Weights/'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        try:\n",
    "            midi = converter.parse(file)\n",
    "            notes_to_parse = None\n",
    "        except Exception as e:\n",
    "            print(\"exception at\", str(file))\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                # should make it a pitch\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    print(\"final parsing finished\")\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "#     print(\"AFTER GET NOTES\\n\", notes)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.load_weights('DataX/Model_Weights/Weights_400.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 200):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1+400, epochs))\n",
    "#         print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            \n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                print(\"DNE\")\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1+200)))\n",
    "#             model.save_weights(model_weights_directory, \"Weights_{}.h5\".format(epoch+1))\n",
    "#           dump it to a file, instead of printing everything\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1+400, epoch+1+400))\n",
    "#             print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1+200, epoch+1+200))\n",
    "    \n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"DataX/log3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception at midi_songs/Vexilla_Regis_Palestrina.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Vexilla_Regis_Palestrina_tr.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-magv-impares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Hostis_Herodes_impie_Palestrina.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Veni_Creator_Spiritus_Palestrina.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag1-pares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Magnificat_octavi_toni_Palestrina.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Palestrina-Benedictusa5.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag4-pares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-magii-impares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Palestrina-Benedictusa5-2.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-magiv-impares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag2-pares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag8-pares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag5-pares-bflat.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-mag5-pares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Benedictus_Dominus_Deus_Israel.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Veni_Creator_Spiritus_Palestrina_tr.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Pal-magvii-impares.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "exception at midi_songs/Magnificat_octavi_toni_Palestrina_tr.mid\n",
      "Cannot set partition by 0 (0/1)\n",
      "final parsing finished\n"
     ]
    }
   ],
   "source": [
    "data = get_notes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 150\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (16, 64, 512)             76800     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (16, 64, 128)             197120    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (16, 64, 128)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (16, 64, 150)             19350     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (16, 64, 150)             0         \n",
      "=================================================================\n",
      "Total params: 1,080,726\n",
      "Trainable params: 1,080,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 159368\n",
      "Epoch 401/200\n",
      "Batch: 1, Loss: 2.246173143386841, Accuracy: 0.44921875\n",
      "Batch: 2, Loss: 1.2080109119415283, Accuracy: 0.6162109375\n",
      "Batch: 3, Loss: 1.1222243309020996, Accuracy: 0.62890625\n",
      "Batch: 4, Loss: 1.174464464187622, Accuracy: 0.607421875\n",
      "Batch: 5, Loss: 1.0739805698394775, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.165640115737915, Accuracy: 0.609375\n",
      "Batch: 7, Loss: 1.0558021068572998, Accuracy: 0.654296875\n",
      "Batch: 8, Loss: 1.1093662977218628, Accuracy: 0.6484375\n",
      "Batch: 9, Loss: 1.1155768632888794, Accuracy: 0.64453125\n",
      "Batch: 10, Loss: 1.0755953788757324, Accuracy: 0.6513671875\n",
      "Batch: 11, Loss: 1.0518832206726074, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 1.1606718301773071, Accuracy: 0.6328125\n",
      "Batch: 13, Loss: 1.0609252452850342, Accuracy: 0.65625\n",
      "Batch: 14, Loss: 1.078995943069458, Accuracy: 0.650390625\n",
      "Batch: 15, Loss: 1.0504961013793945, Accuracy: 0.6630859375\n",
      "Batch: 16, Loss: 1.1586699485778809, Accuracy: 0.6435546875\n",
      "Batch: 17, Loss: 1.117138147354126, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.2087202072143555, Accuracy: 0.5986328125\n",
      "Batch: 19, Loss: 1.2909469604492188, Accuracy: 0.5810546875\n",
      "Batch: 20, Loss: 1.201740026473999, Accuracy: 0.609375\n",
      "Batch: 21, Loss: 1.1787512302398682, Accuracy: 0.6298828125\n",
      "Batch: 22, Loss: 1.356048345565796, Accuracy: 0.5791015625\n",
      "Batch: 23, Loss: 1.3370532989501953, Accuracy: 0.57421875\n",
      "Batch: 24, Loss: 1.2092385292053223, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.2554322481155396, Accuracy: 0.603515625\n",
      "Batch: 26, Loss: 1.238724946975708, Accuracy: 0.5810546875\n",
      "Batch: 27, Loss: 1.2195227146148682, Accuracy: 0.5888671875\n",
      "Batch: 28, Loss: 1.1858981847763062, Accuracy: 0.5947265625\n",
      "Batch: 29, Loss: 1.127845287322998, Accuracy: 0.6171875\n",
      "Batch: 30, Loss: 1.2843070030212402, Accuracy: 0.583984375\n",
      "Batch: 31, Loss: 1.2758607864379883, Accuracy: 0.58984375\n",
      "Batch: 32, Loss: 1.1379296779632568, Accuracy: 0.6162109375\n",
      "Batch: 33, Loss: 1.074155330657959, Accuracy: 0.638671875\n",
      "Batch: 34, Loss: 1.195765733718872, Accuracy: 0.6171875\n",
      "Batch: 35, Loss: 1.2035901546478271, Accuracy: 0.6083984375\n",
      "Batch: 36, Loss: 1.2540867328643799, Accuracy: 0.595703125\n",
      "Batch: 37, Loss: 1.318171501159668, Accuracy: 0.5673828125\n",
      "Batch: 38, Loss: 1.2003083229064941, Accuracy: 0.6123046875\n",
      "Batch: 39, Loss: 1.1414449214935303, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.1787647008895874, Accuracy: 0.6181640625\n",
      "Batch: 41, Loss: 1.266223669052124, Accuracy: 0.58984375\n",
      "Batch: 42, Loss: 1.123398780822754, Accuracy: 0.619140625\n",
      "Batch: 43, Loss: 1.0985546112060547, Accuracy: 0.6357421875\n",
      "Batch: 44, Loss: 1.103210210800171, Accuracy: 0.623046875\n",
      "Batch: 45, Loss: 1.1351051330566406, Accuracy: 0.625\n",
      "Batch: 46, Loss: 1.2096848487854004, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.1446987390518188, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.2195868492126465, Accuracy: 0.59765625\n",
      "Batch: 49, Loss: 1.2263567447662354, Accuracy: 0.6220703125\n",
      "Batch: 50, Loss: 1.236089825630188, Accuracy: 0.5947265625\n",
      "Batch: 51, Loss: 1.265737533569336, Accuracy: 0.5810546875\n",
      "Batch: 52, Loss: 1.305042028427124, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.211353063583374, Accuracy: 0.6044921875\n",
      "Batch: 54, Loss: 1.2749435901641846, Accuracy: 0.5908203125\n",
      "Batch: 55, Loss: 1.216019630432129, Accuracy: 0.6103515625\n",
      "Batch: 56, Loss: 1.1744966506958008, Accuracy: 0.6181640625\n",
      "Batch: 57, Loss: 1.19203782081604, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.1728057861328125, Accuracy: 0.619140625\n",
      "Batch: 59, Loss: 1.202916145324707, Accuracy: 0.6171875\n",
      "Batch: 60, Loss: 1.374929666519165, Accuracy: 0.5703125\n",
      "Batch: 61, Loss: 1.2230041027069092, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.228454828262329, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.2267158031463623, Accuracy: 0.59375\n",
      "Batch: 64, Loss: 1.339048147201538, Accuracy: 0.5693359375\n",
      "Batch: 65, Loss: 1.2555385828018188, Accuracy: 0.5947265625\n",
      "Batch: 66, Loss: 1.2553653717041016, Accuracy: 0.59765625\n",
      "Batch: 67, Loss: 1.2264466285705566, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.140282392501831, Accuracy: 0.6240234375\n",
      "Batch: 69, Loss: 1.275179386138916, Accuracy: 0.5888671875\n",
      "Batch: 70, Loss: 1.219364881515503, Accuracy: 0.6025390625\n",
      "Batch: 71, Loss: 1.2227463722229004, Accuracy: 0.6171875\n",
      "Batch: 72, Loss: 1.2674756050109863, Accuracy: 0.599609375\n",
      "Batch: 73, Loss: 1.2611111402511597, Accuracy: 0.5859375\n",
      "Batch: 74, Loss: 1.2069162130355835, Accuracy: 0.6025390625\n",
      "Batch: 75, Loss: 1.2028841972351074, Accuracy: 0.6064453125\n",
      "Batch: 76, Loss: 1.1295883655548096, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.0832624435424805, Accuracy: 0.6455078125\n",
      "Batch: 78, Loss: 1.1958603858947754, Accuracy: 0.6015625\n",
      "Batch: 79, Loss: 1.239577293395996, Accuracy: 0.5869140625\n",
      "Batch: 80, Loss: 1.2527387142181396, Accuracy: 0.5927734375\n",
      "Batch: 81, Loss: 1.200782299041748, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.1972277164459229, Accuracy: 0.60546875\n",
      "Batch: 83, Loss: 1.2937321662902832, Accuracy: 0.5888671875\n",
      "Batch: 84, Loss: 1.170699954032898, Accuracy: 0.642578125\n",
      "Batch: 85, Loss: 1.2861239910125732, Accuracy: 0.599609375\n",
      "Batch: 86, Loss: 1.2647513151168823, Accuracy: 0.580078125\n",
      "Batch: 87, Loss: 1.274491548538208, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.331190824508667, Accuracy: 0.5712890625\n",
      "Batch: 89, Loss: 1.2352583408355713, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.2396495342254639, Accuracy: 0.6044921875\n",
      "Batch: 91, Loss: 1.2255089282989502, Accuracy: 0.60546875\n",
      "Batch: 92, Loss: 1.2582639455795288, Accuracy: 0.595703125\n",
      "Batch: 93, Loss: 1.2300004959106445, Accuracy: 0.6015625\n",
      "Batch: 94, Loss: 1.251673936843872, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.2771036624908447, Accuracy: 0.572265625\n",
      "Batch: 96, Loss: 1.2861827611923218, Accuracy: 0.6064453125\n",
      "Batch: 97, Loss: 1.2613539695739746, Accuracy: 0.58203125\n",
      "Batch: 98, Loss: 1.1807610988616943, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.21787691116333, Accuracy: 0.59375\n",
      "Batch: 100, Loss: 1.1930452585220337, Accuracy: 0.6123046875\n",
      "Batch: 101, Loss: 1.1719615459442139, Accuracy: 0.6259765625\n",
      "Batch: 102, Loss: 1.2601147890090942, Accuracy: 0.5908203125\n",
      "Batch: 103, Loss: 1.2322568893432617, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.2271015644073486, Accuracy: 0.607421875\n",
      "Batch: 105, Loss: 1.2760026454925537, Accuracy: 0.599609375\n",
      "Batch: 106, Loss: 1.2382595539093018, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.316183090209961, Accuracy: 0.5771484375\n",
      "Batch: 108, Loss: 1.2255709171295166, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.2777118682861328, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.248986005783081, Accuracy: 0.59375\n",
      "Batch: 111, Loss: 1.1672031879425049, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.1563122272491455, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.2077580690383911, Accuracy: 0.6044921875\n",
      "Batch: 114, Loss: 1.2256793975830078, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.265519142150879, Accuracy: 0.5859375\n",
      "Batch: 116, Loss: 1.2385904788970947, Accuracy: 0.5771484375\n",
      "Batch: 117, Loss: 1.2343171834945679, Accuracy: 0.595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 1.2780169248580933, Accuracy: 0.580078125\n",
      "Batch: 119, Loss: 1.3090252876281738, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.3848559856414795, Accuracy: 0.5634765625\n",
      "Batch: 121, Loss: 1.3575050830841064, Accuracy: 0.580078125\n",
      "Batch: 122, Loss: 1.2873919010162354, Accuracy: 0.5810546875\n",
      "Batch: 123, Loss: 1.2767267227172852, Accuracy: 0.5673828125\n",
      "Batch: 124, Loss: 1.349716067314148, Accuracy: 0.5654296875\n",
      "Batch: 125, Loss: 1.2803499698638916, Accuracy: 0.580078125\n",
      "Batch: 126, Loss: 1.3148913383483887, Accuracy: 0.580078125\n",
      "Batch: 127, Loss: 1.350731611251831, Accuracy: 0.5771484375\n",
      "Batch: 128, Loss: 1.307934045791626, Accuracy: 0.578125\n",
      "Batch: 129, Loss: 1.2272684574127197, Accuracy: 0.595703125\n",
      "Batch: 130, Loss: 1.2606940269470215, Accuracy: 0.58984375\n",
      "Batch: 131, Loss: 1.3227769136428833, Accuracy: 0.5791015625\n",
      "Batch: 132, Loss: 1.1413426399230957, Accuracy: 0.63671875\n",
      "Batch: 133, Loss: 1.234006643295288, Accuracy: 0.5927734375\n",
      "Batch: 134, Loss: 1.1988277435302734, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.1432310342788696, Accuracy: 0.634765625\n",
      "Batch: 136, Loss: 1.1402877569198608, Accuracy: 0.6201171875\n",
      "Batch: 137, Loss: 1.2853803634643555, Accuracy: 0.5810546875\n",
      "Batch: 138, Loss: 1.3238916397094727, Accuracy: 0.560546875\n",
      "Batch: 139, Loss: 1.2543511390686035, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.314936876296997, Accuracy: 0.5888671875\n",
      "Batch: 141, Loss: 1.2812492847442627, Accuracy: 0.6103515625\n",
      "Batch: 142, Loss: 1.2508058547973633, Accuracy: 0.6015625\n",
      "Batch: 143, Loss: 1.286501407623291, Accuracy: 0.5830078125\n",
      "Batch: 144, Loss: 1.3161042928695679, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.3153481483459473, Accuracy: 0.5791015625\n",
      "Batch: 146, Loss: 1.2773807048797607, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.2533085346221924, Accuracy: 0.57421875\n",
      "Batch: 148, Loss: 1.3148775100708008, Accuracy: 0.5849609375\n",
      "Batch: 149, Loss: 1.2415777444839478, Accuracy: 0.580078125\n",
      "Batch: 150, Loss: 1.255920171737671, Accuracy: 0.5908203125\n",
      "Batch: 151, Loss: 1.2741084098815918, Accuracy: 0.6005859375\n",
      "Batch: 152, Loss: 1.2189829349517822, Accuracy: 0.599609375\n",
      "Batch: 153, Loss: 1.1999229192733765, Accuracy: 0.62109375\n",
      "Batch: 154, Loss: 1.2034181356430054, Accuracy: 0.6171875\n",
      "Batch: 155, Loss: 1.2020061016082764, Accuracy: 0.6171875\n",
      "Epoch 402/200\n",
      "Batch: 1, Loss: 1.256812572479248, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 1.1433544158935547, Accuracy: 0.6064453125\n",
      "Batch: 3, Loss: 1.0583922863006592, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.2037732601165771, Accuracy: 0.6123046875\n",
      "Batch: 5, Loss: 1.0293020009994507, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.1062116622924805, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.0703933238983154, Accuracy: 0.66015625\n",
      "Batch: 8, Loss: 1.084956169128418, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0035101175308228, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 1.0135537385940552, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 1.031463384628296, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 1.0809600353240967, Accuracy: 0.6416015625\n",
      "Batch: 13, Loss: 1.0953246355056763, Accuracy: 0.658203125\n",
      "Batch: 14, Loss: 1.0198049545288086, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 0.9995205402374268, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 1.1044981479644775, Accuracy: 0.6435546875\n",
      "Batch: 17, Loss: 1.0902163982391357, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1955294609069824, Accuracy: 0.6064453125\n",
      "Batch: 19, Loss: 1.2172112464904785, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.1470822095870972, Accuracy: 0.6396484375\n",
      "Batch: 21, Loss: 1.1824402809143066, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.2750614881515503, Accuracy: 0.5810546875\n",
      "Batch: 23, Loss: 1.2995414733886719, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.2111485004425049, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.209587812423706, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.2073065042495728, Accuracy: 0.607421875\n",
      "Batch: 27, Loss: 1.2159780263900757, Accuracy: 0.6103515625\n",
      "Batch: 28, Loss: 1.1801462173461914, Accuracy: 0.6162109375\n",
      "Batch: 29, Loss: 1.1400935649871826, Accuracy: 0.6171875\n",
      "Batch: 30, Loss: 1.183456540107727, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.2908440828323364, Accuracy: 0.5927734375\n",
      "Batch: 32, Loss: 1.086045503616333, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.0753073692321777, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.1562367677688599, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.2348809242248535, Accuracy: 0.5966796875\n",
      "Batch: 36, Loss: 1.2437115907669067, Accuracy: 0.58203125\n",
      "Batch: 37, Loss: 1.2483292818069458, Accuracy: 0.587890625\n",
      "Batch: 38, Loss: 1.2217875719070435, Accuracy: 0.591796875\n",
      "Batch: 39, Loss: 1.1488207578659058, Accuracy: 0.615234375\n",
      "Batch: 40, Loss: 1.169639229774475, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.2759171724319458, Accuracy: 0.564453125\n",
      "Batch: 42, Loss: 1.1217914819717407, Accuracy: 0.634765625\n",
      "Batch: 43, Loss: 1.111314296722412, Accuracy: 0.6328125\n",
      "Batch: 44, Loss: 1.1392524242401123, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 1.170194149017334, Accuracy: 0.611328125\n",
      "Batch: 46, Loss: 1.2194284200668335, Accuracy: 0.6064453125\n",
      "Batch: 47, Loss: 1.1847728490829468, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.1845272779464722, Accuracy: 0.609375\n",
      "Batch: 49, Loss: 1.265293836593628, Accuracy: 0.5888671875\n",
      "Batch: 50, Loss: 1.169217824935913, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.1956584453582764, Accuracy: 0.59765625\n",
      "Batch: 52, Loss: 1.3135113716125488, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.281691312789917, Accuracy: 0.5869140625\n",
      "Batch: 54, Loss: 1.3073323965072632, Accuracy: 0.5712890625\n",
      "Batch: 55, Loss: 1.17212975025177, Accuracy: 0.615234375\n",
      "Batch: 56, Loss: 1.1265661716461182, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.1861436367034912, Accuracy: 0.630859375\n",
      "Batch: 58, Loss: 1.158041000366211, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.1597058773040771, Accuracy: 0.623046875\n",
      "Batch: 60, Loss: 1.3162903785705566, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.2612935304641724, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.1738810539245605, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.2168806791305542, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2381658554077148, Accuracy: 0.59375\n",
      "Batch: 65, Loss: 1.2755584716796875, Accuracy: 0.59375\n",
      "Batch: 66, Loss: 1.292711853981018, Accuracy: 0.58984375\n",
      "Batch: 67, Loss: 1.214301586151123, Accuracy: 0.60546875\n",
      "Batch: 68, Loss: 1.1706113815307617, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.2406952381134033, Accuracy: 0.6123046875\n",
      "Batch: 70, Loss: 1.2496058940887451, Accuracy: 0.6015625\n",
      "Batch: 71, Loss: 1.2225673198699951, Accuracy: 0.6044921875\n",
      "Batch: 72, Loss: 1.2655549049377441, Accuracy: 0.595703125\n",
      "Batch: 73, Loss: 1.274909496307373, Accuracy: 0.5908203125\n",
      "Batch: 74, Loss: 1.1681621074676514, Accuracy: 0.626953125\n",
      "Batch: 75, Loss: 1.181560754776001, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.1620221138000488, Accuracy: 0.6142578125\n",
      "Batch: 77, Loss: 1.1127519607543945, Accuracy: 0.6416015625\n",
      "Batch: 78, Loss: 1.1582732200622559, Accuracy: 0.6318359375\n",
      "Batch: 79, Loss: 1.1947523355484009, Accuracy: 0.6123046875\n",
      "Batch: 80, Loss: 1.1890487670898438, Accuracy: 0.5986328125\n",
      "Batch: 81, Loss: 1.209519863128662, Accuracy: 0.615234375\n",
      "Batch: 82, Loss: 1.171576976776123, Accuracy: 0.6279296875\n",
      "Batch: 83, Loss: 1.268190622329712, Accuracy: 0.587890625\n",
      "Batch: 84, Loss: 1.2304986715316772, Accuracy: 0.607421875\n",
      "Batch: 85, Loss: 1.2166216373443604, Accuracy: 0.607421875\n",
      "Batch: 86, Loss: 1.1906665563583374, Accuracy: 0.6171875\n",
      "Batch: 87, Loss: 1.2665051221847534, Accuracy: 0.59765625\n",
      "Batch: 88, Loss: 1.254431962966919, Accuracy: 0.583984375\n",
      "Batch: 89, Loss: 1.2298164367675781, Accuracy: 0.6005859375\n",
      "Batch: 90, Loss: 1.2220513820648193, Accuracy: 0.5927734375\n",
      "Batch: 91, Loss: 1.1749162673950195, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.2034156322479248, Accuracy: 0.6201171875\n",
      "Batch: 93, Loss: 1.1956170797348022, Accuracy: 0.6025390625\n",
      "Batch: 94, Loss: 1.3209834098815918, Accuracy: 0.578125\n",
      "Batch: 95, Loss: 1.2156996726989746, Accuracy: 0.6005859375\n",
      "Batch: 96, Loss: 1.2745649814605713, Accuracy: 0.609375\n",
      "Batch: 97, Loss: 1.2646183967590332, Accuracy: 0.5859375\n",
      "Batch: 98, Loss: 1.2053440809249878, Accuracy: 0.6181640625\n",
      "Batch: 99, Loss: 1.247135877609253, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.1423882246017456, Accuracy: 0.6220703125\n",
      "Batch: 101, Loss: 1.1429002285003662, Accuracy: 0.6416015625\n",
      "Batch: 102, Loss: 1.2526508569717407, Accuracy: 0.6025390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 1.2068535089492798, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.2866212129592896, Accuracy: 0.59765625\n",
      "Batch: 105, Loss: 1.2669503688812256, Accuracy: 0.6025390625\n",
      "Batch: 106, Loss: 1.2216265201568604, Accuracy: 0.609375\n",
      "Batch: 107, Loss: 1.3806151151657104, Accuracy: 0.55859375\n",
      "Batch: 108, Loss: 1.269707202911377, Accuracy: 0.5673828125\n",
      "Batch: 109, Loss: 1.291745662689209, Accuracy: 0.576171875\n",
      "Batch: 110, Loss: 1.1915934085845947, Accuracy: 0.6025390625\n",
      "Batch: 111, Loss: 1.217429757118225, Accuracy: 0.6015625\n",
      "Batch: 112, Loss: 1.1636340618133545, Accuracy: 0.6103515625\n",
      "Batch: 113, Loss: 1.2643892765045166, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.1949682235717773, Accuracy: 0.5927734375\n",
      "Batch: 115, Loss: 1.2824578285217285, Accuracy: 0.5791015625\n",
      "Batch: 116, Loss: 1.2675042152404785, Accuracy: 0.5751953125\n",
      "Batch: 117, Loss: 1.236356258392334, Accuracy: 0.6015625\n",
      "Batch: 118, Loss: 1.306516170501709, Accuracy: 0.5712890625\n",
      "Batch: 119, Loss: 1.2887027263641357, Accuracy: 0.6005859375\n",
      "Batch: 120, Loss: 1.380349040031433, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.2302908897399902, Accuracy: 0.59375\n",
      "Batch: 122, Loss: 1.2820801734924316, Accuracy: 0.58984375\n",
      "Batch: 123, Loss: 1.2814396619796753, Accuracy: 0.5947265625\n",
      "Batch: 124, Loss: 1.3207051753997803, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.248687744140625, Accuracy: 0.599609375\n",
      "Batch: 126, Loss: 1.298807144165039, Accuracy: 0.568359375\n",
      "Batch: 127, Loss: 1.3390328884124756, Accuracy: 0.572265625\n",
      "Batch: 128, Loss: 1.2415454387664795, Accuracy: 0.6044921875\n",
      "Batch: 129, Loss: 1.2536765336990356, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.2321854829788208, Accuracy: 0.603515625\n",
      "Batch: 131, Loss: 1.3071529865264893, Accuracy: 0.5771484375\n",
      "Batch: 132, Loss: 1.1503795385360718, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.2578798532485962, Accuracy: 0.59375\n",
      "Batch: 134, Loss: 1.172032117843628, Accuracy: 0.6298828125\n",
      "Batch: 135, Loss: 1.151902437210083, Accuracy: 0.638671875\n",
      "Batch: 136, Loss: 1.1524419784545898, Accuracy: 0.6259765625\n",
      "Batch: 137, Loss: 1.295529842376709, Accuracy: 0.5986328125\n",
      "Batch: 138, Loss: 1.303288221359253, Accuracy: 0.56640625\n",
      "Batch: 139, Loss: 1.24784517288208, Accuracy: 0.5859375\n",
      "Batch: 140, Loss: 1.315114140510559, Accuracy: 0.564453125\n",
      "Batch: 141, Loss: 1.240727424621582, Accuracy: 0.6220703125\n",
      "Batch: 142, Loss: 1.2803120613098145, Accuracy: 0.5908203125\n",
      "Batch: 143, Loss: 1.3061881065368652, Accuracy: 0.5703125\n",
      "Batch: 144, Loss: 1.3392518758773804, Accuracy: 0.556640625\n",
      "Batch: 145, Loss: 1.3432812690734863, Accuracy: 0.5537109375\n",
      "Batch: 146, Loss: 1.2892029285430908, Accuracy: 0.5869140625\n",
      "Batch: 147, Loss: 1.2535393238067627, Accuracy: 0.6015625\n",
      "Batch: 148, Loss: 1.2817857265472412, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.1943110227584839, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.231058955192566, Accuracy: 0.59375\n",
      "Batch: 151, Loss: 1.2617090940475464, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.2581512928009033, Accuracy: 0.5849609375\n",
      "Batch: 153, Loss: 1.2166944742202759, Accuracy: 0.5966796875\n",
      "Batch: 154, Loss: 1.21526300907135, Accuracy: 0.60546875\n",
      "Batch: 155, Loss: 1.1783794164657593, Accuracy: 0.6259765625\n",
      "Epoch 403/200\n",
      "Batch: 1, Loss: 1.2844951152801514, Accuracy: 0.6171875\n",
      "Batch: 2, Loss: 1.156246542930603, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 1.0652146339416504, Accuracy: 0.65234375\n",
      "Batch: 4, Loss: 1.1284679174423218, Accuracy: 0.62109375\n",
      "Batch: 5, Loss: 1.048409104347229, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.1296217441558838, Accuracy: 0.630859375\n",
      "Batch: 7, Loss: 1.1192066669464111, Accuracy: 0.623046875\n",
      "Batch: 8, Loss: 1.0530309677124023, Accuracy: 0.662109375\n",
      "Batch: 9, Loss: 1.1050910949707031, Accuracy: 0.63671875\n",
      "Batch: 10, Loss: 1.043428897857666, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 1.0268325805664062, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 1.0570921897888184, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 1.0600385665893555, Accuracy: 0.6318359375\n",
      "Batch: 14, Loss: 1.0535093545913696, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9897658824920654, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.075636625289917, Accuracy: 0.650390625\n",
      "Batch: 17, Loss: 1.101562261581421, Accuracy: 0.6220703125\n",
      "Batch: 18, Loss: 1.2214603424072266, Accuracy: 0.5859375\n",
      "Batch: 19, Loss: 1.2313998937606812, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.1709998846054077, Accuracy: 0.625\n",
      "Batch: 21, Loss: 1.1595146656036377, Accuracy: 0.6318359375\n",
      "Batch: 22, Loss: 1.2837320566177368, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.3325347900390625, Accuracy: 0.57421875\n",
      "Batch: 24, Loss: 1.167830467224121, Accuracy: 0.642578125\n",
      "Batch: 25, Loss: 1.1849117279052734, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.2403721809387207, Accuracy: 0.59765625\n",
      "Batch: 27, Loss: 1.20181143283844, Accuracy: 0.59765625\n",
      "Batch: 28, Loss: 1.1472398042678833, Accuracy: 0.6103515625\n",
      "Batch: 29, Loss: 1.138909101486206, Accuracy: 0.6171875\n",
      "Batch: 30, Loss: 1.2309013605117798, Accuracy: 0.599609375\n",
      "Batch: 31, Loss: 1.238521933555603, Accuracy: 0.59375\n",
      "Batch: 32, Loss: 1.1274375915527344, Accuracy: 0.6044921875\n",
      "Batch: 33, Loss: 1.0621724128723145, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.1517037153244019, Accuracy: 0.623046875\n",
      "Batch: 35, Loss: 1.1386324167251587, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.2231309413909912, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.2654318809509277, Accuracy: 0.5732421875\n",
      "Batch: 38, Loss: 1.257379412651062, Accuracy: 0.587890625\n",
      "Batch: 39, Loss: 1.1114495992660522, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.1775106191635132, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1990795135498047, Accuracy: 0.59765625\n",
      "Batch: 42, Loss: 1.1409673690795898, Accuracy: 0.62109375\n",
      "Batch: 43, Loss: 1.133802890777588, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.0829873085021973, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.114530324935913, Accuracy: 0.623046875\n",
      "Batch: 46, Loss: 1.1718919277191162, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.1682965755462646, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.2301737070083618, Accuracy: 0.5986328125\n",
      "Batch: 49, Loss: 1.2743325233459473, Accuracy: 0.5849609375\n",
      "Batch: 50, Loss: 1.2061331272125244, Accuracy: 0.5927734375\n",
      "Batch: 51, Loss: 1.2044124603271484, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.314671516418457, Accuracy: 0.5673828125\n",
      "Batch: 53, Loss: 1.2117247581481934, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.264235258102417, Accuracy: 0.58203125\n",
      "Batch: 55, Loss: 1.1812894344329834, Accuracy: 0.6123046875\n",
      "Batch: 56, Loss: 1.1470122337341309, Accuracy: 0.626953125\n",
      "Batch: 57, Loss: 1.1547685861587524, Accuracy: 0.6240234375\n",
      "Batch: 58, Loss: 1.166814923286438, Accuracy: 0.60546875\n",
      "Batch: 59, Loss: 1.1617624759674072, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.2733477354049683, Accuracy: 0.5625\n",
      "Batch: 61, Loss: 1.167236566543579, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.209104299545288, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.219078779220581, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.2639071941375732, Accuracy: 0.5908203125\n",
      "Batch: 65, Loss: 1.272573709487915, Accuracy: 0.5966796875\n",
      "Batch: 66, Loss: 1.2375080585479736, Accuracy: 0.623046875\n",
      "Batch: 67, Loss: 1.228929042816162, Accuracy: 0.609375\n",
      "Batch: 68, Loss: 1.176661491394043, Accuracy: 0.611328125\n",
      "Batch: 69, Loss: 1.2712595462799072, Accuracy: 0.587890625\n",
      "Batch: 70, Loss: 1.2458308935165405, Accuracy: 0.60546875\n",
      "Batch: 71, Loss: 1.184484839439392, Accuracy: 0.62109375\n",
      "Batch: 72, Loss: 1.2525813579559326, Accuracy: 0.599609375\n",
      "Batch: 73, Loss: 1.245088815689087, Accuracy: 0.5927734375\n",
      "Batch: 74, Loss: 1.110344409942627, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.2427549362182617, Accuracy: 0.587890625\n",
      "Batch: 76, Loss: 1.1548181772232056, Accuracy: 0.611328125\n",
      "Batch: 77, Loss: 1.1670112609863281, Accuracy: 0.6220703125\n",
      "Batch: 78, Loss: 1.130382776260376, Accuracy: 0.6171875\n",
      "Batch: 79, Loss: 1.2098057270050049, Accuracy: 0.611328125\n",
      "Batch: 80, Loss: 1.2346622943878174, Accuracy: 0.59375\n",
      "Batch: 81, Loss: 1.2272515296936035, Accuracy: 0.603515625\n",
      "Batch: 82, Loss: 1.25571608543396, Accuracy: 0.6083984375\n",
      "Batch: 83, Loss: 1.2778798341751099, Accuracy: 0.57421875\n",
      "Batch: 84, Loss: 1.186622142791748, Accuracy: 0.6103515625\n",
      "Batch: 85, Loss: 1.2563250064849854, Accuracy: 0.58984375\n",
      "Batch: 86, Loss: 1.2310552597045898, Accuracy: 0.5810546875\n",
      "Batch: 87, Loss: 1.2697919607162476, Accuracy: 0.591796875\n",
      "Batch: 88, Loss: 1.2485957145690918, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 1.228943109512329, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.1848756074905396, Accuracy: 0.6171875\n",
      "Batch: 91, Loss: 1.2232789993286133, Accuracy: 0.59765625\n",
      "Batch: 92, Loss: 1.18107008934021, Accuracy: 0.6259765625\n",
      "Batch: 93, Loss: 1.2076492309570312, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.3017702102661133, Accuracy: 0.5771484375\n",
      "Batch: 95, Loss: 1.1988906860351562, Accuracy: 0.6240234375\n",
      "Batch: 96, Loss: 1.2409865856170654, Accuracy: 0.6025390625\n",
      "Batch: 97, Loss: 1.2462328672409058, Accuracy: 0.603515625\n",
      "Batch: 98, Loss: 1.1843538284301758, Accuracy: 0.611328125\n",
      "Batch: 99, Loss: 1.281986951828003, Accuracy: 0.5888671875\n",
      "Batch: 100, Loss: 1.176720380783081, Accuracy: 0.626953125\n",
      "Batch: 101, Loss: 1.1783957481384277, Accuracy: 0.62109375\n",
      "Batch: 102, Loss: 1.2098151445388794, Accuracy: 0.6142578125\n",
      "Batch: 103, Loss: 1.1938600540161133, Accuracy: 0.634765625\n",
      "Batch: 104, Loss: 1.2629659175872803, Accuracy: 0.59375\n",
      "Batch: 105, Loss: 1.3207941055297852, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.2316136360168457, Accuracy: 0.603515625\n",
      "Batch: 107, Loss: 1.3156535625457764, Accuracy: 0.5771484375\n",
      "Batch: 108, Loss: 1.2516762018203735, Accuracy: 0.595703125\n",
      "Batch: 109, Loss: 1.2768820524215698, Accuracy: 0.576171875\n",
      "Batch: 110, Loss: 1.2478636503219604, Accuracy: 0.60546875\n",
      "Batch: 111, Loss: 1.1613935232162476, Accuracy: 0.6015625\n",
      "Batch: 112, Loss: 1.1586594581604004, Accuracy: 0.62890625\n",
      "Batch: 113, Loss: 1.2366405725479126, Accuracy: 0.591796875\n",
      "Batch: 114, Loss: 1.2881865501403809, Accuracy: 0.564453125\n",
      "Batch: 115, Loss: 1.2870992422103882, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.26438570022583, Accuracy: 0.57421875\n",
      "Batch: 117, Loss: 1.252345085144043, Accuracy: 0.5927734375\n",
      "Batch: 118, Loss: 1.3174278736114502, Accuracy: 0.5634765625\n",
      "Batch: 119, Loss: 1.316582202911377, Accuracy: 0.572265625\n",
      "Batch: 120, Loss: 1.4039833545684814, Accuracy: 0.546875\n",
      "Batch: 121, Loss: 1.268681526184082, Accuracy: 0.6044921875\n",
      "Batch: 122, Loss: 1.262969970703125, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.309450626373291, Accuracy: 0.595703125\n",
      "Batch: 124, Loss: 1.250260353088379, Accuracy: 0.6025390625\n",
      "Batch: 125, Loss: 1.2474926710128784, Accuracy: 0.6025390625\n",
      "Batch: 126, Loss: 1.305492877960205, Accuracy: 0.5791015625\n",
      "Batch: 127, Loss: 1.3298373222351074, Accuracy: 0.5615234375\n",
      "Batch: 128, Loss: 1.2843513488769531, Accuracy: 0.5703125\n",
      "Batch: 129, Loss: 1.2919936180114746, Accuracy: 0.583984375\n",
      "Batch: 130, Loss: 1.1890573501586914, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.2705693244934082, Accuracy: 0.576171875\n",
      "Batch: 132, Loss: 1.163177251815796, Accuracy: 0.6171875\n",
      "Batch: 133, Loss: 1.2575839757919312, Accuracy: 0.6015625\n",
      "Batch: 134, Loss: 1.156369924545288, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.125878095626831, Accuracy: 0.630859375\n",
      "Batch: 136, Loss: 1.1657836437225342, Accuracy: 0.6455078125\n",
      "Batch: 137, Loss: 1.2366700172424316, Accuracy: 0.6005859375\n",
      "Batch: 138, Loss: 1.3059520721435547, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.2571070194244385, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.316528558731079, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.2039194107055664, Accuracy: 0.6181640625\n",
      "Batch: 142, Loss: 1.209592342376709, Accuracy: 0.61328125\n",
      "Batch: 143, Loss: 1.2737846374511719, Accuracy: 0.5771484375\n",
      "Batch: 144, Loss: 1.307647943496704, Accuracy: 0.58203125\n",
      "Batch: 145, Loss: 1.377947449684143, Accuracy: 0.5537109375\n",
      "Batch: 146, Loss: 1.2679998874664307, Accuracy: 0.576171875\n",
      "Batch: 147, Loss: 1.2906383275985718, Accuracy: 0.5712890625\n",
      "Batch: 148, Loss: 1.2897895574569702, Accuracy: 0.5654296875\n",
      "Batch: 149, Loss: 1.2347545623779297, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.2288539409637451, Accuracy: 0.6103515625\n",
      "Batch: 151, Loss: 1.223037600517273, Accuracy: 0.6103515625\n",
      "Batch: 152, Loss: 1.221313714981079, Accuracy: 0.6064453125\n",
      "Batch: 153, Loss: 1.2420591115951538, Accuracy: 0.623046875\n",
      "Batch: 154, Loss: 1.2564488649368286, Accuracy: 0.6005859375\n",
      "Batch: 155, Loss: 1.207702398300171, Accuracy: 0.607421875\n",
      "Epoch 404/200\n",
      "Batch: 1, Loss: 1.3043339252471924, Accuracy: 0.6103515625\n",
      "Batch: 2, Loss: 1.1491541862487793, Accuracy: 0.6337890625\n",
      "Batch: 3, Loss: 1.0996826887130737, Accuracy: 0.63671875\n",
      "Batch: 4, Loss: 1.1412007808685303, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 1.055882453918457, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 1.0818736553192139, Accuracy: 0.6494140625\n",
      "Batch: 7, Loss: 1.044204592704773, Accuracy: 0.6689453125\n",
      "Batch: 8, Loss: 1.0330297946929932, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 1.0539301633834839, Accuracy: 0.6728515625\n",
      "Batch: 10, Loss: 1.0216708183288574, Accuracy: 0.658203125\n",
      "Batch: 11, Loss: 1.0378531217575073, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 1.0305895805358887, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0750048160552979, Accuracy: 0.6376953125\n",
      "Batch: 14, Loss: 1.036394476890564, Accuracy: 0.66015625\n",
      "Batch: 15, Loss: 0.9807369112968445, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.033027172088623, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.1125801801681519, Accuracy: 0.626953125\n",
      "Batch: 18, Loss: 1.209006905555725, Accuracy: 0.611328125\n",
      "Batch: 19, Loss: 1.276989221572876, Accuracy: 0.587890625\n",
      "Batch: 20, Loss: 1.1480233669281006, Accuracy: 0.6328125\n",
      "Batch: 21, Loss: 1.1582194566726685, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.3388419151306152, Accuracy: 0.564453125\n",
      "Batch: 23, Loss: 1.2797129154205322, Accuracy: 0.5751953125\n",
      "Batch: 24, Loss: 1.2041271924972534, Accuracy: 0.6064453125\n",
      "Batch: 25, Loss: 1.2774007320404053, Accuracy: 0.5830078125\n",
      "Batch: 26, Loss: 1.2379755973815918, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.194087028503418, Accuracy: 0.6103515625\n",
      "Batch: 28, Loss: 1.210512638092041, Accuracy: 0.59765625\n",
      "Batch: 29, Loss: 1.1272345781326294, Accuracy: 0.6259765625\n",
      "Batch: 30, Loss: 1.2053191661834717, Accuracy: 0.603515625\n",
      "Batch: 31, Loss: 1.2452912330627441, Accuracy: 0.5986328125\n",
      "Batch: 32, Loss: 1.1115293502807617, Accuracy: 0.6318359375\n",
      "Batch: 33, Loss: 1.0685076713562012, Accuracy: 0.6416015625\n",
      "Batch: 34, Loss: 1.1017975807189941, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.192120909690857, Accuracy: 0.60546875\n",
      "Batch: 36, Loss: 1.2211072444915771, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.2775803804397583, Accuracy: 0.5732421875\n",
      "Batch: 38, Loss: 1.18557870388031, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.1424354314804077, Accuracy: 0.6279296875\n",
      "Batch: 40, Loss: 1.175797939300537, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.2171576023101807, Accuracy: 0.595703125\n",
      "Batch: 42, Loss: 1.118523359298706, Accuracy: 0.6201171875\n",
      "Batch: 43, Loss: 1.0635584592819214, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0637000799179077, Accuracy: 0.6259765625\n",
      "Batch: 45, Loss: 1.1570467948913574, Accuracy: 0.6083984375\n",
      "Batch: 46, Loss: 1.21220862865448, Accuracy: 0.615234375\n",
      "Batch: 47, Loss: 1.1657156944274902, Accuracy: 0.619140625\n",
      "Batch: 48, Loss: 1.2148497104644775, Accuracy: 0.5791015625\n",
      "Batch: 49, Loss: 1.2666311264038086, Accuracy: 0.5927734375\n",
      "Batch: 50, Loss: 1.167151689529419, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.202635645866394, Accuracy: 0.58984375\n",
      "Batch: 52, Loss: 1.2483115196228027, Accuracy: 0.6005859375\n",
      "Batch: 53, Loss: 1.2242884635925293, Accuracy: 0.5966796875\n",
      "Batch: 54, Loss: 1.2600057125091553, Accuracy: 0.6015625\n",
      "Batch: 55, Loss: 1.1700921058654785, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.1875426769256592, Accuracy: 0.6328125\n",
      "Batch: 57, Loss: 1.1853479146957397, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.159226655960083, Accuracy: 0.619140625\n",
      "Batch: 59, Loss: 1.2017099857330322, Accuracy: 0.6259765625\n",
      "Batch: 60, Loss: 1.3142250776290894, Accuracy: 0.5810546875\n",
      "Batch: 61, Loss: 1.1853837966918945, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.2121639251708984, Accuracy: 0.6142578125\n",
      "Batch: 63, Loss: 1.2288779020309448, Accuracy: 0.603515625\n",
      "Batch: 64, Loss: 1.25883150100708, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.27423894405365, Accuracy: 0.583984375\n",
      "Batch: 66, Loss: 1.240812063217163, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.2755800485610962, Accuracy: 0.5791015625\n",
      "Batch: 68, Loss: 1.1637755632400513, Accuracy: 0.6376953125\n",
      "Batch: 69, Loss: 1.2410608530044556, Accuracy: 0.6064453125\n",
      "Batch: 70, Loss: 1.2293496131896973, Accuracy: 0.59375\n",
      "Batch: 71, Loss: 1.1847741603851318, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.2442302703857422, Accuracy: 0.6083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73, Loss: 1.2540388107299805, Accuracy: 0.5791015625\n",
      "Batch: 74, Loss: 1.1104613542556763, Accuracy: 0.6494140625\n",
      "Batch: 75, Loss: 1.2325079441070557, Accuracy: 0.61328125\n",
      "Batch: 76, Loss: 1.1186223030090332, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.1123766899108887, Accuracy: 0.6240234375\n",
      "Batch: 78, Loss: 1.1322619915008545, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.2305271625518799, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.2476857900619507, Accuracy: 0.5849609375\n",
      "Batch: 81, Loss: 1.1867715120315552, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.176523208618164, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 1.1957701444625854, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.1824159622192383, Accuracy: 0.615234375\n",
      "Batch: 85, Loss: 1.2543463706970215, Accuracy: 0.6142578125\n",
      "Batch: 86, Loss: 1.2024376392364502, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.2323112487792969, Accuracy: 0.599609375\n",
      "Batch: 88, Loss: 1.2406738996505737, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.2555782794952393, Accuracy: 0.5927734375\n",
      "Batch: 90, Loss: 1.2068846225738525, Accuracy: 0.61328125\n",
      "Batch: 91, Loss: 1.2272095680236816, Accuracy: 0.6083984375\n",
      "Batch: 92, Loss: 1.216093897819519, Accuracy: 0.6201171875\n",
      "Batch: 93, Loss: 1.2318799495697021, Accuracy: 0.599609375\n",
      "Batch: 94, Loss: 1.237545371055603, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.2776501178741455, Accuracy: 0.59375\n",
      "Batch: 96, Loss: 1.2565659284591675, Accuracy: 0.607421875\n",
      "Batch: 97, Loss: 1.2320117950439453, Accuracy: 0.5966796875\n",
      "Batch: 98, Loss: 1.2037677764892578, Accuracy: 0.61328125\n",
      "Batch: 99, Loss: 1.240018606185913, Accuracy: 0.6015625\n",
      "Batch: 100, Loss: 1.190407633781433, Accuracy: 0.603515625\n",
      "Batch: 101, Loss: 1.1491968631744385, Accuracy: 0.6240234375\n",
      "Batch: 102, Loss: 1.2475318908691406, Accuracy: 0.6025390625\n",
      "Batch: 103, Loss: 1.2410409450531006, Accuracy: 0.6162109375\n",
      "Batch: 104, Loss: 1.2271132469177246, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.3397868871688843, Accuracy: 0.5791015625\n",
      "Batch: 106, Loss: 1.2596943378448486, Accuracy: 0.576171875\n",
      "Batch: 107, Loss: 1.347277283668518, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.2400466203689575, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.275640606880188, Accuracy: 0.6005859375\n",
      "Batch: 110, Loss: 1.229102373123169, Accuracy: 0.59765625\n",
      "Batch: 111, Loss: 1.2079522609710693, Accuracy: 0.6181640625\n",
      "Batch: 112, Loss: 1.1501960754394531, Accuracy: 0.6298828125\n",
      "Batch: 113, Loss: 1.2061352729797363, Accuracy: 0.6240234375\n",
      "Batch: 114, Loss: 1.2653459310531616, Accuracy: 0.5751953125\n",
      "Batch: 115, Loss: 1.2356324195861816, Accuracy: 0.5810546875\n",
      "Batch: 116, Loss: 1.2655526399612427, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.2581593990325928, Accuracy: 0.5888671875\n",
      "Batch: 118, Loss: 1.2907440662384033, Accuracy: 0.578125\n",
      "Batch: 119, Loss: 1.279961109161377, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.348728895187378, Accuracy: 0.568359375\n",
      "Batch: 121, Loss: 1.284135341644287, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2936674356460571, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.2307095527648926, Accuracy: 0.607421875\n",
      "Batch: 124, Loss: 1.2216038703918457, Accuracy: 0.62109375\n",
      "Batch: 125, Loss: 1.2838544845581055, Accuracy: 0.595703125\n",
      "Batch: 126, Loss: 1.3050587177276611, Accuracy: 0.5810546875\n",
      "Batch: 127, Loss: 1.2770419120788574, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.265030860900879, Accuracy: 0.591796875\n",
      "Batch: 129, Loss: 1.2399146556854248, Accuracy: 0.611328125\n",
      "Batch: 130, Loss: 1.193402886390686, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.267217755317688, Accuracy: 0.607421875\n",
      "Batch: 132, Loss: 1.126531720161438, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.2348237037658691, Accuracy: 0.6123046875\n",
      "Batch: 134, Loss: 1.1759533882141113, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.111045479774475, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.1809840202331543, Accuracy: 0.623046875\n",
      "Batch: 137, Loss: 1.2222498655319214, Accuracy: 0.59765625\n",
      "Batch: 138, Loss: 1.250636100769043, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.2509829998016357, Accuracy: 0.595703125\n",
      "Batch: 140, Loss: 1.3346431255340576, Accuracy: 0.572265625\n",
      "Batch: 141, Loss: 1.2504085302352905, Accuracy: 0.6142578125\n",
      "Batch: 142, Loss: 1.217273235321045, Accuracy: 0.6025390625\n",
      "Batch: 143, Loss: 1.3005428314208984, Accuracy: 0.56640625\n",
      "Batch: 144, Loss: 1.3732068538665771, Accuracy: 0.56640625\n",
      "Batch: 145, Loss: 1.3168385028839111, Accuracy: 0.5693359375\n",
      "Batch: 146, Loss: 1.2811949253082275, Accuracy: 0.5908203125\n",
      "Batch: 147, Loss: 1.3127403259277344, Accuracy: 0.580078125\n",
      "Batch: 148, Loss: 1.2717472314834595, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.2504184246063232, Accuracy: 0.5927734375\n",
      "Batch: 150, Loss: 1.2034871578216553, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.2345266342163086, Accuracy: 0.60546875\n",
      "Batch: 152, Loss: 1.2301967144012451, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.2219455242156982, Accuracy: 0.6044921875\n",
      "Batch: 154, Loss: 1.1971626281738281, Accuracy: 0.5986328125\n",
      "Batch: 155, Loss: 1.2002800703048706, Accuracy: 0.6025390625\n",
      "Epoch 405/200\n",
      "Batch: 1, Loss: 1.2818397283554077, Accuracy: 0.6240234375\n",
      "Batch: 2, Loss: 1.1264402866363525, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 1.0803184509277344, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.1029090881347656, Accuracy: 0.6123046875\n",
      "Batch: 5, Loss: 1.0489749908447266, Accuracy: 0.64453125\n",
      "Batch: 6, Loss: 1.0876582860946655, Accuracy: 0.6337890625\n",
      "Batch: 7, Loss: 1.0724395513534546, Accuracy: 0.6552734375\n",
      "Batch: 8, Loss: 1.0226223468780518, Accuracy: 0.6728515625\n",
      "Batch: 9, Loss: 1.0445271730422974, Accuracy: 0.662109375\n",
      "Batch: 10, Loss: 1.036247968673706, Accuracy: 0.650390625\n",
      "Batch: 11, Loss: 1.0297009944915771, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.0586652755737305, Accuracy: 0.64453125\n",
      "Batch: 13, Loss: 1.0739020109176636, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 1.0099453926086426, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.9743280410766602, Accuracy: 0.681640625\n",
      "Batch: 16, Loss: 1.1011732816696167, Accuracy: 0.64453125\n",
      "Batch: 17, Loss: 1.1103465557098389, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.2204712629318237, Accuracy: 0.5986328125\n",
      "Batch: 19, Loss: 1.242614507675171, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.187364935874939, Accuracy: 0.6318359375\n",
      "Batch: 21, Loss: 1.1422502994537354, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.2693147659301758, Accuracy: 0.5986328125\n",
      "Batch: 23, Loss: 1.3352909088134766, Accuracy: 0.580078125\n",
      "Batch: 24, Loss: 1.159700870513916, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.2421472072601318, Accuracy: 0.6064453125\n",
      "Batch: 26, Loss: 1.2014195919036865, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.1981176137924194, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.1783857345581055, Accuracy: 0.609375\n",
      "Batch: 29, Loss: 1.1216256618499756, Accuracy: 0.638671875\n",
      "Batch: 30, Loss: 1.240684986114502, Accuracy: 0.5927734375\n",
      "Batch: 31, Loss: 1.2584280967712402, Accuracy: 0.5888671875\n",
      "Batch: 32, Loss: 1.1286075115203857, Accuracy: 0.625\n",
      "Batch: 33, Loss: 1.0722551345825195, Accuracy: 0.6435546875\n",
      "Batch: 34, Loss: 1.1905286312103271, Accuracy: 0.6123046875\n",
      "Batch: 35, Loss: 1.1914806365966797, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2574760913848877, Accuracy: 0.5771484375\n",
      "Batch: 37, Loss: 1.215080976486206, Accuracy: 0.583984375\n",
      "Batch: 38, Loss: 1.212172031402588, Accuracy: 0.5888671875\n",
      "Batch: 39, Loss: 1.1458990573883057, Accuracy: 0.6171875\n",
      "Batch: 40, Loss: 1.170222520828247, Accuracy: 0.6162109375\n",
      "Batch: 41, Loss: 1.2376210689544678, Accuracy: 0.5810546875\n",
      "Batch: 42, Loss: 1.125838279724121, Accuracy: 0.6396484375\n",
      "Batch: 43, Loss: 1.1322526931762695, Accuracy: 0.62109375\n",
      "Batch: 44, Loss: 1.155148983001709, Accuracy: 0.625\n",
      "Batch: 45, Loss: 1.1571096181869507, Accuracy: 0.6162109375\n",
      "Batch: 46, Loss: 1.2094521522521973, Accuracy: 0.6123046875\n",
      "Batch: 47, Loss: 1.204174518585205, Accuracy: 0.634765625\n",
      "Batch: 48, Loss: 1.1803148984909058, Accuracy: 0.6005859375\n",
      "Batch: 49, Loss: 1.2501187324523926, Accuracy: 0.6044921875\n",
      "Batch: 50, Loss: 1.1962647438049316, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.221194863319397, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.2845364809036255, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.2342791557312012, Accuracy: 0.58984375\n",
      "Batch: 54, Loss: 1.2084625959396362, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.1765429973602295, Accuracy: 0.6201171875\n",
      "Batch: 56, Loss: 1.1766619682312012, Accuracy: 0.6337890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 57, Loss: 1.1253845691680908, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.165752649307251, Accuracy: 0.6259765625\n",
      "Batch: 59, Loss: 1.2041114568710327, Accuracy: 0.6103515625\n",
      "Batch: 60, Loss: 1.2797551155090332, Accuracy: 0.59375\n",
      "Batch: 61, Loss: 1.2119359970092773, Accuracy: 0.611328125\n",
      "Batch: 62, Loss: 1.286126732826233, Accuracy: 0.5712890625\n",
      "Batch: 63, Loss: 1.2089712619781494, Accuracy: 0.6015625\n",
      "Batch: 64, Loss: 1.2510879039764404, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.2155404090881348, Accuracy: 0.603515625\n",
      "Batch: 66, Loss: 1.286496877670288, Accuracy: 0.583984375\n",
      "Batch: 67, Loss: 1.258764386177063, Accuracy: 0.6103515625\n",
      "Batch: 68, Loss: 1.17960786819458, Accuracy: 0.6142578125\n",
      "Batch: 69, Loss: 1.2511725425720215, Accuracy: 0.609375\n",
      "Batch: 70, Loss: 1.2761484384536743, Accuracy: 0.599609375\n",
      "Batch: 71, Loss: 1.1547878980636597, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.3385809659957886, Accuracy: 0.5693359375\n",
      "Batch: 73, Loss: 1.2764509916305542, Accuracy: 0.5849609375\n",
      "Batch: 74, Loss: 1.2061840295791626, Accuracy: 0.6005859375\n",
      "Batch: 75, Loss: 1.1579214334487915, Accuracy: 0.6171875\n",
      "Batch: 76, Loss: 1.1350042819976807, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.0603994131088257, Accuracy: 0.6611328125\n",
      "Batch: 78, Loss: 1.1814467906951904, Accuracy: 0.619140625\n",
      "Batch: 79, Loss: 1.16845703125, Accuracy: 0.6455078125\n",
      "Batch: 80, Loss: 1.1931350231170654, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.1461573839187622, Accuracy: 0.6376953125\n",
      "Batch: 82, Loss: 1.2165470123291016, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.2955384254455566, Accuracy: 0.56640625\n",
      "Batch: 84, Loss: 1.257577896118164, Accuracy: 0.5986328125\n",
      "Batch: 85, Loss: 1.2315022945404053, Accuracy: 0.6171875\n",
      "Batch: 86, Loss: 1.2220371961593628, Accuracy: 0.6025390625\n",
      "Batch: 87, Loss: 1.2597966194152832, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.2415411472320557, Accuracy: 0.6025390625\n",
      "Batch: 89, Loss: 1.2712271213531494, Accuracy: 0.5966796875\n",
      "Batch: 90, Loss: 1.2140114307403564, Accuracy: 0.6103515625\n",
      "Batch: 91, Loss: 1.2400829792022705, Accuracy: 0.5908203125\n",
      "Batch: 92, Loss: 1.1818461418151855, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.2254118919372559, Accuracy: 0.5966796875\n",
      "Batch: 94, Loss: 1.294553279876709, Accuracy: 0.572265625\n",
      "Batch: 95, Loss: 1.2701252698898315, Accuracy: 0.62109375\n",
      "Batch: 96, Loss: 1.2804996967315674, Accuracy: 0.603515625\n",
      "Batch: 97, Loss: 1.251920461654663, Accuracy: 0.587890625\n",
      "Batch: 98, Loss: 1.2075179815292358, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.213308334350586, Accuracy: 0.607421875\n",
      "Batch: 100, Loss: 1.1825459003448486, Accuracy: 0.6298828125\n",
      "Batch: 101, Loss: 1.2271077632904053, Accuracy: 0.6015625\n",
      "Batch: 102, Loss: 1.1920239925384521, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.2051085233688354, Accuracy: 0.60546875\n",
      "Batch: 104, Loss: 1.2176569700241089, Accuracy: 0.62109375\n",
      "Batch: 105, Loss: 1.3203701972961426, Accuracy: 0.5703125\n",
      "Batch: 106, Loss: 1.2215006351470947, Accuracy: 0.6162109375\n",
      "Batch: 107, Loss: 1.3396930694580078, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.2521066665649414, Accuracy: 0.5712890625\n",
      "Batch: 109, Loss: 1.2671535015106201, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.2162549495697021, Accuracy: 0.5986328125\n",
      "Batch: 111, Loss: 1.1671199798583984, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.1748549938201904, Accuracy: 0.615234375\n",
      "Batch: 113, Loss: 1.2539758682250977, Accuracy: 0.60546875\n",
      "Batch: 114, Loss: 1.2302954196929932, Accuracy: 0.5888671875\n",
      "Batch: 115, Loss: 1.2343723773956299, Accuracy: 0.607421875\n",
      "Batch: 116, Loss: 1.2562025785446167, Accuracy: 0.599609375\n",
      "Batch: 117, Loss: 1.2067930698394775, Accuracy: 0.595703125\n",
      "Batch: 118, Loss: 1.3024983406066895, Accuracy: 0.580078125\n",
      "Batch: 119, Loss: 1.2912529706954956, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.3342199325561523, Accuracy: 0.5888671875\n",
      "Batch: 121, Loss: 1.2801756858825684, Accuracy: 0.5966796875\n",
      "Batch: 122, Loss: 1.2483628988265991, Accuracy: 0.607421875\n",
      "Batch: 123, Loss: 1.2878894805908203, Accuracy: 0.583984375\n",
      "Batch: 124, Loss: 1.2630198001861572, Accuracy: 0.587890625\n",
      "Batch: 125, Loss: 1.2768487930297852, Accuracy: 0.6015625\n",
      "Batch: 126, Loss: 1.3346741199493408, Accuracy: 0.57421875\n",
      "Batch: 127, Loss: 1.3566241264343262, Accuracy: 0.5576171875\n",
      "Batch: 128, Loss: 1.2675771713256836, Accuracy: 0.59765625\n",
      "Batch: 129, Loss: 1.2509973049163818, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.1877647638320923, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.2940330505371094, Accuracy: 0.5810546875\n",
      "Batch: 132, Loss: 1.1515759229660034, Accuracy: 0.630859375\n",
      "Batch: 133, Loss: 1.320004940032959, Accuracy: 0.5859375\n",
      "Batch: 134, Loss: 1.246847152709961, Accuracy: 0.6142578125\n",
      "Batch: 135, Loss: 1.1460964679718018, Accuracy: 0.6328125\n",
      "Batch: 136, Loss: 1.1431891918182373, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.2182197570800781, Accuracy: 0.611328125\n",
      "Batch: 138, Loss: 1.3066538572311401, Accuracy: 0.591796875\n",
      "Batch: 139, Loss: 1.2742353677749634, Accuracy: 0.5927734375\n",
      "Batch: 140, Loss: 1.326339602470398, Accuracy: 0.583984375\n",
      "Batch: 141, Loss: 1.2490241527557373, Accuracy: 0.5908203125\n",
      "Batch: 142, Loss: 1.2216861248016357, Accuracy: 0.61328125\n",
      "Batch: 143, Loss: 1.3199257850646973, Accuracy: 0.572265625\n",
      "Batch: 144, Loss: 1.3244550228118896, Accuracy: 0.591796875\n",
      "Batch: 145, Loss: 1.3724637031555176, Accuracy: 0.5625\n",
      "Batch: 146, Loss: 1.2734661102294922, Accuracy: 0.58984375\n",
      "Batch: 147, Loss: 1.2665684223175049, Accuracy: 0.595703125\n",
      "Batch: 148, Loss: 1.35941743850708, Accuracy: 0.5556640625\n",
      "Batch: 149, Loss: 1.295387625694275, Accuracy: 0.5732421875\n",
      "Batch: 150, Loss: 1.214299201965332, Accuracy: 0.61328125\n",
      "Batch: 151, Loss: 1.1586804389953613, Accuracy: 0.62109375\n",
      "Batch: 152, Loss: 1.207944631576538, Accuracy: 0.59375\n",
      "Batch: 153, Loss: 1.1825730800628662, Accuracy: 0.6376953125\n",
      "Batch: 154, Loss: 1.1914366483688354, Accuracy: 0.6181640625\n",
      "Batch: 155, Loss: 1.1992357969284058, Accuracy: 0.6337890625\n",
      "Epoch 406/200\n",
      "Batch: 1, Loss: 1.2791717052459717, Accuracy: 0.62109375\n",
      "Batch: 2, Loss: 1.1843987703323364, Accuracy: 0.6162109375\n",
      "Batch: 3, Loss: 1.0381925106048584, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.1132752895355225, Accuracy: 0.677734375\n",
      "Batch: 5, Loss: 1.0658740997314453, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.1151543855667114, Accuracy: 0.6376953125\n",
      "Batch: 7, Loss: 1.1076091527938843, Accuracy: 0.623046875\n",
      "Batch: 8, Loss: 1.0593668222427368, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.102823257446289, Accuracy: 0.6591796875\n",
      "Batch: 10, Loss: 1.032448172569275, Accuracy: 0.6552734375\n",
      "Batch: 11, Loss: 1.1009507179260254, Accuracy: 0.6376953125\n",
      "Batch: 12, Loss: 1.0781559944152832, Accuracy: 0.650390625\n",
      "Batch: 13, Loss: 1.0480899810791016, Accuracy: 0.6689453125\n",
      "Batch: 14, Loss: 1.041535496711731, Accuracy: 0.6484375\n",
      "Batch: 15, Loss: 1.0336687564849854, Accuracy: 0.654296875\n",
      "Batch: 16, Loss: 1.0930900573730469, Accuracy: 0.6484375\n",
      "Batch: 17, Loss: 1.1185836791992188, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1666263341903687, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2167538404464722, Accuracy: 0.6181640625\n",
      "Batch: 20, Loss: 1.1614540815353394, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1943507194519043, Accuracy: 0.6044921875\n",
      "Batch: 22, Loss: 1.3023886680603027, Accuracy: 0.578125\n",
      "Batch: 23, Loss: 1.328911542892456, Accuracy: 0.57421875\n",
      "Batch: 24, Loss: 1.1989035606384277, Accuracy: 0.619140625\n",
      "Batch: 25, Loss: 1.223990559577942, Accuracy: 0.5947265625\n",
      "Batch: 26, Loss: 1.2206335067749023, Accuracy: 0.5947265625\n",
      "Batch: 27, Loss: 1.2101261615753174, Accuracy: 0.607421875\n",
      "Batch: 28, Loss: 1.1104438304901123, Accuracy: 0.6376953125\n",
      "Batch: 29, Loss: 1.113672137260437, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.1913995742797852, Accuracy: 0.6064453125\n",
      "Batch: 31, Loss: 1.252091646194458, Accuracy: 0.599609375\n",
      "Batch: 32, Loss: 1.1803171634674072, Accuracy: 0.615234375\n",
      "Batch: 33, Loss: 1.0949816703796387, Accuracy: 0.634765625\n",
      "Batch: 34, Loss: 1.156740665435791, Accuracy: 0.6279296875\n",
      "Batch: 35, Loss: 1.2089123725891113, Accuracy: 0.6015625\n",
      "Batch: 36, Loss: 1.272674560546875, Accuracy: 0.580078125\n",
      "Batch: 37, Loss: 1.2822476625442505, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.2310543060302734, Accuracy: 0.58984375\n",
      "Batch: 39, Loss: 1.1111412048339844, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.1814544200897217, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.237260341644287, Accuracy: 0.6015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 42, Loss: 1.1925530433654785, Accuracy: 0.6181640625\n",
      "Batch: 43, Loss: 1.1096596717834473, Accuracy: 0.619140625\n",
      "Batch: 44, Loss: 1.102919101715088, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 1.128065824508667, Accuracy: 0.6201171875\n",
      "Batch: 46, Loss: 1.2328529357910156, Accuracy: 0.58984375\n",
      "Batch: 47, Loss: 1.1875805854797363, Accuracy: 0.6123046875\n",
      "Batch: 48, Loss: 1.1761970520019531, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.2544691562652588, Accuracy: 0.6025390625\n",
      "Batch: 50, Loss: 1.2107068300247192, Accuracy: 0.615234375\n",
      "Batch: 51, Loss: 1.1970314979553223, Accuracy: 0.5947265625\n",
      "Batch: 52, Loss: 1.2940089702606201, Accuracy: 0.572265625\n",
      "Batch: 53, Loss: 1.2111095190048218, Accuracy: 0.6044921875\n",
      "Batch: 54, Loss: 1.2516849040985107, Accuracy: 0.568359375\n",
      "Batch: 55, Loss: 1.210566520690918, Accuracy: 0.60546875\n",
      "Batch: 56, Loss: 1.1676864624023438, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.2033190727233887, Accuracy: 0.623046875\n",
      "Batch: 58, Loss: 1.1356451511383057, Accuracy: 0.630859375\n",
      "Batch: 59, Loss: 1.2494401931762695, Accuracy: 0.591796875\n",
      "Batch: 60, Loss: 1.291832685470581, Accuracy: 0.5703125\n",
      "Batch: 61, Loss: 1.2665095329284668, Accuracy: 0.576171875\n",
      "Batch: 62, Loss: 1.2186601161956787, Accuracy: 0.6123046875\n",
      "Batch: 63, Loss: 1.2507014274597168, Accuracy: 0.5927734375\n",
      "Batch: 64, Loss: 1.2699685096740723, Accuracy: 0.5732421875\n",
      "Batch: 65, Loss: 1.279043436050415, Accuracy: 0.5859375\n",
      "Batch: 66, Loss: 1.2214982509613037, Accuracy: 0.603515625\n",
      "Batch: 67, Loss: 1.1839349269866943, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.1733014583587646, Accuracy: 0.625\n",
      "Batch: 69, Loss: 1.287338376045227, Accuracy: 0.5810546875\n",
      "Batch: 70, Loss: 1.2076557874679565, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1717736721038818, Accuracy: 0.60546875\n",
      "Batch: 72, Loss: 1.2787091732025146, Accuracy: 0.5810546875\n",
      "Batch: 73, Loss: 1.2516818046569824, Accuracy: 0.58984375\n",
      "Batch: 74, Loss: 1.1917109489440918, Accuracy: 0.611328125\n",
      "Batch: 75, Loss: 1.2032917737960815, Accuracy: 0.60546875\n",
      "Batch: 76, Loss: 1.1638338565826416, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.1262938976287842, Accuracy: 0.625\n",
      "Batch: 78, Loss: 1.1714093685150146, Accuracy: 0.62890625\n",
      "Batch: 79, Loss: 1.1948739290237427, Accuracy: 0.611328125\n",
      "Batch: 80, Loss: 1.231107473373413, Accuracy: 0.59765625\n",
      "Batch: 81, Loss: 1.2042086124420166, Accuracy: 0.6005859375\n",
      "Batch: 82, Loss: 1.174270510673523, Accuracy: 0.619140625\n",
      "Batch: 83, Loss: 1.2764424085617065, Accuracy: 0.60546875\n",
      "Batch: 84, Loss: 1.2217299938201904, Accuracy: 0.6162109375\n",
      "Batch: 85, Loss: 1.264286994934082, Accuracy: 0.6025390625\n",
      "Batch: 86, Loss: 1.3025041818618774, Accuracy: 0.5771484375\n",
      "Batch: 87, Loss: 1.2662162780761719, Accuracy: 0.58203125\n",
      "Batch: 88, Loss: 1.2438700199127197, Accuracy: 0.59765625\n",
      "Batch: 89, Loss: 1.2344403266906738, Accuracy: 0.619140625\n",
      "Batch: 90, Loss: 1.21453857421875, Accuracy: 0.5986328125\n",
      "Batch: 91, Loss: 1.2301284074783325, Accuracy: 0.6083984375\n",
      "Batch: 92, Loss: 1.217555284500122, Accuracy: 0.619140625\n",
      "Batch: 93, Loss: 1.2574951648712158, Accuracy: 0.5849609375\n",
      "Batch: 94, Loss: 1.2968409061431885, Accuracy: 0.5947265625\n",
      "Batch: 95, Loss: 1.2321410179138184, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.248244047164917, Accuracy: 0.5888671875\n",
      "Batch: 97, Loss: 1.236250877380371, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1974339485168457, Accuracy: 0.6123046875\n",
      "Batch: 99, Loss: 1.2580690383911133, Accuracy: 0.5908203125\n",
      "Batch: 100, Loss: 1.1565604209899902, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.1884756088256836, Accuracy: 0.603515625\n",
      "Batch: 102, Loss: 1.252769112586975, Accuracy: 0.5888671875\n",
      "Batch: 103, Loss: 1.2649588584899902, Accuracy: 0.60546875\n",
      "Batch: 104, Loss: 1.2342615127563477, Accuracy: 0.607421875\n",
      "Batch: 105, Loss: 1.2701754570007324, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.1655817031860352, Accuracy: 0.6298828125\n",
      "Batch: 107, Loss: 1.278870701789856, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.2393889427185059, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.307262897491455, Accuracy: 0.580078125\n",
      "Batch: 110, Loss: 1.1734179258346558, Accuracy: 0.630859375\n",
      "Batch: 111, Loss: 1.181440830230713, Accuracy: 0.611328125\n",
      "Batch: 112, Loss: 1.1589330434799194, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.255074143409729, Accuracy: 0.5859375\n",
      "Batch: 114, Loss: 1.2241520881652832, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.3035380840301514, Accuracy: 0.5771484375\n",
      "Batch: 116, Loss: 1.2469804286956787, Accuracy: 0.580078125\n",
      "Batch: 117, Loss: 1.2354482412338257, Accuracy: 0.5986328125\n",
      "Batch: 118, Loss: 1.2775501012802124, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.3159704208374023, Accuracy: 0.595703125\n",
      "Batch: 120, Loss: 1.383960247039795, Accuracy: 0.578125\n",
      "Batch: 121, Loss: 1.2009544372558594, Accuracy: 0.6337890625\n",
      "Batch: 122, Loss: 1.2933523654937744, Accuracy: 0.58984375\n",
      "Batch: 123, Loss: 1.2237616777420044, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.2861828804016113, Accuracy: 0.595703125\n",
      "Batch: 125, Loss: 1.257469654083252, Accuracy: 0.5927734375\n",
      "Batch: 126, Loss: 1.3333137035369873, Accuracy: 0.5771484375\n",
      "Batch: 127, Loss: 1.3180142641067505, Accuracy: 0.5830078125\n",
      "Batch: 128, Loss: 1.343379259109497, Accuracy: 0.5810546875\n",
      "Batch: 129, Loss: 1.252774953842163, Accuracy: 0.60546875\n",
      "Batch: 130, Loss: 1.1854565143585205, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.344912052154541, Accuracy: 0.5712890625\n",
      "Batch: 132, Loss: 1.1909072399139404, Accuracy: 0.62890625\n",
      "Batch: 133, Loss: 1.177620768547058, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1626620292663574, Accuracy: 0.630859375\n",
      "Batch: 135, Loss: 1.1174787282943726, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.1273796558380127, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.2529377937316895, Accuracy: 0.60546875\n",
      "Batch: 138, Loss: 1.3460816144943237, Accuracy: 0.5615234375\n",
      "Batch: 139, Loss: 1.2874178886413574, Accuracy: 0.5810546875\n",
      "Batch: 140, Loss: 1.3014029264450073, Accuracy: 0.5888671875\n",
      "Batch: 141, Loss: 1.2806143760681152, Accuracy: 0.59375\n",
      "Batch: 142, Loss: 1.27215576171875, Accuracy: 0.599609375\n",
      "Batch: 143, Loss: 1.377987265586853, Accuracy: 0.5546875\n",
      "Batch: 144, Loss: 1.3525612354278564, Accuracy: 0.5693359375\n",
      "Batch: 145, Loss: 1.3151040077209473, Accuracy: 0.5712890625\n",
      "Batch: 146, Loss: 1.274474859237671, Accuracy: 0.5791015625\n",
      "Batch: 147, Loss: 1.2908246517181396, Accuracy: 0.5869140625\n",
      "Batch: 148, Loss: 1.297383427619934, Accuracy: 0.5830078125\n",
      "Batch: 149, Loss: 1.2698974609375, Accuracy: 0.5791015625\n",
      "Batch: 150, Loss: 1.1749356985092163, Accuracy: 0.6162109375\n",
      "Batch: 151, Loss: 1.3096942901611328, Accuracy: 0.5869140625\n",
      "Batch: 152, Loss: 1.2123088836669922, Accuracy: 0.6103515625\n",
      "Batch: 153, Loss: 1.174118995666504, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.2187268733978271, Accuracy: 0.6083984375\n",
      "Batch: 155, Loss: 1.2054362297058105, Accuracy: 0.615234375\n",
      "Epoch 407/200\n",
      "Batch: 1, Loss: 1.2776081562042236, Accuracy: 0.61328125\n",
      "Batch: 2, Loss: 1.1258512735366821, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0664135217666626, Accuracy: 0.6640625\n",
      "Batch: 4, Loss: 1.080364465713501, Accuracy: 0.6552734375\n",
      "Batch: 5, Loss: 1.0831825733184814, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.1164591312408447, Accuracy: 0.630859375\n",
      "Batch: 7, Loss: 1.1120941638946533, Accuracy: 0.6484375\n",
      "Batch: 8, Loss: 1.0616660118103027, Accuracy: 0.6611328125\n",
      "Batch: 9, Loss: 1.0268611907958984, Accuracy: 0.6767578125\n",
      "Batch: 10, Loss: 1.0411688089370728, Accuracy: 0.6474609375\n",
      "Batch: 11, Loss: 1.0486376285552979, Accuracy: 0.658203125\n",
      "Batch: 12, Loss: 1.0935702323913574, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.075008749961853, Accuracy: 0.6416015625\n",
      "Batch: 14, Loss: 1.0185538530349731, Accuracy: 0.65625\n",
      "Batch: 15, Loss: 0.9935929775238037, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0621298551559448, Accuracy: 0.662109375\n",
      "Batch: 17, Loss: 1.124831199645996, Accuracy: 0.619140625\n",
      "Batch: 18, Loss: 1.1637250185012817, Accuracy: 0.6396484375\n",
      "Batch: 19, Loss: 1.2861672639846802, Accuracy: 0.5849609375\n",
      "Batch: 20, Loss: 1.149693489074707, Accuracy: 0.6416015625\n",
      "Batch: 21, Loss: 1.1499969959259033, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.3179960250854492, Accuracy: 0.5859375\n",
      "Batch: 23, Loss: 1.339880347251892, Accuracy: 0.5771484375\n",
      "Batch: 24, Loss: 1.208164930343628, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.2028474807739258, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.280407428741455, Accuracy: 0.576171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 1.1964013576507568, Accuracy: 0.6025390625\n",
      "Batch: 28, Loss: 1.1416540145874023, Accuracy: 0.6220703125\n",
      "Batch: 29, Loss: 1.0868710279464722, Accuracy: 0.63671875\n",
      "Batch: 30, Loss: 1.26728355884552, Accuracy: 0.599609375\n",
      "Batch: 31, Loss: 1.2811264991760254, Accuracy: 0.5908203125\n",
      "Batch: 32, Loss: 1.120474100112915, Accuracy: 0.6337890625\n",
      "Batch: 33, Loss: 1.0551748275756836, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.1602365970611572, Accuracy: 0.6162109375\n",
      "Batch: 35, Loss: 1.2398724555969238, Accuracy: 0.6025390625\n",
      "Batch: 36, Loss: 1.2399553060531616, Accuracy: 0.595703125\n",
      "Batch: 37, Loss: 1.2543622255325317, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.1767613887786865, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.128609538078308, Accuracy: 0.6318359375\n",
      "Batch: 40, Loss: 1.1620666980743408, Accuracy: 0.6201171875\n",
      "Batch: 41, Loss: 1.2039799690246582, Accuracy: 0.599609375\n",
      "Batch: 42, Loss: 1.165053129196167, Accuracy: 0.6201171875\n",
      "Batch: 43, Loss: 1.124746322631836, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.1431430578231812, Accuracy: 0.62890625\n",
      "Batch: 45, Loss: 1.1438933610916138, Accuracy: 0.6416015625\n",
      "Batch: 46, Loss: 1.2766039371490479, Accuracy: 0.591796875\n",
      "Batch: 47, Loss: 1.1848591566085815, Accuracy: 0.6396484375\n",
      "Batch: 48, Loss: 1.1432353258132935, Accuracy: 0.6259765625\n",
      "Batch: 49, Loss: 1.2664027214050293, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.1946208477020264, Accuracy: 0.607421875\n",
      "Batch: 51, Loss: 1.1852654218673706, Accuracy: 0.5830078125\n",
      "Batch: 52, Loss: 1.2863686084747314, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.1790752410888672, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.2435920238494873, Accuracy: 0.6015625\n",
      "Batch: 55, Loss: 1.1763994693756104, Accuracy: 0.6064453125\n",
      "Batch: 56, Loss: 1.2120765447616577, Accuracy: 0.619140625\n",
      "Batch: 57, Loss: 1.1853971481323242, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.2138440608978271, Accuracy: 0.61328125\n",
      "Batch: 59, Loss: 1.1113371849060059, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2392287254333496, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.2343717813491821, Accuracy: 0.58203125\n",
      "Batch: 62, Loss: 1.2340190410614014, Accuracy: 0.6015625\n",
      "Batch: 63, Loss: 1.212216854095459, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.281132459640503, Accuracy: 0.583984375\n",
      "Batch: 65, Loss: 1.2452278137207031, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.2177672386169434, Accuracy: 0.6005859375\n",
      "Batch: 67, Loss: 1.2469710111618042, Accuracy: 0.6005859375\n",
      "Batch: 68, Loss: 1.200120210647583, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.2410441637039185, Accuracy: 0.5947265625\n",
      "Batch: 70, Loss: 1.2705497741699219, Accuracy: 0.6044921875\n",
      "Batch: 71, Loss: 1.1891028881072998, Accuracy: 0.626953125\n",
      "Batch: 72, Loss: 1.2304245233535767, Accuracy: 0.6025390625\n",
      "Batch: 73, Loss: 1.237808346748352, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.1401114463806152, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.0967516899108887, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.2145240306854248, Accuracy: 0.6015625\n",
      "Batch: 77, Loss: 1.103132724761963, Accuracy: 0.64453125\n",
      "Batch: 78, Loss: 1.156216025352478, Accuracy: 0.6240234375\n",
      "Batch: 79, Loss: 1.186915636062622, Accuracy: 0.6259765625\n",
      "Batch: 80, Loss: 1.2339202165603638, Accuracy: 0.58984375\n",
      "Batch: 81, Loss: 1.167344331741333, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.22551429271698, Accuracy: 0.6064453125\n",
      "Batch: 83, Loss: 1.2801018953323364, Accuracy: 0.5859375\n",
      "Batch: 84, Loss: 1.2602115869522095, Accuracy: 0.58984375\n",
      "Batch: 85, Loss: 1.2273023128509521, Accuracy: 0.5986328125\n",
      "Batch: 86, Loss: 1.266446590423584, Accuracy: 0.57421875\n",
      "Batch: 87, Loss: 1.2655954360961914, Accuracy: 0.5927734375\n",
      "Batch: 88, Loss: 1.2729136943817139, Accuracy: 0.5869140625\n",
      "Batch: 89, Loss: 1.2129201889038086, Accuracy: 0.6015625\n",
      "Batch: 90, Loss: 1.1993558406829834, Accuracy: 0.611328125\n",
      "Batch: 91, Loss: 1.1888551712036133, Accuracy: 0.607421875\n",
      "Batch: 92, Loss: 1.2779624462127686, Accuracy: 0.5869140625\n",
      "Batch: 93, Loss: 1.1904518604278564, Accuracy: 0.615234375\n",
      "Batch: 94, Loss: 1.2842552661895752, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.2585800886154175, Accuracy: 0.599609375\n",
      "Batch: 96, Loss: 1.2637072801589966, Accuracy: 0.6162109375\n",
      "Batch: 97, Loss: 1.2478079795837402, Accuracy: 0.5869140625\n",
      "Batch: 98, Loss: 1.193381428718567, Accuracy: 0.6328125\n",
      "Batch: 99, Loss: 1.2486186027526855, Accuracy: 0.6044921875\n",
      "Batch: 100, Loss: 1.1480640172958374, Accuracy: 0.638671875\n",
      "Batch: 101, Loss: 1.1550716161727905, Accuracy: 0.6220703125\n",
      "Batch: 102, Loss: 1.2257866859436035, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.2467235326766968, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.2754740715026855, Accuracy: 0.595703125\n",
      "Batch: 105, Loss: 1.342477798461914, Accuracy: 0.568359375\n",
      "Batch: 106, Loss: 1.2192258834838867, Accuracy: 0.6123046875\n",
      "Batch: 107, Loss: 1.298159122467041, Accuracy: 0.5673828125\n",
      "Batch: 108, Loss: 1.2390515804290771, Accuracy: 0.5869140625\n",
      "Batch: 109, Loss: 1.283299207687378, Accuracy: 0.578125\n",
      "Batch: 110, Loss: 1.1975253820419312, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.2211015224456787, Accuracy: 0.6103515625\n",
      "Batch: 112, Loss: 1.1199164390563965, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.229824423789978, Accuracy: 0.60546875\n",
      "Batch: 114, Loss: 1.2671427726745605, Accuracy: 0.5859375\n",
      "Batch: 115, Loss: 1.247338891029358, Accuracy: 0.595703125\n",
      "Batch: 116, Loss: 1.2477102279663086, Accuracy: 0.58203125\n",
      "Batch: 117, Loss: 1.2609822750091553, Accuracy: 0.5927734375\n",
      "Batch: 118, Loss: 1.2554023265838623, Accuracy: 0.6005859375\n",
      "Batch: 119, Loss: 1.293371319770813, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.385224461555481, Accuracy: 0.5693359375\n",
      "Batch: 121, Loss: 1.266792893409729, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.277553915977478, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.253336787223816, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2812368869781494, Accuracy: 0.5888671875\n",
      "Batch: 125, Loss: 1.2242870330810547, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.335783839225769, Accuracy: 0.5810546875\n",
      "Batch: 127, Loss: 1.2927368879318237, Accuracy: 0.58203125\n",
      "Batch: 128, Loss: 1.30596923828125, Accuracy: 0.5673828125\n",
      "Batch: 129, Loss: 1.238548755645752, Accuracy: 0.5849609375\n",
      "Batch: 130, Loss: 1.215047836303711, Accuracy: 0.599609375\n",
      "Batch: 131, Loss: 1.2647583484649658, Accuracy: 0.58984375\n",
      "Batch: 132, Loss: 1.111983060836792, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.2095870971679688, Accuracy: 0.599609375\n",
      "Batch: 134, Loss: 1.1923658847808838, Accuracy: 0.6337890625\n",
      "Batch: 135, Loss: 1.1670384407043457, Accuracy: 0.6298828125\n",
      "Batch: 136, Loss: 1.1771711111068726, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.2582553625106812, Accuracy: 0.6015625\n",
      "Batch: 138, Loss: 1.3391218185424805, Accuracy: 0.5625\n",
      "Batch: 139, Loss: 1.2793772220611572, Accuracy: 0.5869140625\n",
      "Batch: 140, Loss: 1.3326287269592285, Accuracy: 0.5693359375\n",
      "Batch: 141, Loss: 1.2695218324661255, Accuracy: 0.5791015625\n",
      "Batch: 142, Loss: 1.2885406017303467, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.2576614618301392, Accuracy: 0.5810546875\n",
      "Batch: 144, Loss: 1.340466022491455, Accuracy: 0.5712890625\n",
      "Batch: 145, Loss: 1.2896275520324707, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.3022301197052002, Accuracy: 0.5791015625\n",
      "Batch: 147, Loss: 1.2569807767868042, Accuracy: 0.5927734375\n",
      "Batch: 148, Loss: 1.3363453149795532, Accuracy: 0.58203125\n",
      "Batch: 149, Loss: 1.2788808345794678, Accuracy: 0.56640625\n",
      "Batch: 150, Loss: 1.196495532989502, Accuracy: 0.6015625\n",
      "Batch: 151, Loss: 1.2711671590805054, Accuracy: 0.5986328125\n",
      "Batch: 152, Loss: 1.2105833292007446, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.2000765800476074, Accuracy: 0.609375\n",
      "Batch: 154, Loss: 1.173595905303955, Accuracy: 0.6123046875\n",
      "Batch: 155, Loss: 1.1507041454315186, Accuracy: 0.625\n",
      "Epoch 408/200\n",
      "Batch: 1, Loss: 1.2877360582351685, Accuracy: 0.6220703125\n",
      "Batch: 2, Loss: 1.1359484195709229, Accuracy: 0.619140625\n",
      "Batch: 3, Loss: 1.0625230073928833, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.1596777439117432, Accuracy: 0.6201171875\n",
      "Batch: 5, Loss: 1.0680104494094849, Accuracy: 0.6376953125\n",
      "Batch: 6, Loss: 1.0799444913864136, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.1078729629516602, Accuracy: 0.640625\n",
      "Batch: 8, Loss: 1.0137693881988525, Accuracy: 0.6806640625\n",
      "Batch: 9, Loss: 1.0418639183044434, Accuracy: 0.6357421875\n",
      "Batch: 10, Loss: 1.0459871292114258, Accuracy: 0.6494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 0.9964225888252258, Accuracy: 0.66796875\n",
      "Batch: 12, Loss: 1.0552124977111816, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 1.0490647554397583, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 1.0441436767578125, Accuracy: 0.638671875\n",
      "Batch: 15, Loss: 1.0011953115463257, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0898714065551758, Accuracy: 0.642578125\n",
      "Batch: 17, Loss: 1.0975873470306396, Accuracy: 0.634765625\n",
      "Batch: 18, Loss: 1.1821174621582031, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.24745512008667, Accuracy: 0.611328125\n",
      "Batch: 20, Loss: 1.135957956314087, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.1150550842285156, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.315659999847412, Accuracy: 0.58203125\n",
      "Batch: 23, Loss: 1.3095892667770386, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.190898060798645, Accuracy: 0.607421875\n",
      "Batch: 25, Loss: 1.2225862741470337, Accuracy: 0.6064453125\n",
      "Batch: 26, Loss: 1.262387752532959, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.232213020324707, Accuracy: 0.5888671875\n",
      "Batch: 28, Loss: 1.1207267045974731, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.1457476615905762, Accuracy: 0.6181640625\n",
      "Batch: 30, Loss: 1.2534904479980469, Accuracy: 0.6064453125\n",
      "Batch: 31, Loss: 1.2500965595245361, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.107006549835205, Accuracy: 0.6240234375\n",
      "Batch: 33, Loss: 1.0592845678329468, Accuracy: 0.6396484375\n",
      "Batch: 34, Loss: 1.1368533372879028, Accuracy: 0.6171875\n",
      "Batch: 35, Loss: 1.180156946182251, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2577710151672363, Accuracy: 0.5830078125\n",
      "Batch: 37, Loss: 1.2469532489776611, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.2020500898361206, Accuracy: 0.5966796875\n",
      "Batch: 39, Loss: 1.162289023399353, Accuracy: 0.611328125\n",
      "Batch: 40, Loss: 1.1770532131195068, Accuracy: 0.609375\n",
      "Batch: 41, Loss: 1.2069841623306274, Accuracy: 0.607421875\n",
      "Batch: 42, Loss: 1.1414611339569092, Accuracy: 0.615234375\n",
      "Batch: 43, Loss: 1.1343392133712769, Accuracy: 0.625\n",
      "Batch: 44, Loss: 1.1103038787841797, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.0968351364135742, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.2366949319839478, Accuracy: 0.5966796875\n",
      "Batch: 47, Loss: 1.1727323532104492, Accuracy: 0.63671875\n",
      "Batch: 48, Loss: 1.1303287744522095, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.2588372230529785, Accuracy: 0.5908203125\n",
      "Batch: 50, Loss: 1.163386583328247, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.2109670639038086, Accuracy: 0.59765625\n",
      "Batch: 52, Loss: 1.3435189723968506, Accuracy: 0.5615234375\n",
      "Batch: 53, Loss: 1.2394130229949951, Accuracy: 0.5947265625\n",
      "Batch: 54, Loss: 1.2593498229980469, Accuracy: 0.57421875\n",
      "Batch: 55, Loss: 1.2000263929367065, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.191180944442749, Accuracy: 0.6220703125\n",
      "Batch: 57, Loss: 1.2418876886367798, Accuracy: 0.6005859375\n",
      "Batch: 58, Loss: 1.206394910812378, Accuracy: 0.6083984375\n",
      "Batch: 59, Loss: 1.2314889430999756, Accuracy: 0.603515625\n",
      "Batch: 60, Loss: 1.279314398765564, Accuracy: 0.5732421875\n",
      "Batch: 61, Loss: 1.1889926195144653, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.2668393850326538, Accuracy: 0.6025390625\n",
      "Batch: 63, Loss: 1.2484334707260132, Accuracy: 0.6005859375\n",
      "Batch: 64, Loss: 1.2922991514205933, Accuracy: 0.5869140625\n",
      "Batch: 65, Loss: 1.2921605110168457, Accuracy: 0.5712890625\n",
      "Batch: 66, Loss: 1.2275383472442627, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.2040808200836182, Accuracy: 0.5986328125\n",
      "Batch: 68, Loss: 1.1791284084320068, Accuracy: 0.6171875\n",
      "Batch: 69, Loss: 1.2014744281768799, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.2536952495574951, Accuracy: 0.595703125\n",
      "Batch: 71, Loss: 1.1976771354675293, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.294959306716919, Accuracy: 0.591796875\n",
      "Batch: 73, Loss: 1.2763419151306152, Accuracy: 0.6064453125\n",
      "Batch: 74, Loss: 1.1992340087890625, Accuracy: 0.623046875\n",
      "Batch: 75, Loss: 1.1716722249984741, Accuracy: 0.6171875\n",
      "Batch: 76, Loss: 1.1049987077713013, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.1619622707366943, Accuracy: 0.634765625\n",
      "Batch: 78, Loss: 1.1739829778671265, Accuracy: 0.6044921875\n",
      "Batch: 79, Loss: 1.2042419910430908, Accuracy: 0.607421875\n",
      "Batch: 80, Loss: 1.2490341663360596, Accuracy: 0.5849609375\n",
      "Batch: 81, Loss: 1.2507925033569336, Accuracy: 0.59765625\n",
      "Batch: 82, Loss: 1.2167339324951172, Accuracy: 0.609375\n",
      "Batch: 83, Loss: 1.3329201936721802, Accuracy: 0.5673828125\n",
      "Batch: 84, Loss: 1.1963366270065308, Accuracy: 0.6240234375\n",
      "Batch: 85, Loss: 1.2505264282226562, Accuracy: 0.59375\n",
      "Batch: 86, Loss: 1.2192912101745605, Accuracy: 0.60546875\n",
      "Batch: 87, Loss: 1.258333683013916, Accuracy: 0.5927734375\n",
      "Batch: 88, Loss: 1.2525033950805664, Accuracy: 0.5869140625\n",
      "Batch: 89, Loss: 1.2216798067092896, Accuracy: 0.595703125\n",
      "Batch: 90, Loss: 1.212059736251831, Accuracy: 0.6171875\n",
      "Batch: 91, Loss: 1.195292353630066, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.2710167169570923, Accuracy: 0.591796875\n",
      "Batch: 93, Loss: 1.1442151069641113, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.237921953201294, Accuracy: 0.5966796875\n",
      "Batch: 95, Loss: 1.2852976322174072, Accuracy: 0.591796875\n",
      "Batch: 96, Loss: 1.2813301086425781, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.2013201713562012, Accuracy: 0.611328125\n",
      "Batch: 98, Loss: 1.1894659996032715, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.2103307247161865, Accuracy: 0.611328125\n",
      "Batch: 100, Loss: 1.1193393468856812, Accuracy: 0.6279296875\n",
      "Batch: 101, Loss: 1.2133305072784424, Accuracy: 0.609375\n",
      "Batch: 102, Loss: 1.2739062309265137, Accuracy: 0.587890625\n",
      "Batch: 103, Loss: 1.2513234615325928, Accuracy: 0.61328125\n",
      "Batch: 104, Loss: 1.2138569355010986, Accuracy: 0.6201171875\n",
      "Batch: 105, Loss: 1.3085566759109497, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.259119987487793, Accuracy: 0.5986328125\n",
      "Batch: 107, Loss: 1.3211650848388672, Accuracy: 0.5791015625\n",
      "Batch: 108, Loss: 1.262630581855774, Accuracy: 0.5849609375\n",
      "Batch: 109, Loss: 1.3101478815078735, Accuracy: 0.580078125\n",
      "Batch: 110, Loss: 1.2382501363754272, Accuracy: 0.5830078125\n",
      "Batch: 111, Loss: 1.1771550178527832, Accuracy: 0.60546875\n",
      "Batch: 112, Loss: 1.1695550680160522, Accuracy: 0.6201171875\n",
      "Batch: 113, Loss: 1.2070786952972412, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.2252352237701416, Accuracy: 0.5810546875\n",
      "Batch: 115, Loss: 1.287746787071228, Accuracy: 0.6005859375\n",
      "Batch: 116, Loss: 1.1982927322387695, Accuracy: 0.6162109375\n",
      "Batch: 117, Loss: 1.2195976972579956, Accuracy: 0.5859375\n",
      "Batch: 118, Loss: 1.306129813194275, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.290984034538269, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.3270827531814575, Accuracy: 0.5771484375\n",
      "Batch: 121, Loss: 1.2739992141723633, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2485839128494263, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.2559876441955566, Accuracy: 0.6005859375\n",
      "Batch: 124, Loss: 1.290916919708252, Accuracy: 0.609375\n",
      "Batch: 125, Loss: 1.2453875541687012, Accuracy: 0.6044921875\n",
      "Batch: 126, Loss: 1.29488205909729, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.2528005838394165, Accuracy: 0.59765625\n",
      "Batch: 128, Loss: 1.2531911134719849, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.2607372999191284, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.2465240955352783, Accuracy: 0.6025390625\n",
      "Batch: 131, Loss: 1.270992398262024, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.1495903730392456, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.2268016338348389, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.1409378051757812, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 1.1626917123794556, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.1552107334136963, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.2043745517730713, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.3151395320892334, Accuracy: 0.5771484375\n",
      "Batch: 139, Loss: 1.2735116481781006, Accuracy: 0.5732421875\n",
      "Batch: 140, Loss: 1.2968926429748535, Accuracy: 0.5771484375\n",
      "Batch: 141, Loss: 1.2431080341339111, Accuracy: 0.611328125\n",
      "Batch: 142, Loss: 1.2609742879867554, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.2480497360229492, Accuracy: 0.609375\n",
      "Batch: 144, Loss: 1.3162589073181152, Accuracy: 0.5537109375\n",
      "Batch: 145, Loss: 1.3126096725463867, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.3052263259887695, Accuracy: 0.576171875\n",
      "Batch: 147, Loss: 1.288170576095581, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.307682991027832, Accuracy: 0.59375\n",
      "Batch: 149, Loss: 1.1959859132766724, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.2917447090148926, Accuracy: 0.58203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 151, Loss: 1.25778067111969, Accuracy: 0.603515625\n",
      "Batch: 152, Loss: 1.2286462783813477, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.2423851490020752, Accuracy: 0.609375\n",
      "Batch: 154, Loss: 1.1974942684173584, Accuracy: 0.6044921875\n",
      "Batch: 155, Loss: 1.1509400606155396, Accuracy: 0.6318359375\n",
      "Epoch 409/200\n",
      "Batch: 1, Loss: 1.3246309757232666, Accuracy: 0.60546875\n",
      "Batch: 2, Loss: 1.1067607402801514, Accuracy: 0.6396484375\n",
      "Batch: 3, Loss: 1.0467206239700317, Accuracy: 0.6591796875\n",
      "Batch: 4, Loss: 1.1655406951904297, Accuracy: 0.6005859375\n",
      "Batch: 5, Loss: 1.0502907037734985, Accuracy: 0.6376953125\n",
      "Batch: 6, Loss: 1.1142085790634155, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.0957671403884888, Accuracy: 0.6513671875\n",
      "Batch: 8, Loss: 1.0177788734436035, Accuracy: 0.6796875\n",
      "Batch: 9, Loss: 1.0762710571289062, Accuracy: 0.658203125\n",
      "Batch: 10, Loss: 1.0290236473083496, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 1.0312092304229736, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 1.0508842468261719, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 1.0879265069961548, Accuracy: 0.640625\n",
      "Batch: 14, Loss: 1.0676038265228271, Accuracy: 0.658203125\n",
      "Batch: 15, Loss: 0.9892548322677612, Accuracy: 0.6796875\n",
      "Batch: 16, Loss: 1.1132194995880127, Accuracy: 0.6474609375\n",
      "Batch: 17, Loss: 1.0965135097503662, Accuracy: 0.646484375\n",
      "Batch: 18, Loss: 1.2071075439453125, Accuracy: 0.6162109375\n",
      "Batch: 19, Loss: 1.2398715019226074, Accuracy: 0.587890625\n",
      "Batch: 20, Loss: 1.1598893404006958, Accuracy: 0.619140625\n",
      "Batch: 21, Loss: 1.122948408126831, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.271639347076416, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.254105806350708, Accuracy: 0.587890625\n",
      "Batch: 24, Loss: 1.293633222579956, Accuracy: 0.5830078125\n",
      "Batch: 25, Loss: 1.25138258934021, Accuracy: 0.599609375\n",
      "Batch: 26, Loss: 1.262378215789795, Accuracy: 0.5947265625\n",
      "Batch: 27, Loss: 1.1854658126831055, Accuracy: 0.6015625\n",
      "Batch: 28, Loss: 1.1602020263671875, Accuracy: 0.6298828125\n",
      "Batch: 29, Loss: 1.1105635166168213, Accuracy: 0.638671875\n",
      "Batch: 30, Loss: 1.2379062175750732, Accuracy: 0.6025390625\n",
      "Batch: 31, Loss: 1.2606383562088013, Accuracy: 0.58984375\n",
      "Batch: 32, Loss: 1.11094069480896, Accuracy: 0.638671875\n",
      "Batch: 33, Loss: 1.081241488456726, Accuracy: 0.65234375\n",
      "Batch: 34, Loss: 1.1877946853637695, Accuracy: 0.6103515625\n",
      "Batch: 35, Loss: 1.1748151779174805, Accuracy: 0.615234375\n",
      "Batch: 36, Loss: 1.2531179189682007, Accuracy: 0.5869140625\n",
      "Batch: 37, Loss: 1.2320175170898438, Accuracy: 0.62109375\n",
      "Batch: 38, Loss: 1.2465578317642212, Accuracy: 0.5947265625\n",
      "Batch: 39, Loss: 1.1597568988800049, Accuracy: 0.6298828125\n",
      "Batch: 40, Loss: 1.1752800941467285, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.2182860374450684, Accuracy: 0.6025390625\n",
      "Batch: 42, Loss: 1.1509160995483398, Accuracy: 0.6201171875\n",
      "Batch: 43, Loss: 1.1266157627105713, Accuracy: 0.6201171875\n",
      "Batch: 44, Loss: 1.1181378364562988, Accuracy: 0.658203125\n",
      "Batch: 45, Loss: 1.121689796447754, Accuracy: 0.62890625\n",
      "Batch: 46, Loss: 1.2116491794586182, Accuracy: 0.5986328125\n",
      "Batch: 47, Loss: 1.1503229141235352, Accuracy: 0.6318359375\n",
      "Batch: 48, Loss: 1.225705862045288, Accuracy: 0.603515625\n",
      "Batch: 49, Loss: 1.2321991920471191, Accuracy: 0.595703125\n",
      "Batch: 50, Loss: 1.2183072566986084, Accuracy: 0.603515625\n",
      "Batch: 51, Loss: 1.2188611030578613, Accuracy: 0.5869140625\n",
      "Batch: 52, Loss: 1.3290377855300903, Accuracy: 0.5556640625\n",
      "Batch: 53, Loss: 1.2255892753601074, Accuracy: 0.5986328125\n",
      "Batch: 54, Loss: 1.300020456314087, Accuracy: 0.5927734375\n",
      "Batch: 55, Loss: 1.2503271102905273, Accuracy: 0.5869140625\n",
      "Batch: 56, Loss: 1.1883622407913208, Accuracy: 0.62109375\n",
      "Batch: 57, Loss: 1.2362617254257202, Accuracy: 0.6201171875\n",
      "Batch: 58, Loss: 1.2138618230819702, Accuracy: 0.609375\n",
      "Batch: 59, Loss: 1.182413935661316, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.3238694667816162, Accuracy: 0.58203125\n",
      "Batch: 61, Loss: 1.205480933189392, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.2874908447265625, Accuracy: 0.611328125\n",
      "Batch: 63, Loss: 1.2209962606430054, Accuracy: 0.5966796875\n",
      "Batch: 64, Loss: 1.2548973560333252, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.2483304738998413, Accuracy: 0.5966796875\n",
      "Batch: 66, Loss: 1.2171382904052734, Accuracy: 0.6064453125\n",
      "Batch: 67, Loss: 1.2480677366256714, Accuracy: 0.595703125\n",
      "Batch: 68, Loss: 1.1690177917480469, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.2383666038513184, Accuracy: 0.58203125\n",
      "Batch: 70, Loss: 1.2401986122131348, Accuracy: 0.6123046875\n",
      "Batch: 71, Loss: 1.2230730056762695, Accuracy: 0.6123046875\n",
      "Batch: 72, Loss: 1.2629176378250122, Accuracy: 0.583984375\n",
      "Batch: 73, Loss: 1.2812583446502686, Accuracy: 0.591796875\n",
      "Batch: 74, Loss: 1.1916531324386597, Accuracy: 0.6201171875\n",
      "Batch: 75, Loss: 1.1274117231369019, Accuracy: 0.6435546875\n",
      "Batch: 76, Loss: 1.1552845239639282, Accuracy: 0.6123046875\n",
      "Batch: 77, Loss: 1.1425490379333496, Accuracy: 0.6259765625\n",
      "Batch: 78, Loss: 1.1396801471710205, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.1858187913894653, Accuracy: 0.62890625\n",
      "Batch: 80, Loss: 1.2320952415466309, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.1581358909606934, Accuracy: 0.6171875\n",
      "Batch: 82, Loss: 1.177908182144165, Accuracy: 0.6201171875\n",
      "Batch: 83, Loss: 1.2270195484161377, Accuracy: 0.599609375\n",
      "Batch: 84, Loss: 1.2021946907043457, Accuracy: 0.6044921875\n",
      "Batch: 85, Loss: 1.2272167205810547, Accuracy: 0.6123046875\n",
      "Batch: 86, Loss: 1.2123733758926392, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.261781096458435, Accuracy: 0.591796875\n",
      "Batch: 88, Loss: 1.243251085281372, Accuracy: 0.5859375\n",
      "Batch: 89, Loss: 1.1743378639221191, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.2038307189941406, Accuracy: 0.5966796875\n",
      "Batch: 91, Loss: 1.235271692276001, Accuracy: 0.6005859375\n",
      "Batch: 92, Loss: 1.2273809909820557, Accuracy: 0.625\n",
      "Batch: 93, Loss: 1.1962628364562988, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.2941772937774658, Accuracy: 0.5830078125\n",
      "Batch: 95, Loss: 1.278865933418274, Accuracy: 0.609375\n",
      "Batch: 96, Loss: 1.292970895767212, Accuracy: 0.6015625\n",
      "Batch: 97, Loss: 1.2056385278701782, Accuracy: 0.6142578125\n",
      "Batch: 98, Loss: 1.1980679035186768, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.2210121154785156, Accuracy: 0.6015625\n",
      "Batch: 100, Loss: 1.1557540893554688, Accuracy: 0.6318359375\n",
      "Batch: 101, Loss: 1.1458178758621216, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.2215383052825928, Accuracy: 0.595703125\n",
      "Batch: 103, Loss: 1.2866939306259155, Accuracy: 0.587890625\n",
      "Batch: 104, Loss: 1.2284886837005615, Accuracy: 0.6044921875\n",
      "Batch: 105, Loss: 1.2890477180480957, Accuracy: 0.591796875\n",
      "Batch: 106, Loss: 1.2351685762405396, Accuracy: 0.609375\n",
      "Batch: 107, Loss: 1.3327395915985107, Accuracy: 0.56640625\n",
      "Batch: 108, Loss: 1.3097352981567383, Accuracy: 0.595703125\n",
      "Batch: 109, Loss: 1.3313519954681396, Accuracy: 0.5634765625\n",
      "Batch: 110, Loss: 1.2177653312683105, Accuracy: 0.609375\n",
      "Batch: 111, Loss: 1.1788177490234375, Accuracy: 0.6181640625\n",
      "Batch: 112, Loss: 1.175896406173706, Accuracy: 0.6298828125\n",
      "Batch: 113, Loss: 1.1916369199752808, Accuracy: 0.6171875\n",
      "Batch: 114, Loss: 1.2205381393432617, Accuracy: 0.6044921875\n",
      "Batch: 115, Loss: 1.2484831809997559, Accuracy: 0.5927734375\n",
      "Batch: 116, Loss: 1.2624599933624268, Accuracy: 0.5927734375\n",
      "Batch: 117, Loss: 1.2921150922775269, Accuracy: 0.576171875\n",
      "Batch: 118, Loss: 1.2646535634994507, Accuracy: 0.591796875\n",
      "Batch: 119, Loss: 1.3070924282073975, Accuracy: 0.5849609375\n",
      "Batch: 120, Loss: 1.3535077571868896, Accuracy: 0.5556640625\n",
      "Batch: 121, Loss: 1.2309688329696655, Accuracy: 0.6044921875\n",
      "Batch: 122, Loss: 1.336244821548462, Accuracy: 0.5859375\n",
      "Batch: 123, Loss: 1.259021282196045, Accuracy: 0.591796875\n",
      "Batch: 124, Loss: 1.3091001510620117, Accuracy: 0.5830078125\n",
      "Batch: 125, Loss: 1.2469110488891602, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.2935588359832764, Accuracy: 0.568359375\n",
      "Batch: 127, Loss: 1.3044520616531372, Accuracy: 0.5947265625\n",
      "Batch: 128, Loss: 1.293860912322998, Accuracy: 0.5859375\n",
      "Batch: 129, Loss: 1.245750904083252, Accuracy: 0.5966796875\n",
      "Batch: 130, Loss: 1.1864521503448486, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.2447669506072998, Accuracy: 0.595703125\n",
      "Batch: 132, Loss: 1.1943204402923584, Accuracy: 0.6201171875\n",
      "Batch: 133, Loss: 1.1894357204437256, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.1996448040008545, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 135, Loss: 1.0929094552993774, Accuracy: 0.6396484375\n",
      "Batch: 136, Loss: 1.1403300762176514, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.2101616859436035, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.3115622997283936, Accuracy: 0.564453125\n",
      "Batch: 139, Loss: 1.251434326171875, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.3622103929519653, Accuracy: 0.568359375\n",
      "Batch: 141, Loss: 1.2248096466064453, Accuracy: 0.5947265625\n",
      "Batch: 142, Loss: 1.2739806175231934, Accuracy: 0.5947265625\n",
      "Batch: 143, Loss: 1.316107988357544, Accuracy: 0.5771484375\n",
      "Batch: 144, Loss: 1.2996586561203003, Accuracy: 0.6015625\n",
      "Batch: 145, Loss: 1.306318759918213, Accuracy: 0.5908203125\n",
      "Batch: 146, Loss: 1.259092092514038, Accuracy: 0.599609375\n",
      "Batch: 147, Loss: 1.2292505502700806, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.304386854171753, Accuracy: 0.5810546875\n",
      "Batch: 149, Loss: 1.2447600364685059, Accuracy: 0.595703125\n",
      "Batch: 150, Loss: 1.2002878189086914, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.233703851699829, Accuracy: 0.6064453125\n",
      "Batch: 152, Loss: 1.2332613468170166, Accuracy: 0.5986328125\n",
      "Batch: 153, Loss: 1.1440000534057617, Accuracy: 0.6416015625\n",
      "Batch: 154, Loss: 1.197831153869629, Accuracy: 0.58984375\n",
      "Batch: 155, Loss: 1.1901870965957642, Accuracy: 0.609375\n",
      "Epoch 410/200\n",
      "Batch: 1, Loss: 1.3161709308624268, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.1169809103012085, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 1.1328600645065308, Accuracy: 0.6142578125\n",
      "Batch: 4, Loss: 1.1631314754486084, Accuracy: 0.619140625\n",
      "Batch: 5, Loss: 1.0575751066207886, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.1100656986236572, Accuracy: 0.642578125\n",
      "Batch: 7, Loss: 1.0389600992202759, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 1.095555305480957, Accuracy: 0.6455078125\n",
      "Batch: 9, Loss: 1.0779337882995605, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 1.0247111320495605, Accuracy: 0.6552734375\n",
      "Batch: 11, Loss: 0.9988433122634888, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.052597999572754, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 1.1203114986419678, Accuracy: 0.634765625\n",
      "Batch: 14, Loss: 1.0490602254867554, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 1.0190258026123047, Accuracy: 0.6494140625\n",
      "Batch: 16, Loss: 1.1012877225875854, Accuracy: 0.650390625\n",
      "Batch: 17, Loss: 1.0769808292388916, Accuracy: 0.6591796875\n",
      "Batch: 18, Loss: 1.161362886428833, Accuracy: 0.6328125\n",
      "Batch: 19, Loss: 1.309741497039795, Accuracy: 0.5771484375\n",
      "Batch: 20, Loss: 1.1533093452453613, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.1581485271453857, Accuracy: 0.625\n",
      "Batch: 22, Loss: 1.2585346698760986, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.326749563217163, Accuracy: 0.5771484375\n",
      "Batch: 24, Loss: 1.2140474319458008, Accuracy: 0.603515625\n",
      "Batch: 25, Loss: 1.2541611194610596, Accuracy: 0.6015625\n",
      "Batch: 26, Loss: 1.221024513244629, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.1863185167312622, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.105675220489502, Accuracy: 0.6337890625\n",
      "Batch: 29, Loss: 1.1725759506225586, Accuracy: 0.615234375\n",
      "Batch: 30, Loss: 1.2173779010772705, Accuracy: 0.58984375\n",
      "Batch: 31, Loss: 1.2539231777191162, Accuracy: 0.576171875\n",
      "Batch: 32, Loss: 1.109403133392334, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 1.0208128690719604, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.187033772468567, Accuracy: 0.63671875\n",
      "Batch: 35, Loss: 1.252307415008545, Accuracy: 0.60546875\n",
      "Batch: 36, Loss: 1.2893255949020386, Accuracy: 0.591796875\n",
      "Batch: 37, Loss: 1.2840723991394043, Accuracy: 0.5810546875\n",
      "Batch: 38, Loss: 1.2488155364990234, Accuracy: 0.58203125\n",
      "Batch: 39, Loss: 1.1696058511734009, Accuracy: 0.623046875\n",
      "Batch: 40, Loss: 1.152886152267456, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1972405910491943, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0876600742340088, Accuracy: 0.634765625\n",
      "Batch: 43, Loss: 1.102268934249878, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.0990724563598633, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.1217788457870483, Accuracy: 0.623046875\n",
      "Batch: 46, Loss: 1.2442258596420288, Accuracy: 0.5859375\n",
      "Batch: 47, Loss: 1.1978123188018799, Accuracy: 0.626953125\n",
      "Batch: 48, Loss: 1.1958407163619995, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.2317824363708496, Accuracy: 0.6240234375\n",
      "Batch: 50, Loss: 1.214402675628662, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.1726967096328735, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.3065662384033203, Accuracy: 0.5830078125\n",
      "Batch: 53, Loss: 1.2428580522537231, Accuracy: 0.5888671875\n",
      "Batch: 54, Loss: 1.2323684692382812, Accuracy: 0.587890625\n",
      "Batch: 55, Loss: 1.1768391132354736, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.1692149639129639, Accuracy: 0.6142578125\n",
      "Batch: 57, Loss: 1.2242906093597412, Accuracy: 0.6123046875\n",
      "Batch: 58, Loss: 1.2088301181793213, Accuracy: 0.6240234375\n",
      "Batch: 59, Loss: 1.1865739822387695, Accuracy: 0.6142578125\n",
      "Batch: 60, Loss: 1.3769125938415527, Accuracy: 0.5576171875\n",
      "Batch: 61, Loss: 1.1957690715789795, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.2263461351394653, Accuracy: 0.603515625\n",
      "Batch: 63, Loss: 1.1927292346954346, Accuracy: 0.61328125\n",
      "Batch: 64, Loss: 1.2953181266784668, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.2657908201217651, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.223440170288086, Accuracy: 0.607421875\n",
      "Batch: 67, Loss: 1.2131187915802002, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.1040687561035156, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.2205010652542114, Accuracy: 0.611328125\n",
      "Batch: 70, Loss: 1.2835668325424194, Accuracy: 0.591796875\n",
      "Batch: 71, Loss: 1.1869142055511475, Accuracy: 0.615234375\n",
      "Batch: 72, Loss: 1.221002459526062, Accuracy: 0.6123046875\n",
      "Batch: 73, Loss: 1.176293134689331, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1721093654632568, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.2115592956542969, Accuracy: 0.5791015625\n",
      "Batch: 76, Loss: 1.1967566013336182, Accuracy: 0.603515625\n",
      "Batch: 77, Loss: 1.1157902479171753, Accuracy: 0.63671875\n",
      "Batch: 78, Loss: 1.1538232564926147, Accuracy: 0.6201171875\n",
      "Batch: 79, Loss: 1.1384220123291016, Accuracy: 0.63671875\n",
      "Batch: 80, Loss: 1.2631393671035767, Accuracy: 0.5791015625\n",
      "Batch: 81, Loss: 1.2070248126983643, Accuracy: 0.62109375\n",
      "Batch: 82, Loss: 1.2699127197265625, Accuracy: 0.58203125\n",
      "Batch: 83, Loss: 1.2664086818695068, Accuracy: 0.599609375\n",
      "Batch: 84, Loss: 1.2273434400558472, Accuracy: 0.5888671875\n",
      "Batch: 85, Loss: 1.2461628913879395, Accuracy: 0.62109375\n",
      "Batch: 86, Loss: 1.2351369857788086, Accuracy: 0.59765625\n",
      "Batch: 87, Loss: 1.2315475940704346, Accuracy: 0.615234375\n",
      "Batch: 88, Loss: 1.2493817806243896, Accuracy: 0.5986328125\n",
      "Batch: 89, Loss: 1.2362737655639648, Accuracy: 0.603515625\n",
      "Batch: 90, Loss: 1.1868488788604736, Accuracy: 0.6181640625\n",
      "Batch: 91, Loss: 1.179699182510376, Accuracy: 0.607421875\n",
      "Batch: 92, Loss: 1.1820929050445557, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.2064285278320312, Accuracy: 0.6083984375\n",
      "Batch: 94, Loss: 1.3229269981384277, Accuracy: 0.5751953125\n",
      "Batch: 95, Loss: 1.2268390655517578, Accuracy: 0.611328125\n",
      "Batch: 96, Loss: 1.2888902425765991, Accuracy: 0.5986328125\n",
      "Batch: 97, Loss: 1.234540581703186, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.1948055028915405, Accuracy: 0.6162109375\n",
      "Batch: 99, Loss: 1.2658158540725708, Accuracy: 0.595703125\n",
      "Batch: 100, Loss: 1.1056876182556152, Accuracy: 0.640625\n",
      "Batch: 101, Loss: 1.1702754497528076, Accuracy: 0.619140625\n",
      "Batch: 102, Loss: 1.2318811416625977, Accuracy: 0.6025390625\n",
      "Batch: 103, Loss: 1.221442461013794, Accuracy: 0.5966796875\n",
      "Batch: 104, Loss: 1.1606849431991577, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.270114541053772, Accuracy: 0.5810546875\n",
      "Batch: 106, Loss: 1.2335894107818604, Accuracy: 0.61328125\n",
      "Batch: 107, Loss: 1.2708184719085693, Accuracy: 0.580078125\n",
      "Batch: 108, Loss: 1.2598114013671875, Accuracy: 0.591796875\n",
      "Batch: 109, Loss: 1.2373199462890625, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.237518310546875, Accuracy: 0.5947265625\n",
      "Batch: 111, Loss: 1.2196147441864014, Accuracy: 0.611328125\n",
      "Batch: 112, Loss: 1.201667070388794, Accuracy: 0.6005859375\n",
      "Batch: 113, Loss: 1.2009305953979492, Accuracy: 0.599609375\n",
      "Batch: 114, Loss: 1.2646867036819458, Accuracy: 0.580078125\n",
      "Batch: 115, Loss: 1.2310482263565063, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.3212158679962158, Accuracy: 0.572265625\n",
      "Batch: 117, Loss: 1.2148687839508057, Accuracy: 0.62109375\n",
      "Batch: 118, Loss: 1.248722791671753, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2838420867919922, Accuracy: 0.5830078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 1.3670885562896729, Accuracy: 0.576171875\n",
      "Batch: 121, Loss: 1.272801399230957, Accuracy: 0.59375\n",
      "Batch: 122, Loss: 1.255629062652588, Accuracy: 0.5888671875\n",
      "Batch: 123, Loss: 1.2662885189056396, Accuracy: 0.6005859375\n",
      "Batch: 124, Loss: 1.2900774478912354, Accuracy: 0.5908203125\n",
      "Batch: 125, Loss: 1.2545292377471924, Accuracy: 0.611328125\n",
      "Batch: 126, Loss: 1.2856378555297852, Accuracy: 0.5849609375\n",
      "Batch: 127, Loss: 1.3419888019561768, Accuracy: 0.5703125\n",
      "Batch: 128, Loss: 1.2971696853637695, Accuracy: 0.5849609375\n",
      "Batch: 129, Loss: 1.2223234176635742, Accuracy: 0.5908203125\n",
      "Batch: 130, Loss: 1.2214374542236328, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.280468225479126, Accuracy: 0.609375\n",
      "Batch: 132, Loss: 1.19587242603302, Accuracy: 0.6103515625\n",
      "Batch: 133, Loss: 1.1985265016555786, Accuracy: 0.603515625\n",
      "Batch: 134, Loss: 1.149400234222412, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.08699369430542, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.1401569843292236, Accuracy: 0.6279296875\n",
      "Batch: 137, Loss: 1.2637947797775269, Accuracy: 0.5966796875\n",
      "Batch: 138, Loss: 1.3158185482025146, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.2591822147369385, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.3062849044799805, Accuracy: 0.583984375\n",
      "Batch: 141, Loss: 1.2480127811431885, Accuracy: 0.611328125\n",
      "Batch: 142, Loss: 1.253049612045288, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.3003342151641846, Accuracy: 0.5771484375\n",
      "Batch: 144, Loss: 1.326297402381897, Accuracy: 0.58203125\n",
      "Batch: 145, Loss: 1.366239070892334, Accuracy: 0.5615234375\n",
      "Batch: 146, Loss: 1.3332377672195435, Accuracy: 0.5654296875\n",
      "Batch: 147, Loss: 1.2588319778442383, Accuracy: 0.587890625\n",
      "Batch: 148, Loss: 1.2388328313827515, Accuracy: 0.595703125\n",
      "Batch: 149, Loss: 1.2365212440490723, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.2008429765701294, Accuracy: 0.6171875\n",
      "Batch: 151, Loss: 1.237807273864746, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.2325464487075806, Accuracy: 0.5849609375\n",
      "Batch: 153, Loss: 1.1895674467086792, Accuracy: 0.626953125\n",
      "Batch: 154, Loss: 1.223618745803833, Accuracy: 0.58984375\n",
      "Batch: 155, Loss: 1.1331512928009033, Accuracy: 0.642578125\n",
      "Saved Weights at epoch 410 to file Weights_410.h5\n",
      "Epoch 411/200\n",
      "Batch: 1, Loss: 1.2887601852416992, Accuracy: 0.630859375\n",
      "Batch: 2, Loss: 1.1291418075561523, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0194388628005981, Accuracy: 0.646484375\n",
      "Batch: 4, Loss: 1.1106643676757812, Accuracy: 0.6328125\n",
      "Batch: 5, Loss: 1.044327735900879, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.1296957731246948, Accuracy: 0.638671875\n",
      "Batch: 7, Loss: 1.0737320184707642, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 1.0605525970458984, Accuracy: 0.66015625\n",
      "Batch: 9, Loss: 1.018700361251831, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 1.0210460424423218, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 1.037373661994934, Accuracy: 0.6494140625\n",
      "Batch: 12, Loss: 1.1176952123641968, Accuracy: 0.62109375\n",
      "Batch: 13, Loss: 1.0730173587799072, Accuracy: 0.638671875\n",
      "Batch: 14, Loss: 1.035717248916626, Accuracy: 0.65234375\n",
      "Batch: 15, Loss: 0.9759026765823364, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.066920518875122, Accuracy: 0.6669921875\n",
      "Batch: 17, Loss: 1.1563423871994019, Accuracy: 0.619140625\n",
      "Batch: 18, Loss: 1.1924086809158325, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.2659120559692383, Accuracy: 0.591796875\n",
      "Batch: 20, Loss: 1.1715795993804932, Accuracy: 0.6220703125\n",
      "Batch: 21, Loss: 1.157414436340332, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.306394100189209, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.3184640407562256, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.1696491241455078, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.2107419967651367, Accuracy: 0.6025390625\n",
      "Batch: 26, Loss: 1.234553337097168, Accuracy: 0.5869140625\n",
      "Batch: 27, Loss: 1.1906960010528564, Accuracy: 0.615234375\n",
      "Batch: 28, Loss: 1.1127004623413086, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.09881591796875, Accuracy: 0.6279296875\n",
      "Batch: 30, Loss: 1.2717269659042358, Accuracy: 0.578125\n",
      "Batch: 31, Loss: 1.2427269220352173, Accuracy: 0.591796875\n",
      "Batch: 32, Loss: 1.1048915386199951, Accuracy: 0.625\n",
      "Batch: 33, Loss: 1.033450961112976, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.1312315464019775, Accuracy: 0.6123046875\n",
      "Batch: 35, Loss: 1.2090990543365479, Accuracy: 0.5888671875\n",
      "Batch: 36, Loss: 1.2539634704589844, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.289302110671997, Accuracy: 0.5859375\n",
      "Batch: 38, Loss: 1.1865553855895996, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.188772201538086, Accuracy: 0.6044921875\n",
      "Batch: 40, Loss: 1.1227073669433594, Accuracy: 0.6416015625\n",
      "Batch: 41, Loss: 1.1733372211456299, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.0900201797485352, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.1575961112976074, Accuracy: 0.63671875\n",
      "Batch: 44, Loss: 1.1059497594833374, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 1.118876576423645, Accuracy: 0.6201171875\n",
      "Batch: 46, Loss: 1.1743340492248535, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.165928840637207, Accuracy: 0.6396484375\n",
      "Batch: 48, Loss: 1.223004937171936, Accuracy: 0.595703125\n",
      "Batch: 49, Loss: 1.263326644897461, Accuracy: 0.6015625\n",
      "Batch: 50, Loss: 1.2373615503311157, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.284761905670166, Accuracy: 0.5712890625\n",
      "Batch: 52, Loss: 1.2850236892700195, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.2836942672729492, Accuracy: 0.59375\n",
      "Batch: 54, Loss: 1.246066689491272, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.1687147617340088, Accuracy: 0.62109375\n",
      "Batch: 56, Loss: 1.1412444114685059, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.188980221748352, Accuracy: 0.6181640625\n",
      "Batch: 58, Loss: 1.1700925827026367, Accuracy: 0.607421875\n",
      "Batch: 59, Loss: 1.2187780141830444, Accuracy: 0.603515625\n",
      "Batch: 60, Loss: 1.308476209640503, Accuracy: 0.572265625\n",
      "Batch: 61, Loss: 1.1700937747955322, Accuracy: 0.6162109375\n",
      "Batch: 62, Loss: 1.229461431503296, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.1871130466461182, Accuracy: 0.6181640625\n",
      "Batch: 64, Loss: 1.3318662643432617, Accuracy: 0.568359375\n",
      "Batch: 65, Loss: 1.2472634315490723, Accuracy: 0.6005859375\n",
      "Batch: 66, Loss: 1.1952879428863525, Accuracy: 0.6103515625\n",
      "Batch: 67, Loss: 1.1875171661376953, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.174415111541748, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.3009297847747803, Accuracy: 0.5830078125\n",
      "Batch: 70, Loss: 1.2669930458068848, Accuracy: 0.5859375\n",
      "Batch: 71, Loss: 1.154843807220459, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.2813384532928467, Accuracy: 0.5869140625\n",
      "Batch: 73, Loss: 1.2439414262771606, Accuracy: 0.572265625\n",
      "Batch: 74, Loss: 1.1898958683013916, Accuracy: 0.609375\n",
      "Batch: 75, Loss: 1.1614279747009277, Accuracy: 0.615234375\n",
      "Batch: 76, Loss: 1.1716461181640625, Accuracy: 0.6181640625\n",
      "Batch: 77, Loss: 1.1237047910690308, Accuracy: 0.6298828125\n",
      "Batch: 78, Loss: 1.1356559991836548, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.1347788572311401, Accuracy: 0.6318359375\n",
      "Batch: 80, Loss: 1.205849289894104, Accuracy: 0.615234375\n",
      "Batch: 81, Loss: 1.1675057411193848, Accuracy: 0.6162109375\n",
      "Batch: 82, Loss: 1.2092509269714355, Accuracy: 0.6123046875\n",
      "Batch: 83, Loss: 1.2825732231140137, Accuracy: 0.6025390625\n",
      "Batch: 84, Loss: 1.2058576345443726, Accuracy: 0.6044921875\n",
      "Batch: 85, Loss: 1.2078231573104858, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.2448848485946655, Accuracy: 0.5986328125\n",
      "Batch: 87, Loss: 1.2181514501571655, Accuracy: 0.599609375\n",
      "Batch: 88, Loss: 1.301265835762024, Accuracy: 0.5791015625\n",
      "Batch: 89, Loss: 1.23496413230896, Accuracy: 0.6064453125\n",
      "Batch: 90, Loss: 1.1763418912887573, Accuracy: 0.619140625\n",
      "Batch: 91, Loss: 1.2226393222808838, Accuracy: 0.6142578125\n",
      "Batch: 92, Loss: 1.199150562286377, Accuracy: 0.6142578125\n",
      "Batch: 93, Loss: 1.2010071277618408, Accuracy: 0.59375\n",
      "Batch: 94, Loss: 1.283387303352356, Accuracy: 0.578125\n",
      "Batch: 95, Loss: 1.2793996334075928, Accuracy: 0.5966796875\n",
      "Batch: 96, Loss: 1.2644422054290771, Accuracy: 0.607421875\n",
      "Batch: 97, Loss: 1.2555880546569824, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.1513510942459106, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.160399317741394, Accuracy: 0.6220703125\n",
      "Batch: 100, Loss: 1.181547999382019, Accuracy: 0.6103515625\n",
      "Batch: 101, Loss: 1.1739897727966309, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2354273796081543, Accuracy: 0.59765625\n",
      "Batch: 103, Loss: 1.2188115119934082, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.1568340063095093, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 105, Loss: 1.2984846830368042, Accuracy: 0.5810546875\n",
      "Batch: 106, Loss: 1.2265048027038574, Accuracy: 0.5986328125\n",
      "Batch: 107, Loss: 1.2906825542449951, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.2747375965118408, Accuracy: 0.6005859375\n",
      "Batch: 109, Loss: 1.3272888660430908, Accuracy: 0.560546875\n",
      "Batch: 110, Loss: 1.2329858541488647, Accuracy: 0.583984375\n",
      "Batch: 111, Loss: 1.2017271518707275, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.2219396829605103, Accuracy: 0.611328125\n",
      "Batch: 113, Loss: 1.257063388824463, Accuracy: 0.5908203125\n",
      "Batch: 114, Loss: 1.2197465896606445, Accuracy: 0.6025390625\n",
      "Batch: 115, Loss: 1.228492021560669, Accuracy: 0.5859375\n",
      "Batch: 116, Loss: 1.3052217960357666, Accuracy: 0.587890625\n",
      "Batch: 117, Loss: 1.2159135341644287, Accuracy: 0.5986328125\n",
      "Batch: 118, Loss: 1.2785015106201172, Accuracy: 0.572265625\n",
      "Batch: 119, Loss: 1.3358937501907349, Accuracy: 0.5615234375\n",
      "Batch: 120, Loss: 1.3481624126434326, Accuracy: 0.564453125\n",
      "Batch: 121, Loss: 1.2717946767807007, Accuracy: 0.59375\n",
      "Batch: 122, Loss: 1.283993124961853, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.2303173542022705, Accuracy: 0.60546875\n",
      "Batch: 124, Loss: 1.2700824737548828, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.2703486680984497, Accuracy: 0.58984375\n",
      "Batch: 126, Loss: 1.282875895500183, Accuracy: 0.5869140625\n",
      "Batch: 127, Loss: 1.2861337661743164, Accuracy: 0.5849609375\n",
      "Batch: 128, Loss: 1.305372953414917, Accuracy: 0.5830078125\n",
      "Batch: 129, Loss: 1.2981107234954834, Accuracy: 0.578125\n",
      "Batch: 130, Loss: 1.242403507232666, Accuracy: 0.6015625\n",
      "Batch: 131, Loss: 1.3119988441467285, Accuracy: 0.59375\n",
      "Batch: 132, Loss: 1.1850008964538574, Accuracy: 0.6142578125\n",
      "Batch: 133, Loss: 1.230109691619873, Accuracy: 0.619140625\n",
      "Batch: 134, Loss: 1.1933575868606567, Accuracy: 0.6298828125\n",
      "Batch: 135, Loss: 1.103867530822754, Accuracy: 0.6455078125\n",
      "Batch: 136, Loss: 1.1333348751068115, Accuracy: 0.6337890625\n",
      "Batch: 137, Loss: 1.2094978094100952, Accuracy: 0.6171875\n",
      "Batch: 138, Loss: 1.353670597076416, Accuracy: 0.576171875\n",
      "Batch: 139, Loss: 1.2568529844284058, Accuracy: 0.6064453125\n",
      "Batch: 140, Loss: 1.3105742931365967, Accuracy: 0.5791015625\n",
      "Batch: 141, Loss: 1.267364263534546, Accuracy: 0.5966796875\n",
      "Batch: 142, Loss: 1.261918544769287, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.3243818283081055, Accuracy: 0.5791015625\n",
      "Batch: 144, Loss: 1.3833450078964233, Accuracy: 0.5615234375\n",
      "Batch: 145, Loss: 1.3044638633728027, Accuracy: 0.576171875\n",
      "Batch: 146, Loss: 1.2972722053527832, Accuracy: 0.5810546875\n",
      "Batch: 147, Loss: 1.3068939447402954, Accuracy: 0.56640625\n",
      "Batch: 148, Loss: 1.302492380142212, Accuracy: 0.57421875\n",
      "Batch: 149, Loss: 1.2693555355072021, Accuracy: 0.595703125\n",
      "Batch: 150, Loss: 1.230586290359497, Accuracy: 0.6171875\n",
      "Batch: 151, Loss: 1.2566664218902588, Accuracy: 0.591796875\n",
      "Batch: 152, Loss: 1.3014687299728394, Accuracy: 0.591796875\n",
      "Batch: 153, Loss: 1.1953715085983276, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.1947908401489258, Accuracy: 0.59765625\n",
      "Batch: 155, Loss: 1.1482617855072021, Accuracy: 0.63671875\n",
      "Epoch 412/200\n",
      "Batch: 1, Loss: 1.3017321825027466, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.1703848838806152, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 1.1188665628433228, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.1305952072143555, Accuracy: 0.6201171875\n",
      "Batch: 5, Loss: 1.0518187284469604, Accuracy: 0.6494140625\n",
      "Batch: 6, Loss: 1.0979275703430176, Accuracy: 0.642578125\n",
      "Batch: 7, Loss: 1.1106922626495361, Accuracy: 0.6240234375\n",
      "Batch: 8, Loss: 1.0756897926330566, Accuracy: 0.646484375\n",
      "Batch: 9, Loss: 1.054197072982788, Accuracy: 0.6416015625\n",
      "Batch: 10, Loss: 1.049377202987671, Accuracy: 0.65625\n",
      "Batch: 11, Loss: 1.0270116329193115, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0766133069992065, Accuracy: 0.62890625\n",
      "Batch: 13, Loss: 1.045767068862915, Accuracy: 0.6552734375\n",
      "Batch: 14, Loss: 1.0695436000823975, Accuracy: 0.65234375\n",
      "Batch: 15, Loss: 0.9983261823654175, Accuracy: 0.6630859375\n",
      "Batch: 16, Loss: 1.084873080253601, Accuracy: 0.6591796875\n",
      "Batch: 17, Loss: 1.1447097063064575, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.2093793153762817, Accuracy: 0.599609375\n",
      "Batch: 19, Loss: 1.2539324760437012, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.195271611213684, Accuracy: 0.6201171875\n",
      "Batch: 21, Loss: 1.1400692462921143, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2730517387390137, Accuracy: 0.5810546875\n",
      "Batch: 23, Loss: 1.3116724491119385, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.2168846130371094, Accuracy: 0.6123046875\n",
      "Batch: 25, Loss: 1.2082850933074951, Accuracy: 0.6083984375\n",
      "Batch: 26, Loss: 1.2726154327392578, Accuracy: 0.57421875\n",
      "Batch: 27, Loss: 1.193344235420227, Accuracy: 0.60546875\n",
      "Batch: 28, Loss: 1.135413408279419, Accuracy: 0.6142578125\n",
      "Batch: 29, Loss: 1.0942745208740234, Accuracy: 0.6201171875\n",
      "Batch: 30, Loss: 1.2457654476165771, Accuracy: 0.6025390625\n",
      "Batch: 31, Loss: 1.2392685413360596, Accuracy: 0.5966796875\n",
      "Batch: 32, Loss: 1.113000512123108, Accuracy: 0.6259765625\n",
      "Batch: 33, Loss: 1.0440988540649414, Accuracy: 0.673828125\n",
      "Batch: 34, Loss: 1.1139910221099854, Accuracy: 0.6162109375\n",
      "Batch: 35, Loss: 1.1610527038574219, Accuracy: 0.62890625\n",
      "Batch: 36, Loss: 1.2719995975494385, Accuracy: 0.5908203125\n",
      "Batch: 37, Loss: 1.2997987270355225, Accuracy: 0.57421875\n",
      "Batch: 38, Loss: 1.2321910858154297, Accuracy: 0.59375\n",
      "Batch: 39, Loss: 1.1198439598083496, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.1833736896514893, Accuracy: 0.6123046875\n",
      "Batch: 41, Loss: 1.2641704082489014, Accuracy: 0.5869140625\n",
      "Batch: 42, Loss: 1.1098235845565796, Accuracy: 0.623046875\n",
      "Batch: 43, Loss: 1.1711585521697998, Accuracy: 0.6220703125\n",
      "Batch: 44, Loss: 1.0932996273040771, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.1277594566345215, Accuracy: 0.62890625\n",
      "Batch: 46, Loss: 1.2048957347869873, Accuracy: 0.6181640625\n",
      "Batch: 47, Loss: 1.1637382507324219, Accuracy: 0.6171875\n",
      "Batch: 48, Loss: 1.1904182434082031, Accuracy: 0.6025390625\n",
      "Batch: 49, Loss: 1.1953208446502686, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.1956689357757568, Accuracy: 0.611328125\n",
      "Batch: 51, Loss: 1.2071616649627686, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.3116734027862549, Accuracy: 0.5771484375\n",
      "Batch: 53, Loss: 1.2449127435684204, Accuracy: 0.5810546875\n",
      "Batch: 54, Loss: 1.2376503944396973, Accuracy: 0.6044921875\n",
      "Batch: 55, Loss: 1.1603702306747437, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.16842520236969, Accuracy: 0.619140625\n",
      "Batch: 57, Loss: 1.194098949432373, Accuracy: 0.62890625\n",
      "Batch: 58, Loss: 1.154280185699463, Accuracy: 0.6220703125\n",
      "Batch: 59, Loss: 1.1786291599273682, Accuracy: 0.6142578125\n",
      "Batch: 60, Loss: 1.306492567062378, Accuracy: 0.5712890625\n",
      "Batch: 61, Loss: 1.2151213884353638, Accuracy: 0.59375\n",
      "Batch: 62, Loss: 1.2939581871032715, Accuracy: 0.5888671875\n",
      "Batch: 63, Loss: 1.2351824045181274, Accuracy: 0.603515625\n",
      "Batch: 64, Loss: 1.2592239379882812, Accuracy: 0.583984375\n",
      "Batch: 65, Loss: 1.244586706161499, Accuracy: 0.5947265625\n",
      "Batch: 66, Loss: 1.1955540180206299, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.212536334991455, Accuracy: 0.6201171875\n",
      "Batch: 68, Loss: 1.1586928367614746, Accuracy: 0.60546875\n",
      "Batch: 69, Loss: 1.2660222053527832, Accuracy: 0.58203125\n",
      "Batch: 70, Loss: 1.2634069919586182, Accuracy: 0.59375\n",
      "Batch: 71, Loss: 1.181968092918396, Accuracy: 0.626953125\n",
      "Batch: 72, Loss: 1.2479290962219238, Accuracy: 0.599609375\n",
      "Batch: 73, Loss: 1.1857136487960815, Accuracy: 0.6279296875\n",
      "Batch: 74, Loss: 1.153580904006958, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.1840033531188965, Accuracy: 0.6240234375\n",
      "Batch: 76, Loss: 1.1636497974395752, Accuracy: 0.615234375\n",
      "Batch: 77, Loss: 1.137810230255127, Accuracy: 0.6416015625\n",
      "Batch: 78, Loss: 1.1791695356369019, Accuracy: 0.62109375\n",
      "Batch: 79, Loss: 1.1962337493896484, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.272140383720398, Accuracy: 0.5830078125\n",
      "Batch: 81, Loss: 1.2263966798782349, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.1653732061386108, Accuracy: 0.6171875\n",
      "Batch: 83, Loss: 1.2337805032730103, Accuracy: 0.6220703125\n",
      "Batch: 84, Loss: 1.1973642110824585, Accuracy: 0.6142578125\n",
      "Batch: 85, Loss: 1.2140533924102783, Accuracy: 0.609375\n",
      "Batch: 86, Loss: 1.194333553314209, Accuracy: 0.603515625\n",
      "Batch: 87, Loss: 1.2669188976287842, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.236337661743164, Accuracy: 0.591796875\n",
      "Batch: 89, Loss: 1.2454867362976074, Accuracy: 0.61328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 1.1862831115722656, Accuracy: 0.62109375\n",
      "Batch: 91, Loss: 1.1987695693969727, Accuracy: 0.6171875\n",
      "Batch: 92, Loss: 1.2623379230499268, Accuracy: 0.6025390625\n",
      "Batch: 93, Loss: 1.2401083707809448, Accuracy: 0.6142578125\n",
      "Batch: 94, Loss: 1.268730878829956, Accuracy: 0.57421875\n",
      "Batch: 95, Loss: 1.2843103408813477, Accuracy: 0.58203125\n",
      "Batch: 96, Loss: 1.2669780254364014, Accuracy: 0.5927734375\n",
      "Batch: 97, Loss: 1.2563039064407349, Accuracy: 0.595703125\n",
      "Batch: 98, Loss: 1.1786161661148071, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.220300555229187, Accuracy: 0.6220703125\n",
      "Batch: 100, Loss: 1.0989456176757812, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.1897753477096558, Accuracy: 0.6337890625\n",
      "Batch: 102, Loss: 1.2359895706176758, Accuracy: 0.6044921875\n",
      "Batch: 103, Loss: 1.2378164529800415, Accuracy: 0.61328125\n",
      "Batch: 104, Loss: 1.2395694255828857, Accuracy: 0.6064453125\n",
      "Batch: 105, Loss: 1.3161675930023193, Accuracy: 0.5859375\n",
      "Batch: 106, Loss: 1.2373156547546387, Accuracy: 0.599609375\n",
      "Batch: 107, Loss: 1.2870194911956787, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.2143056392669678, Accuracy: 0.59375\n",
      "Batch: 109, Loss: 1.2668884992599487, Accuracy: 0.5791015625\n",
      "Batch: 110, Loss: 1.268718957901001, Accuracy: 0.576171875\n",
      "Batch: 111, Loss: 1.19052255153656, Accuracy: 0.6005859375\n",
      "Batch: 112, Loss: 1.1797477006912231, Accuracy: 0.623046875\n",
      "Batch: 113, Loss: 1.1975784301757812, Accuracy: 0.609375\n",
      "Batch: 114, Loss: 1.153615951538086, Accuracy: 0.619140625\n",
      "Batch: 115, Loss: 1.209578514099121, Accuracy: 0.5927734375\n",
      "Batch: 116, Loss: 1.2253696918487549, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.214904546737671, Accuracy: 0.595703125\n",
      "Batch: 118, Loss: 1.2627805471420288, Accuracy: 0.576171875\n",
      "Batch: 119, Loss: 1.3085386753082275, Accuracy: 0.5810546875\n",
      "Batch: 120, Loss: 1.3563570976257324, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.227452039718628, Accuracy: 0.603515625\n",
      "Batch: 122, Loss: 1.2015655040740967, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1918926239013672, Accuracy: 0.6083984375\n",
      "Batch: 124, Loss: 1.2589997053146362, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.27162766456604, Accuracy: 0.607421875\n",
      "Batch: 126, Loss: 1.362741470336914, Accuracy: 0.576171875\n",
      "Batch: 127, Loss: 1.3063899278640747, Accuracy: 0.5888671875\n",
      "Batch: 128, Loss: 1.2159068584442139, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.2804718017578125, Accuracy: 0.603515625\n",
      "Batch: 130, Loss: 1.209438681602478, Accuracy: 0.6015625\n",
      "Batch: 131, Loss: 1.300931453704834, Accuracy: 0.57421875\n",
      "Batch: 132, Loss: 1.1740734577178955, Accuracy: 0.6201171875\n",
      "Batch: 133, Loss: 1.1871085166931152, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.1384295225143433, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.1148407459259033, Accuracy: 0.6357421875\n",
      "Batch: 136, Loss: 1.1821398735046387, Accuracy: 0.6162109375\n",
      "Batch: 137, Loss: 1.2187339067459106, Accuracy: 0.607421875\n",
      "Batch: 138, Loss: 1.3264292478561401, Accuracy: 0.5576171875\n",
      "Batch: 139, Loss: 1.2577505111694336, Accuracy: 0.609375\n",
      "Batch: 140, Loss: 1.3386507034301758, Accuracy: 0.5654296875\n",
      "Batch: 141, Loss: 1.2338519096374512, Accuracy: 0.591796875\n",
      "Batch: 142, Loss: 1.239211082458496, Accuracy: 0.599609375\n",
      "Batch: 143, Loss: 1.2795606851577759, Accuracy: 0.59375\n",
      "Batch: 144, Loss: 1.2884042263031006, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.342210292816162, Accuracy: 0.55859375\n",
      "Batch: 146, Loss: 1.298802137374878, Accuracy: 0.576171875\n",
      "Batch: 147, Loss: 1.2575856447219849, Accuracy: 0.5947265625\n",
      "Batch: 148, Loss: 1.2836461067199707, Accuracy: 0.5830078125\n",
      "Batch: 149, Loss: 1.2290914058685303, Accuracy: 0.5888671875\n",
      "Batch: 150, Loss: 1.2023999691009521, Accuracy: 0.6044921875\n",
      "Batch: 151, Loss: 1.22146737575531, Accuracy: 0.5947265625\n",
      "Batch: 152, Loss: 1.215355396270752, Accuracy: 0.5830078125\n",
      "Batch: 153, Loss: 1.1647182703018188, Accuracy: 0.626953125\n",
      "Batch: 154, Loss: 1.1541457176208496, Accuracy: 0.62109375\n",
      "Batch: 155, Loss: 1.1675117015838623, Accuracy: 0.6298828125\n",
      "Epoch 413/200\n",
      "Batch: 1, Loss: 1.2745965719223022, Accuracy: 0.62109375\n",
      "Batch: 2, Loss: 1.13499116897583, Accuracy: 0.63671875\n",
      "Batch: 3, Loss: 1.02418851852417, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.1401958465576172, Accuracy: 0.62890625\n",
      "Batch: 5, Loss: 1.0491125583648682, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.0963973999023438, Accuracy: 0.62890625\n",
      "Batch: 7, Loss: 1.079188346862793, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 1.0570268630981445, Accuracy: 0.654296875\n",
      "Batch: 9, Loss: 1.0135819911956787, Accuracy: 0.6689453125\n",
      "Batch: 10, Loss: 1.0354297161102295, Accuracy: 0.662109375\n",
      "Batch: 11, Loss: 1.069061517715454, Accuracy: 0.65234375\n",
      "Batch: 12, Loss: 1.0550941228866577, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.1059801578521729, Accuracy: 0.638671875\n",
      "Batch: 14, Loss: 1.0276226997375488, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 1.0119798183441162, Accuracy: 0.65625\n",
      "Batch: 16, Loss: 1.0832841396331787, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.0819584131240845, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.195483684539795, Accuracy: 0.609375\n",
      "Batch: 19, Loss: 1.3127268552780151, Accuracy: 0.5673828125\n",
      "Batch: 20, Loss: 1.1451466083526611, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1150610446929932, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.2486701011657715, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.3121217489242554, Accuracy: 0.5732421875\n",
      "Batch: 24, Loss: 1.2056572437286377, Accuracy: 0.623046875\n",
      "Batch: 25, Loss: 1.1835203170776367, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.205690860748291, Accuracy: 0.6171875\n",
      "Batch: 27, Loss: 1.205875277519226, Accuracy: 0.6015625\n",
      "Batch: 28, Loss: 1.072754144668579, Accuracy: 0.662109375\n",
      "Batch: 29, Loss: 1.113785743713379, Accuracy: 0.6240234375\n",
      "Batch: 30, Loss: 1.2230753898620605, Accuracy: 0.5947265625\n",
      "Batch: 31, Loss: 1.2306861877441406, Accuracy: 0.61328125\n",
      "Batch: 32, Loss: 1.1399335861206055, Accuracy: 0.6220703125\n",
      "Batch: 33, Loss: 1.0579489469528198, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.1325554847717285, Accuracy: 0.6435546875\n",
      "Batch: 35, Loss: 1.1939263343811035, Accuracy: 0.611328125\n",
      "Batch: 36, Loss: 1.2744659185409546, Accuracy: 0.5849609375\n",
      "Batch: 37, Loss: 1.2605373859405518, Accuracy: 0.572265625\n",
      "Batch: 38, Loss: 1.2243068218231201, Accuracy: 0.595703125\n",
      "Batch: 39, Loss: 1.1101009845733643, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.225348949432373, Accuracy: 0.6142578125\n",
      "Batch: 41, Loss: 1.2571947574615479, Accuracy: 0.5791015625\n",
      "Batch: 42, Loss: 1.143024206161499, Accuracy: 0.61328125\n",
      "Batch: 43, Loss: 1.1329365968704224, Accuracy: 0.6083984375\n",
      "Batch: 44, Loss: 1.1206462383270264, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.100792646408081, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.1549742221832275, Accuracy: 0.607421875\n",
      "Batch: 47, Loss: 1.1236493587493896, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1359091997146606, Accuracy: 0.611328125\n",
      "Batch: 49, Loss: 1.2321178913116455, Accuracy: 0.6005859375\n",
      "Batch: 50, Loss: 1.1973764896392822, Accuracy: 0.5927734375\n",
      "Batch: 51, Loss: 1.2273094654083252, Accuracy: 0.5888671875\n",
      "Batch: 52, Loss: 1.3015778064727783, Accuracy: 0.591796875\n",
      "Batch: 53, Loss: 1.267664909362793, Accuracy: 0.568359375\n",
      "Batch: 54, Loss: 1.2078361511230469, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.153834342956543, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.1501303911209106, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.23433518409729, Accuracy: 0.6044921875\n",
      "Batch: 58, Loss: 1.1568750143051147, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.173003911972046, Accuracy: 0.6201171875\n",
      "Batch: 60, Loss: 1.2923657894134521, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.191978096961975, Accuracy: 0.603515625\n",
      "Batch: 62, Loss: 1.2184770107269287, Accuracy: 0.59375\n",
      "Batch: 63, Loss: 1.2159333229064941, Accuracy: 0.5859375\n",
      "Batch: 64, Loss: 1.270969033241272, Accuracy: 0.5830078125\n",
      "Batch: 65, Loss: 1.2180590629577637, Accuracy: 0.6162109375\n",
      "Batch: 66, Loss: 1.1592485904693604, Accuracy: 0.6474609375\n",
      "Batch: 67, Loss: 1.1739270687103271, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.1452200412750244, Accuracy: 0.63671875\n",
      "Batch: 69, Loss: 1.2403454780578613, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.2187654972076416, Accuracy: 0.599609375\n",
      "Batch: 71, Loss: 1.236544132232666, Accuracy: 0.60546875\n",
      "Batch: 72, Loss: 1.2940301895141602, Accuracy: 0.578125\n",
      "Batch: 73, Loss: 1.248695969581604, Accuracy: 0.607421875\n",
      "Batch: 74, Loss: 1.1499946117401123, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 75, Loss: 1.1861196756362915, Accuracy: 0.611328125\n",
      "Batch: 76, Loss: 1.1438422203063965, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.1316232681274414, Accuracy: 0.623046875\n",
      "Batch: 78, Loss: 1.1623599529266357, Accuracy: 0.6279296875\n",
      "Batch: 79, Loss: 1.171980381011963, Accuracy: 0.6064453125\n",
      "Batch: 80, Loss: 1.2161273956298828, Accuracy: 0.6123046875\n",
      "Batch: 81, Loss: 1.1431461572647095, Accuracy: 0.62890625\n",
      "Batch: 82, Loss: 1.174924612045288, Accuracy: 0.6123046875\n",
      "Batch: 83, Loss: 1.2592990398406982, Accuracy: 0.5791015625\n",
      "Batch: 84, Loss: 1.2259446382522583, Accuracy: 0.611328125\n",
      "Batch: 85, Loss: 1.2376830577850342, Accuracy: 0.5986328125\n",
      "Batch: 86, Loss: 1.2378615140914917, Accuracy: 0.58984375\n",
      "Batch: 87, Loss: 1.2837063074111938, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.258427619934082, Accuracy: 0.5810546875\n",
      "Batch: 89, Loss: 1.1709067821502686, Accuracy: 0.642578125\n",
      "Batch: 90, Loss: 1.16786527633667, Accuracy: 0.6220703125\n",
      "Batch: 91, Loss: 1.197687029838562, Accuracy: 0.603515625\n",
      "Batch: 92, Loss: 1.2429288625717163, Accuracy: 0.6171875\n",
      "Batch: 93, Loss: 1.1854628324508667, Accuracy: 0.630859375\n",
      "Batch: 94, Loss: 1.229109764099121, Accuracy: 0.6083984375\n",
      "Batch: 95, Loss: 1.2582728862762451, Accuracy: 0.6103515625\n",
      "Batch: 96, Loss: 1.260106086730957, Accuracy: 0.6025390625\n",
      "Batch: 97, Loss: 1.2721840143203735, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.1971502304077148, Accuracy: 0.6083984375\n",
      "Batch: 99, Loss: 1.2008771896362305, Accuracy: 0.609375\n",
      "Batch: 100, Loss: 1.1288104057312012, Accuracy: 0.6376953125\n",
      "Batch: 101, Loss: 1.1720969676971436, Accuracy: 0.6328125\n",
      "Batch: 102, Loss: 1.2208818197250366, Accuracy: 0.603515625\n",
      "Batch: 103, Loss: 1.2486672401428223, Accuracy: 0.607421875\n",
      "Batch: 104, Loss: 1.2092503309249878, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.304330587387085, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.1957412958145142, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.2974612712860107, Accuracy: 0.576171875\n",
      "Batch: 108, Loss: 1.2536259889602661, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.2710131406784058, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.2366291284561157, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.182027816772461, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.1513478755950928, Accuracy: 0.623046875\n",
      "Batch: 113, Loss: 1.2398898601531982, Accuracy: 0.6015625\n",
      "Batch: 114, Loss: 1.2432996034622192, Accuracy: 0.572265625\n",
      "Batch: 115, Loss: 1.2258681058883667, Accuracy: 0.595703125\n",
      "Batch: 116, Loss: 1.1833393573760986, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.2015721797943115, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.3141460418701172, Accuracy: 0.5654296875\n",
      "Batch: 119, Loss: 1.2915077209472656, Accuracy: 0.5888671875\n",
      "Batch: 120, Loss: 1.3660072088241577, Accuracy: 0.5673828125\n",
      "Batch: 121, Loss: 1.2412298917770386, Accuracy: 0.587890625\n",
      "Batch: 122, Loss: 1.2426724433898926, Accuracy: 0.6005859375\n",
      "Batch: 123, Loss: 1.1936618089675903, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.3146637678146362, Accuracy: 0.5712890625\n",
      "Batch: 125, Loss: 1.250360369682312, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.288597822189331, Accuracy: 0.5908203125\n",
      "Batch: 127, Loss: 1.3295842409133911, Accuracy: 0.576171875\n",
      "Batch: 128, Loss: 1.2411777973175049, Accuracy: 0.6015625\n",
      "Batch: 129, Loss: 1.1993420124053955, Accuracy: 0.6025390625\n",
      "Batch: 130, Loss: 1.192803978919983, Accuracy: 0.623046875\n",
      "Batch: 131, Loss: 1.305877923965454, Accuracy: 0.5751953125\n",
      "Batch: 132, Loss: 1.1836211681365967, Accuracy: 0.611328125\n",
      "Batch: 133, Loss: 1.2829803228378296, Accuracy: 0.587890625\n",
      "Batch: 134, Loss: 1.179587960243225, Accuracy: 0.6328125\n",
      "Batch: 135, Loss: 1.1432276964187622, Accuracy: 0.65234375\n",
      "Batch: 136, Loss: 1.1391855478286743, Accuracy: 0.6298828125\n",
      "Batch: 137, Loss: 1.24605131149292, Accuracy: 0.6064453125\n",
      "Batch: 138, Loss: 1.2635210752487183, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.2604517936706543, Accuracy: 0.6044921875\n",
      "Batch: 140, Loss: 1.3137133121490479, Accuracy: 0.576171875\n",
      "Batch: 141, Loss: 1.2136284112930298, Accuracy: 0.6123046875\n",
      "Batch: 142, Loss: 1.225955605506897, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.2509344816207886, Accuracy: 0.578125\n",
      "Batch: 144, Loss: 1.26352858543396, Accuracy: 0.58984375\n",
      "Batch: 145, Loss: 1.3292531967163086, Accuracy: 0.5634765625\n",
      "Batch: 146, Loss: 1.2003825902938843, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.245178461074829, Accuracy: 0.595703125\n",
      "Batch: 148, Loss: 1.259559154510498, Accuracy: 0.603515625\n",
      "Batch: 149, Loss: 1.1977813243865967, Accuracy: 0.5869140625\n",
      "Batch: 150, Loss: 1.2020337581634521, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.2744777202606201, Accuracy: 0.59375\n",
      "Batch: 152, Loss: 1.2070058584213257, Accuracy: 0.6015625\n",
      "Batch: 153, Loss: 1.2060816287994385, Accuracy: 0.599609375\n",
      "Batch: 154, Loss: 1.1909836530685425, Accuracy: 0.607421875\n",
      "Batch: 155, Loss: 1.1526362895965576, Accuracy: 0.625\n",
      "Epoch 414/200\n",
      "Batch: 1, Loss: 1.2969624996185303, Accuracy: 0.5986328125\n",
      "Batch: 2, Loss: 1.1332058906555176, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 1.051897644996643, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.1502950191497803, Accuracy: 0.6201171875\n",
      "Batch: 5, Loss: 1.039191484451294, Accuracy: 0.6748046875\n",
      "Batch: 6, Loss: 1.1214604377746582, Accuracy: 0.63671875\n",
      "Batch: 7, Loss: 1.0967763662338257, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 1.088432788848877, Accuracy: 0.65625\n",
      "Batch: 9, Loss: 1.0904825925827026, Accuracy: 0.6474609375\n",
      "Batch: 10, Loss: 1.0238627195358276, Accuracy: 0.6591796875\n",
      "Batch: 11, Loss: 1.0383814573287964, Accuracy: 0.65234375\n",
      "Batch: 12, Loss: 1.0902392864227295, Accuracy: 0.640625\n",
      "Batch: 13, Loss: 1.082407832145691, Accuracy: 0.6337890625\n",
      "Batch: 14, Loss: 1.0415112972259521, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.9447202086448669, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.0694165229797363, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.1555800437927246, Accuracy: 0.6064453125\n",
      "Batch: 18, Loss: 1.1823972463607788, Accuracy: 0.6025390625\n",
      "Batch: 19, Loss: 1.3196909427642822, Accuracy: 0.568359375\n",
      "Batch: 20, Loss: 1.1368285417556763, Accuracy: 0.63671875\n",
      "Batch: 21, Loss: 1.1330411434173584, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.263846516609192, Accuracy: 0.59375\n",
      "Batch: 23, Loss: 1.346977710723877, Accuracy: 0.55078125\n",
      "Batch: 24, Loss: 1.20548677444458, Accuracy: 0.603515625\n",
      "Batch: 25, Loss: 1.1986815929412842, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.2240241765975952, Accuracy: 0.609375\n",
      "Batch: 27, Loss: 1.2037309408187866, Accuracy: 0.6123046875\n",
      "Batch: 28, Loss: 1.1168994903564453, Accuracy: 0.630859375\n",
      "Batch: 29, Loss: 1.091879963874817, Accuracy: 0.6455078125\n",
      "Batch: 30, Loss: 1.253899097442627, Accuracy: 0.5908203125\n",
      "Batch: 31, Loss: 1.2631208896636963, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.0914487838745117, Accuracy: 0.6591796875\n",
      "Batch: 33, Loss: 1.0489745140075684, Accuracy: 0.65234375\n",
      "Batch: 34, Loss: 1.152510166168213, Accuracy: 0.6259765625\n",
      "Batch: 35, Loss: 1.1806683540344238, Accuracy: 0.6015625\n",
      "Batch: 36, Loss: 1.275965690612793, Accuracy: 0.5732421875\n",
      "Batch: 37, Loss: 1.3024367094039917, Accuracy: 0.5634765625\n",
      "Batch: 38, Loss: 1.2266287803649902, Accuracy: 0.5908203125\n",
      "Batch: 39, Loss: 1.1246229410171509, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.1384319067001343, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1956262588500977, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.1343958377838135, Accuracy: 0.6298828125\n",
      "Batch: 43, Loss: 1.1146752834320068, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.1203398704528809, Accuracy: 0.6279296875\n",
      "Batch: 45, Loss: 1.0976440906524658, Accuracy: 0.634765625\n",
      "Batch: 46, Loss: 1.1511048078536987, Accuracy: 0.609375\n",
      "Batch: 47, Loss: 1.1925761699676514, Accuracy: 0.6015625\n",
      "Batch: 48, Loss: 1.1652312278747559, Accuracy: 0.611328125\n",
      "Batch: 49, Loss: 1.1924026012420654, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.1575536727905273, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.1558849811553955, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.319996953010559, Accuracy: 0.578125\n",
      "Batch: 53, Loss: 1.2123149633407593, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.2565977573394775, Accuracy: 0.58203125\n",
      "Batch: 55, Loss: 1.147920846939087, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.1407651901245117, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.162519931793213, Accuracy: 0.634765625\n",
      "Batch: 58, Loss: 1.1336851119995117, Accuracy: 0.6240234375\n",
      "Batch: 59, Loss: 1.1929038763046265, Accuracy: 0.6220703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 1.2419029474258423, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.208109974861145, Accuracy: 0.599609375\n",
      "Batch: 62, Loss: 1.1897321939468384, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.185098648071289, Accuracy: 0.6240234375\n",
      "Batch: 64, Loss: 1.275625228881836, Accuracy: 0.5712890625\n",
      "Batch: 65, Loss: 1.2316474914550781, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.2372713088989258, Accuracy: 0.599609375\n",
      "Batch: 67, Loss: 1.2093607187271118, Accuracy: 0.5966796875\n",
      "Batch: 68, Loss: 1.162574291229248, Accuracy: 0.6103515625\n",
      "Batch: 69, Loss: 1.2489327192306519, Accuracy: 0.60546875\n",
      "Batch: 70, Loss: 1.2409327030181885, Accuracy: 0.5927734375\n",
      "Batch: 71, Loss: 1.1718767881393433, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.2397544384002686, Accuracy: 0.5947265625\n",
      "Batch: 73, Loss: 1.2319481372833252, Accuracy: 0.599609375\n",
      "Batch: 74, Loss: 1.1414484977722168, Accuracy: 0.6181640625\n",
      "Batch: 75, Loss: 1.1857292652130127, Accuracy: 0.61328125\n",
      "Batch: 76, Loss: 1.109365463256836, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.121111512184143, Accuracy: 0.634765625\n",
      "Batch: 78, Loss: 1.1263599395751953, Accuracy: 0.615234375\n",
      "Batch: 79, Loss: 1.2310209274291992, Accuracy: 0.6025390625\n",
      "Batch: 80, Loss: 1.2281218767166138, Accuracy: 0.5908203125\n",
      "Batch: 81, Loss: 1.1841654777526855, Accuracy: 0.6279296875\n",
      "Batch: 82, Loss: 1.181688666343689, Accuracy: 0.611328125\n",
      "Batch: 83, Loss: 1.2715318202972412, Accuracy: 0.5810546875\n",
      "Batch: 84, Loss: 1.177458643913269, Accuracy: 0.6083984375\n",
      "Batch: 85, Loss: 1.189866065979004, Accuracy: 0.6142578125\n",
      "Batch: 86, Loss: 1.2092373371124268, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.2547744512557983, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.3077929019927979, Accuracy: 0.5830078125\n",
      "Batch: 89, Loss: 1.222569227218628, Accuracy: 0.6142578125\n",
      "Batch: 90, Loss: 1.189430832862854, Accuracy: 0.6142578125\n",
      "Batch: 91, Loss: 1.2090601921081543, Accuracy: 0.6142578125\n",
      "Batch: 92, Loss: 1.2257378101348877, Accuracy: 0.6416015625\n",
      "Batch: 93, Loss: 1.2415237426757812, Accuracy: 0.6083984375\n",
      "Batch: 94, Loss: 1.2832893133163452, Accuracy: 0.59765625\n",
      "Batch: 95, Loss: 1.222272276878357, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.2285064458847046, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.2580183744430542, Accuracy: 0.59375\n",
      "Batch: 98, Loss: 1.169154167175293, Accuracy: 0.609375\n",
      "Batch: 99, Loss: 1.2412347793579102, Accuracy: 0.5927734375\n",
      "Batch: 100, Loss: 1.1067579984664917, Accuracy: 0.6357421875\n",
      "Batch: 101, Loss: 1.1333012580871582, Accuracy: 0.6416015625\n",
      "Batch: 102, Loss: 1.2465157508850098, Accuracy: 0.6123046875\n",
      "Batch: 103, Loss: 1.237269639968872, Accuracy: 0.595703125\n",
      "Batch: 104, Loss: 1.2125744819641113, Accuracy: 0.60546875\n",
      "Batch: 105, Loss: 1.3268110752105713, Accuracy: 0.5732421875\n",
      "Batch: 106, Loss: 1.2154645919799805, Accuracy: 0.619140625\n",
      "Batch: 107, Loss: 1.3442535400390625, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.250765323638916, Accuracy: 0.5732421875\n",
      "Batch: 109, Loss: 1.2650184631347656, Accuracy: 0.5810546875\n",
      "Batch: 110, Loss: 1.2036199569702148, Accuracy: 0.6259765625\n",
      "Batch: 111, Loss: 1.1727830171585083, Accuracy: 0.6083984375\n",
      "Batch: 112, Loss: 1.15865159034729, Accuracy: 0.6298828125\n",
      "Batch: 113, Loss: 1.1652374267578125, Accuracy: 0.62109375\n",
      "Batch: 114, Loss: 1.2171998023986816, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2235462665557861, Accuracy: 0.5908203125\n",
      "Batch: 116, Loss: 1.2428621053695679, Accuracy: 0.5908203125\n",
      "Batch: 117, Loss: 1.1755584478378296, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.256610631942749, Accuracy: 0.5810546875\n",
      "Batch: 119, Loss: 1.2925400733947754, Accuracy: 0.5810546875\n",
      "Batch: 120, Loss: 1.360844612121582, Accuracy: 0.5712890625\n",
      "Batch: 121, Loss: 1.2662906646728516, Accuracy: 0.611328125\n",
      "Batch: 122, Loss: 1.2650264501571655, Accuracy: 0.578125\n",
      "Batch: 123, Loss: 1.2523255348205566, Accuracy: 0.5888671875\n",
      "Batch: 124, Loss: 1.2865431308746338, Accuracy: 0.576171875\n",
      "Batch: 125, Loss: 1.224441647529602, Accuracy: 0.6201171875\n",
      "Batch: 126, Loss: 1.3537139892578125, Accuracy: 0.58203125\n",
      "Batch: 127, Loss: 1.3038287162780762, Accuracy: 0.5908203125\n",
      "Batch: 128, Loss: 1.2565287351608276, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.227464199066162, Accuracy: 0.60546875\n",
      "Batch: 130, Loss: 1.2074697017669678, Accuracy: 0.6044921875\n",
      "Batch: 131, Loss: 1.2928602695465088, Accuracy: 0.59375\n",
      "Batch: 132, Loss: 1.1921427249908447, Accuracy: 0.6220703125\n",
      "Batch: 133, Loss: 1.2271286249160767, Accuracy: 0.60546875\n",
      "Batch: 134, Loss: 1.1372390985488892, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 1.1763863563537598, Accuracy: 0.619140625\n",
      "Batch: 136, Loss: 1.1515223979949951, Accuracy: 0.6181640625\n",
      "Batch: 137, Loss: 1.1531226634979248, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.2953741550445557, Accuracy: 0.58203125\n",
      "Batch: 139, Loss: 1.2294210195541382, Accuracy: 0.609375\n",
      "Batch: 140, Loss: 1.3677897453308105, Accuracy: 0.568359375\n",
      "Batch: 141, Loss: 1.2470027208328247, Accuracy: 0.5859375\n",
      "Batch: 142, Loss: 1.2745683193206787, Accuracy: 0.6015625\n",
      "Batch: 143, Loss: 1.2911921739578247, Accuracy: 0.583984375\n",
      "Batch: 144, Loss: 1.3432865142822266, Accuracy: 0.560546875\n",
      "Batch: 145, Loss: 1.3497021198272705, Accuracy: 0.5791015625\n",
      "Batch: 146, Loss: 1.2571187019348145, Accuracy: 0.59375\n",
      "Batch: 147, Loss: 1.262303113937378, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.2456259727478027, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.2156918048858643, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.2581987380981445, Accuracy: 0.6083984375\n",
      "Batch: 151, Loss: 1.2292901277542114, Accuracy: 0.609375\n",
      "Batch: 152, Loss: 1.2309682369232178, Accuracy: 0.6123046875\n",
      "Batch: 153, Loss: 1.1841669082641602, Accuracy: 0.615234375\n",
      "Batch: 154, Loss: 1.2016572952270508, Accuracy: 0.6142578125\n",
      "Batch: 155, Loss: 1.1774002313613892, Accuracy: 0.6279296875\n",
      "Epoch 415/200\n",
      "Batch: 1, Loss: 1.2858270406723022, Accuracy: 0.625\n",
      "Batch: 2, Loss: 1.1472804546356201, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0633800029754639, Accuracy: 0.6357421875\n",
      "Batch: 4, Loss: 1.1215934753417969, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.0452501773834229, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.073915958404541, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 1.0749266147613525, Accuracy: 0.654296875\n",
      "Batch: 8, Loss: 1.0462114810943604, Accuracy: 0.6611328125\n",
      "Batch: 9, Loss: 0.9905754923820496, Accuracy: 0.6826171875\n",
      "Batch: 10, Loss: 1.027634620666504, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.0518543720245361, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 1.074009656906128, Accuracy: 0.6396484375\n",
      "Batch: 13, Loss: 1.051180362701416, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.013175368309021, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.9983593225479126, Accuracy: 0.666015625\n",
      "Batch: 16, Loss: 1.0621936321258545, Accuracy: 0.6591796875\n",
      "Batch: 17, Loss: 1.0910062789916992, Accuracy: 0.6279296875\n",
      "Batch: 18, Loss: 1.1944961547851562, Accuracy: 0.615234375\n",
      "Batch: 19, Loss: 1.2288792133331299, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.1584217548370361, Accuracy: 0.640625\n",
      "Batch: 21, Loss: 1.1054446697235107, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.288539171218872, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.2552096843719482, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.191811203956604, Accuracy: 0.6220703125\n",
      "Batch: 25, Loss: 1.239186406135559, Accuracy: 0.5966796875\n",
      "Batch: 26, Loss: 1.2855751514434814, Accuracy: 0.58203125\n",
      "Batch: 27, Loss: 1.2111856937408447, Accuracy: 0.599609375\n",
      "Batch: 28, Loss: 1.1301008462905884, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.1214042901992798, Accuracy: 0.6162109375\n",
      "Batch: 30, Loss: 1.2351030111312866, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.2655961513519287, Accuracy: 0.5927734375\n",
      "Batch: 32, Loss: 1.1167171001434326, Accuracy: 0.6328125\n",
      "Batch: 33, Loss: 1.0375850200653076, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.1223411560058594, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.1739709377288818, Accuracy: 0.6044921875\n",
      "Batch: 36, Loss: 1.2727429866790771, Accuracy: 0.5791015625\n",
      "Batch: 37, Loss: 1.3088569641113281, Accuracy: 0.5703125\n",
      "Batch: 38, Loss: 1.1497018337249756, Accuracy: 0.5986328125\n",
      "Batch: 39, Loss: 1.0873665809631348, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.1595041751861572, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.2643457651138306, Accuracy: 0.587890625\n",
      "Batch: 42, Loss: 1.0825378894805908, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 1.1323047876358032, Accuracy: 0.6025390625\n",
      "Batch: 44, Loss: 1.0968942642211914, Accuracy: 0.6533203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 1.0787644386291504, Accuracy: 0.63671875\n",
      "Batch: 46, Loss: 1.170952320098877, Accuracy: 0.625\n",
      "Batch: 47, Loss: 1.204427719116211, Accuracy: 0.6123046875\n",
      "Batch: 48, Loss: 1.1670769453048706, Accuracy: 0.5966796875\n",
      "Batch: 49, Loss: 1.2074604034423828, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.213780164718628, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.2350478172302246, Accuracy: 0.5869140625\n",
      "Batch: 52, Loss: 1.3176078796386719, Accuracy: 0.5595703125\n",
      "Batch: 53, Loss: 1.2319576740264893, Accuracy: 0.59375\n",
      "Batch: 54, Loss: 1.2319679260253906, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.2350852489471436, Accuracy: 0.599609375\n",
      "Batch: 56, Loss: 1.133587121963501, Accuracy: 0.630859375\n",
      "Batch: 57, Loss: 1.1687302589416504, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.1975312232971191, Accuracy: 0.6162109375\n",
      "Batch: 59, Loss: 1.2101778984069824, Accuracy: 0.6064453125\n",
      "Batch: 60, Loss: 1.3111023902893066, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.1899176836013794, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.2137540578842163, Accuracy: 0.6123046875\n",
      "Batch: 63, Loss: 1.2473725080490112, Accuracy: 0.587890625\n",
      "Batch: 64, Loss: 1.2740591764450073, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.2606370449066162, Accuracy: 0.6015625\n",
      "Batch: 66, Loss: 1.2256600856781006, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.2294504642486572, Accuracy: 0.599609375\n",
      "Batch: 68, Loss: 1.1098377704620361, Accuracy: 0.6435546875\n",
      "Batch: 69, Loss: 1.2344021797180176, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.258173942565918, Accuracy: 0.5849609375\n",
      "Batch: 71, Loss: 1.237959623336792, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.2212834358215332, Accuracy: 0.6044921875\n",
      "Batch: 73, Loss: 1.3019813299179077, Accuracy: 0.5849609375\n",
      "Batch: 74, Loss: 1.0990920066833496, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.1761105060577393, Accuracy: 0.623046875\n",
      "Batch: 76, Loss: 1.1044597625732422, Accuracy: 0.6494140625\n",
      "Batch: 77, Loss: 1.0942528247833252, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.1614378690719604, Accuracy: 0.61328125\n",
      "Batch: 79, Loss: 1.2050517797470093, Accuracy: 0.6103515625\n",
      "Batch: 80, Loss: 1.2540727853775024, Accuracy: 0.59765625\n",
      "Batch: 81, Loss: 1.1573220491409302, Accuracy: 0.619140625\n",
      "Batch: 82, Loss: 1.2240980863571167, Accuracy: 0.6171875\n",
      "Batch: 83, Loss: 1.3030908107757568, Accuracy: 0.5947265625\n",
      "Batch: 84, Loss: 1.213802695274353, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.196835994720459, Accuracy: 0.625\n",
      "Batch: 86, Loss: 1.2165066003799438, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.2862557172775269, Accuracy: 0.5869140625\n",
      "Batch: 88, Loss: 1.2311069965362549, Accuracy: 0.59765625\n",
      "Batch: 89, Loss: 1.2104398012161255, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.1890337467193604, Accuracy: 0.607421875\n",
      "Batch: 91, Loss: 1.2012754678726196, Accuracy: 0.6123046875\n",
      "Batch: 92, Loss: 1.1969212293624878, Accuracy: 0.615234375\n",
      "Batch: 93, Loss: 1.228219985961914, Accuracy: 0.595703125\n",
      "Batch: 94, Loss: 1.3076382875442505, Accuracy: 0.580078125\n",
      "Batch: 95, Loss: 1.2928361892700195, Accuracy: 0.595703125\n",
      "Batch: 96, Loss: 1.2504966259002686, Accuracy: 0.6005859375\n",
      "Batch: 97, Loss: 1.2355890274047852, Accuracy: 0.5908203125\n",
      "Batch: 98, Loss: 1.1962745189666748, Accuracy: 0.6142578125\n",
      "Batch: 99, Loss: 1.2303659915924072, Accuracy: 0.6142578125\n",
      "Batch: 100, Loss: 1.1340041160583496, Accuracy: 0.625\n",
      "Batch: 101, Loss: 1.240971326828003, Accuracy: 0.611328125\n",
      "Batch: 102, Loss: 1.2591547966003418, Accuracy: 0.5966796875\n",
      "Batch: 103, Loss: 1.3052668571472168, Accuracy: 0.5966796875\n",
      "Batch: 104, Loss: 1.224034070968628, Accuracy: 0.6123046875\n",
      "Batch: 105, Loss: 1.2853565216064453, Accuracy: 0.5986328125\n",
      "Batch: 106, Loss: 1.2146081924438477, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.3024952411651611, Accuracy: 0.5634765625\n",
      "Batch: 108, Loss: 1.2290518283843994, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.2825309038162231, Accuracy: 0.576171875\n",
      "Batch: 110, Loss: 1.1822595596313477, Accuracy: 0.62109375\n",
      "Batch: 111, Loss: 1.205259919166565, Accuracy: 0.6083984375\n",
      "Batch: 112, Loss: 1.1702625751495361, Accuracy: 0.62109375\n",
      "Batch: 113, Loss: 1.1991645097732544, Accuracy: 0.6015625\n",
      "Batch: 114, Loss: 1.2050608396530151, Accuracy: 0.6220703125\n",
      "Batch: 115, Loss: 1.280726432800293, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.2615855932235718, Accuracy: 0.5859375\n",
      "Batch: 117, Loss: 1.2302327156066895, Accuracy: 0.59765625\n",
      "Batch: 118, Loss: 1.29655122756958, Accuracy: 0.5927734375\n",
      "Batch: 119, Loss: 1.2793340682983398, Accuracy: 0.5947265625\n",
      "Batch: 120, Loss: 1.3297057151794434, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.2300344705581665, Accuracy: 0.59375\n",
      "Batch: 122, Loss: 1.2655198574066162, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.3130296468734741, Accuracy: 0.5908203125\n",
      "Batch: 124, Loss: 1.3005950450897217, Accuracy: 0.5849609375\n",
      "Batch: 125, Loss: 1.2834453582763672, Accuracy: 0.5908203125\n",
      "Batch: 126, Loss: 1.2759928703308105, Accuracy: 0.5859375\n",
      "Batch: 127, Loss: 1.326029658317566, Accuracy: 0.5927734375\n",
      "Batch: 128, Loss: 1.2172772884368896, Accuracy: 0.6181640625\n",
      "Batch: 129, Loss: 1.2658767700195312, Accuracy: 0.5888671875\n",
      "Batch: 130, Loss: 1.248239278793335, Accuracy: 0.5927734375\n",
      "Batch: 131, Loss: 1.320357084274292, Accuracy: 0.580078125\n",
      "Batch: 132, Loss: 1.1660468578338623, Accuracy: 0.630859375\n",
      "Batch: 133, Loss: 1.2361772060394287, Accuracy: 0.58984375\n",
      "Batch: 134, Loss: 1.1739332675933838, Accuracy: 0.634765625\n",
      "Batch: 135, Loss: 1.1514663696289062, Accuracy: 0.6396484375\n",
      "Batch: 136, Loss: 1.1847426891326904, Accuracy: 0.61328125\n",
      "Batch: 137, Loss: 1.2146544456481934, Accuracy: 0.5849609375\n",
      "Batch: 138, Loss: 1.3012540340423584, Accuracy: 0.57421875\n",
      "Batch: 139, Loss: 1.2501615285873413, Accuracy: 0.5966796875\n",
      "Batch: 140, Loss: 1.349392294883728, Accuracy: 0.568359375\n",
      "Batch: 141, Loss: 1.2394542694091797, Accuracy: 0.587890625\n",
      "Batch: 142, Loss: 1.2200968265533447, Accuracy: 0.6142578125\n",
      "Batch: 143, Loss: 1.3017926216125488, Accuracy: 0.556640625\n",
      "Batch: 144, Loss: 1.2914502620697021, Accuracy: 0.5849609375\n",
      "Batch: 145, Loss: 1.3274774551391602, Accuracy: 0.5615234375\n",
      "Batch: 146, Loss: 1.2455965280532837, Accuracy: 0.587890625\n",
      "Batch: 147, Loss: 1.2535316944122314, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.2750986814498901, Accuracy: 0.5947265625\n",
      "Batch: 149, Loss: 1.2412800788879395, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.23655104637146, Accuracy: 0.5859375\n",
      "Batch: 151, Loss: 1.2396774291992188, Accuracy: 0.5966796875\n",
      "Batch: 152, Loss: 1.2239024639129639, Accuracy: 0.5966796875\n",
      "Batch: 153, Loss: 1.2134021520614624, Accuracy: 0.609375\n",
      "Batch: 154, Loss: 1.1902772188186646, Accuracy: 0.6103515625\n",
      "Batch: 155, Loss: 1.175166130065918, Accuracy: 0.6220703125\n",
      "Epoch 416/200\n",
      "Batch: 1, Loss: 1.2900123596191406, Accuracy: 0.6220703125\n",
      "Batch: 2, Loss: 1.0959117412567139, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0964808464050293, Accuracy: 0.65234375\n",
      "Batch: 4, Loss: 1.1167819499969482, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 1.0679240226745605, Accuracy: 0.6396484375\n",
      "Batch: 6, Loss: 1.0554771423339844, Accuracy: 0.66015625\n",
      "Batch: 7, Loss: 1.0856983661651611, Accuracy: 0.6533203125\n",
      "Batch: 8, Loss: 1.0158250331878662, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0142245292663574, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 1.0097764730453491, Accuracy: 0.671875\n",
      "Batch: 11, Loss: 1.0447355508804321, Accuracy: 0.63671875\n",
      "Batch: 12, Loss: 1.057051420211792, Accuracy: 0.64453125\n",
      "Batch: 13, Loss: 1.0420533418655396, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 1.0266854763031006, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 1.022337555885315, Accuracy: 0.65234375\n",
      "Batch: 16, Loss: 1.1053400039672852, Accuracy: 0.6494140625\n",
      "Batch: 17, Loss: 1.1411433219909668, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.172025203704834, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.223140835762024, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.1898739337921143, Accuracy: 0.6396484375\n",
      "Batch: 21, Loss: 1.1020240783691406, Accuracy: 0.6474609375\n",
      "Batch: 22, Loss: 1.320229411125183, Accuracy: 0.57421875\n",
      "Batch: 23, Loss: 1.3194198608398438, Accuracy: 0.5634765625\n",
      "Batch: 24, Loss: 1.1862329244613647, Accuracy: 0.611328125\n",
      "Batch: 25, Loss: 1.1717050075531006, Accuracy: 0.6181640625\n",
      "Batch: 26, Loss: 1.2743446826934814, Accuracy: 0.591796875\n",
      "Batch: 27, Loss: 1.1955815553665161, Accuracy: 0.60546875\n",
      "Batch: 28, Loss: 1.188547134399414, Accuracy: 0.607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 1.1211493015289307, Accuracy: 0.623046875\n",
      "Batch: 30, Loss: 1.22400963306427, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.254333257675171, Accuracy: 0.5859375\n",
      "Batch: 32, Loss: 1.1013526916503906, Accuracy: 0.623046875\n",
      "Batch: 33, Loss: 1.0757064819335938, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.1209664344787598, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.1773650646209717, Accuracy: 0.615234375\n",
      "Batch: 36, Loss: 1.2492456436157227, Accuracy: 0.6064453125\n",
      "Batch: 37, Loss: 1.2312196493148804, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.2408535480499268, Accuracy: 0.5791015625\n",
      "Batch: 39, Loss: 1.1767295598983765, Accuracy: 0.6220703125\n",
      "Batch: 40, Loss: 1.1744916439056396, Accuracy: 0.6044921875\n",
      "Batch: 41, Loss: 1.1960315704345703, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.1113133430480957, Accuracy: 0.62890625\n",
      "Batch: 43, Loss: 1.0772496461868286, Accuracy: 0.6337890625\n",
      "Batch: 44, Loss: 1.0878562927246094, Accuracy: 0.634765625\n",
      "Batch: 45, Loss: 1.1218786239624023, Accuracy: 0.619140625\n",
      "Batch: 46, Loss: 1.1648743152618408, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.1456397771835327, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1760165691375732, Accuracy: 0.6025390625\n",
      "Batch: 49, Loss: 1.201123595237732, Accuracy: 0.611328125\n",
      "Batch: 50, Loss: 1.2210891246795654, Accuracy: 0.6015625\n",
      "Batch: 51, Loss: 1.1876238584518433, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.3044025897979736, Accuracy: 0.5673828125\n",
      "Batch: 53, Loss: 1.2324702739715576, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.2123535871505737, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.1697542667388916, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.1442170143127441, Accuracy: 0.64453125\n",
      "Batch: 57, Loss: 1.2147785425186157, Accuracy: 0.6025390625\n",
      "Batch: 58, Loss: 1.1246861219406128, Accuracy: 0.6572265625\n",
      "Batch: 59, Loss: 1.1669719219207764, Accuracy: 0.6123046875\n",
      "Batch: 60, Loss: 1.2898465394973755, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.1683967113494873, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.2098959684371948, Accuracy: 0.6103515625\n",
      "Batch: 63, Loss: 1.2063922882080078, Accuracy: 0.603515625\n",
      "Batch: 64, Loss: 1.1976518630981445, Accuracy: 0.6005859375\n",
      "Batch: 65, Loss: 1.2322092056274414, Accuracy: 0.6123046875\n",
      "Batch: 66, Loss: 1.1688686609268188, Accuracy: 0.6318359375\n",
      "Batch: 67, Loss: 1.247737169265747, Accuracy: 0.60546875\n",
      "Batch: 68, Loss: 1.088042974472046, Accuracy: 0.6611328125\n",
      "Batch: 69, Loss: 1.2540379762649536, Accuracy: 0.5986328125\n",
      "Batch: 70, Loss: 1.2821599245071411, Accuracy: 0.583984375\n",
      "Batch: 71, Loss: 1.1530896425247192, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.2509171962738037, Accuracy: 0.5986328125\n",
      "Batch: 73, Loss: 1.2176462411880493, Accuracy: 0.591796875\n",
      "Batch: 74, Loss: 1.1749238967895508, Accuracy: 0.62109375\n",
      "Batch: 75, Loss: 1.1927785873413086, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.1116313934326172, Accuracy: 0.646484375\n",
      "Batch: 77, Loss: 1.1261382102966309, Accuracy: 0.634765625\n",
      "Batch: 78, Loss: 1.1474239826202393, Accuracy: 0.6123046875\n",
      "Batch: 79, Loss: 1.1433035135269165, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.2208917140960693, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.2013131380081177, Accuracy: 0.6025390625\n",
      "Batch: 82, Loss: 1.1872161626815796, Accuracy: 0.6162109375\n",
      "Batch: 83, Loss: 1.232616662979126, Accuracy: 0.591796875\n",
      "Batch: 84, Loss: 1.1862589120864868, Accuracy: 0.634765625\n",
      "Batch: 85, Loss: 1.1987409591674805, Accuracy: 0.5927734375\n",
      "Batch: 86, Loss: 1.2631206512451172, Accuracy: 0.5888671875\n",
      "Batch: 87, Loss: 1.3110616207122803, Accuracy: 0.580078125\n",
      "Batch: 88, Loss: 1.251272201538086, Accuracy: 0.6015625\n",
      "Batch: 89, Loss: 1.1907992362976074, Accuracy: 0.630859375\n",
      "Batch: 90, Loss: 1.1527148485183716, Accuracy: 0.6259765625\n",
      "Batch: 91, Loss: 1.2178618907928467, Accuracy: 0.6025390625\n",
      "Batch: 92, Loss: 1.1943656206130981, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.213089942932129, Accuracy: 0.607421875\n",
      "Batch: 94, Loss: 1.2966156005859375, Accuracy: 0.578125\n",
      "Batch: 95, Loss: 1.2325787544250488, Accuracy: 0.6044921875\n",
      "Batch: 96, Loss: 1.2344279289245605, Accuracy: 0.599609375\n",
      "Batch: 97, Loss: 1.244300127029419, Accuracy: 0.5927734375\n",
      "Batch: 98, Loss: 1.1714674234390259, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.2248945236206055, Accuracy: 0.60546875\n",
      "Batch: 100, Loss: 1.1572198867797852, Accuracy: 0.634765625\n",
      "Batch: 101, Loss: 1.1756671667099, Accuracy: 0.63671875\n",
      "Batch: 102, Loss: 1.206282138824463, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.2467552423477173, Accuracy: 0.5927734375\n",
      "Batch: 104, Loss: 1.2405171394348145, Accuracy: 0.609375\n",
      "Batch: 105, Loss: 1.2777749300003052, Accuracy: 0.591796875\n",
      "Batch: 106, Loss: 1.2277352809906006, Accuracy: 0.6044921875\n",
      "Batch: 107, Loss: 1.2659320831298828, Accuracy: 0.59375\n",
      "Batch: 108, Loss: 1.248586654663086, Accuracy: 0.5888671875\n",
      "Batch: 109, Loss: 1.2175012826919556, Accuracy: 0.6015625\n",
      "Batch: 110, Loss: 1.18852698802948, Accuracy: 0.599609375\n",
      "Batch: 111, Loss: 1.207068920135498, Accuracy: 0.62109375\n",
      "Batch: 112, Loss: 1.142741084098816, Accuracy: 0.6171875\n",
      "Batch: 113, Loss: 1.2372825145721436, Accuracy: 0.6005859375\n",
      "Batch: 114, Loss: 1.2231512069702148, Accuracy: 0.591796875\n",
      "Batch: 115, Loss: 1.3095636367797852, Accuracy: 0.5751953125\n",
      "Batch: 116, Loss: 1.2806322574615479, Accuracy: 0.576171875\n",
      "Batch: 117, Loss: 1.2377705574035645, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.2423679828643799, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.2841498851776123, Accuracy: 0.5888671875\n",
      "Batch: 120, Loss: 1.3224741220474243, Accuracy: 0.587890625\n",
      "Batch: 121, Loss: 1.2549316883087158, Accuracy: 0.599609375\n",
      "Batch: 122, Loss: 1.2275928258895874, Accuracy: 0.623046875\n",
      "Batch: 123, Loss: 1.2104194164276123, Accuracy: 0.61328125\n",
      "Batch: 124, Loss: 1.280929446220398, Accuracy: 0.583984375\n",
      "Batch: 125, Loss: 1.2540924549102783, Accuracy: 0.60546875\n",
      "Batch: 126, Loss: 1.3246538639068604, Accuracy: 0.58984375\n",
      "Batch: 127, Loss: 1.3179421424865723, Accuracy: 0.580078125\n",
      "Batch: 128, Loss: 1.2791764736175537, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.2387113571166992, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.1738626956939697, Accuracy: 0.6103515625\n",
      "Batch: 131, Loss: 1.2656002044677734, Accuracy: 0.58203125\n",
      "Batch: 132, Loss: 1.1183480024337769, Accuracy: 0.6494140625\n",
      "Batch: 133, Loss: 1.23520028591156, Accuracy: 0.5986328125\n",
      "Batch: 134, Loss: 1.171480417251587, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.147794485092163, Accuracy: 0.638671875\n",
      "Batch: 136, Loss: 1.2005499601364136, Accuracy: 0.625\n",
      "Batch: 137, Loss: 1.230194330215454, Accuracy: 0.6064453125\n",
      "Batch: 138, Loss: 1.2916933298110962, Accuracy: 0.58984375\n",
      "Batch: 139, Loss: 1.2470057010650635, Accuracy: 0.5986328125\n",
      "Batch: 140, Loss: 1.311357855796814, Accuracy: 0.5830078125\n",
      "Batch: 141, Loss: 1.2245322465896606, Accuracy: 0.6103515625\n",
      "Batch: 142, Loss: 1.2360684871673584, Accuracy: 0.6025390625\n",
      "Batch: 143, Loss: 1.2870492935180664, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.3339416980743408, Accuracy: 0.5703125\n",
      "Batch: 145, Loss: 1.3076465129852295, Accuracy: 0.572265625\n",
      "Batch: 146, Loss: 1.338226318359375, Accuracy: 0.5751953125\n",
      "Batch: 147, Loss: 1.2703328132629395, Accuracy: 0.576171875\n",
      "Batch: 148, Loss: 1.2387630939483643, Accuracy: 0.6123046875\n",
      "Batch: 149, Loss: 1.2503712177276611, Accuracy: 0.5859375\n",
      "Batch: 150, Loss: 1.215727686882019, Accuracy: 0.6025390625\n",
      "Batch: 151, Loss: 1.2627959251403809, Accuracy: 0.6025390625\n",
      "Batch: 152, Loss: 1.1931638717651367, Accuracy: 0.611328125\n",
      "Batch: 153, Loss: 1.1920671463012695, Accuracy: 0.6103515625\n",
      "Batch: 154, Loss: 1.1893198490142822, Accuracy: 0.623046875\n",
      "Batch: 155, Loss: 1.1693062782287598, Accuracy: 0.6142578125\n",
      "Epoch 417/200\n",
      "Batch: 1, Loss: 1.2947593927383423, Accuracy: 0.607421875\n",
      "Batch: 2, Loss: 1.146402359008789, Accuracy: 0.6259765625\n",
      "Batch: 3, Loss: 1.0488243103027344, Accuracy: 0.642578125\n",
      "Batch: 4, Loss: 1.1428529024124146, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0595165491104126, Accuracy: 0.646484375\n",
      "Batch: 6, Loss: 1.0820698738098145, Accuracy: 0.642578125\n",
      "Batch: 7, Loss: 1.0737141370773315, Accuracy: 0.654296875\n",
      "Batch: 8, Loss: 1.0541160106658936, Accuracy: 0.6435546875\n",
      "Batch: 9, Loss: 1.0523576736450195, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.0380125045776367, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 1.0954475402832031, Accuracy: 0.625\n",
      "Batch: 12, Loss: 1.076740026473999, Accuracy: 0.6376953125\n",
      "Batch: 13, Loss: 1.031086802482605, Accuracy: 0.671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 1.0566251277923584, Accuracy: 0.654296875\n",
      "Batch: 15, Loss: 0.9799544811248779, Accuracy: 0.662109375\n",
      "Batch: 16, Loss: 1.0810623168945312, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.1189011335372925, Accuracy: 0.6357421875\n",
      "Batch: 18, Loss: 1.1789861917495728, Accuracy: 0.6005859375\n",
      "Batch: 19, Loss: 1.2088309526443481, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.1589348316192627, Accuracy: 0.6240234375\n",
      "Batch: 21, Loss: 1.1431801319122314, Accuracy: 0.623046875\n",
      "Batch: 22, Loss: 1.30238676071167, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.298071026802063, Accuracy: 0.5810546875\n",
      "Batch: 24, Loss: 1.140690565109253, Accuracy: 0.626953125\n",
      "Batch: 25, Loss: 1.223562240600586, Accuracy: 0.6044921875\n",
      "Batch: 26, Loss: 1.2491965293884277, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.2109410762786865, Accuracy: 0.6123046875\n",
      "Batch: 28, Loss: 1.1435729265213013, Accuracy: 0.6201171875\n",
      "Batch: 29, Loss: 1.1269574165344238, Accuracy: 0.6298828125\n",
      "Batch: 30, Loss: 1.2250792980194092, Accuracy: 0.6005859375\n",
      "Batch: 31, Loss: 1.2729668617248535, Accuracy: 0.57421875\n",
      "Batch: 32, Loss: 1.1194686889648438, Accuracy: 0.634765625\n",
      "Batch: 33, Loss: 1.095302700996399, Accuracy: 0.638671875\n",
      "Batch: 34, Loss: 1.1356749534606934, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.164467453956604, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.264176368713379, Accuracy: 0.5849609375\n",
      "Batch: 37, Loss: 1.3460822105407715, Accuracy: 0.5595703125\n",
      "Batch: 38, Loss: 1.2144150733947754, Accuracy: 0.607421875\n",
      "Batch: 39, Loss: 1.1961208581924438, Accuracy: 0.609375\n",
      "Batch: 40, Loss: 1.1731699705123901, Accuracy: 0.609375\n",
      "Batch: 41, Loss: 1.2473976612091064, Accuracy: 0.5908203125\n",
      "Batch: 42, Loss: 1.0828728675842285, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0833685398101807, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.1286005973815918, Accuracy: 0.63671875\n",
      "Batch: 45, Loss: 1.0642728805541992, Accuracy: 0.6416015625\n",
      "Batch: 46, Loss: 1.1876055002212524, Accuracy: 0.619140625\n",
      "Batch: 47, Loss: 1.1229430437088013, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.203660011291504, Accuracy: 0.5947265625\n",
      "Batch: 49, Loss: 1.2574007511138916, Accuracy: 0.58984375\n",
      "Batch: 50, Loss: 1.201337456703186, Accuracy: 0.595703125\n",
      "Batch: 51, Loss: 1.2442725896835327, Accuracy: 0.5771484375\n",
      "Batch: 52, Loss: 1.2723112106323242, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.251781702041626, Accuracy: 0.5869140625\n",
      "Batch: 54, Loss: 1.227219820022583, Accuracy: 0.62109375\n",
      "Batch: 55, Loss: 1.181074857711792, Accuracy: 0.625\n",
      "Batch: 56, Loss: 1.1951816082000732, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.1564159393310547, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.1412007808685303, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.1936490535736084, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2715718746185303, Accuracy: 0.6025390625\n",
      "Batch: 61, Loss: 1.1890159845352173, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.2058241367340088, Accuracy: 0.611328125\n",
      "Batch: 63, Loss: 1.1799803972244263, Accuracy: 0.6083984375\n",
      "Batch: 64, Loss: 1.2675899267196655, Accuracy: 0.568359375\n",
      "Batch: 65, Loss: 1.2632118463516235, Accuracy: 0.5888671875\n",
      "Batch: 66, Loss: 1.2008917331695557, Accuracy: 0.6259765625\n",
      "Batch: 67, Loss: 1.2420985698699951, Accuracy: 0.587890625\n",
      "Batch: 68, Loss: 1.1402394771575928, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.163090467453003, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.2267565727233887, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1673320531845093, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.302461862564087, Accuracy: 0.5908203125\n",
      "Batch: 73, Loss: 1.3013144731521606, Accuracy: 0.57421875\n",
      "Batch: 74, Loss: 1.1258366107940674, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.1966924667358398, Accuracy: 0.6025390625\n",
      "Batch: 76, Loss: 1.128380537033081, Accuracy: 0.6376953125\n",
      "Batch: 77, Loss: 1.1461296081542969, Accuracy: 0.634765625\n",
      "Batch: 78, Loss: 1.1468323469161987, Accuracy: 0.6171875\n",
      "Batch: 79, Loss: 1.2135858535766602, Accuracy: 0.603515625\n",
      "Batch: 80, Loss: 1.2121400833129883, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.1453927755355835, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.2006347179412842, Accuracy: 0.60546875\n",
      "Batch: 83, Loss: 1.2563395500183105, Accuracy: 0.580078125\n",
      "Batch: 84, Loss: 1.2121318578720093, Accuracy: 0.607421875\n",
      "Batch: 85, Loss: 1.1945223808288574, Accuracy: 0.6025390625\n",
      "Batch: 86, Loss: 1.2671749591827393, Accuracy: 0.583984375\n",
      "Batch: 87, Loss: 1.2227706909179688, Accuracy: 0.60546875\n",
      "Batch: 88, Loss: 1.1990575790405273, Accuracy: 0.6201171875\n",
      "Batch: 89, Loss: 1.240670919418335, Accuracy: 0.6171875\n",
      "Batch: 90, Loss: 1.171911597251892, Accuracy: 0.619140625\n",
      "Batch: 91, Loss: 1.2115870714187622, Accuracy: 0.6201171875\n",
      "Batch: 92, Loss: 1.183874487876892, Accuracy: 0.615234375\n",
      "Batch: 93, Loss: 1.193279504776001, Accuracy: 0.6025390625\n",
      "Batch: 94, Loss: 1.2717329263687134, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.2069292068481445, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.312155842781067, Accuracy: 0.591796875\n",
      "Batch: 97, Loss: 1.206628441810608, Accuracy: 0.62109375\n",
      "Batch: 98, Loss: 1.2335114479064941, Accuracy: 0.607421875\n",
      "Batch: 99, Loss: 1.2196801900863647, Accuracy: 0.615234375\n",
      "Batch: 100, Loss: 1.1379750967025757, Accuracy: 0.6123046875\n",
      "Batch: 101, Loss: 1.1655749082565308, Accuracy: 0.623046875\n",
      "Batch: 102, Loss: 1.285873532295227, Accuracy: 0.5888671875\n",
      "Batch: 103, Loss: 1.185178518295288, Accuracy: 0.6279296875\n",
      "Batch: 104, Loss: 1.1898868083953857, Accuracy: 0.6103515625\n",
      "Batch: 105, Loss: 1.2858779430389404, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.2229948043823242, Accuracy: 0.6005859375\n",
      "Batch: 107, Loss: 1.3026063442230225, Accuracy: 0.5771484375\n",
      "Batch: 108, Loss: 1.2092294692993164, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.2587134838104248, Accuracy: 0.6005859375\n",
      "Batch: 110, Loss: 1.1714937686920166, Accuracy: 0.623046875\n",
      "Batch: 111, Loss: 1.2143139839172363, Accuracy: 0.5869140625\n",
      "Batch: 112, Loss: 1.2101035118103027, Accuracy: 0.599609375\n",
      "Batch: 113, Loss: 1.208800196647644, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.2216951847076416, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.2698888778686523, Accuracy: 0.58203125\n",
      "Batch: 116, Loss: 1.2159146070480347, Accuracy: 0.5966796875\n",
      "Batch: 117, Loss: 1.2365487813949585, Accuracy: 0.595703125\n",
      "Batch: 118, Loss: 1.3008856773376465, Accuracy: 0.576171875\n",
      "Batch: 119, Loss: 1.2942360639572144, Accuracy: 0.5947265625\n",
      "Batch: 120, Loss: 1.3588533401489258, Accuracy: 0.5927734375\n",
      "Batch: 121, Loss: 1.2199081182479858, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.2737627029418945, Accuracy: 0.5830078125\n",
      "Batch: 123, Loss: 1.243866205215454, Accuracy: 0.6083984375\n",
      "Batch: 124, Loss: 1.2658931016921997, Accuracy: 0.6083984375\n",
      "Batch: 125, Loss: 1.3100178241729736, Accuracy: 0.59765625\n",
      "Batch: 126, Loss: 1.310539722442627, Accuracy: 0.5771484375\n",
      "Batch: 127, Loss: 1.2546067237854004, Accuracy: 0.6005859375\n",
      "Batch: 128, Loss: 1.259269118309021, Accuracy: 0.59765625\n",
      "Batch: 129, Loss: 1.2508883476257324, Accuracy: 0.59765625\n",
      "Batch: 130, Loss: 1.2106504440307617, Accuracy: 0.6142578125\n",
      "Batch: 131, Loss: 1.25047767162323, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.1629468202590942, Accuracy: 0.6162109375\n",
      "Batch: 133, Loss: 1.2258456945419312, Accuracy: 0.6083984375\n",
      "Batch: 134, Loss: 1.2150343656539917, Accuracy: 0.62109375\n",
      "Batch: 135, Loss: 1.1231449842453003, Accuracy: 0.6259765625\n",
      "Batch: 136, Loss: 1.1587551832199097, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.239147424697876, Accuracy: 0.6162109375\n",
      "Batch: 138, Loss: 1.319088339805603, Accuracy: 0.595703125\n",
      "Batch: 139, Loss: 1.316365122795105, Accuracy: 0.5732421875\n",
      "Batch: 140, Loss: 1.2938750982284546, Accuracy: 0.6015625\n",
      "Batch: 141, Loss: 1.2078721523284912, Accuracy: 0.6044921875\n",
      "Batch: 142, Loss: 1.1988813877105713, Accuracy: 0.6279296875\n",
      "Batch: 143, Loss: 1.2785546779632568, Accuracy: 0.5791015625\n",
      "Batch: 144, Loss: 1.3157092332839966, Accuracy: 0.5927734375\n",
      "Batch: 145, Loss: 1.289473533630371, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.3043208122253418, Accuracy: 0.5771484375\n",
      "Batch: 147, Loss: 1.2302628755569458, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.31007719039917, Accuracy: 0.5771484375\n",
      "Batch: 149, Loss: 1.2136859893798828, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.2231676578521729, Accuracy: 0.6025390625\n",
      "Batch: 151, Loss: 1.142115592956543, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.2308430671691895, Accuracy: 0.58203125\n",
      "Batch: 153, Loss: 1.2356581687927246, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 154, Loss: 1.168912649154663, Accuracy: 0.6181640625\n",
      "Batch: 155, Loss: 1.1592497825622559, Accuracy: 0.619140625\n",
      "Epoch 418/200\n",
      "Batch: 1, Loss: 1.3061057329177856, Accuracy: 0.6103515625\n",
      "Batch: 2, Loss: 1.133272409439087, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.074965000152588, Accuracy: 0.64453125\n",
      "Batch: 4, Loss: 1.1261018514633179, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0352809429168701, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.0757087469100952, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 1.0689846277236938, Accuracy: 0.6435546875\n",
      "Batch: 8, Loss: 1.0281189680099487, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 1.0162757635116577, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 1.0429658889770508, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9880988597869873, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.0304038524627686, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 1.0339841842651367, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 1.0192813873291016, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.951383113861084, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.089917778968811, Accuracy: 0.6416015625\n",
      "Batch: 17, Loss: 1.093796968460083, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.1848955154418945, Accuracy: 0.619140625\n",
      "Batch: 19, Loss: 1.2425811290740967, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.1578643321990967, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.0822038650512695, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.294645071029663, Accuracy: 0.5927734375\n",
      "Batch: 23, Loss: 1.2972034215927124, Accuracy: 0.560546875\n",
      "Batch: 24, Loss: 1.2198189496994019, Accuracy: 0.6103515625\n",
      "Batch: 25, Loss: 1.2323694229125977, Accuracy: 0.5966796875\n",
      "Batch: 26, Loss: 1.2423607110977173, Accuracy: 0.5859375\n",
      "Batch: 27, Loss: 1.1798226833343506, Accuracy: 0.609375\n",
      "Batch: 28, Loss: 1.1064372062683105, Accuracy: 0.625\n",
      "Batch: 29, Loss: 1.1244983673095703, Accuracy: 0.6142578125\n",
      "Batch: 30, Loss: 1.2124278545379639, Accuracy: 0.5908203125\n",
      "Batch: 31, Loss: 1.2167805433273315, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.107511281967163, Accuracy: 0.6357421875\n",
      "Batch: 33, Loss: 1.0380444526672363, Accuracy: 0.642578125\n",
      "Batch: 34, Loss: 1.0601297616958618, Accuracy: 0.6640625\n",
      "Batch: 35, Loss: 1.1419529914855957, Accuracy: 0.6357421875\n",
      "Batch: 36, Loss: 1.272116780281067, Accuracy: 0.578125\n",
      "Batch: 37, Loss: 1.2623249292373657, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.1943421363830566, Accuracy: 0.591796875\n",
      "Batch: 39, Loss: 1.1339281797409058, Accuracy: 0.6240234375\n",
      "Batch: 40, Loss: 1.1785252094268799, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.1933882236480713, Accuracy: 0.60546875\n",
      "Batch: 42, Loss: 1.1428799629211426, Accuracy: 0.60546875\n",
      "Batch: 43, Loss: 1.1472880840301514, Accuracy: 0.619140625\n",
      "Batch: 44, Loss: 1.134239673614502, Accuracy: 0.6357421875\n",
      "Batch: 45, Loss: 1.0803368091583252, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.1874018907546997, Accuracy: 0.6328125\n",
      "Batch: 47, Loss: 1.172210693359375, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.1864360570907593, Accuracy: 0.609375\n",
      "Batch: 49, Loss: 1.2939594984054565, Accuracy: 0.603515625\n",
      "Batch: 50, Loss: 1.185788869857788, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.2043721675872803, Accuracy: 0.599609375\n",
      "Batch: 52, Loss: 1.2839685678482056, Accuracy: 0.576171875\n",
      "Batch: 53, Loss: 1.2243194580078125, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.2283923625946045, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.1804101467132568, Accuracy: 0.6181640625\n",
      "Batch: 56, Loss: 1.1254220008850098, Accuracy: 0.6552734375\n",
      "Batch: 57, Loss: 1.186302900314331, Accuracy: 0.623046875\n",
      "Batch: 58, Loss: 1.1937634944915771, Accuracy: 0.6181640625\n",
      "Batch: 59, Loss: 1.1624772548675537, Accuracy: 0.6220703125\n",
      "Batch: 60, Loss: 1.3002204895019531, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.2707805633544922, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.2295647859573364, Accuracy: 0.609375\n",
      "Batch: 63, Loss: 1.2011338472366333, Accuracy: 0.611328125\n",
      "Batch: 64, Loss: 1.2611651420593262, Accuracy: 0.59765625\n",
      "Batch: 65, Loss: 1.2310168743133545, Accuracy: 0.5966796875\n",
      "Batch: 66, Loss: 1.227095603942871, Accuracy: 0.609375\n",
      "Batch: 67, Loss: 1.203645944595337, Accuracy: 0.60546875\n",
      "Batch: 68, Loss: 1.11709725856781, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.2220239639282227, Accuracy: 0.6171875\n",
      "Batch: 70, Loss: 1.2055484056472778, Accuracy: 0.611328125\n",
      "Batch: 71, Loss: 1.247307538986206, Accuracy: 0.595703125\n",
      "Batch: 72, Loss: 1.2703301906585693, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.2068437337875366, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.1273137331008911, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.1884257793426514, Accuracy: 0.5966796875\n",
      "Batch: 76, Loss: 1.138096809387207, Accuracy: 0.6162109375\n",
      "Batch: 77, Loss: 1.1051104068756104, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.1493654251098633, Accuracy: 0.6162109375\n",
      "Batch: 79, Loss: 1.1906392574310303, Accuracy: 0.59375\n",
      "Batch: 80, Loss: 1.19899320602417, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.1932339668273926, Accuracy: 0.615234375\n",
      "Batch: 82, Loss: 1.1675381660461426, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.2272212505340576, Accuracy: 0.6015625\n",
      "Batch: 84, Loss: 1.197058081626892, Accuracy: 0.6162109375\n",
      "Batch: 85, Loss: 1.2196002006530762, Accuracy: 0.6083984375\n",
      "Batch: 86, Loss: 1.2502118349075317, Accuracy: 0.6044921875\n",
      "Batch: 87, Loss: 1.2586859464645386, Accuracy: 0.5849609375\n",
      "Batch: 88, Loss: 1.2478406429290771, Accuracy: 0.6123046875\n",
      "Batch: 89, Loss: 1.2143020629882812, Accuracy: 0.6103515625\n",
      "Batch: 90, Loss: 1.1780370473861694, Accuracy: 0.6162109375\n",
      "Batch: 91, Loss: 1.1918529272079468, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.2285585403442383, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.2269105911254883, Accuracy: 0.603515625\n",
      "Batch: 94, Loss: 1.2333009243011475, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.213517665863037, Accuracy: 0.6240234375\n",
      "Batch: 96, Loss: 1.3021559715270996, Accuracy: 0.583984375\n",
      "Batch: 97, Loss: 1.2620861530303955, Accuracy: 0.5751953125\n",
      "Batch: 98, Loss: 1.1655001640319824, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.1988048553466797, Accuracy: 0.595703125\n",
      "Batch: 100, Loss: 1.139167070388794, Accuracy: 0.6171875\n",
      "Batch: 101, Loss: 1.176938533782959, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.2553917169570923, Accuracy: 0.599609375\n",
      "Batch: 103, Loss: 1.2026238441467285, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.2257661819458008, Accuracy: 0.611328125\n",
      "Batch: 105, Loss: 1.2524914741516113, Accuracy: 0.6015625\n",
      "Batch: 106, Loss: 1.2946908473968506, Accuracy: 0.587890625\n",
      "Batch: 107, Loss: 1.343106746673584, Accuracy: 0.5791015625\n",
      "Batch: 108, Loss: 1.222604513168335, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.258095383644104, Accuracy: 0.583984375\n",
      "Batch: 110, Loss: 1.2303320169448853, Accuracy: 0.6005859375\n",
      "Batch: 111, Loss: 1.2036603689193726, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.1901599168777466, Accuracy: 0.6083984375\n",
      "Batch: 113, Loss: 1.2228063344955444, Accuracy: 0.5908203125\n",
      "Batch: 114, Loss: 1.1970114707946777, Accuracy: 0.6005859375\n",
      "Batch: 115, Loss: 1.231742262840271, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.2165298461914062, Accuracy: 0.591796875\n",
      "Batch: 117, Loss: 1.246751070022583, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.2578885555267334, Accuracy: 0.5888671875\n",
      "Batch: 119, Loss: 1.2324409484863281, Accuracy: 0.6220703125\n",
      "Batch: 120, Loss: 1.3576668500900269, Accuracy: 0.564453125\n",
      "Batch: 121, Loss: 1.2434707880020142, Accuracy: 0.595703125\n",
      "Batch: 122, Loss: 1.2619779109954834, Accuracy: 0.5927734375\n",
      "Batch: 123, Loss: 1.2239140272140503, Accuracy: 0.6005859375\n",
      "Batch: 124, Loss: 1.2518894672393799, Accuracy: 0.5947265625\n",
      "Batch: 125, Loss: 1.2548778057098389, Accuracy: 0.58984375\n",
      "Batch: 126, Loss: 1.3152366876602173, Accuracy: 0.5947265625\n",
      "Batch: 127, Loss: 1.3120691776275635, Accuracy: 0.5693359375\n",
      "Batch: 128, Loss: 1.2571313381195068, Accuracy: 0.5888671875\n",
      "Batch: 129, Loss: 1.2945964336395264, Accuracy: 0.57421875\n",
      "Batch: 130, Loss: 1.1504961252212524, Accuracy: 0.623046875\n",
      "Batch: 131, Loss: 1.2696216106414795, Accuracy: 0.5927734375\n",
      "Batch: 132, Loss: 1.1309001445770264, Accuracy: 0.646484375\n",
      "Batch: 133, Loss: 1.2581384181976318, Accuracy: 0.603515625\n",
      "Batch: 134, Loss: 1.1574596166610718, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.0989024639129639, Accuracy: 0.6357421875\n",
      "Batch: 136, Loss: 1.1173129081726074, Accuracy: 0.6318359375\n",
      "Batch: 137, Loss: 1.216485619544983, Accuracy: 0.6005859375\n",
      "Batch: 138, Loss: 1.2615045309066772, Accuracy: 0.5908203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 1.2402129173278809, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.3346431255340576, Accuracy: 0.5771484375\n",
      "Batch: 141, Loss: 1.229940414428711, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.2875887155532837, Accuracy: 0.5791015625\n",
      "Batch: 143, Loss: 1.3400249481201172, Accuracy: 0.5556640625\n",
      "Batch: 144, Loss: 1.3363463878631592, Accuracy: 0.564453125\n",
      "Batch: 145, Loss: 1.3455555438995361, Accuracy: 0.55859375\n",
      "Batch: 146, Loss: 1.2782979011535645, Accuracy: 0.580078125\n",
      "Batch: 147, Loss: 1.3170583248138428, Accuracy: 0.5791015625\n",
      "Batch: 148, Loss: 1.2588704824447632, Accuracy: 0.5927734375\n",
      "Batch: 149, Loss: 1.2194669246673584, Accuracy: 0.6162109375\n",
      "Batch: 150, Loss: 1.1659815311431885, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.2111256122589111, Accuracy: 0.6025390625\n",
      "Batch: 152, Loss: 1.2205238342285156, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.1957018375396729, Accuracy: 0.6123046875\n",
      "Batch: 154, Loss: 1.1756796836853027, Accuracy: 0.609375\n",
      "Batch: 155, Loss: 1.1845495700836182, Accuracy: 0.638671875\n",
      "Epoch 419/200\n",
      "Batch: 1, Loss: 1.2720354795455933, Accuracy: 0.6181640625\n",
      "Batch: 2, Loss: 1.1018483638763428, Accuracy: 0.6533203125\n",
      "Batch: 3, Loss: 1.1022238731384277, Accuracy: 0.6318359375\n",
      "Batch: 4, Loss: 1.1241271495819092, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0465936660766602, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0670137405395508, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 1.0516958236694336, Accuracy: 0.6572265625\n",
      "Batch: 8, Loss: 1.0353658199310303, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0522372722625732, Accuracy: 0.650390625\n",
      "Batch: 10, Loss: 1.0300662517547607, Accuracy: 0.638671875\n",
      "Batch: 11, Loss: 1.0193411111831665, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 1.0877254009246826, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 1.056897521018982, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 1.0077102184295654, Accuracy: 0.66796875\n",
      "Batch: 15, Loss: 0.9986735582351685, Accuracy: 0.6630859375\n",
      "Batch: 16, Loss: 1.1173372268676758, Accuracy: 0.6416015625\n",
      "Batch: 17, Loss: 1.1209490299224854, Accuracy: 0.6318359375\n",
      "Batch: 18, Loss: 1.139892339706421, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2470526695251465, Accuracy: 0.59375\n",
      "Batch: 20, Loss: 1.1339201927185059, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.136260986328125, Accuracy: 0.6494140625\n",
      "Batch: 22, Loss: 1.2933316230773926, Accuracy: 0.5771484375\n",
      "Batch: 23, Loss: 1.2992188930511475, Accuracy: 0.5869140625\n",
      "Batch: 24, Loss: 1.1973199844360352, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.2074717283248901, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.238213062286377, Accuracy: 0.607421875\n",
      "Batch: 27, Loss: 1.1832756996154785, Accuracy: 0.5830078125\n",
      "Batch: 28, Loss: 1.1420117616653442, Accuracy: 0.619140625\n",
      "Batch: 29, Loss: 1.14211905002594, Accuracy: 0.625\n",
      "Batch: 30, Loss: 1.2484173774719238, Accuracy: 0.591796875\n",
      "Batch: 31, Loss: 1.2422927618026733, Accuracy: 0.5888671875\n",
      "Batch: 32, Loss: 1.1353181600570679, Accuracy: 0.6328125\n",
      "Batch: 33, Loss: 1.0496845245361328, Accuracy: 0.6552734375\n",
      "Batch: 34, Loss: 1.116469383239746, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.1287012100219727, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.2334271669387817, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.250563621520996, Accuracy: 0.583984375\n",
      "Batch: 38, Loss: 1.2204551696777344, Accuracy: 0.5966796875\n",
      "Batch: 39, Loss: 1.1834678649902344, Accuracy: 0.6201171875\n",
      "Batch: 40, Loss: 1.1077412366867065, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.180736780166626, Accuracy: 0.5947265625\n",
      "Batch: 42, Loss: 1.1035032272338867, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.091431736946106, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.0688846111297607, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0820178985595703, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.1546380519866943, Accuracy: 0.6083984375\n",
      "Batch: 47, Loss: 1.1176679134368896, Accuracy: 0.634765625\n",
      "Batch: 48, Loss: 1.2145395278930664, Accuracy: 0.6064453125\n",
      "Batch: 49, Loss: 1.2501612901687622, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.214052438735962, Accuracy: 0.607421875\n",
      "Batch: 51, Loss: 1.191091537475586, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.2467514276504517, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.2280769348144531, Accuracy: 0.5986328125\n",
      "Batch: 54, Loss: 1.276287317276001, Accuracy: 0.6005859375\n",
      "Batch: 55, Loss: 1.224524974822998, Accuracy: 0.607421875\n",
      "Batch: 56, Loss: 1.22273850440979, Accuracy: 0.61328125\n",
      "Batch: 57, Loss: 1.2213094234466553, Accuracy: 0.6162109375\n",
      "Batch: 58, Loss: 1.193642020225525, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.1651769876480103, Accuracy: 0.6201171875\n",
      "Batch: 60, Loss: 1.2449135780334473, Accuracy: 0.6015625\n",
      "Batch: 61, Loss: 1.2324105501174927, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.261580467224121, Accuracy: 0.58984375\n",
      "Batch: 63, Loss: 1.2457565069198608, Accuracy: 0.60546875\n",
      "Batch: 64, Loss: 1.2705658674240112, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.2568092346191406, Accuracy: 0.5927734375\n",
      "Batch: 66, Loss: 1.1759419441223145, Accuracy: 0.6142578125\n",
      "Batch: 67, Loss: 1.1533637046813965, Accuracy: 0.634765625\n",
      "Batch: 68, Loss: 1.2051475048065186, Accuracy: 0.615234375\n",
      "Batch: 69, Loss: 1.2434194087982178, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.261247158050537, Accuracy: 0.6025390625\n",
      "Batch: 71, Loss: 1.184577465057373, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.2757643461227417, Accuracy: 0.5908203125\n",
      "Batch: 73, Loss: 1.249812364578247, Accuracy: 0.595703125\n",
      "Batch: 74, Loss: 1.1701027154922485, Accuracy: 0.60546875\n",
      "Batch: 75, Loss: 1.1821119785308838, Accuracy: 0.5908203125\n",
      "Batch: 76, Loss: 1.123841643333435, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.1324374675750732, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.1195919513702393, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.2283542156219482, Accuracy: 0.6123046875\n",
      "Batch: 80, Loss: 1.2448780536651611, Accuracy: 0.6025390625\n",
      "Batch: 81, Loss: 1.1795117855072021, Accuracy: 0.625\n",
      "Batch: 82, Loss: 1.205597162246704, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.317986249923706, Accuracy: 0.5830078125\n",
      "Batch: 84, Loss: 1.1824376583099365, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.2242321968078613, Accuracy: 0.60546875\n",
      "Batch: 86, Loss: 1.221520185470581, Accuracy: 0.59765625\n",
      "Batch: 87, Loss: 1.2547355890274048, Accuracy: 0.58984375\n",
      "Batch: 88, Loss: 1.2451324462890625, Accuracy: 0.609375\n",
      "Batch: 89, Loss: 1.264145851135254, Accuracy: 0.6025390625\n",
      "Batch: 90, Loss: 1.1299610137939453, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.2302095890045166, Accuracy: 0.6005859375\n",
      "Batch: 92, Loss: 1.2019505500793457, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.2017322778701782, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.306414008140564, Accuracy: 0.5751953125\n",
      "Batch: 95, Loss: 1.2597684860229492, Accuracy: 0.5927734375\n",
      "Batch: 96, Loss: 1.2841594219207764, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.215922474861145, Accuracy: 0.607421875\n",
      "Batch: 98, Loss: 1.1216267347335815, Accuracy: 0.64453125\n",
      "Batch: 99, Loss: 1.1967241764068604, Accuracy: 0.619140625\n",
      "Batch: 100, Loss: 1.1678998470306396, Accuracy: 0.609375\n",
      "Batch: 101, Loss: 1.1884742975234985, Accuracy: 0.6162109375\n",
      "Batch: 102, Loss: 1.2330187559127808, Accuracy: 0.59765625\n",
      "Batch: 103, Loss: 1.2305938005447388, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.2128627300262451, Accuracy: 0.60546875\n",
      "Batch: 105, Loss: 1.2865151166915894, Accuracy: 0.59375\n",
      "Batch: 106, Loss: 1.2117195129394531, Accuracy: 0.6083984375\n",
      "Batch: 107, Loss: 1.2366443872451782, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.2076926231384277, Accuracy: 0.6162109375\n",
      "Batch: 109, Loss: 1.2731027603149414, Accuracy: 0.6015625\n",
      "Batch: 110, Loss: 1.2437124252319336, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.150707483291626, Accuracy: 0.6435546875\n",
      "Batch: 112, Loss: 1.1342761516571045, Accuracy: 0.6416015625\n",
      "Batch: 113, Loss: 1.2358473539352417, Accuracy: 0.5966796875\n",
      "Batch: 114, Loss: 1.259145975112915, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.200250506401062, Accuracy: 0.61328125\n",
      "Batch: 116, Loss: 1.313768744468689, Accuracy: 0.578125\n",
      "Batch: 117, Loss: 1.1625034809112549, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.2781789302825928, Accuracy: 0.595703125\n",
      "Batch: 119, Loss: 1.2654041051864624, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.3569176197052002, Accuracy: 0.576171875\n",
      "Batch: 121, Loss: 1.2550088167190552, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.2262734174728394, Accuracy: 0.6005859375\n",
      "Batch: 123, Loss: 1.2224681377410889, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 1.2587954998016357, Accuracy: 0.611328125\n",
      "Batch: 125, Loss: 1.2208064794540405, Accuracy: 0.61328125\n",
      "Batch: 126, Loss: 1.2498525381088257, Accuracy: 0.5986328125\n",
      "Batch: 127, Loss: 1.294147253036499, Accuracy: 0.5791015625\n",
      "Batch: 128, Loss: 1.2630703449249268, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.2377010583877563, Accuracy: 0.6171875\n",
      "Batch: 130, Loss: 1.183005690574646, Accuracy: 0.61328125\n",
      "Batch: 131, Loss: 1.251579999923706, Accuracy: 0.5703125\n",
      "Batch: 132, Loss: 1.1652003526687622, Accuracy: 0.626953125\n",
      "Batch: 133, Loss: 1.1954686641693115, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.2195041179656982, Accuracy: 0.6123046875\n",
      "Batch: 135, Loss: 1.1398530006408691, Accuracy: 0.6376953125\n",
      "Batch: 136, Loss: 1.1393998861312866, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.2522975206375122, Accuracy: 0.591796875\n",
      "Batch: 138, Loss: 1.3251584768295288, Accuracy: 0.5791015625\n",
      "Batch: 139, Loss: 1.2164033651351929, Accuracy: 0.607421875\n",
      "Batch: 140, Loss: 1.3221031427383423, Accuracy: 0.556640625\n",
      "Batch: 141, Loss: 1.2132959365844727, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2856459617614746, Accuracy: 0.6103515625\n",
      "Batch: 143, Loss: 1.2607203722000122, Accuracy: 0.5908203125\n",
      "Batch: 144, Loss: 1.3426648378372192, Accuracy: 0.5673828125\n",
      "Batch: 145, Loss: 1.32582426071167, Accuracy: 0.5732421875\n",
      "Batch: 146, Loss: 1.2505955696105957, Accuracy: 0.5751953125\n",
      "Batch: 147, Loss: 1.24570631980896, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.233971357345581, Accuracy: 0.6123046875\n",
      "Batch: 149, Loss: 1.2318623065948486, Accuracy: 0.5849609375\n",
      "Batch: 150, Loss: 1.1787981986999512, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.158507227897644, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.2746552228927612, Accuracy: 0.59765625\n",
      "Batch: 153, Loss: 1.1812156438827515, Accuracy: 0.62109375\n",
      "Batch: 154, Loss: 1.2148022651672363, Accuracy: 0.6083984375\n",
      "Batch: 155, Loss: 1.125004529953003, Accuracy: 0.6259765625\n",
      "Epoch 420/200\n",
      "Batch: 1, Loss: 1.2838127613067627, Accuracy: 0.62109375\n",
      "Batch: 2, Loss: 1.1561133861541748, Accuracy: 0.6123046875\n",
      "Batch: 3, Loss: 1.0676143169403076, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.1371920108795166, Accuracy: 0.6181640625\n",
      "Batch: 5, Loss: 1.014650583267212, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0755627155303955, Accuracy: 0.638671875\n",
      "Batch: 7, Loss: 1.0249552726745605, Accuracy: 0.62890625\n",
      "Batch: 8, Loss: 1.028433084487915, Accuracy: 0.677734375\n",
      "Batch: 9, Loss: 1.0394327640533447, Accuracy: 0.6533203125\n",
      "Batch: 10, Loss: 1.0173842906951904, Accuracy: 0.650390625\n",
      "Batch: 11, Loss: 1.052307367324829, Accuracy: 0.66796875\n",
      "Batch: 12, Loss: 1.0522593259811401, Accuracy: 0.64453125\n",
      "Batch: 13, Loss: 1.0736653804779053, Accuracy: 0.6552734375\n",
      "Batch: 14, Loss: 1.0029821395874023, Accuracy: 0.669921875\n",
      "Batch: 15, Loss: 0.9747536778450012, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.15439772605896, Accuracy: 0.6357421875\n",
      "Batch: 17, Loss: 1.1271765232086182, Accuracy: 0.6328125\n",
      "Batch: 18, Loss: 1.140451192855835, Accuracy: 0.6455078125\n",
      "Batch: 19, Loss: 1.2276538610458374, Accuracy: 0.60546875\n",
      "Batch: 20, Loss: 1.1500893831253052, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.1070210933685303, Accuracy: 0.638671875\n",
      "Batch: 22, Loss: 1.2524840831756592, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.2978594303131104, Accuracy: 0.587890625\n",
      "Batch: 24, Loss: 1.1804916858673096, Accuracy: 0.619140625\n",
      "Batch: 25, Loss: 1.1918290853500366, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.2472116947174072, Accuracy: 0.5947265625\n",
      "Batch: 27, Loss: 1.2464888095855713, Accuracy: 0.6044921875\n",
      "Batch: 28, Loss: 1.1232683658599854, Accuracy: 0.6396484375\n",
      "Batch: 29, Loss: 1.1849031448364258, Accuracy: 0.6142578125\n",
      "Batch: 30, Loss: 1.192537784576416, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.2037160396575928, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.085738182067871, Accuracy: 0.6357421875\n",
      "Batch: 33, Loss: 1.051870346069336, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.182139277458191, Accuracy: 0.626953125\n",
      "Batch: 35, Loss: 1.113356113433838, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.2137725353240967, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.2138786315917969, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.192378044128418, Accuracy: 0.5986328125\n",
      "Batch: 39, Loss: 1.1084568500518799, Accuracy: 0.6240234375\n",
      "Batch: 40, Loss: 1.171921968460083, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1684467792510986, Accuracy: 0.6142578125\n",
      "Batch: 42, Loss: 1.1300208568572998, Accuracy: 0.634765625\n",
      "Batch: 43, Loss: 1.1404850482940674, Accuracy: 0.6083984375\n",
      "Batch: 44, Loss: 1.0819201469421387, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 1.062941312789917, Accuracy: 0.6494140625\n",
      "Batch: 46, Loss: 1.2224469184875488, Accuracy: 0.60546875\n",
      "Batch: 47, Loss: 1.1528198719024658, Accuracy: 0.6259765625\n",
      "Batch: 48, Loss: 1.1709518432617188, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.2422246932983398, Accuracy: 0.6044921875\n",
      "Batch: 50, Loss: 1.114935278892517, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.2234406471252441, Accuracy: 0.58984375\n",
      "Batch: 52, Loss: 1.285459280014038, Accuracy: 0.564453125\n",
      "Batch: 53, Loss: 1.2517735958099365, Accuracy: 0.59375\n",
      "Batch: 54, Loss: 1.216782569885254, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.16280996799469, Accuracy: 0.6279296875\n",
      "Batch: 56, Loss: 1.1231727600097656, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1842622756958008, Accuracy: 0.6171875\n",
      "Batch: 58, Loss: 1.1956117153167725, Accuracy: 0.62109375\n",
      "Batch: 59, Loss: 1.1812162399291992, Accuracy: 0.61328125\n",
      "Batch: 60, Loss: 1.2682243585586548, Accuracy: 0.6015625\n",
      "Batch: 61, Loss: 1.1870181560516357, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.2547028064727783, Accuracy: 0.5927734375\n",
      "Batch: 63, Loss: 1.2549920082092285, Accuracy: 0.59765625\n",
      "Batch: 64, Loss: 1.236441731452942, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.2328872680664062, Accuracy: 0.6005859375\n",
      "Batch: 66, Loss: 1.2202980518341064, Accuracy: 0.6025390625\n",
      "Batch: 67, Loss: 1.21976637840271, Accuracy: 0.6123046875\n",
      "Batch: 68, Loss: 1.1235946416854858, Accuracy: 0.6328125\n",
      "Batch: 69, Loss: 1.2089264392852783, Accuracy: 0.615234375\n",
      "Batch: 70, Loss: 1.2171053886413574, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.2274991273880005, Accuracy: 0.59765625\n",
      "Batch: 72, Loss: 1.2967169284820557, Accuracy: 0.5703125\n",
      "Batch: 73, Loss: 1.1809141635894775, Accuracy: 0.6025390625\n",
      "Batch: 74, Loss: 1.2325941324234009, Accuracy: 0.595703125\n",
      "Batch: 75, Loss: 1.1586593389511108, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.0996170043945312, Accuracy: 0.630859375\n",
      "Batch: 77, Loss: 1.1392221450805664, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.114057183265686, Accuracy: 0.6240234375\n",
      "Batch: 79, Loss: 1.1886082887649536, Accuracy: 0.6044921875\n",
      "Batch: 80, Loss: 1.198507308959961, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.169127106666565, Accuracy: 0.62109375\n",
      "Batch: 82, Loss: 1.1991833448410034, Accuracy: 0.6162109375\n",
      "Batch: 83, Loss: 1.2458056211471558, Accuracy: 0.5869140625\n",
      "Batch: 84, Loss: 1.172662615776062, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.1829311847686768, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.2313339710235596, Accuracy: 0.603515625\n",
      "Batch: 87, Loss: 1.2558445930480957, Accuracy: 0.6025390625\n",
      "Batch: 88, Loss: 1.2330999374389648, Accuracy: 0.591796875\n",
      "Batch: 89, Loss: 1.1642274856567383, Accuracy: 0.61328125\n",
      "Batch: 90, Loss: 1.1744847297668457, Accuracy: 0.6083984375\n",
      "Batch: 91, Loss: 1.230363130569458, Accuracy: 0.595703125\n",
      "Batch: 92, Loss: 1.178001880645752, Accuracy: 0.6396484375\n",
      "Batch: 93, Loss: 1.1959813833236694, Accuracy: 0.6181640625\n",
      "Batch: 94, Loss: 1.2189286947250366, Accuracy: 0.6162109375\n",
      "Batch: 95, Loss: 1.24331796169281, Accuracy: 0.5966796875\n",
      "Batch: 96, Loss: 1.2095632553100586, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.23320734500885, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1903786659240723, Accuracy: 0.615234375\n",
      "Batch: 99, Loss: 1.2204504013061523, Accuracy: 0.609375\n",
      "Batch: 100, Loss: 1.1035137176513672, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.1461366415023804, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.1986454725265503, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.2073509693145752, Accuracy: 0.607421875\n",
      "Batch: 104, Loss: 1.2105076313018799, Accuracy: 0.6259765625\n",
      "Batch: 105, Loss: 1.275951623916626, Accuracy: 0.6025390625\n",
      "Batch: 106, Loss: 1.195928931236267, Accuracy: 0.6044921875\n",
      "Batch: 107, Loss: 1.2630953788757324, Accuracy: 0.591796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 1.2350540161132812, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.234165906906128, Accuracy: 0.5830078125\n",
      "Batch: 110, Loss: 1.1961448192596436, Accuracy: 0.6083984375\n",
      "Batch: 111, Loss: 1.1902469396591187, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.1384758949279785, Accuracy: 0.619140625\n",
      "Batch: 113, Loss: 1.1659090518951416, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.2152127027511597, Accuracy: 0.599609375\n",
      "Batch: 115, Loss: 1.2329437732696533, Accuracy: 0.5849609375\n",
      "Batch: 116, Loss: 1.2061090469360352, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.1959445476531982, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.2094616889953613, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.2754950523376465, Accuracy: 0.6005859375\n",
      "Batch: 120, Loss: 1.327417254447937, Accuracy: 0.59765625\n",
      "Batch: 121, Loss: 1.284604549407959, Accuracy: 0.6005859375\n",
      "Batch: 122, Loss: 1.2680730819702148, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.2504818439483643, Accuracy: 0.59765625\n",
      "Batch: 124, Loss: 1.202866554260254, Accuracy: 0.6025390625\n",
      "Batch: 125, Loss: 1.1699433326721191, Accuracy: 0.6318359375\n",
      "Batch: 126, Loss: 1.2351224422454834, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.3057146072387695, Accuracy: 0.5908203125\n",
      "Batch: 128, Loss: 1.1939120292663574, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.2236132621765137, Accuracy: 0.6103515625\n",
      "Batch: 130, Loss: 1.2286179065704346, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.2760193347930908, Accuracy: 0.5986328125\n",
      "Batch: 132, Loss: 1.1450880765914917, Accuracy: 0.6259765625\n",
      "Batch: 133, Loss: 1.2295491695404053, Accuracy: 0.5986328125\n",
      "Batch: 134, Loss: 1.1279816627502441, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.0945539474487305, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.1735734939575195, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1789605617523193, Accuracy: 0.6044921875\n",
      "Batch: 138, Loss: 1.2978956699371338, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.2619528770446777, Accuracy: 0.6044921875\n",
      "Batch: 140, Loss: 1.2945575714111328, Accuracy: 0.6025390625\n",
      "Batch: 141, Loss: 1.1847467422485352, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.218930959701538, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.2488927841186523, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.327874779701233, Accuracy: 0.560546875\n",
      "Batch: 145, Loss: 1.320617437362671, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.3326655626296997, Accuracy: 0.5791015625\n",
      "Batch: 147, Loss: 1.2455298900604248, Accuracy: 0.62109375\n",
      "Batch: 148, Loss: 1.2550501823425293, Accuracy: 0.5869140625\n",
      "Batch: 149, Loss: 1.2251031398773193, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.1714372634887695, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.2633326053619385, Accuracy: 0.5888671875\n",
      "Batch: 152, Loss: 1.206146240234375, Accuracy: 0.607421875\n",
      "Batch: 153, Loss: 1.1527900695800781, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1928879022598267, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.1260590553283691, Accuracy: 0.6357421875\n",
      "Saved Weights at epoch 420 to file Weights_420.h5\n",
      "Epoch 421/200\n",
      "Batch: 1, Loss: 1.2855639457702637, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.146042823791504, Accuracy: 0.62109375\n",
      "Batch: 3, Loss: 1.0921423435211182, Accuracy: 0.6396484375\n",
      "Batch: 4, Loss: 1.167607307434082, Accuracy: 0.6220703125\n",
      "Batch: 5, Loss: 1.0499582290649414, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.062241554260254, Accuracy: 0.6708984375\n",
      "Batch: 7, Loss: 1.0510958433151245, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 1.0720198154449463, Accuracy: 0.6650390625\n",
      "Batch: 9, Loss: 1.0332566499710083, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 1.0693790912628174, Accuracy: 0.6435546875\n",
      "Batch: 11, Loss: 1.0827598571777344, Accuracy: 0.6484375\n",
      "Batch: 12, Loss: 1.0272974967956543, Accuracy: 0.6728515625\n",
      "Batch: 13, Loss: 1.0658960342407227, Accuracy: 0.6513671875\n",
      "Batch: 14, Loss: 1.028597354888916, Accuracy: 0.66015625\n",
      "Batch: 15, Loss: 1.008545994758606, Accuracy: 0.65625\n",
      "Batch: 16, Loss: 1.0776108503341675, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.1124062538146973, Accuracy: 0.6328125\n",
      "Batch: 18, Loss: 1.1876962184906006, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.2914350032806396, Accuracy: 0.572265625\n",
      "Batch: 20, Loss: 1.1739556789398193, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1890733242034912, Accuracy: 0.595703125\n",
      "Batch: 22, Loss: 1.2539101839065552, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.2920900583267212, Accuracy: 0.5849609375\n",
      "Batch: 24, Loss: 1.1345069408416748, Accuracy: 0.6298828125\n",
      "Batch: 25, Loss: 1.1685699224472046, Accuracy: 0.6220703125\n",
      "Batch: 26, Loss: 1.2485857009887695, Accuracy: 0.5751953125\n",
      "Batch: 27, Loss: 1.144561767578125, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.108944058418274, Accuracy: 0.6259765625\n",
      "Batch: 29, Loss: 1.1463525295257568, Accuracy: 0.6220703125\n",
      "Batch: 30, Loss: 1.237672209739685, Accuracy: 0.6005859375\n",
      "Batch: 31, Loss: 1.2690966129302979, Accuracy: 0.5888671875\n",
      "Batch: 32, Loss: 1.143346905708313, Accuracy: 0.6181640625\n",
      "Batch: 33, Loss: 1.0504008531570435, Accuracy: 0.658203125\n",
      "Batch: 34, Loss: 1.1398162841796875, Accuracy: 0.6103515625\n",
      "Batch: 35, Loss: 1.2050122022628784, Accuracy: 0.60546875\n",
      "Batch: 36, Loss: 1.26025390625, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.239104986190796, Accuracy: 0.599609375\n",
      "Batch: 38, Loss: 1.1964550018310547, Accuracy: 0.6181640625\n",
      "Batch: 39, Loss: 1.1305097341537476, Accuracy: 0.611328125\n",
      "Batch: 40, Loss: 1.1656899452209473, Accuracy: 0.6142578125\n",
      "Batch: 41, Loss: 1.1419785022735596, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 1.1304540634155273, Accuracy: 0.6337890625\n",
      "Batch: 43, Loss: 1.1111352443695068, Accuracy: 0.6201171875\n",
      "Batch: 44, Loss: 1.0870587825775146, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.077715516090393, Accuracy: 0.640625\n",
      "Batch: 46, Loss: 1.2241369485855103, Accuracy: 0.61328125\n",
      "Batch: 47, Loss: 1.1634588241577148, Accuracy: 0.6162109375\n",
      "Batch: 48, Loss: 1.1791455745697021, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.166644811630249, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.192173719406128, Accuracy: 0.615234375\n",
      "Batch: 51, Loss: 1.2330176830291748, Accuracy: 0.587890625\n",
      "Batch: 52, Loss: 1.2895079851150513, Accuracy: 0.5810546875\n",
      "Batch: 53, Loss: 1.269365668296814, Accuracy: 0.5791015625\n",
      "Batch: 54, Loss: 1.251399278640747, Accuracy: 0.6064453125\n",
      "Batch: 55, Loss: 1.1793599128723145, Accuracy: 0.6162109375\n",
      "Batch: 56, Loss: 1.173392653465271, Accuracy: 0.619140625\n",
      "Batch: 57, Loss: 1.1732892990112305, Accuracy: 0.60546875\n",
      "Batch: 58, Loss: 1.2139208316802979, Accuracy: 0.607421875\n",
      "Batch: 59, Loss: 1.1772490739822388, Accuracy: 0.6376953125\n",
      "Batch: 60, Loss: 1.24674654006958, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.2323970794677734, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.2105351686477661, Accuracy: 0.59765625\n",
      "Batch: 63, Loss: 1.151490569114685, Accuracy: 0.6337890625\n",
      "Batch: 64, Loss: 1.3018813133239746, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.2720293998718262, Accuracy: 0.5927734375\n",
      "Batch: 66, Loss: 1.2026879787445068, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.2135992050170898, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.1886235475540161, Accuracy: 0.6025390625\n",
      "Batch: 69, Loss: 1.2765717506408691, Accuracy: 0.5859375\n",
      "Batch: 70, Loss: 1.2283480167388916, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.1836782693862915, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.2924559116363525, Accuracy: 0.59375\n",
      "Batch: 73, Loss: 1.2774649858474731, Accuracy: 0.591796875\n",
      "Batch: 74, Loss: 1.1923158168792725, Accuracy: 0.591796875\n",
      "Batch: 75, Loss: 1.1888456344604492, Accuracy: 0.5986328125\n",
      "Batch: 76, Loss: 1.1627672910690308, Accuracy: 0.6259765625\n",
      "Batch: 77, Loss: 1.066205620765686, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 1.1426557302474976, Accuracy: 0.6259765625\n",
      "Batch: 79, Loss: 1.2099237442016602, Accuracy: 0.62890625\n",
      "Batch: 80, Loss: 1.1743172407150269, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.1640522480010986, Accuracy: 0.61328125\n",
      "Batch: 82, Loss: 1.1712250709533691, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.2337651252746582, Accuracy: 0.5859375\n",
      "Batch: 84, Loss: 1.2116293907165527, Accuracy: 0.607421875\n",
      "Batch: 85, Loss: 1.1872241497039795, Accuracy: 0.599609375\n",
      "Batch: 86, Loss: 1.1954773664474487, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.2844477891921997, Accuracy: 0.576171875\n",
      "Batch: 88, Loss: 1.2311768531799316, Accuracy: 0.61328125\n",
      "Batch: 89, Loss: 1.2104623317718506, Accuracy: 0.609375\n",
      "Batch: 90, Loss: 1.1575918197631836, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 91, Loss: 1.1566030979156494, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.1974462270736694, Accuracy: 0.609375\n",
      "Batch: 93, Loss: 1.226928949356079, Accuracy: 0.58984375\n",
      "Batch: 94, Loss: 1.2339825630187988, Accuracy: 0.587890625\n",
      "Batch: 95, Loss: 1.2507977485656738, Accuracy: 0.5986328125\n",
      "Batch: 96, Loss: 1.2643176317214966, Accuracy: 0.609375\n",
      "Batch: 97, Loss: 1.2187272310256958, Accuracy: 0.595703125\n",
      "Batch: 98, Loss: 1.1635655164718628, Accuracy: 0.625\n",
      "Batch: 99, Loss: 1.1738686561584473, Accuracy: 0.630859375\n",
      "Batch: 100, Loss: 1.1182905435562134, Accuracy: 0.6357421875\n",
      "Batch: 101, Loss: 1.1612879037857056, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.224876880645752, Accuracy: 0.619140625\n",
      "Batch: 103, Loss: 1.22523033618927, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.2450740337371826, Accuracy: 0.6025390625\n",
      "Batch: 105, Loss: 1.2935535907745361, Accuracy: 0.5947265625\n",
      "Batch: 106, Loss: 1.2326927185058594, Accuracy: 0.599609375\n",
      "Batch: 107, Loss: 1.2457911968231201, Accuracy: 0.6123046875\n",
      "Batch: 108, Loss: 1.205620288848877, Accuracy: 0.5869140625\n",
      "Batch: 109, Loss: 1.2620506286621094, Accuracy: 0.599609375\n",
      "Batch: 110, Loss: 1.2058215141296387, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.1491376161575317, Accuracy: 0.6435546875\n",
      "Batch: 112, Loss: 1.1411553621292114, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.1917622089385986, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.2022207975387573, Accuracy: 0.6103515625\n",
      "Batch: 115, Loss: 1.244355320930481, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.2579971551895142, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.211915135383606, Accuracy: 0.6005859375\n",
      "Batch: 118, Loss: 1.2621417045593262, Accuracy: 0.6015625\n",
      "Batch: 119, Loss: 1.2561156749725342, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.319731593132019, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.269307255744934, Accuracy: 0.591796875\n",
      "Batch: 122, Loss: 1.2226722240447998, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.2460832595825195, Accuracy: 0.5927734375\n",
      "Batch: 124, Loss: 1.2534468173980713, Accuracy: 0.5927734375\n",
      "Batch: 125, Loss: 1.190853238105774, Accuracy: 0.62890625\n",
      "Batch: 126, Loss: 1.3045480251312256, Accuracy: 0.5771484375\n",
      "Batch: 127, Loss: 1.2599858045578003, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.2584385871887207, Accuracy: 0.5947265625\n",
      "Batch: 129, Loss: 1.2124603986740112, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.1925666332244873, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.2557432651519775, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.1681644916534424, Accuracy: 0.6337890625\n",
      "Batch: 133, Loss: 1.2135257720947266, Accuracy: 0.59765625\n",
      "Batch: 134, Loss: 1.2122775316238403, Accuracy: 0.6220703125\n",
      "Batch: 135, Loss: 1.0877606868743896, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.143728494644165, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.2589092254638672, Accuracy: 0.58203125\n",
      "Batch: 138, Loss: 1.260915994644165, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.2270228862762451, Accuracy: 0.59765625\n",
      "Batch: 140, Loss: 1.2564780712127686, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.202859878540039, Accuracy: 0.6162109375\n",
      "Batch: 142, Loss: 1.2565016746520996, Accuracy: 0.609375\n",
      "Batch: 143, Loss: 1.278351902961731, Accuracy: 0.6005859375\n",
      "Batch: 144, Loss: 1.308708667755127, Accuracy: 0.5654296875\n",
      "Batch: 145, Loss: 1.3375377655029297, Accuracy: 0.5693359375\n",
      "Batch: 146, Loss: 1.2731660604476929, Accuracy: 0.5771484375\n",
      "Batch: 147, Loss: 1.2853682041168213, Accuracy: 0.58203125\n",
      "Batch: 148, Loss: 1.2730464935302734, Accuracy: 0.5869140625\n",
      "Batch: 149, Loss: 1.2084696292877197, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.2247252464294434, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.2394886016845703, Accuracy: 0.6015625\n",
      "Batch: 152, Loss: 1.1813766956329346, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.1919045448303223, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.1998753547668457, Accuracy: 0.61328125\n",
      "Batch: 155, Loss: 1.1663587093353271, Accuracy: 0.63671875\n",
      "Epoch 422/200\n",
      "Batch: 1, Loss: 1.2497152090072632, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.1453043222427368, Accuracy: 0.638671875\n",
      "Batch: 3, Loss: 1.0927698612213135, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 1.1516519784927368, Accuracy: 0.611328125\n",
      "Batch: 5, Loss: 1.0575058460235596, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.108405351638794, Accuracy: 0.625\n",
      "Batch: 7, Loss: 1.0364866256713867, Accuracy: 0.673828125\n",
      "Batch: 8, Loss: 1.0609015226364136, Accuracy: 0.66015625\n",
      "Batch: 9, Loss: 1.0518124103546143, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9938254356384277, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 0.9886558055877686, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 1.0820724964141846, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0442829132080078, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.0165834426879883, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.989985466003418, Accuracy: 0.673828125\n",
      "Batch: 16, Loss: 1.0686755180358887, Accuracy: 0.658203125\n",
      "Batch: 17, Loss: 1.1000134944915771, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.1188445091247559, Accuracy: 0.62890625\n",
      "Batch: 19, Loss: 1.2944482564926147, Accuracy: 0.5791015625\n",
      "Batch: 20, Loss: 1.1525850296020508, Accuracy: 0.623046875\n",
      "Batch: 21, Loss: 1.1561448574066162, Accuracy: 0.6181640625\n",
      "Batch: 22, Loss: 1.3139822483062744, Accuracy: 0.5927734375\n",
      "Batch: 23, Loss: 1.3161051273345947, Accuracy: 0.5712890625\n",
      "Batch: 24, Loss: 1.1820114850997925, Accuracy: 0.6220703125\n",
      "Batch: 25, Loss: 1.2412071228027344, Accuracy: 0.607421875\n",
      "Batch: 26, Loss: 1.2667077779769897, Accuracy: 0.5859375\n",
      "Batch: 27, Loss: 1.146314024925232, Accuracy: 0.6240234375\n",
      "Batch: 28, Loss: 1.168212652206421, Accuracy: 0.6220703125\n",
      "Batch: 29, Loss: 1.1824350357055664, Accuracy: 0.6025390625\n",
      "Batch: 30, Loss: 1.1627073287963867, Accuracy: 0.6328125\n",
      "Batch: 31, Loss: 1.2450090646743774, Accuracy: 0.6064453125\n",
      "Batch: 32, Loss: 1.0910463333129883, Accuracy: 0.638671875\n",
      "Batch: 33, Loss: 1.0338214635849, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.1248713731765747, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.2409214973449707, Accuracy: 0.5908203125\n",
      "Batch: 36, Loss: 1.2275346517562866, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.290789008140564, Accuracy: 0.572265625\n",
      "Batch: 38, Loss: 1.217320203781128, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.2062386274337769, Accuracy: 0.6123046875\n",
      "Batch: 40, Loss: 1.13801908493042, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1672536134719849, Accuracy: 0.615234375\n",
      "Batch: 42, Loss: 1.1608108282089233, Accuracy: 0.623046875\n",
      "Batch: 43, Loss: 1.120429515838623, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.075461506843567, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 1.0837242603302002, Accuracy: 0.638671875\n",
      "Batch: 46, Loss: 1.1621754169464111, Accuracy: 0.607421875\n",
      "Batch: 47, Loss: 1.1416797637939453, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.1780750751495361, Accuracy: 0.6142578125\n",
      "Batch: 49, Loss: 1.2872045040130615, Accuracy: 0.5908203125\n",
      "Batch: 50, Loss: 1.164082646369934, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.164571762084961, Accuracy: 0.6220703125\n",
      "Batch: 52, Loss: 1.2720482349395752, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.2664861679077148, Accuracy: 0.5791015625\n",
      "Batch: 54, Loss: 1.2542654275894165, Accuracy: 0.595703125\n",
      "Batch: 55, Loss: 1.1876113414764404, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.1399407386779785, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.1486891508102417, Accuracy: 0.615234375\n",
      "Batch: 58, Loss: 1.1979596614837646, Accuracy: 0.6123046875\n",
      "Batch: 59, Loss: 1.1989727020263672, Accuracy: 0.6142578125\n",
      "Batch: 60, Loss: 1.2536978721618652, Accuracy: 0.587890625\n",
      "Batch: 61, Loss: 1.1904520988464355, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.237025499343872, Accuracy: 0.615234375\n",
      "Batch: 63, Loss: 1.2307381629943848, Accuracy: 0.6103515625\n",
      "Batch: 64, Loss: 1.241952896118164, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.30039644241333, Accuracy: 0.591796875\n",
      "Batch: 66, Loss: 1.2364494800567627, Accuracy: 0.603515625\n",
      "Batch: 67, Loss: 1.1917967796325684, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.1775932312011719, Accuracy: 0.62109375\n",
      "Batch: 69, Loss: 1.2006611824035645, Accuracy: 0.6171875\n",
      "Batch: 70, Loss: 1.2296111583709717, Accuracy: 0.5966796875\n",
      "Batch: 71, Loss: 1.2540873289108276, Accuracy: 0.5791015625\n",
      "Batch: 72, Loss: 1.2768999338150024, Accuracy: 0.6015625\n",
      "Batch: 73, Loss: 1.2648389339447021, Accuracy: 0.5859375\n",
      "Batch: 74, Loss: 1.1716779470443726, Accuracy: 0.6064453125\n",
      "Batch: 75, Loss: 1.1580389738082886, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 1.1483848094940186, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.0871491432189941, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.1219370365142822, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.216306209564209, Accuracy: 0.6044921875\n",
      "Batch: 80, Loss: 1.2731825113296509, Accuracy: 0.58203125\n",
      "Batch: 81, Loss: 1.1610084772109985, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.2257425785064697, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.2603150606155396, Accuracy: 0.595703125\n",
      "Batch: 84, Loss: 1.202558994293213, Accuracy: 0.615234375\n",
      "Batch: 85, Loss: 1.2297464609146118, Accuracy: 0.6044921875\n",
      "Batch: 86, Loss: 1.2073562145233154, Accuracy: 0.61328125\n",
      "Batch: 87, Loss: 1.2170226573944092, Accuracy: 0.5947265625\n",
      "Batch: 88, Loss: 1.2216813564300537, Accuracy: 0.61328125\n",
      "Batch: 89, Loss: 1.22661292552948, Accuracy: 0.603515625\n",
      "Batch: 90, Loss: 1.1748790740966797, Accuracy: 0.623046875\n",
      "Batch: 91, Loss: 1.177587628364563, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.2091022729873657, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.1944267749786377, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.249293565750122, Accuracy: 0.6123046875\n",
      "Batch: 95, Loss: 1.245514988899231, Accuracy: 0.6123046875\n",
      "Batch: 96, Loss: 1.2447657585144043, Accuracy: 0.6259765625\n",
      "Batch: 97, Loss: 1.2501487731933594, Accuracy: 0.5791015625\n",
      "Batch: 98, Loss: 1.1735702753067017, Accuracy: 0.6025390625\n",
      "Batch: 99, Loss: 1.205522894859314, Accuracy: 0.6162109375\n",
      "Batch: 100, Loss: 1.1352598667144775, Accuracy: 0.6279296875\n",
      "Batch: 101, Loss: 1.1732287406921387, Accuracy: 0.6298828125\n",
      "Batch: 102, Loss: 1.2063970565795898, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.1371817588806152, Accuracy: 0.6435546875\n",
      "Batch: 104, Loss: 1.1990389823913574, Accuracy: 0.6083984375\n",
      "Batch: 105, Loss: 1.3189570903778076, Accuracy: 0.58984375\n",
      "Batch: 106, Loss: 1.2356376647949219, Accuracy: 0.61328125\n",
      "Batch: 107, Loss: 1.2641746997833252, Accuracy: 0.578125\n",
      "Batch: 108, Loss: 1.2477730512619019, Accuracy: 0.5888671875\n",
      "Batch: 109, Loss: 1.2723137140274048, Accuracy: 0.578125\n",
      "Batch: 110, Loss: 1.2419356107711792, Accuracy: 0.595703125\n",
      "Batch: 111, Loss: 1.1773622035980225, Accuracy: 0.6162109375\n",
      "Batch: 112, Loss: 1.1749281883239746, Accuracy: 0.615234375\n",
      "Batch: 113, Loss: 1.2108426094055176, Accuracy: 0.5986328125\n",
      "Batch: 114, Loss: 1.2707370519638062, Accuracy: 0.55859375\n",
      "Batch: 115, Loss: 1.3253328800201416, Accuracy: 0.5615234375\n",
      "Batch: 116, Loss: 1.2608716487884521, Accuracy: 0.5888671875\n",
      "Batch: 117, Loss: 1.2406871318817139, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.302727222442627, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.299527883529663, Accuracy: 0.57421875\n",
      "Batch: 120, Loss: 1.3949699401855469, Accuracy: 0.5732421875\n",
      "Batch: 121, Loss: 1.2652850151062012, Accuracy: 0.5966796875\n",
      "Batch: 122, Loss: 1.2360267639160156, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.1830298900604248, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.267919659614563, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.2717316150665283, Accuracy: 0.6083984375\n",
      "Batch: 126, Loss: 1.366815209388733, Accuracy: 0.5712890625\n",
      "Batch: 127, Loss: 1.2919031381607056, Accuracy: 0.576171875\n",
      "Batch: 128, Loss: 1.2766526937484741, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.2526315450668335, Accuracy: 0.59765625\n",
      "Batch: 130, Loss: 1.1999918222427368, Accuracy: 0.6171875\n",
      "Batch: 131, Loss: 1.271230936050415, Accuracy: 0.5859375\n",
      "Batch: 132, Loss: 1.178838849067688, Accuracy: 0.62109375\n",
      "Batch: 133, Loss: 1.2660846710205078, Accuracy: 0.5869140625\n",
      "Batch: 134, Loss: 1.2205724716186523, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.1206791400909424, Accuracy: 0.6337890625\n",
      "Batch: 136, Loss: 1.0976853370666504, Accuracy: 0.658203125\n",
      "Batch: 137, Loss: 1.242469072341919, Accuracy: 0.60546875\n",
      "Batch: 138, Loss: 1.3182967901229858, Accuracy: 0.5771484375\n",
      "Batch: 139, Loss: 1.3106951713562012, Accuracy: 0.5732421875\n",
      "Batch: 140, Loss: 1.3081234693527222, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.2424651384353638, Accuracy: 0.60546875\n",
      "Batch: 142, Loss: 1.1826817989349365, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.300987958908081, Accuracy: 0.5791015625\n",
      "Batch: 144, Loss: 1.328210711479187, Accuracy: 0.580078125\n",
      "Batch: 145, Loss: 1.3134677410125732, Accuracy: 0.5712890625\n",
      "Batch: 146, Loss: 1.2574843168258667, Accuracy: 0.5927734375\n",
      "Batch: 147, Loss: 1.272012710571289, Accuracy: 0.6005859375\n",
      "Batch: 148, Loss: 1.2724075317382812, Accuracy: 0.5771484375\n",
      "Batch: 149, Loss: 1.2818670272827148, Accuracy: 0.5830078125\n",
      "Batch: 150, Loss: 1.2756972312927246, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.2126681804656982, Accuracy: 0.6220703125\n",
      "Batch: 152, Loss: 1.244401216506958, Accuracy: 0.59375\n",
      "Batch: 153, Loss: 1.1652106046676636, Accuracy: 0.623046875\n",
      "Batch: 154, Loss: 1.1951102018356323, Accuracy: 0.6220703125\n",
      "Batch: 155, Loss: 1.1362450122833252, Accuracy: 0.6357421875\n",
      "Epoch 423/200\n",
      "Batch: 1, Loss: 1.277160882949829, Accuracy: 0.6083984375\n",
      "Batch: 2, Loss: 1.1493043899536133, Accuracy: 0.6279296875\n",
      "Batch: 3, Loss: 1.0828282833099365, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 1.1145433187484741, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 1.050689458847046, Accuracy: 0.662109375\n",
      "Batch: 6, Loss: 1.1029460430145264, Accuracy: 0.6357421875\n",
      "Batch: 7, Loss: 1.0565693378448486, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 1.0108542442321777, Accuracy: 0.6767578125\n",
      "Batch: 9, Loss: 1.011427640914917, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 0.98888099193573, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 1.0600744485855103, Accuracy: 0.65234375\n",
      "Batch: 12, Loss: 1.0134187936782837, Accuracy: 0.6787109375\n",
      "Batch: 13, Loss: 1.0699572563171387, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 1.0295065641403198, Accuracy: 0.658203125\n",
      "Batch: 15, Loss: 0.9513987302780151, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.1050386428833008, Accuracy: 0.6767578125\n",
      "Batch: 17, Loss: 1.128627061843872, Accuracy: 0.61328125\n",
      "Batch: 18, Loss: 1.1618186235427856, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2386842966079712, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.162774682044983, Accuracy: 0.6396484375\n",
      "Batch: 21, Loss: 1.1247674226760864, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.2720403671264648, Accuracy: 0.587890625\n",
      "Batch: 23, Loss: 1.2706496715545654, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.1710937023162842, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.2484750747680664, Accuracy: 0.5966796875\n",
      "Batch: 26, Loss: 1.2036418914794922, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.1635560989379883, Accuracy: 0.6240234375\n",
      "Batch: 28, Loss: 1.1292665004730225, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.0966391563415527, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1727850437164307, Accuracy: 0.6025390625\n",
      "Batch: 31, Loss: 1.256459355354309, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.11130690574646, Accuracy: 0.634765625\n",
      "Batch: 33, Loss: 1.0042716264724731, Accuracy: 0.6826171875\n",
      "Batch: 34, Loss: 1.11691153049469, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.136782169342041, Accuracy: 0.61328125\n",
      "Batch: 36, Loss: 1.1931371688842773, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.2598919868469238, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.153051733970642, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.1160491704940796, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.1310912370681763, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.1787627935409546, Accuracy: 0.6259765625\n",
      "Batch: 42, Loss: 1.1505122184753418, Accuracy: 0.62109375\n",
      "Batch: 43, Loss: 1.0922393798828125, Accuracy: 0.642578125\n",
      "Batch: 44, Loss: 1.0514476299285889, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.1098697185516357, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1991181373596191, Accuracy: 0.5927734375\n",
      "Batch: 47, Loss: 1.1740467548370361, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.1904313564300537, Accuracy: 0.6064453125\n",
      "Batch: 49, Loss: 1.2700128555297852, Accuracy: 0.5703125\n",
      "Batch: 50, Loss: 1.1957480907440186, Accuracy: 0.609375\n",
      "Batch: 51, Loss: 1.2040936946868896, Accuracy: 0.5869140625\n",
      "Batch: 52, Loss: 1.3037750720977783, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.1788299083709717, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.2155933380126953, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.2122538089752197, Accuracy: 0.607421875\n",
      "Batch: 56, Loss: 1.1963541507720947, Accuracy: 0.6171875\n",
      "Batch: 57, Loss: 1.1484767198562622, Accuracy: 0.6318359375\n",
      "Batch: 58, Loss: 1.1444058418273926, Accuracy: 0.6181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 1.1645890474319458, Accuracy: 0.634765625\n",
      "Batch: 60, Loss: 1.268150806427002, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.2442795038223267, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.282475233078003, Accuracy: 0.5791015625\n",
      "Batch: 63, Loss: 1.2109973430633545, Accuracy: 0.6025390625\n",
      "Batch: 64, Loss: 1.271643042564392, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.1764936447143555, Accuracy: 0.62890625\n",
      "Batch: 66, Loss: 1.2351713180541992, Accuracy: 0.595703125\n",
      "Batch: 67, Loss: 1.189799189567566, Accuracy: 0.609375\n",
      "Batch: 68, Loss: 1.1569592952728271, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.2487175464630127, Accuracy: 0.5966796875\n",
      "Batch: 70, Loss: 1.241628885269165, Accuracy: 0.6103515625\n",
      "Batch: 71, Loss: 1.1954984664916992, Accuracy: 0.6044921875\n",
      "Batch: 72, Loss: 1.2953517436981201, Accuracy: 0.5830078125\n",
      "Batch: 73, Loss: 1.1995587348937988, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.1282132863998413, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.1653738021850586, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.1222331523895264, Accuracy: 0.625\n",
      "Batch: 77, Loss: 1.1622989177703857, Accuracy: 0.6142578125\n",
      "Batch: 78, Loss: 1.142698049545288, Accuracy: 0.6318359375\n",
      "Batch: 79, Loss: 1.2240493297576904, Accuracy: 0.6015625\n",
      "Batch: 80, Loss: 1.2143595218658447, Accuracy: 0.6025390625\n",
      "Batch: 81, Loss: 1.1254596710205078, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.1962029933929443, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.2582547664642334, Accuracy: 0.59375\n",
      "Batch: 84, Loss: 1.1880348920822144, Accuracy: 0.62109375\n",
      "Batch: 85, Loss: 1.27811861038208, Accuracy: 0.5908203125\n",
      "Batch: 86, Loss: 1.2519983053207397, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.22403883934021, Accuracy: 0.6123046875\n",
      "Batch: 88, Loss: 1.1813857555389404, Accuracy: 0.5986328125\n",
      "Batch: 89, Loss: 1.2837352752685547, Accuracy: 0.5830078125\n",
      "Batch: 90, Loss: 1.1997021436691284, Accuracy: 0.62109375\n",
      "Batch: 91, Loss: 1.198798418045044, Accuracy: 0.6083984375\n",
      "Batch: 92, Loss: 1.2132484912872314, Accuracy: 0.6201171875\n",
      "Batch: 93, Loss: 1.1912682056427002, Accuracy: 0.6103515625\n",
      "Batch: 94, Loss: 1.257394552230835, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.22408926486969, Accuracy: 0.6064453125\n",
      "Batch: 96, Loss: 1.2684727907180786, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.2543102502822876, Accuracy: 0.599609375\n",
      "Batch: 98, Loss: 1.136170744895935, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.1960690021514893, Accuracy: 0.607421875\n",
      "Batch: 100, Loss: 1.0839126110076904, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.1376696825027466, Accuracy: 0.619140625\n",
      "Batch: 102, Loss: 1.212599754333496, Accuracy: 0.607421875\n",
      "Batch: 103, Loss: 1.1928436756134033, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.1865179538726807, Accuracy: 0.6044921875\n",
      "Batch: 105, Loss: 1.2611048221588135, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.247521162033081, Accuracy: 0.59765625\n",
      "Batch: 107, Loss: 1.267551302909851, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.217090129852295, Accuracy: 0.5927734375\n",
      "Batch: 109, Loss: 1.2842161655426025, Accuracy: 0.5869140625\n",
      "Batch: 110, Loss: 1.1918613910675049, Accuracy: 0.5966796875\n",
      "Batch: 111, Loss: 1.151029348373413, Accuracy: 0.6298828125\n",
      "Batch: 112, Loss: 1.1546962261199951, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.217625617980957, Accuracy: 0.607421875\n",
      "Batch: 114, Loss: 1.259790301322937, Accuracy: 0.591796875\n",
      "Batch: 115, Loss: 1.2053368091583252, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2597718238830566, Accuracy: 0.6005859375\n",
      "Batch: 117, Loss: 1.1983616352081299, Accuracy: 0.5986328125\n",
      "Batch: 118, Loss: 1.2577239274978638, Accuracy: 0.5859375\n",
      "Batch: 119, Loss: 1.2810794115066528, Accuracy: 0.6015625\n",
      "Batch: 120, Loss: 1.3650784492492676, Accuracy: 0.58203125\n",
      "Batch: 121, Loss: 1.255710482597351, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2948468923568726, Accuracy: 0.5947265625\n",
      "Batch: 123, Loss: 1.2717478275299072, Accuracy: 0.5927734375\n",
      "Batch: 124, Loss: 1.2878122329711914, Accuracy: 0.6015625\n",
      "Batch: 125, Loss: 1.2155287265777588, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.314037561416626, Accuracy: 0.57421875\n",
      "Batch: 127, Loss: 1.2537548542022705, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.275757074356079, Accuracy: 0.59765625\n",
      "Batch: 129, Loss: 1.2259416580200195, Accuracy: 0.6025390625\n",
      "Batch: 130, Loss: 1.2031781673431396, Accuracy: 0.6123046875\n",
      "Batch: 131, Loss: 1.2940938472747803, Accuracy: 0.6025390625\n",
      "Batch: 132, Loss: 1.1136178970336914, Accuracy: 0.63671875\n",
      "Batch: 133, Loss: 1.2014455795288086, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.1796928644180298, Accuracy: 0.6220703125\n",
      "Batch: 135, Loss: 1.084442377090454, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.1546895503997803, Accuracy: 0.634765625\n",
      "Batch: 137, Loss: 1.2603611946105957, Accuracy: 0.583984375\n",
      "Batch: 138, Loss: 1.2647318840026855, Accuracy: 0.58984375\n",
      "Batch: 139, Loss: 1.306261658668518, Accuracy: 0.56640625\n",
      "Batch: 140, Loss: 1.342247724533081, Accuracy: 0.578125\n",
      "Batch: 141, Loss: 1.265062689781189, Accuracy: 0.5888671875\n",
      "Batch: 142, Loss: 1.226502776145935, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.292349100112915, Accuracy: 0.5732421875\n",
      "Batch: 144, Loss: 1.3114652633666992, Accuracy: 0.583984375\n",
      "Batch: 145, Loss: 1.373889446258545, Accuracy: 0.5439453125\n",
      "Batch: 146, Loss: 1.2585015296936035, Accuracy: 0.6005859375\n",
      "Batch: 147, Loss: 1.268589973449707, Accuracy: 0.5947265625\n",
      "Batch: 148, Loss: 1.2435990571975708, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.2265084981918335, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.1619492769241333, Accuracy: 0.6298828125\n",
      "Batch: 151, Loss: 1.1687308549880981, Accuracy: 0.615234375\n",
      "Batch: 152, Loss: 1.1914775371551514, Accuracy: 0.5986328125\n",
      "Batch: 153, Loss: 1.1401244401931763, Accuracy: 0.6416015625\n",
      "Batch: 154, Loss: 1.1542878150939941, Accuracy: 0.607421875\n",
      "Batch: 155, Loss: 1.1846566200256348, Accuracy: 0.61328125\n",
      "Epoch 424/200\n",
      "Batch: 1, Loss: 1.2314871549606323, Accuracy: 0.6201171875\n",
      "Batch: 2, Loss: 1.14508056640625, Accuracy: 0.62109375\n",
      "Batch: 3, Loss: 1.0665416717529297, Accuracy: 0.642578125\n",
      "Batch: 4, Loss: 1.0740859508514404, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.0974572896957397, Accuracy: 0.625\n",
      "Batch: 6, Loss: 1.1100828647613525, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.1218936443328857, Accuracy: 0.62890625\n",
      "Batch: 8, Loss: 0.9790518879890442, Accuracy: 0.6865234375\n",
      "Batch: 9, Loss: 1.0760248899459839, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9874881505966187, Accuracy: 0.6591796875\n",
      "Batch: 11, Loss: 1.030883550643921, Accuracy: 0.6494140625\n",
      "Batch: 12, Loss: 1.0600987672805786, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 1.0754663944244385, Accuracy: 0.6455078125\n",
      "Batch: 14, Loss: 1.0527490377426147, Accuracy: 0.662109375\n",
      "Batch: 15, Loss: 0.9374750852584839, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.0976183414459229, Accuracy: 0.642578125\n",
      "Batch: 17, Loss: 1.072357177734375, Accuracy: 0.6357421875\n",
      "Batch: 18, Loss: 1.1753884553909302, Accuracy: 0.615234375\n",
      "Batch: 19, Loss: 1.1836801767349243, Accuracy: 0.6259765625\n",
      "Batch: 20, Loss: 1.153287649154663, Accuracy: 0.6484375\n",
      "Batch: 21, Loss: 1.1558973789215088, Accuracy: 0.615234375\n",
      "Batch: 22, Loss: 1.3000329732894897, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.2711049318313599, Accuracy: 0.58984375\n",
      "Batch: 24, Loss: 1.2214069366455078, Accuracy: 0.60546875\n",
      "Batch: 25, Loss: 1.196498155593872, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.2553943395614624, Accuracy: 0.599609375\n",
      "Batch: 27, Loss: 1.1791632175445557, Accuracy: 0.6123046875\n",
      "Batch: 28, Loss: 1.1586828231811523, Accuracy: 0.6103515625\n",
      "Batch: 29, Loss: 1.1075794696807861, Accuracy: 0.6279296875\n",
      "Batch: 30, Loss: 1.1870672702789307, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.2459172010421753, Accuracy: 0.6123046875\n",
      "Batch: 32, Loss: 1.0926904678344727, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.0418376922607422, Accuracy: 0.66015625\n",
      "Batch: 34, Loss: 1.1215364933013916, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.1575840711593628, Accuracy: 0.61328125\n",
      "Batch: 36, Loss: 1.198256254196167, Accuracy: 0.587890625\n",
      "Batch: 37, Loss: 1.2344608306884766, Accuracy: 0.599609375\n",
      "Batch: 38, Loss: 1.1969292163848877, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.1210429668426514, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.150047779083252, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.1724224090576172, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.067854642868042, Accuracy: 0.64453125\n",
      "Batch: 43, Loss: 1.1149718761444092, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 1.0894514322280884, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.1214370727539062, Accuracy: 0.626953125\n",
      "Batch: 46, Loss: 1.210444688796997, Accuracy: 0.6083984375\n",
      "Batch: 47, Loss: 1.141486406326294, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.2106183767318726, Accuracy: 0.6015625\n",
      "Batch: 49, Loss: 1.2375389337539673, Accuracy: 0.611328125\n",
      "Batch: 50, Loss: 1.1943650245666504, Accuracy: 0.6103515625\n",
      "Batch: 51, Loss: 1.173265814781189, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.2528712749481201, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.1731176376342773, Accuracy: 0.599609375\n",
      "Batch: 54, Loss: 1.2817466259002686, Accuracy: 0.58984375\n",
      "Batch: 55, Loss: 1.1784119606018066, Accuracy: 0.6162109375\n",
      "Batch: 56, Loss: 1.1289458274841309, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.1031582355499268, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.1733819246292114, Accuracy: 0.62109375\n",
      "Batch: 59, Loss: 1.1649363040924072, Accuracy: 0.642578125\n",
      "Batch: 60, Loss: 1.2993814945220947, Accuracy: 0.5859375\n",
      "Batch: 61, Loss: 1.2383465766906738, Accuracy: 0.6025390625\n",
      "Batch: 62, Loss: 1.2499382495880127, Accuracy: 0.59765625\n",
      "Batch: 63, Loss: 1.1978142261505127, Accuracy: 0.595703125\n",
      "Batch: 64, Loss: 1.2599066495895386, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.245718240737915, Accuracy: 0.5869140625\n",
      "Batch: 66, Loss: 1.212157130241394, Accuracy: 0.6064453125\n",
      "Batch: 67, Loss: 1.1456782817840576, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.112990379333496, Accuracy: 0.642578125\n",
      "Batch: 69, Loss: 1.2010924816131592, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.2130188941955566, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.2010183334350586, Accuracy: 0.6103515625\n",
      "Batch: 72, Loss: 1.2745763063430786, Accuracy: 0.5947265625\n",
      "Batch: 73, Loss: 1.2533574104309082, Accuracy: 0.5859375\n",
      "Batch: 74, Loss: 1.1310099363327026, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.211495280265808, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.1298458576202393, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.1602818965911865, Accuracy: 0.626953125\n",
      "Batch: 78, Loss: 1.1710383892059326, Accuracy: 0.6181640625\n",
      "Batch: 79, Loss: 1.136462926864624, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.226346731185913, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.1717472076416016, Accuracy: 0.62109375\n",
      "Batch: 82, Loss: 1.1842113733291626, Accuracy: 0.6220703125\n",
      "Batch: 83, Loss: 1.2757229804992676, Accuracy: 0.58984375\n",
      "Batch: 84, Loss: 1.1810106039047241, Accuracy: 0.62109375\n",
      "Batch: 85, Loss: 1.2292101383209229, Accuracy: 0.607421875\n",
      "Batch: 86, Loss: 1.228163719177246, Accuracy: 0.6005859375\n",
      "Batch: 87, Loss: 1.2393323183059692, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.1932569742202759, Accuracy: 0.61328125\n",
      "Batch: 89, Loss: 1.2547998428344727, Accuracy: 0.607421875\n",
      "Batch: 90, Loss: 1.1543203592300415, Accuracy: 0.623046875\n",
      "Batch: 91, Loss: 1.2219442129135132, Accuracy: 0.5888671875\n",
      "Batch: 92, Loss: 1.2678883075714111, Accuracy: 0.5791015625\n",
      "Batch: 93, Loss: 1.248430848121643, Accuracy: 0.6162109375\n",
      "Batch: 94, Loss: 1.2491633892059326, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.2312644720077515, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2184792757034302, Accuracy: 0.6240234375\n",
      "Batch: 97, Loss: 1.301242470741272, Accuracy: 0.5830078125\n",
      "Batch: 98, Loss: 1.1251850128173828, Accuracy: 0.650390625\n",
      "Batch: 99, Loss: 1.2261059284210205, Accuracy: 0.595703125\n",
      "Batch: 100, Loss: 1.1247899532318115, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.1414365768432617, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.2710705995559692, Accuracy: 0.5986328125\n",
      "Batch: 103, Loss: 1.2466888427734375, Accuracy: 0.611328125\n",
      "Batch: 104, Loss: 1.2317527532577515, Accuracy: 0.5966796875\n",
      "Batch: 105, Loss: 1.2461731433868408, Accuracy: 0.6240234375\n",
      "Batch: 106, Loss: 1.1978766918182373, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.3382468223571777, Accuracy: 0.56640625\n",
      "Batch: 108, Loss: 1.1958792209625244, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.236984133720398, Accuracy: 0.587890625\n",
      "Batch: 110, Loss: 1.2255778312683105, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.1740407943725586, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.1505234241485596, Accuracy: 0.6201171875\n",
      "Batch: 113, Loss: 1.2288784980773926, Accuracy: 0.5888671875\n",
      "Batch: 114, Loss: 1.2345526218414307, Accuracy: 0.6005859375\n",
      "Batch: 115, Loss: 1.210341215133667, Accuracy: 0.607421875\n",
      "Batch: 116, Loss: 1.2361773252487183, Accuracy: 0.5888671875\n",
      "Batch: 117, Loss: 1.2102692127227783, Accuracy: 0.5986328125\n",
      "Batch: 118, Loss: 1.2511974573135376, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.2661526203155518, Accuracy: 0.5859375\n",
      "Batch: 120, Loss: 1.3482871055603027, Accuracy: 0.57421875\n",
      "Batch: 121, Loss: 1.2927577495574951, Accuracy: 0.578125\n",
      "Batch: 122, Loss: 1.228408932685852, Accuracy: 0.59765625\n",
      "Batch: 123, Loss: 1.1905407905578613, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.2679725885391235, Accuracy: 0.5888671875\n",
      "Batch: 125, Loss: 1.237585425376892, Accuracy: 0.62890625\n",
      "Batch: 126, Loss: 1.2972360849380493, Accuracy: 0.5888671875\n",
      "Batch: 127, Loss: 1.2953373193740845, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.288683295249939, Accuracy: 0.583984375\n",
      "Batch: 129, Loss: 1.2026599645614624, Accuracy: 0.6220703125\n",
      "Batch: 130, Loss: 1.207682728767395, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.2435026168823242, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.1401417255401611, Accuracy: 0.625\n",
      "Batch: 133, Loss: 1.176008939743042, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.2228150367736816, Accuracy: 0.6083984375\n",
      "Batch: 135, Loss: 1.161494493484497, Accuracy: 0.6337890625\n",
      "Batch: 136, Loss: 1.1368110179901123, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.2848842144012451, Accuracy: 0.583984375\n",
      "Batch: 138, Loss: 1.2598187923431396, Accuracy: 0.5908203125\n",
      "Batch: 139, Loss: 1.2318254709243774, Accuracy: 0.595703125\n",
      "Batch: 140, Loss: 1.3120710849761963, Accuracy: 0.5927734375\n",
      "Batch: 141, Loss: 1.2045767307281494, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.237376093864441, Accuracy: 0.595703125\n",
      "Batch: 143, Loss: 1.2710392475128174, Accuracy: 0.5732421875\n",
      "Batch: 144, Loss: 1.2783350944519043, Accuracy: 0.5859375\n",
      "Batch: 145, Loss: 1.3018933534622192, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.229499101638794, Accuracy: 0.591796875\n",
      "Batch: 147, Loss: 1.213606595993042, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.2453577518463135, Accuracy: 0.6171875\n",
      "Batch: 149, Loss: 1.2020426988601685, Accuracy: 0.609375\n",
      "Batch: 150, Loss: 1.2205100059509277, Accuracy: 0.609375\n",
      "Batch: 151, Loss: 1.2570480108261108, Accuracy: 0.591796875\n",
      "Batch: 152, Loss: 1.1898589134216309, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.1779112815856934, Accuracy: 0.6162109375\n",
      "Batch: 154, Loss: 1.1856125593185425, Accuracy: 0.6142578125\n",
      "Batch: 155, Loss: 1.1968492269515991, Accuracy: 0.611328125\n",
      "Epoch 425/200\n",
      "Batch: 1, Loss: 1.3001673221588135, Accuracy: 0.6103515625\n",
      "Batch: 2, Loss: 1.1752249002456665, Accuracy: 0.6123046875\n",
      "Batch: 3, Loss: 1.0988103151321411, Accuracy: 0.63671875\n",
      "Batch: 4, Loss: 1.0740013122558594, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.090783715248108, Accuracy: 0.650390625\n",
      "Batch: 6, Loss: 1.09090256690979, Accuracy: 0.630859375\n",
      "Batch: 7, Loss: 1.0412496328353882, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 1.0438804626464844, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0179681777954102, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9616450667381287, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 1.0577391386032104, Accuracy: 0.658203125\n",
      "Batch: 12, Loss: 1.1086543798446655, Accuracy: 0.6416015625\n",
      "Batch: 13, Loss: 1.078195333480835, Accuracy: 0.646484375\n",
      "Batch: 14, Loss: 1.00563383102417, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.9855932593345642, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0964900255203247, Accuracy: 0.6552734375\n",
      "Batch: 17, Loss: 1.1089694499969482, Accuracy: 0.626953125\n",
      "Batch: 18, Loss: 1.1565759181976318, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2806941270828247, Accuracy: 0.58203125\n",
      "Batch: 20, Loss: 1.2081011533737183, Accuracy: 0.6171875\n",
      "Batch: 21, Loss: 1.1485395431518555, Accuracy: 0.626953125\n",
      "Batch: 22, Loss: 1.3005073070526123, Accuracy: 0.5791015625\n",
      "Batch: 23, Loss: 1.3284085988998413, Accuracy: 0.568359375\n",
      "Batch: 24, Loss: 1.1872880458831787, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.1952592134475708, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.2648324966430664, Accuracy: 0.5888671875\n",
      "Batch: 27, Loss: 1.2159661054611206, Accuracy: 0.595703125\n",
      "Batch: 28, Loss: 1.0899860858917236, Accuracy: 0.640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 1.104141116142273, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.2249163389205933, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2624711990356445, Accuracy: 0.583984375\n",
      "Batch: 32, Loss: 1.0945602655410767, Accuracy: 0.626953125\n",
      "Batch: 33, Loss: 1.0315511226654053, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.1415599584579468, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.1740673780441284, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.3004292249679565, Accuracy: 0.5830078125\n",
      "Batch: 37, Loss: 1.2301616668701172, Accuracy: 0.58203125\n",
      "Batch: 38, Loss: 1.2248725891113281, Accuracy: 0.59375\n",
      "Batch: 39, Loss: 1.123679280281067, Accuracy: 0.634765625\n",
      "Batch: 40, Loss: 1.1493563652038574, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.186747670173645, Accuracy: 0.6142578125\n",
      "Batch: 42, Loss: 1.1227517127990723, Accuracy: 0.626953125\n",
      "Batch: 43, Loss: 1.100400447845459, Accuracy: 0.642578125\n",
      "Batch: 44, Loss: 1.0916602611541748, Accuracy: 0.63671875\n",
      "Batch: 45, Loss: 1.0882017612457275, Accuracy: 0.640625\n",
      "Batch: 46, Loss: 1.1644954681396484, Accuracy: 0.60546875\n",
      "Batch: 47, Loss: 1.152693271636963, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.1588443517684937, Accuracy: 0.615234375\n",
      "Batch: 49, Loss: 1.1979036331176758, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.168412685394287, Accuracy: 0.619140625\n",
      "Batch: 51, Loss: 1.199695348739624, Accuracy: 0.6015625\n",
      "Batch: 52, Loss: 1.274442195892334, Accuracy: 0.580078125\n",
      "Batch: 53, Loss: 1.2313082218170166, Accuracy: 0.5869140625\n",
      "Batch: 54, Loss: 1.2139911651611328, Accuracy: 0.5966796875\n",
      "Batch: 55, Loss: 1.1983888149261475, Accuracy: 0.6103515625\n",
      "Batch: 56, Loss: 1.1450737714767456, Accuracy: 0.6318359375\n",
      "Batch: 57, Loss: 1.208322525024414, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.1515127420425415, Accuracy: 0.626953125\n",
      "Batch: 59, Loss: 1.1908881664276123, Accuracy: 0.599609375\n",
      "Batch: 60, Loss: 1.2750352621078491, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.2046163082122803, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.1844909191131592, Accuracy: 0.6142578125\n",
      "Batch: 63, Loss: 1.225367784500122, Accuracy: 0.6025390625\n",
      "Batch: 64, Loss: 1.2841877937316895, Accuracy: 0.5966796875\n",
      "Batch: 65, Loss: 1.2812448740005493, Accuracy: 0.58203125\n",
      "Batch: 66, Loss: 1.1738157272338867, Accuracy: 0.626953125\n",
      "Batch: 67, Loss: 1.189087986946106, Accuracy: 0.599609375\n",
      "Batch: 68, Loss: 1.123636245727539, Accuracy: 0.64453125\n",
      "Batch: 69, Loss: 1.1937888860702515, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.2346162796020508, Accuracy: 0.5947265625\n",
      "Batch: 71, Loss: 1.193412184715271, Accuracy: 0.6025390625\n",
      "Batch: 72, Loss: 1.3031620979309082, Accuracy: 0.58203125\n",
      "Batch: 73, Loss: 1.2213361263275146, Accuracy: 0.599609375\n",
      "Batch: 74, Loss: 1.163169264793396, Accuracy: 0.611328125\n",
      "Batch: 75, Loss: 1.145039439201355, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.101597547531128, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 1.1371755599975586, Accuracy: 0.63671875\n",
      "Batch: 78, Loss: 1.1146719455718994, Accuracy: 0.6279296875\n",
      "Batch: 79, Loss: 1.165745496749878, Accuracy: 0.6083984375\n",
      "Batch: 80, Loss: 1.1840500831604004, Accuracy: 0.607421875\n",
      "Batch: 81, Loss: 1.1671456098556519, Accuracy: 0.62109375\n",
      "Batch: 82, Loss: 1.1741255521774292, Accuracy: 0.6162109375\n",
      "Batch: 83, Loss: 1.2265539169311523, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1909857988357544, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.1674317121505737, Accuracy: 0.6220703125\n",
      "Batch: 86, Loss: 1.2244086265563965, Accuracy: 0.6005859375\n",
      "Batch: 87, Loss: 1.2111127376556396, Accuracy: 0.615234375\n",
      "Batch: 88, Loss: 1.2699472904205322, Accuracy: 0.607421875\n",
      "Batch: 89, Loss: 1.231781244277954, Accuracy: 0.62109375\n",
      "Batch: 90, Loss: 1.171436071395874, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.194409966468811, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.2083631753921509, Accuracy: 0.6015625\n",
      "Batch: 93, Loss: 1.2525218725204468, Accuracy: 0.5888671875\n",
      "Batch: 94, Loss: 1.3010964393615723, Accuracy: 0.5732421875\n",
      "Batch: 95, Loss: 1.2442203760147095, Accuracy: 0.6337890625\n",
      "Batch: 96, Loss: 1.2860445976257324, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.233386754989624, Accuracy: 0.6015625\n",
      "Batch: 98, Loss: 1.1457747220993042, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.1987504959106445, Accuracy: 0.6171875\n",
      "Batch: 100, Loss: 1.0962694883346558, Accuracy: 0.6435546875\n",
      "Batch: 101, Loss: 1.1815855503082275, Accuracy: 0.6064453125\n",
      "Batch: 102, Loss: 1.2099337577819824, Accuracy: 0.6103515625\n",
      "Batch: 103, Loss: 1.2350162267684937, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1949098110198975, Accuracy: 0.6123046875\n",
      "Batch: 105, Loss: 1.250491738319397, Accuracy: 0.6044921875\n",
      "Batch: 106, Loss: 1.2405731678009033, Accuracy: 0.60546875\n",
      "Batch: 107, Loss: 1.3458795547485352, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.2029790878295898, Accuracy: 0.60546875\n",
      "Batch: 109, Loss: 1.2206580638885498, Accuracy: 0.603515625\n",
      "Batch: 110, Loss: 1.1604639291763306, Accuracy: 0.619140625\n",
      "Batch: 111, Loss: 1.170164704322815, Accuracy: 0.611328125\n",
      "Batch: 112, Loss: 1.1132521629333496, Accuracy: 0.650390625\n",
      "Batch: 113, Loss: 1.22696053981781, Accuracy: 0.6025390625\n",
      "Batch: 114, Loss: 1.2325221300125122, Accuracy: 0.6103515625\n",
      "Batch: 115, Loss: 1.2183176279067993, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.227492332458496, Accuracy: 0.6171875\n",
      "Batch: 117, Loss: 1.256683111190796, Accuracy: 0.5732421875\n",
      "Batch: 118, Loss: 1.2309008836746216, Accuracy: 0.615234375\n",
      "Batch: 119, Loss: 1.3064720630645752, Accuracy: 0.5732421875\n",
      "Batch: 120, Loss: 1.3248332738876343, Accuracy: 0.578125\n",
      "Batch: 121, Loss: 1.231050968170166, Accuracy: 0.619140625\n",
      "Batch: 122, Loss: 1.266277551651001, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.2425971031188965, Accuracy: 0.59375\n",
      "Batch: 124, Loss: 1.3182427883148193, Accuracy: 0.5625\n",
      "Batch: 125, Loss: 1.204097032546997, Accuracy: 0.626953125\n",
      "Batch: 126, Loss: 1.306570053100586, Accuracy: 0.5888671875\n",
      "Batch: 127, Loss: 1.2716561555862427, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2637677192687988, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.3157470226287842, Accuracy: 0.5859375\n",
      "Batch: 130, Loss: 1.2187589406967163, Accuracy: 0.58203125\n",
      "Batch: 131, Loss: 1.2648091316223145, Accuracy: 0.5869140625\n",
      "Batch: 132, Loss: 1.0896778106689453, Accuracy: 0.6318359375\n",
      "Batch: 133, Loss: 1.2525198459625244, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1268486976623535, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.063011884689331, Accuracy: 0.6572265625\n",
      "Batch: 136, Loss: 1.1727467775344849, Accuracy: 0.6123046875\n",
      "Batch: 137, Loss: 1.206051230430603, Accuracy: 0.6015625\n",
      "Batch: 138, Loss: 1.3003578186035156, Accuracy: 0.5771484375\n",
      "Batch: 139, Loss: 1.2111964225769043, Accuracy: 0.6181640625\n",
      "Batch: 140, Loss: 1.2858060598373413, Accuracy: 0.5810546875\n",
      "Batch: 141, Loss: 1.238022804260254, Accuracy: 0.6015625\n",
      "Batch: 142, Loss: 1.2303078174591064, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.248162031173706, Accuracy: 0.59765625\n",
      "Batch: 144, Loss: 1.271367073059082, Accuracy: 0.5830078125\n",
      "Batch: 145, Loss: 1.297204613685608, Accuracy: 0.5771484375\n",
      "Batch: 146, Loss: 1.3111438751220703, Accuracy: 0.5830078125\n",
      "Batch: 147, Loss: 1.2640719413757324, Accuracy: 0.5986328125\n",
      "Batch: 148, Loss: 1.2531225681304932, Accuracy: 0.58203125\n",
      "Batch: 149, Loss: 1.226407766342163, Accuracy: 0.6162109375\n",
      "Batch: 150, Loss: 1.204498052597046, Accuracy: 0.6064453125\n",
      "Batch: 151, Loss: 1.2481880187988281, Accuracy: 0.6103515625\n",
      "Batch: 152, Loss: 1.2305878400802612, Accuracy: 0.5947265625\n",
      "Batch: 153, Loss: 1.2234852313995361, Accuracy: 0.609375\n",
      "Batch: 154, Loss: 1.1468877792358398, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.2048896551132202, Accuracy: 0.6123046875\n",
      "Epoch 426/200\n",
      "Batch: 1, Loss: 1.2552459239959717, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.1237082481384277, Accuracy: 0.6416015625\n",
      "Batch: 3, Loss: 1.1092033386230469, Accuracy: 0.6396484375\n",
      "Batch: 4, Loss: 1.0892773866653442, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 1.0664680004119873, Accuracy: 0.6494140625\n",
      "Batch: 6, Loss: 1.0937103033065796, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0771169662475586, Accuracy: 0.65625\n",
      "Batch: 8, Loss: 1.0948328971862793, Accuracy: 0.650390625\n",
      "Batch: 9, Loss: 1.0321531295776367, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 1.0247886180877686, Accuracy: 0.669921875\n",
      "Batch: 11, Loss: 1.0666477680206299, Accuracy: 0.6357421875\n",
      "Batch: 12, Loss: 1.079053521156311, Accuracy: 0.6357421875\n",
      "Batch: 13, Loss: 1.0086891651153564, Accuracy: 0.6572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 1.0296730995178223, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 1.0136184692382812, Accuracy: 0.6572265625\n",
      "Batch: 16, Loss: 1.121713638305664, Accuracy: 0.626953125\n",
      "Batch: 17, Loss: 1.0859153270721436, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1722228527069092, Accuracy: 0.5966796875\n",
      "Batch: 19, Loss: 1.230435848236084, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.1446342468261719, Accuracy: 0.6259765625\n",
      "Batch: 21, Loss: 1.1099241971969604, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.2929487228393555, Accuracy: 0.5849609375\n",
      "Batch: 23, Loss: 1.3211500644683838, Accuracy: 0.583984375\n",
      "Batch: 24, Loss: 1.1676421165466309, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.1973587274551392, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.2393255233764648, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.159239649772644, Accuracy: 0.607421875\n",
      "Batch: 28, Loss: 1.1418323516845703, Accuracy: 0.6171875\n",
      "Batch: 29, Loss: 1.161850929260254, Accuracy: 0.619140625\n",
      "Batch: 30, Loss: 1.2060856819152832, Accuracy: 0.5869140625\n",
      "Batch: 31, Loss: 1.2395682334899902, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0608649253845215, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 0.9994481205940247, Accuracy: 0.6728515625\n",
      "Batch: 34, Loss: 1.0910032987594604, Accuracy: 0.6328125\n",
      "Batch: 35, Loss: 1.134185791015625, Accuracy: 0.642578125\n",
      "Batch: 36, Loss: 1.2491822242736816, Accuracy: 0.5927734375\n",
      "Batch: 37, Loss: 1.2707080841064453, Accuracy: 0.5810546875\n",
      "Batch: 38, Loss: 1.2093124389648438, Accuracy: 0.59375\n",
      "Batch: 39, Loss: 1.086503028869629, Accuracy: 0.64453125\n",
      "Batch: 40, Loss: 1.135321855545044, Accuracy: 0.6318359375\n",
      "Batch: 41, Loss: 1.1712018251419067, Accuracy: 0.60546875\n",
      "Batch: 42, Loss: 1.0824018716812134, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 1.13901686668396, Accuracy: 0.630859375\n",
      "Batch: 44, Loss: 1.0686345100402832, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 1.075803518295288, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.235675573348999, Accuracy: 0.599609375\n",
      "Batch: 47, Loss: 1.1529868841171265, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.1592731475830078, Accuracy: 0.615234375\n",
      "Batch: 49, Loss: 1.2588002681732178, Accuracy: 0.60546875\n",
      "Batch: 50, Loss: 1.165750503540039, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.205055594444275, Accuracy: 0.599609375\n",
      "Batch: 52, Loss: 1.2310423851013184, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.2114167213439941, Accuracy: 0.58203125\n",
      "Batch: 54, Loss: 1.1971402168273926, Accuracy: 0.6376953125\n",
      "Batch: 55, Loss: 1.1685386896133423, Accuracy: 0.623046875\n",
      "Batch: 56, Loss: 1.113049030303955, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.1237175464630127, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.1674165725708008, Accuracy: 0.6142578125\n",
      "Batch: 59, Loss: 1.2345249652862549, Accuracy: 0.603515625\n",
      "Batch: 60, Loss: 1.2669695615768433, Accuracy: 0.6025390625\n",
      "Batch: 61, Loss: 1.2299261093139648, Accuracy: 0.5859375\n",
      "Batch: 62, Loss: 1.2149136066436768, Accuracy: 0.6083984375\n",
      "Batch: 63, Loss: 1.2168762683868408, Accuracy: 0.599609375\n",
      "Batch: 64, Loss: 1.2713115215301514, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.236055850982666, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.192610740661621, Accuracy: 0.6064453125\n",
      "Batch: 67, Loss: 1.1681525707244873, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.1608006954193115, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.229079008102417, Accuracy: 0.60546875\n",
      "Batch: 70, Loss: 1.1528451442718506, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.177304983139038, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.2696022987365723, Accuracy: 0.5830078125\n",
      "Batch: 73, Loss: 1.1939207315444946, Accuracy: 0.6025390625\n",
      "Batch: 74, Loss: 1.1316195726394653, Accuracy: 0.6318359375\n",
      "Batch: 75, Loss: 1.1696968078613281, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.1351215839385986, Accuracy: 0.638671875\n",
      "Batch: 77, Loss: 1.1245718002319336, Accuracy: 0.625\n",
      "Batch: 78, Loss: 1.098107933998108, Accuracy: 0.6318359375\n",
      "Batch: 79, Loss: 1.186669945716858, Accuracy: 0.6123046875\n",
      "Batch: 80, Loss: 1.2465460300445557, Accuracy: 0.6064453125\n",
      "Batch: 81, Loss: 1.1687498092651367, Accuracy: 0.6171875\n",
      "Batch: 82, Loss: 1.1766748428344727, Accuracy: 0.6513671875\n",
      "Batch: 83, Loss: 1.2648980617523193, Accuracy: 0.59375\n",
      "Batch: 84, Loss: 1.1988794803619385, Accuracy: 0.6201171875\n",
      "Batch: 85, Loss: 1.2079983949661255, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.2106742858886719, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.284533143043518, Accuracy: 0.5859375\n",
      "Batch: 88, Loss: 1.2152220010757446, Accuracy: 0.603515625\n",
      "Batch: 89, Loss: 1.241375207901001, Accuracy: 0.5947265625\n",
      "Batch: 90, Loss: 1.137378215789795, Accuracy: 0.6259765625\n",
      "Batch: 91, Loss: 1.1681029796600342, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.1608656644821167, Accuracy: 0.6396484375\n",
      "Batch: 93, Loss: 1.170548677444458, Accuracy: 0.6123046875\n",
      "Batch: 94, Loss: 1.235883355140686, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.234002709388733, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.2253234386444092, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.231809377670288, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.20109224319458, Accuracy: 0.6044921875\n",
      "Batch: 99, Loss: 1.2637369632720947, Accuracy: 0.5966796875\n",
      "Batch: 100, Loss: 1.1003339290618896, Accuracy: 0.6328125\n",
      "Batch: 101, Loss: 1.1628243923187256, Accuracy: 0.6337890625\n",
      "Batch: 102, Loss: 1.238175630569458, Accuracy: 0.5947265625\n",
      "Batch: 103, Loss: 1.1917929649353027, Accuracy: 0.6201171875\n",
      "Batch: 104, Loss: 1.2395275831222534, Accuracy: 0.5859375\n",
      "Batch: 105, Loss: 1.2721741199493408, Accuracy: 0.5947265625\n",
      "Batch: 106, Loss: 1.229210376739502, Accuracy: 0.609375\n",
      "Batch: 107, Loss: 1.324256420135498, Accuracy: 0.572265625\n",
      "Batch: 108, Loss: 1.200189232826233, Accuracy: 0.59765625\n",
      "Batch: 109, Loss: 1.2057756185531616, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.1767539978027344, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.1357502937316895, Accuracy: 0.630859375\n",
      "Batch: 112, Loss: 1.1353442668914795, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.2548184394836426, Accuracy: 0.583984375\n",
      "Batch: 114, Loss: 1.2181452512741089, Accuracy: 0.6005859375\n",
      "Batch: 115, Loss: 1.222021460533142, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.2283276319503784, Accuracy: 0.6142578125\n",
      "Batch: 117, Loss: 1.1819885969161987, Accuracy: 0.609375\n",
      "Batch: 118, Loss: 1.2980223894119263, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.320751667022705, Accuracy: 0.58203125\n",
      "Batch: 120, Loss: 1.3359497785568237, Accuracy: 0.572265625\n",
      "Batch: 121, Loss: 1.3039313554763794, Accuracy: 0.5712890625\n",
      "Batch: 122, Loss: 1.2851234674453735, Accuracy: 0.599609375\n",
      "Batch: 123, Loss: 1.2313109636306763, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.2666562795639038, Accuracy: 0.5849609375\n",
      "Batch: 125, Loss: 1.2557697296142578, Accuracy: 0.5888671875\n",
      "Batch: 126, Loss: 1.3605960607528687, Accuracy: 0.568359375\n",
      "Batch: 127, Loss: 1.3390755653381348, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.2769209146499634, Accuracy: 0.580078125\n",
      "Batch: 129, Loss: 1.2387707233428955, Accuracy: 0.611328125\n",
      "Batch: 130, Loss: 1.1264978647232056, Accuracy: 0.6396484375\n",
      "Batch: 131, Loss: 1.3115770816802979, Accuracy: 0.5888671875\n",
      "Batch: 132, Loss: 1.1257392168045044, Accuracy: 0.6337890625\n",
      "Batch: 133, Loss: 1.2115137577056885, Accuracy: 0.6123046875\n",
      "Batch: 134, Loss: 1.1233456134796143, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 1.072305679321289, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.1770553588867188, Accuracy: 0.6318359375\n",
      "Batch: 137, Loss: 1.1808302402496338, Accuracy: 0.6279296875\n",
      "Batch: 138, Loss: 1.2157278060913086, Accuracy: 0.615234375\n",
      "Batch: 139, Loss: 1.2465651035308838, Accuracy: 0.591796875\n",
      "Batch: 140, Loss: 1.333644151687622, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.2750117778778076, Accuracy: 0.583984375\n",
      "Batch: 142, Loss: 1.2075066566467285, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.2830898761749268, Accuracy: 0.591796875\n",
      "Batch: 144, Loss: 1.2485556602478027, Accuracy: 0.6025390625\n",
      "Batch: 145, Loss: 1.3705167770385742, Accuracy: 0.5537109375\n",
      "Batch: 146, Loss: 1.2203887701034546, Accuracy: 0.6044921875\n",
      "Batch: 147, Loss: 1.2011842727661133, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.2702064514160156, Accuracy: 0.587890625\n",
      "Batch: 149, Loss: 1.1680148839950562, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.207986831665039, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.2164616584777832, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.211213231086731, Accuracy: 0.6025390625\n",
      "Batch: 153, Loss: 1.1780694723129272, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 154, Loss: 1.1841493844985962, Accuracy: 0.6181640625\n",
      "Batch: 155, Loss: 1.0993244647979736, Accuracy: 0.6552734375\n",
      "Epoch 427/200\n",
      "Batch: 1, Loss: 1.2828266620635986, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.1217353343963623, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.0324960947036743, Accuracy: 0.650390625\n",
      "Batch: 4, Loss: 1.1568129062652588, Accuracy: 0.609375\n",
      "Batch: 5, Loss: 1.0712857246398926, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.1143866777420044, Accuracy: 0.634765625\n",
      "Batch: 7, Loss: 1.1067476272583008, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.079329013824463, Accuracy: 0.6533203125\n",
      "Batch: 9, Loss: 1.0199716091156006, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 1.0105347633361816, Accuracy: 0.662109375\n",
      "Batch: 11, Loss: 1.0269187688827515, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 1.0584297180175781, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 1.064851999282837, Accuracy: 0.65625\n",
      "Batch: 14, Loss: 0.9891119599342346, Accuracy: 0.6650390625\n",
      "Batch: 15, Loss: 0.9969325065612793, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.0967698097229004, Accuracy: 0.642578125\n",
      "Batch: 17, Loss: 1.1222145557403564, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1750527620315552, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.2259747982025146, Accuracy: 0.609375\n",
      "Batch: 20, Loss: 1.1281198263168335, Accuracy: 0.6357421875\n",
      "Batch: 21, Loss: 1.1496117115020752, Accuracy: 0.630859375\n",
      "Batch: 22, Loss: 1.287566065788269, Accuracy: 0.5859375\n",
      "Batch: 23, Loss: 1.2851932048797607, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1826601028442383, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.2107532024383545, Accuracy: 0.59375\n",
      "Batch: 26, Loss: 1.265287160873413, Accuracy: 0.59375\n",
      "Batch: 27, Loss: 1.1730738878250122, Accuracy: 0.607421875\n",
      "Batch: 28, Loss: 1.1379711627960205, Accuracy: 0.6142578125\n",
      "Batch: 29, Loss: 1.0814729928970337, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.1968297958374023, Accuracy: 0.607421875\n",
      "Batch: 31, Loss: 1.2662032842636108, Accuracy: 0.58203125\n",
      "Batch: 32, Loss: 1.078801155090332, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.0241501331329346, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.096447229385376, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.1798748970031738, Accuracy: 0.603515625\n",
      "Batch: 36, Loss: 1.2490818500518799, Accuracy: 0.5986328125\n",
      "Batch: 37, Loss: 1.2725722789764404, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.1708054542541504, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.1168724298477173, Accuracy: 0.625\n",
      "Batch: 40, Loss: 1.1462771892547607, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.1889036893844604, Accuracy: 0.6064453125\n",
      "Batch: 42, Loss: 1.0682563781738281, Accuracy: 0.6689453125\n",
      "Batch: 43, Loss: 1.1034443378448486, Accuracy: 0.6318359375\n",
      "Batch: 44, Loss: 1.1090600490570068, Accuracy: 0.6318359375\n",
      "Batch: 45, Loss: 1.1384713649749756, Accuracy: 0.6259765625\n",
      "Batch: 46, Loss: 1.187216877937317, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.152338981628418, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1551282405853271, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.15664803981781, Accuracy: 0.6298828125\n",
      "Batch: 50, Loss: 1.1415092945098877, Accuracy: 0.62109375\n",
      "Batch: 51, Loss: 1.1734838485717773, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.207409381866455, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.2124152183532715, Accuracy: 0.5830078125\n",
      "Batch: 54, Loss: 1.2248750925064087, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.202559232711792, Accuracy: 0.6142578125\n",
      "Batch: 56, Loss: 1.1494272947311401, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.1665916442871094, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.1631096601486206, Accuracy: 0.6142578125\n",
      "Batch: 59, Loss: 1.1696819067001343, Accuracy: 0.6083984375\n",
      "Batch: 60, Loss: 1.2840863466262817, Accuracy: 0.5791015625\n",
      "Batch: 61, Loss: 1.2516201734542847, Accuracy: 0.5966796875\n",
      "Batch: 62, Loss: 1.2325990200042725, Accuracy: 0.5947265625\n",
      "Batch: 63, Loss: 1.2217493057250977, Accuracy: 0.59765625\n",
      "Batch: 64, Loss: 1.2620601654052734, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.2054157257080078, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.1673622131347656, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1860778331756592, Accuracy: 0.6064453125\n",
      "Batch: 68, Loss: 1.1050282716751099, Accuracy: 0.6416015625\n",
      "Batch: 69, Loss: 1.2041292190551758, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.2027665376663208, Accuracy: 0.59765625\n",
      "Batch: 71, Loss: 1.1784865856170654, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.2415916919708252, Accuracy: 0.59765625\n",
      "Batch: 73, Loss: 1.2137631177902222, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.1189565658569336, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.1165368556976318, Accuracy: 0.658203125\n",
      "Batch: 76, Loss: 1.0923243761062622, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 1.0482836961746216, Accuracy: 0.66796875\n",
      "Batch: 78, Loss: 1.116685152053833, Accuracy: 0.6328125\n",
      "Batch: 79, Loss: 1.1226415634155273, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.1918931007385254, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.1158686876296997, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.1680488586425781, Accuracy: 0.625\n",
      "Batch: 83, Loss: 1.2167139053344727, Accuracy: 0.5966796875\n",
      "Batch: 84, Loss: 1.2498619556427002, Accuracy: 0.59765625\n",
      "Batch: 85, Loss: 1.1969928741455078, Accuracy: 0.6240234375\n",
      "Batch: 86, Loss: 1.2425918579101562, Accuracy: 0.615234375\n",
      "Batch: 87, Loss: 1.2526962757110596, Accuracy: 0.59765625\n",
      "Batch: 88, Loss: 1.2204828262329102, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.2020411491394043, Accuracy: 0.599609375\n",
      "Batch: 90, Loss: 1.1565730571746826, Accuracy: 0.6123046875\n",
      "Batch: 91, Loss: 1.169836163520813, Accuracy: 0.6171875\n",
      "Batch: 92, Loss: 1.1831474304199219, Accuracy: 0.61328125\n",
      "Batch: 93, Loss: 1.1616594791412354, Accuracy: 0.6259765625\n",
      "Batch: 94, Loss: 1.2025197744369507, Accuracy: 0.59765625\n",
      "Batch: 95, Loss: 1.234081745147705, Accuracy: 0.6103515625\n",
      "Batch: 96, Loss: 1.2805827856063843, Accuracy: 0.591796875\n",
      "Batch: 97, Loss: 1.1944539546966553, Accuracy: 0.6181640625\n",
      "Batch: 98, Loss: 1.161451816558838, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.2753913402557373, Accuracy: 0.5888671875\n",
      "Batch: 100, Loss: 1.0906941890716553, Accuracy: 0.634765625\n",
      "Batch: 101, Loss: 1.1387913227081299, Accuracy: 0.6240234375\n",
      "Batch: 102, Loss: 1.2018210887908936, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.2071362733840942, Accuracy: 0.615234375\n",
      "Batch: 104, Loss: 1.2182152271270752, Accuracy: 0.6103515625\n",
      "Batch: 105, Loss: 1.2889587879180908, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.2213540077209473, Accuracy: 0.6123046875\n",
      "Batch: 107, Loss: 1.3409512042999268, Accuracy: 0.58203125\n",
      "Batch: 108, Loss: 1.2306766510009766, Accuracy: 0.572265625\n",
      "Batch: 109, Loss: 1.2200920581817627, Accuracy: 0.599609375\n",
      "Batch: 110, Loss: 1.2037533521652222, Accuracy: 0.615234375\n",
      "Batch: 111, Loss: 1.1254935264587402, Accuracy: 0.6494140625\n",
      "Batch: 112, Loss: 1.1420104503631592, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.2189030647277832, Accuracy: 0.607421875\n",
      "Batch: 114, Loss: 1.2183539867401123, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.2070648670196533, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.2458149194717407, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.186936378479004, Accuracy: 0.59765625\n",
      "Batch: 118, Loss: 1.2619333267211914, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.3055953979492188, Accuracy: 0.5888671875\n",
      "Batch: 120, Loss: 1.2837083339691162, Accuracy: 0.6005859375\n",
      "Batch: 121, Loss: 1.2379192113876343, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2205226421356201, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.2265065908432007, Accuracy: 0.6181640625\n",
      "Batch: 124, Loss: 1.2915005683898926, Accuracy: 0.583984375\n",
      "Batch: 125, Loss: 1.1882798671722412, Accuracy: 0.611328125\n",
      "Batch: 126, Loss: 1.2691516876220703, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.301059365272522, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.2627105712890625, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.204461932182312, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.1597466468811035, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.26055109500885, Accuracy: 0.5869140625\n",
      "Batch: 132, Loss: 1.1394011974334717, Accuracy: 0.6337890625\n",
      "Batch: 133, Loss: 1.218072772026062, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.144827127456665, Accuracy: 0.642578125\n",
      "Batch: 135, Loss: 1.1266740560531616, Accuracy: 0.62890625\n",
      "Batch: 136, Loss: 1.1282732486724854, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.2804782390594482, Accuracy: 0.580078125\n",
      "Batch: 138, Loss: 1.2755986452102661, Accuracy: 0.5908203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 1.2179683446884155, Accuracy: 0.6025390625\n",
      "Batch: 140, Loss: 1.2964462041854858, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.2264995574951172, Accuracy: 0.6083984375\n",
      "Batch: 142, Loss: 1.2392159700393677, Accuracy: 0.5810546875\n",
      "Batch: 143, Loss: 1.2864973545074463, Accuracy: 0.578125\n",
      "Batch: 144, Loss: 1.3661251068115234, Accuracy: 0.5654296875\n",
      "Batch: 145, Loss: 1.321336030960083, Accuracy: 0.5673828125\n",
      "Batch: 146, Loss: 1.2955827713012695, Accuracy: 0.5732421875\n",
      "Batch: 147, Loss: 1.2848927974700928, Accuracy: 0.58203125\n",
      "Batch: 148, Loss: 1.196152925491333, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.2361342906951904, Accuracy: 0.5849609375\n",
      "Batch: 150, Loss: 1.1809662580490112, Accuracy: 0.6201171875\n",
      "Batch: 151, Loss: 1.2540169954299927, Accuracy: 0.603515625\n",
      "Batch: 152, Loss: 1.2104945182800293, Accuracy: 0.5888671875\n",
      "Batch: 153, Loss: 1.2042021751403809, Accuracy: 0.6162109375\n",
      "Batch: 154, Loss: 1.153000831604004, Accuracy: 0.64453125\n",
      "Batch: 155, Loss: 1.1519719362258911, Accuracy: 0.611328125\n",
      "Epoch 428/200\n",
      "Batch: 1, Loss: 1.2662732601165771, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.1348098516464233, Accuracy: 0.6376953125\n",
      "Batch: 3, Loss: 1.049656629562378, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.1174023151397705, Accuracy: 0.6416015625\n",
      "Batch: 5, Loss: 1.0593395233154297, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.1153391599655151, Accuracy: 0.626953125\n",
      "Batch: 7, Loss: 1.060875654220581, Accuracy: 0.646484375\n",
      "Batch: 8, Loss: 1.0341987609863281, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 1.083033561706543, Accuracy: 0.6416015625\n",
      "Batch: 10, Loss: 0.9968464374542236, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 1.0680949687957764, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 1.0750840902328491, Accuracy: 0.6328125\n",
      "Batch: 13, Loss: 1.0499054193496704, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 1.0413434505462646, Accuracy: 0.6650390625\n",
      "Batch: 15, Loss: 0.9406040906906128, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.0491487979888916, Accuracy: 0.6630859375\n",
      "Batch: 17, Loss: 1.0661455392837524, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.155327558517456, Accuracy: 0.6181640625\n",
      "Batch: 19, Loss: 1.2747094631195068, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.1369192600250244, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.1337270736694336, Accuracy: 0.6298828125\n",
      "Batch: 22, Loss: 1.2674484252929688, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.2845475673675537, Accuracy: 0.5615234375\n",
      "Batch: 24, Loss: 1.142378568649292, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1851557493209839, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.2392126321792603, Accuracy: 0.5771484375\n",
      "Batch: 27, Loss: 1.1615796089172363, Accuracy: 0.615234375\n",
      "Batch: 28, Loss: 1.1172223091125488, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.1239501237869263, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.164229393005371, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.2271990776062012, Accuracy: 0.595703125\n",
      "Batch: 32, Loss: 1.0986328125, Accuracy: 0.6416015625\n",
      "Batch: 33, Loss: 1.0271662473678589, Accuracy: 0.6455078125\n",
      "Batch: 34, Loss: 1.1495609283447266, Accuracy: 0.640625\n",
      "Batch: 35, Loss: 1.1804163455963135, Accuracy: 0.59765625\n",
      "Batch: 36, Loss: 1.2592300176620483, Accuracy: 0.5888671875\n",
      "Batch: 37, Loss: 1.250199556350708, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.182844877243042, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.1571156978607178, Accuracy: 0.6005859375\n",
      "Batch: 40, Loss: 1.1408400535583496, Accuracy: 0.6298828125\n",
      "Batch: 41, Loss: 1.1929429769515991, Accuracy: 0.5947265625\n",
      "Batch: 42, Loss: 1.123487949371338, Accuracy: 0.6357421875\n",
      "Batch: 43, Loss: 1.0537878274917603, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0672208070755005, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 1.0849251747131348, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.1829257011413574, Accuracy: 0.6083984375\n",
      "Batch: 47, Loss: 1.1871893405914307, Accuracy: 0.6083984375\n",
      "Batch: 48, Loss: 1.1545662879943848, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.1960594654083252, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.1908315420150757, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.1642847061157227, Accuracy: 0.6171875\n",
      "Batch: 52, Loss: 1.2915754318237305, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.2670683860778809, Accuracy: 0.6015625\n",
      "Batch: 54, Loss: 1.2470002174377441, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.1711593866348267, Accuracy: 0.6328125\n",
      "Batch: 56, Loss: 1.187735676765442, Accuracy: 0.6142578125\n",
      "Batch: 57, Loss: 1.179758071899414, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.184711217880249, Accuracy: 0.609375\n",
      "Batch: 59, Loss: 1.1377687454223633, Accuracy: 0.6220703125\n",
      "Batch: 60, Loss: 1.275585651397705, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.2077070474624634, Accuracy: 0.6005859375\n",
      "Batch: 62, Loss: 1.2468807697296143, Accuracy: 0.5859375\n",
      "Batch: 63, Loss: 1.225813388824463, Accuracy: 0.6005859375\n",
      "Batch: 64, Loss: 1.252339243888855, Accuracy: 0.5888671875\n",
      "Batch: 65, Loss: 1.2299854755401611, Accuracy: 0.591796875\n",
      "Batch: 66, Loss: 1.1821670532226562, Accuracy: 0.6240234375\n",
      "Batch: 67, Loss: 1.1688991785049438, Accuracy: 0.6005859375\n",
      "Batch: 68, Loss: 1.1337229013442993, Accuracy: 0.634765625\n",
      "Batch: 69, Loss: 1.2038969993591309, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.1855885982513428, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.198270320892334, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.221251368522644, Accuracy: 0.60546875\n",
      "Batch: 73, Loss: 1.2278292179107666, Accuracy: 0.5830078125\n",
      "Batch: 74, Loss: 1.1288511753082275, Accuracy: 0.6259765625\n",
      "Batch: 75, Loss: 1.1759583950042725, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.1195976734161377, Accuracy: 0.640625\n",
      "Batch: 77, Loss: 1.1061431169509888, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.1450519561767578, Accuracy: 0.6220703125\n",
      "Batch: 79, Loss: 1.1615016460418701, Accuracy: 0.6240234375\n",
      "Batch: 80, Loss: 1.234747290611267, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.1756590604782104, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.1737524271011353, Accuracy: 0.611328125\n",
      "Batch: 83, Loss: 1.246654987335205, Accuracy: 0.6005859375\n",
      "Batch: 84, Loss: 1.2216055393218994, Accuracy: 0.5908203125\n",
      "Batch: 85, Loss: 1.228269338607788, Accuracy: 0.59765625\n",
      "Batch: 86, Loss: 1.2193851470947266, Accuracy: 0.6015625\n",
      "Batch: 87, Loss: 1.2061234712600708, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.226231336593628, Accuracy: 0.6025390625\n",
      "Batch: 89, Loss: 1.2381149530410767, Accuracy: 0.5927734375\n",
      "Batch: 90, Loss: 1.1388218402862549, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.1811492443084717, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.1704378128051758, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.201772928237915, Accuracy: 0.611328125\n",
      "Batch: 94, Loss: 1.2581998109817505, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.222121000289917, Accuracy: 0.6123046875\n",
      "Batch: 96, Loss: 1.2676957845687866, Accuracy: 0.6064453125\n",
      "Batch: 97, Loss: 1.2267084121704102, Accuracy: 0.6044921875\n",
      "Batch: 98, Loss: 1.1311745643615723, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.1661458015441895, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.1143665313720703, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.1749944686889648, Accuracy: 0.59765625\n",
      "Batch: 102, Loss: 1.278529405593872, Accuracy: 0.5810546875\n",
      "Batch: 103, Loss: 1.1793878078460693, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1492140293121338, Accuracy: 0.6337890625\n",
      "Batch: 105, Loss: 1.2879033088684082, Accuracy: 0.583984375\n",
      "Batch: 106, Loss: 1.1911182403564453, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.2858681678771973, Accuracy: 0.57421875\n",
      "Batch: 108, Loss: 1.2316535711288452, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.298214316368103, Accuracy: 0.5771484375\n",
      "Batch: 110, Loss: 1.1766488552093506, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.156414270401001, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.1128342151641846, Accuracy: 0.658203125\n",
      "Batch: 113, Loss: 1.2381962537765503, Accuracy: 0.5849609375\n",
      "Batch: 114, Loss: 1.2658195495605469, Accuracy: 0.5673828125\n",
      "Batch: 115, Loss: 1.232832670211792, Accuracy: 0.5888671875\n",
      "Batch: 116, Loss: 1.2593839168548584, Accuracy: 0.59375\n",
      "Batch: 117, Loss: 1.1829614639282227, Accuracy: 0.60546875\n",
      "Batch: 118, Loss: 1.2254525423049927, Accuracy: 0.5927734375\n",
      "Batch: 119, Loss: 1.2287943363189697, Accuracy: 0.6083984375\n",
      "Batch: 120, Loss: 1.2924387454986572, Accuracy: 0.580078125\n",
      "Batch: 121, Loss: 1.2390942573547363, Accuracy: 0.6083984375\n",
      "Batch: 122, Loss: 1.2447319030761719, Accuracy: 0.6025390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 123, Loss: 1.2016528844833374, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.2247201204299927, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.2256231307983398, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.2783418893814087, Accuracy: 0.5947265625\n",
      "Batch: 127, Loss: 1.2804756164550781, Accuracy: 0.5859375\n",
      "Batch: 128, Loss: 1.2052972316741943, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.243717908859253, Accuracy: 0.5947265625\n",
      "Batch: 130, Loss: 1.1786829233169556, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.2827333211898804, Accuracy: 0.568359375\n",
      "Batch: 132, Loss: 1.1311171054840088, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.2306647300720215, Accuracy: 0.6064453125\n",
      "Batch: 134, Loss: 1.1484248638153076, Accuracy: 0.64453125\n",
      "Batch: 135, Loss: 1.085932970046997, Accuracy: 0.6376953125\n",
      "Batch: 136, Loss: 1.107833981513977, Accuracy: 0.6240234375\n",
      "Batch: 137, Loss: 1.139488697052002, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 1.2756346464157104, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.2471368312835693, Accuracy: 0.5908203125\n",
      "Batch: 140, Loss: 1.2882792949676514, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.2084169387817383, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.2488467693328857, Accuracy: 0.6220703125\n",
      "Batch: 143, Loss: 1.2702419757843018, Accuracy: 0.5927734375\n",
      "Batch: 144, Loss: 1.2836722135543823, Accuracy: 0.578125\n",
      "Batch: 145, Loss: 1.3285564184188843, Accuracy: 0.58203125\n",
      "Batch: 146, Loss: 1.2076416015625, Accuracy: 0.6005859375\n",
      "Batch: 147, Loss: 1.1864292621612549, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.2491304874420166, Accuracy: 0.59375\n",
      "Batch: 149, Loss: 1.248063325881958, Accuracy: 0.5693359375\n",
      "Batch: 150, Loss: 1.1768958568572998, Accuracy: 0.6005859375\n",
      "Batch: 151, Loss: 1.2367238998413086, Accuracy: 0.603515625\n",
      "Batch: 152, Loss: 1.2030372619628906, Accuracy: 0.6044921875\n",
      "Batch: 153, Loss: 1.1771541833877563, Accuracy: 0.6103515625\n",
      "Batch: 154, Loss: 1.1486217975616455, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.1308326721191406, Accuracy: 0.638671875\n",
      "Epoch 429/200\n",
      "Batch: 1, Loss: 1.2657997608184814, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.1552534103393555, Accuracy: 0.6201171875\n",
      "Batch: 3, Loss: 1.0917549133300781, Accuracy: 0.6298828125\n",
      "Batch: 4, Loss: 1.1178686618804932, Accuracy: 0.619140625\n",
      "Batch: 5, Loss: 1.0577408075332642, Accuracy: 0.6513671875\n",
      "Batch: 6, Loss: 1.0346295833587646, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.0171024799346924, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 1.0451918840408325, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 1.0752180814743042, Accuracy: 0.65625\n",
      "Batch: 10, Loss: 0.9764479398727417, Accuracy: 0.6796875\n",
      "Batch: 11, Loss: 1.0243301391601562, Accuracy: 0.6630859375\n",
      "Batch: 12, Loss: 1.0663261413574219, Accuracy: 0.6484375\n",
      "Batch: 13, Loss: 1.1142066717147827, Accuracy: 0.6396484375\n",
      "Batch: 14, Loss: 1.0288397073745728, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.9586395025253296, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0642019510269165, Accuracy: 0.66015625\n",
      "Batch: 17, Loss: 1.0479800701141357, Accuracy: 0.66015625\n",
      "Batch: 18, Loss: 1.1696269512176514, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.2781178951263428, Accuracy: 0.587890625\n",
      "Batch: 20, Loss: 1.1250766515731812, Accuracy: 0.6435546875\n",
      "Batch: 21, Loss: 1.0730457305908203, Accuracy: 0.6669921875\n",
      "Batch: 22, Loss: 1.2905842065811157, Accuracy: 0.5810546875\n",
      "Batch: 23, Loss: 1.2825891971588135, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1538283824920654, Accuracy: 0.626953125\n",
      "Batch: 25, Loss: 1.2048619985580444, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.2597848176956177, Accuracy: 0.583984375\n",
      "Batch: 27, Loss: 1.1844596862792969, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.030108094215393, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 1.0948771238327026, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.194968581199646, Accuracy: 0.595703125\n",
      "Batch: 31, Loss: 1.3013290166854858, Accuracy: 0.57421875\n",
      "Batch: 32, Loss: 1.0858148336410522, Accuracy: 0.6259765625\n",
      "Batch: 33, Loss: 1.0406137704849243, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.165320873260498, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.211958885192871, Accuracy: 0.6015625\n",
      "Batch: 36, Loss: 1.2240525484085083, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.2191927433013916, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.209233283996582, Accuracy: 0.5869140625\n",
      "Batch: 39, Loss: 1.0820279121398926, Accuracy: 0.6689453125\n",
      "Batch: 40, Loss: 1.1343151330947876, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1318213939666748, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.1142523288726807, Accuracy: 0.6357421875\n",
      "Batch: 43, Loss: 1.0580002069473267, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.011548638343811, Accuracy: 0.6611328125\n",
      "Batch: 45, Loss: 1.062438726425171, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.1835432052612305, Accuracy: 0.611328125\n",
      "Batch: 47, Loss: 1.1584231853485107, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.1041855812072754, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.2451024055480957, Accuracy: 0.5859375\n",
      "Batch: 50, Loss: 1.1791027784347534, Accuracy: 0.6162109375\n",
      "Batch: 51, Loss: 1.2189644575119019, Accuracy: 0.595703125\n",
      "Batch: 52, Loss: 1.272469162940979, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.218504786491394, Accuracy: 0.611328125\n",
      "Batch: 54, Loss: 1.2286028861999512, Accuracy: 0.603515625\n",
      "Batch: 55, Loss: 1.1328017711639404, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.114098072052002, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.2205604314804077, Accuracy: 0.6171875\n",
      "Batch: 58, Loss: 1.1200274229049683, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.1778597831726074, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2661302089691162, Accuracy: 0.578125\n",
      "Batch: 61, Loss: 1.1747705936431885, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.2084602117538452, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.2059743404388428, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.2649288177490234, Accuracy: 0.5859375\n",
      "Batch: 65, Loss: 1.2053561210632324, Accuracy: 0.611328125\n",
      "Batch: 66, Loss: 1.2136945724487305, Accuracy: 0.599609375\n",
      "Batch: 67, Loss: 1.200232744216919, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.174630880355835, Accuracy: 0.61328125\n",
      "Batch: 69, Loss: 1.1801018714904785, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.1963034868240356, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.1925902366638184, Accuracy: 0.6064453125\n",
      "Batch: 72, Loss: 1.2943570613861084, Accuracy: 0.5693359375\n",
      "Batch: 73, Loss: 1.216599941253662, Accuracy: 0.609375\n",
      "Batch: 74, Loss: 1.166536808013916, Accuracy: 0.6259765625\n",
      "Batch: 75, Loss: 1.1201274394989014, Accuracy: 0.6513671875\n",
      "Batch: 76, Loss: 1.125783085823059, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.1236035823822021, Accuracy: 0.6279296875\n",
      "Batch: 78, Loss: 1.1530516147613525, Accuracy: 0.6103515625\n",
      "Batch: 79, Loss: 1.154242753982544, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.1946347951889038, Accuracy: 0.615234375\n",
      "Batch: 81, Loss: 1.1715970039367676, Accuracy: 0.6181640625\n",
      "Batch: 82, Loss: 1.1955925226211548, Accuracy: 0.615234375\n",
      "Batch: 83, Loss: 1.2283260822296143, Accuracy: 0.5869140625\n",
      "Batch: 84, Loss: 1.196103811264038, Accuracy: 0.6240234375\n",
      "Batch: 85, Loss: 1.179183840751648, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.240408182144165, Accuracy: 0.5986328125\n",
      "Batch: 87, Loss: 1.2531038522720337, Accuracy: 0.59375\n",
      "Batch: 88, Loss: 1.2373402118682861, Accuracy: 0.58203125\n",
      "Batch: 89, Loss: 1.2020920515060425, Accuracy: 0.6103515625\n",
      "Batch: 90, Loss: 1.1872084140777588, Accuracy: 0.623046875\n",
      "Batch: 91, Loss: 1.1630278825759888, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.2166944742202759, Accuracy: 0.6123046875\n",
      "Batch: 93, Loss: 1.1548818349838257, Accuracy: 0.640625\n",
      "Batch: 94, Loss: 1.283170223236084, Accuracy: 0.58984375\n",
      "Batch: 95, Loss: 1.2365788221359253, Accuracy: 0.6162109375\n",
      "Batch: 96, Loss: 1.2110397815704346, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.2098007202148438, Accuracy: 0.6103515625\n",
      "Batch: 98, Loss: 1.1226943731307983, Accuracy: 0.642578125\n",
      "Batch: 99, Loss: 1.2637827396392822, Accuracy: 0.6044921875\n",
      "Batch: 100, Loss: 1.0973477363586426, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.1160027980804443, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.2185337543487549, Accuracy: 0.6083984375\n",
      "Batch: 103, Loss: 1.1996240615844727, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.1862326860427856, Accuracy: 0.6005859375\n",
      "Batch: 105, Loss: 1.2708864212036133, Accuracy: 0.611328125\n",
      "Batch: 106, Loss: 1.1899070739746094, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.377590298652649, Accuracy: 0.5634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 1.2494100332260132, Accuracy: 0.583984375\n",
      "Batch: 109, Loss: 1.21217942237854, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.1717228889465332, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.1702483892440796, Accuracy: 0.6123046875\n",
      "Batch: 112, Loss: 1.1209995746612549, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1862952709197998, Accuracy: 0.6328125\n",
      "Batch: 114, Loss: 1.1960105895996094, Accuracy: 0.6005859375\n",
      "Batch: 115, Loss: 1.2109801769256592, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.2563352584838867, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.2076025009155273, Accuracy: 0.603515625\n",
      "Batch: 118, Loss: 1.2657642364501953, Accuracy: 0.58984375\n",
      "Batch: 119, Loss: 1.3401365280151367, Accuracy: 0.5859375\n",
      "Batch: 120, Loss: 1.3194140195846558, Accuracy: 0.5712890625\n",
      "Batch: 121, Loss: 1.2438299655914307, Accuracy: 0.59375\n",
      "Batch: 122, Loss: 1.2542521953582764, Accuracy: 0.59765625\n",
      "Batch: 123, Loss: 1.205552101135254, Accuracy: 0.6142578125\n",
      "Batch: 124, Loss: 1.2568154335021973, Accuracy: 0.599609375\n",
      "Batch: 125, Loss: 1.21293306350708, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.2543516159057617, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.2838573455810547, Accuracy: 0.57421875\n",
      "Batch: 128, Loss: 1.2135558128356934, Accuracy: 0.6123046875\n",
      "Batch: 129, Loss: 1.2114453315734863, Accuracy: 0.607421875\n",
      "Batch: 130, Loss: 1.2171717882156372, Accuracy: 0.615234375\n",
      "Batch: 131, Loss: 1.2753849029541016, Accuracy: 0.58203125\n",
      "Batch: 132, Loss: 1.1078617572784424, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.2545065879821777, Accuracy: 0.5859375\n",
      "Batch: 134, Loss: 1.2239242792129517, Accuracy: 0.625\n",
      "Batch: 135, Loss: 1.0590859651565552, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.137022852897644, Accuracy: 0.6435546875\n",
      "Batch: 137, Loss: 1.2493038177490234, Accuracy: 0.599609375\n",
      "Batch: 138, Loss: 1.2864487171173096, Accuracy: 0.583984375\n",
      "Batch: 139, Loss: 1.227382779121399, Accuracy: 0.6025390625\n",
      "Batch: 140, Loss: 1.2515100240707397, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.1866984367370605, Accuracy: 0.609375\n",
      "Batch: 142, Loss: 1.2223789691925049, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.3357185125350952, Accuracy: 0.5654296875\n",
      "Batch: 144, Loss: 1.278618574142456, Accuracy: 0.58984375\n",
      "Batch: 145, Loss: 1.323412537574768, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.2608674764633179, Accuracy: 0.580078125\n",
      "Batch: 147, Loss: 1.2439868450164795, Accuracy: 0.5927734375\n",
      "Batch: 148, Loss: 1.2387096881866455, Accuracy: 0.603515625\n",
      "Batch: 149, Loss: 1.2295811176300049, Accuracy: 0.58984375\n",
      "Batch: 150, Loss: 1.2310798168182373, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.2158507108688354, Accuracy: 0.609375\n",
      "Batch: 152, Loss: 1.242131233215332, Accuracy: 0.5966796875\n",
      "Batch: 153, Loss: 1.1621043682098389, Accuracy: 0.6083984375\n",
      "Batch: 154, Loss: 1.1856242418289185, Accuracy: 0.6181640625\n",
      "Batch: 155, Loss: 1.1414031982421875, Accuracy: 0.6103515625\n",
      "Epoch 430/200\n",
      "Batch: 1, Loss: 1.2717434167861938, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 1.1235506534576416, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.0589157342910767, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.135371446609497, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.080670714378357, Accuracy: 0.638671875\n",
      "Batch: 6, Loss: 1.0992841720581055, Accuracy: 0.638671875\n",
      "Batch: 7, Loss: 1.0919620990753174, Accuracy: 0.6376953125\n",
      "Batch: 8, Loss: 1.0262125730514526, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 1.0619442462921143, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 1.0098345279693604, Accuracy: 0.66015625\n",
      "Batch: 11, Loss: 1.0413146018981934, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 1.0481278896331787, Accuracy: 0.640625\n",
      "Batch: 13, Loss: 1.0379679203033447, Accuracy: 0.6552734375\n",
      "Batch: 14, Loss: 0.9782571196556091, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 1.0063927173614502, Accuracy: 0.6611328125\n",
      "Batch: 16, Loss: 1.068171501159668, Accuracy: 0.658203125\n",
      "Batch: 17, Loss: 1.0596652030944824, Accuracy: 0.658203125\n",
      "Batch: 18, Loss: 1.184709906578064, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2610161304473877, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.1590440273284912, Accuracy: 0.626953125\n",
      "Batch: 21, Loss: 1.1328847408294678, Accuracy: 0.626953125\n",
      "Batch: 22, Loss: 1.2628803253173828, Accuracy: 0.587890625\n",
      "Batch: 23, Loss: 1.2704343795776367, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.1638917922973633, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.234614372253418, Accuracy: 0.5927734375\n",
      "Batch: 26, Loss: 1.2437602281570435, Accuracy: 0.607421875\n",
      "Batch: 27, Loss: 1.2211418151855469, Accuracy: 0.6044921875\n",
      "Batch: 28, Loss: 1.0907013416290283, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.103867530822754, Accuracy: 0.6220703125\n",
      "Batch: 30, Loss: 1.1985507011413574, Accuracy: 0.6162109375\n",
      "Batch: 31, Loss: 1.2841873168945312, Accuracy: 0.5751953125\n",
      "Batch: 32, Loss: 1.0463547706604004, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.0148496627807617, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.1198439598083496, Accuracy: 0.646484375\n",
      "Batch: 35, Loss: 1.1466482877731323, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.21637761592865, Accuracy: 0.5947265625\n",
      "Batch: 37, Loss: 1.2617158889770508, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.200630784034729, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.1230213642120361, Accuracy: 0.6259765625\n",
      "Batch: 40, Loss: 1.1479127407073975, Accuracy: 0.6376953125\n",
      "Batch: 41, Loss: 1.1471619606018066, Accuracy: 0.6259765625\n",
      "Batch: 42, Loss: 1.121872901916504, Accuracy: 0.638671875\n",
      "Batch: 43, Loss: 1.0896875858306885, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.0894110202789307, Accuracy: 0.6318359375\n",
      "Batch: 45, Loss: 1.0729753971099854, Accuracy: 0.6572265625\n",
      "Batch: 46, Loss: 1.1606495380401611, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1422181129455566, Accuracy: 0.6318359375\n",
      "Batch: 48, Loss: 1.1352375745773315, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.2415727376937866, Accuracy: 0.6025390625\n",
      "Batch: 50, Loss: 1.1686646938323975, Accuracy: 0.6103515625\n",
      "Batch: 51, Loss: 1.1307203769683838, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.2749261856079102, Accuracy: 0.5888671875\n",
      "Batch: 53, Loss: 1.1910732984542847, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.2622272968292236, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.1902533769607544, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.1257917881011963, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.2308976650238037, Accuracy: 0.611328125\n",
      "Batch: 58, Loss: 1.1508479118347168, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.2165470123291016, Accuracy: 0.611328125\n",
      "Batch: 60, Loss: 1.267461895942688, Accuracy: 0.6083984375\n",
      "Batch: 61, Loss: 1.1696449518203735, Accuracy: 0.59765625\n",
      "Batch: 62, Loss: 1.2290829420089722, Accuracy: 0.59765625\n",
      "Batch: 63, Loss: 1.1814855337142944, Accuracy: 0.6103515625\n",
      "Batch: 64, Loss: 1.2573935985565186, Accuracy: 0.5810546875\n",
      "Batch: 65, Loss: 1.2476470470428467, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.2159863710403442, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.2047414779663086, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.1400177478790283, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.1845650672912598, Accuracy: 0.6044921875\n",
      "Batch: 70, Loss: 1.2653226852416992, Accuracy: 0.595703125\n",
      "Batch: 71, Loss: 1.1569852828979492, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.218413233757019, Accuracy: 0.591796875\n",
      "Batch: 73, Loss: 1.2108405828475952, Accuracy: 0.6064453125\n",
      "Batch: 74, Loss: 1.1617287397384644, Accuracy: 0.6083984375\n",
      "Batch: 75, Loss: 1.1350529193878174, Accuracy: 0.623046875\n",
      "Batch: 76, Loss: 1.1128852367401123, Accuracy: 0.625\n",
      "Batch: 77, Loss: 1.0754320621490479, Accuracy: 0.662109375\n",
      "Batch: 78, Loss: 1.1113841533660889, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.15755295753479, Accuracy: 0.63671875\n",
      "Batch: 80, Loss: 1.2221145629882812, Accuracy: 0.6083984375\n",
      "Batch: 81, Loss: 1.0869039297103882, Accuracy: 0.6494140625\n",
      "Batch: 82, Loss: 1.2276346683502197, Accuracy: 0.603515625\n",
      "Batch: 83, Loss: 1.2903833389282227, Accuracy: 0.5966796875\n",
      "Batch: 84, Loss: 1.1997418403625488, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.2553149461746216, Accuracy: 0.595703125\n",
      "Batch: 86, Loss: 1.241196632385254, Accuracy: 0.5849609375\n",
      "Batch: 87, Loss: 1.2454047203063965, Accuracy: 0.6015625\n",
      "Batch: 88, Loss: 1.2426791191101074, Accuracy: 0.60546875\n",
      "Batch: 89, Loss: 1.2391293048858643, Accuracy: 0.6201171875\n",
      "Batch: 90, Loss: 1.1470813751220703, Accuracy: 0.6611328125\n",
      "Batch: 91, Loss: 1.1678681373596191, Accuracy: 0.60546875\n",
      "Batch: 92, Loss: 1.2002863883972168, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 93, Loss: 1.2516326904296875, Accuracy: 0.603515625\n",
      "Batch: 94, Loss: 1.3016791343688965, Accuracy: 0.587890625\n",
      "Batch: 95, Loss: 1.1778877973556519, Accuracy: 0.6181640625\n",
      "Batch: 96, Loss: 1.2453467845916748, Accuracy: 0.6162109375\n",
      "Batch: 97, Loss: 1.1938804388046265, Accuracy: 0.619140625\n",
      "Batch: 98, Loss: 1.2241079807281494, Accuracy: 0.6171875\n",
      "Batch: 99, Loss: 1.171520709991455, Accuracy: 0.6328125\n",
      "Batch: 100, Loss: 1.1094881296157837, Accuracy: 0.6376953125\n",
      "Batch: 101, Loss: 1.1678069829940796, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2077313661575317, Accuracy: 0.6171875\n",
      "Batch: 103, Loss: 1.1954140663146973, Accuracy: 0.6240234375\n",
      "Batch: 104, Loss: 1.2111034393310547, Accuracy: 0.6142578125\n",
      "Batch: 105, Loss: 1.3011178970336914, Accuracy: 0.5908203125\n",
      "Batch: 106, Loss: 1.2099673748016357, Accuracy: 0.6015625\n",
      "Batch: 107, Loss: 1.3080532550811768, Accuracy: 0.58203125\n",
      "Batch: 108, Loss: 1.2239046096801758, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.2575008869171143, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.1856852769851685, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.168372392654419, Accuracy: 0.6318359375\n",
      "Batch: 112, Loss: 1.1495823860168457, Accuracy: 0.6064453125\n",
      "Batch: 113, Loss: 1.2009081840515137, Accuracy: 0.5947265625\n",
      "Batch: 114, Loss: 1.2282443046569824, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.2139074802398682, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2313824892044067, Accuracy: 0.6064453125\n",
      "Batch: 117, Loss: 1.1869364976882935, Accuracy: 0.5927734375\n",
      "Batch: 118, Loss: 1.253603458404541, Accuracy: 0.568359375\n",
      "Batch: 119, Loss: 1.2899348735809326, Accuracy: 0.5869140625\n",
      "Batch: 120, Loss: 1.3398206233978271, Accuracy: 0.580078125\n",
      "Batch: 121, Loss: 1.2285805940628052, Accuracy: 0.595703125\n",
      "Batch: 122, Loss: 1.265597939491272, Accuracy: 0.6025390625\n",
      "Batch: 123, Loss: 1.2636370658874512, Accuracy: 0.619140625\n",
      "Batch: 124, Loss: 1.3004987239837646, Accuracy: 0.5849609375\n",
      "Batch: 125, Loss: 1.1981568336486816, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.253596544265747, Accuracy: 0.599609375\n",
      "Batch: 127, Loss: 1.237067699432373, Accuracy: 0.61328125\n",
      "Batch: 128, Loss: 1.2864716053009033, Accuracy: 0.572265625\n",
      "Batch: 129, Loss: 1.274422526359558, Accuracy: 0.5966796875\n",
      "Batch: 130, Loss: 1.23897385597229, Accuracy: 0.59765625\n",
      "Batch: 131, Loss: 1.2752610445022583, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.1720759868621826, Accuracy: 0.6171875\n",
      "Batch: 133, Loss: 1.1559301614761353, Accuracy: 0.6279296875\n",
      "Batch: 134, Loss: 1.1333513259887695, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.0844815969467163, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.0938432216644287, Accuracy: 0.6689453125\n",
      "Batch: 137, Loss: 1.1839444637298584, Accuracy: 0.59765625\n",
      "Batch: 138, Loss: 1.2938642501831055, Accuracy: 0.5791015625\n",
      "Batch: 139, Loss: 1.2337663173675537, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.2744228839874268, Accuracy: 0.583984375\n",
      "Batch: 141, Loss: 1.1937167644500732, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.200952172279358, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.2795840501785278, Accuracy: 0.59765625\n",
      "Batch: 144, Loss: 1.2454582452774048, Accuracy: 0.583984375\n",
      "Batch: 145, Loss: 1.2542469501495361, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.181152582168579, Accuracy: 0.6025390625\n",
      "Batch: 147, Loss: 1.2976937294006348, Accuracy: 0.583984375\n",
      "Batch: 148, Loss: 1.1936994791030884, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.2539892196655273, Accuracy: 0.5849609375\n",
      "Batch: 150, Loss: 1.164919137954712, Accuracy: 0.6123046875\n",
      "Batch: 151, Loss: 1.2286810874938965, Accuracy: 0.6064453125\n",
      "Batch: 152, Loss: 1.199516773223877, Accuracy: 0.595703125\n",
      "Batch: 153, Loss: 1.168752908706665, Accuracy: 0.62109375\n",
      "Batch: 154, Loss: 1.1504433155059814, Accuracy: 0.609375\n",
      "Batch: 155, Loss: 1.14412522315979, Accuracy: 0.630859375\n",
      "Saved Weights at epoch 430 to file Weights_430.h5\n",
      "Epoch 431/200\n",
      "Batch: 1, Loss: 1.2256348133087158, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.1424875259399414, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 1.040778398513794, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.1952368021011353, Accuracy: 0.607421875\n",
      "Batch: 5, Loss: 1.0309805870056152, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 1.1084778308868408, Accuracy: 0.6455078125\n",
      "Batch: 7, Loss: 1.0856555700302124, Accuracy: 0.6435546875\n",
      "Batch: 8, Loss: 1.0308362245559692, Accuracy: 0.66796875\n",
      "Batch: 9, Loss: 1.0241899490356445, Accuracy: 0.658203125\n",
      "Batch: 10, Loss: 1.0152565240859985, Accuracy: 0.6591796875\n",
      "Batch: 11, Loss: 1.027660846710205, Accuracy: 0.654296875\n",
      "Batch: 12, Loss: 1.0817036628723145, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 1.059638261795044, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 1.0498456954956055, Accuracy: 0.654296875\n",
      "Batch: 15, Loss: 1.0016372203826904, Accuracy: 0.6845703125\n",
      "Batch: 16, Loss: 1.0924279689788818, Accuracy: 0.6494140625\n",
      "Batch: 17, Loss: 1.1211881637573242, Accuracy: 0.6162109375\n",
      "Batch: 18, Loss: 1.1084330081939697, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.2393805980682373, Accuracy: 0.6064453125\n",
      "Batch: 20, Loss: 1.1229870319366455, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.1576111316680908, Accuracy: 0.6142578125\n",
      "Batch: 22, Loss: 1.2654502391815186, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.317212462425232, Accuracy: 0.580078125\n",
      "Batch: 24, Loss: 1.1180057525634766, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.2246698141098022, Accuracy: 0.6025390625\n",
      "Batch: 26, Loss: 1.2577459812164307, Accuracy: 0.5810546875\n",
      "Batch: 27, Loss: 1.2322168350219727, Accuracy: 0.5771484375\n",
      "Batch: 28, Loss: 1.0521678924560547, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.1286981105804443, Accuracy: 0.607421875\n",
      "Batch: 30, Loss: 1.2037591934204102, Accuracy: 0.6005859375\n",
      "Batch: 31, Loss: 1.2476427555084229, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.1178412437438965, Accuracy: 0.6357421875\n",
      "Batch: 33, Loss: 1.0235447883605957, Accuracy: 0.66015625\n",
      "Batch: 34, Loss: 1.1177034378051758, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.192769169807434, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2212108373641968, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.3017666339874268, Accuracy: 0.57421875\n",
      "Batch: 38, Loss: 1.194164752960205, Accuracy: 0.591796875\n",
      "Batch: 39, Loss: 1.1390762329101562, Accuracy: 0.619140625\n",
      "Batch: 40, Loss: 1.1263427734375, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.1846833229064941, Accuracy: 0.6357421875\n",
      "Batch: 42, Loss: 1.0948314666748047, Accuracy: 0.6533203125\n",
      "Batch: 43, Loss: 1.1059372425079346, Accuracy: 0.6396484375\n",
      "Batch: 44, Loss: 1.0693833827972412, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.1003189086914062, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.2017881870269775, Accuracy: 0.5986328125\n",
      "Batch: 47, Loss: 1.2201271057128906, Accuracy: 0.599609375\n",
      "Batch: 48, Loss: 1.1383837461471558, Accuracy: 0.6181640625\n",
      "Batch: 49, Loss: 1.2120410203933716, Accuracy: 0.5966796875\n",
      "Batch: 50, Loss: 1.2407509088516235, Accuracy: 0.5947265625\n",
      "Batch: 51, Loss: 1.2065041065216064, Accuracy: 0.5966796875\n",
      "Batch: 52, Loss: 1.2847979068756104, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.2337130308151245, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.2281556129455566, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.113128662109375, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.0969436168670654, Accuracy: 0.6708984375\n",
      "Batch: 57, Loss: 1.1681513786315918, Accuracy: 0.62890625\n",
      "Batch: 58, Loss: 1.1908944845199585, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.2116749286651611, Accuracy: 0.6123046875\n",
      "Batch: 60, Loss: 1.2496272325515747, Accuracy: 0.5966796875\n",
      "Batch: 61, Loss: 1.2477965354919434, Accuracy: 0.5908203125\n",
      "Batch: 62, Loss: 1.235456943511963, Accuracy: 0.62109375\n",
      "Batch: 63, Loss: 1.1943235397338867, Accuracy: 0.6103515625\n",
      "Batch: 64, Loss: 1.2633867263793945, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.2549128532409668, Accuracy: 0.583984375\n",
      "Batch: 66, Loss: 1.2246263027191162, Accuracy: 0.5966796875\n",
      "Batch: 67, Loss: 1.1883139610290527, Accuracy: 0.58984375\n",
      "Batch: 68, Loss: 1.1196174621582031, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.2877535820007324, Accuracy: 0.5908203125\n",
      "Batch: 70, Loss: 1.2128002643585205, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.200453519821167, Accuracy: 0.61328125\n",
      "Batch: 72, Loss: 1.2370134592056274, Accuracy: 0.591796875\n",
      "Batch: 73, Loss: 1.2031667232513428, Accuracy: 0.6162109375\n",
      "Batch: 74, Loss: 1.1654800176620483, Accuracy: 0.619140625\n",
      "Batch: 75, Loss: 1.2229597568511963, Accuracy: 0.6171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 1.1079413890838623, Accuracy: 0.62890625\n",
      "Batch: 77, Loss: 1.1461589336395264, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.1342889070510864, Accuracy: 0.6220703125\n",
      "Batch: 79, Loss: 1.1799076795578003, Accuracy: 0.6142578125\n",
      "Batch: 80, Loss: 1.25990891456604, Accuracy: 0.595703125\n",
      "Batch: 81, Loss: 1.1568926572799683, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.2128872871398926, Accuracy: 0.6064453125\n",
      "Batch: 83, Loss: 1.2123990058898926, Accuracy: 0.6103515625\n",
      "Batch: 84, Loss: 1.2067897319793701, Accuracy: 0.6025390625\n",
      "Batch: 85, Loss: 1.1748676300048828, Accuracy: 0.6123046875\n",
      "Batch: 86, Loss: 1.2168335914611816, Accuracy: 0.6103515625\n",
      "Batch: 87, Loss: 1.2369413375854492, Accuracy: 0.6044921875\n",
      "Batch: 88, Loss: 1.2451376914978027, Accuracy: 0.6123046875\n",
      "Batch: 89, Loss: 1.23341965675354, Accuracy: 0.625\n",
      "Batch: 90, Loss: 1.1972500085830688, Accuracy: 0.615234375\n",
      "Batch: 91, Loss: 1.1726853847503662, Accuracy: 0.611328125\n",
      "Batch: 92, Loss: 1.1828553676605225, Accuracy: 0.640625\n",
      "Batch: 93, Loss: 1.2088205814361572, Accuracy: 0.6279296875\n",
      "Batch: 94, Loss: 1.212449073791504, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.2110331058502197, Accuracy: 0.599609375\n",
      "Batch: 96, Loss: 1.3141059875488281, Accuracy: 0.5966796875\n",
      "Batch: 97, Loss: 1.2048492431640625, Accuracy: 0.6005859375\n",
      "Batch: 98, Loss: 1.1703001260757446, Accuracy: 0.623046875\n",
      "Batch: 99, Loss: 1.2192182540893555, Accuracy: 0.6015625\n",
      "Batch: 100, Loss: 1.1641788482666016, Accuracy: 0.6201171875\n",
      "Batch: 101, Loss: 1.1376025676727295, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.2187029123306274, Accuracy: 0.60546875\n",
      "Batch: 103, Loss: 1.2661573886871338, Accuracy: 0.6064453125\n",
      "Batch: 104, Loss: 1.1912730932235718, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.2848689556121826, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.18626070022583, Accuracy: 0.619140625\n",
      "Batch: 107, Loss: 1.2453687191009521, Accuracy: 0.6025390625\n",
      "Batch: 108, Loss: 1.2074878215789795, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.2013839483261108, Accuracy: 0.611328125\n",
      "Batch: 110, Loss: 1.1385774612426758, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.1456222534179688, Accuracy: 0.6396484375\n",
      "Batch: 112, Loss: 1.0908281803131104, Accuracy: 0.6611328125\n",
      "Batch: 113, Loss: 1.2359437942504883, Accuracy: 0.603515625\n",
      "Batch: 114, Loss: 1.192493200302124, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.2835731506347656, Accuracy: 0.57421875\n",
      "Batch: 116, Loss: 1.2021032571792603, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.245767593383789, Accuracy: 0.5859375\n",
      "Batch: 118, Loss: 1.2929075956344604, Accuracy: 0.58203125\n",
      "Batch: 119, Loss: 1.2961504459381104, Accuracy: 0.57421875\n",
      "Batch: 120, Loss: 1.3256585597991943, Accuracy: 0.56640625\n",
      "Batch: 121, Loss: 1.2194902896881104, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.2115565538406372, Accuracy: 0.62890625\n",
      "Batch: 123, Loss: 1.210008144378662, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.3144941329956055, Accuracy: 0.583984375\n",
      "Batch: 125, Loss: 1.2287993431091309, Accuracy: 0.6015625\n",
      "Batch: 126, Loss: 1.2723772525787354, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.276672124862671, Accuracy: 0.58984375\n",
      "Batch: 128, Loss: 1.263697624206543, Accuracy: 0.5927734375\n",
      "Batch: 129, Loss: 1.2197904586791992, Accuracy: 0.603515625\n",
      "Batch: 130, Loss: 1.1633403301239014, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.2099931240081787, Accuracy: 0.5888671875\n",
      "Batch: 132, Loss: 1.1550557613372803, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.2136642932891846, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.1924333572387695, Accuracy: 0.630859375\n",
      "Batch: 135, Loss: 1.0804585218429565, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.1433824300765991, Accuracy: 0.619140625\n",
      "Batch: 137, Loss: 1.2255973815917969, Accuracy: 0.6162109375\n",
      "Batch: 138, Loss: 1.2953248023986816, Accuracy: 0.5751953125\n",
      "Batch: 139, Loss: 1.1887307167053223, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.3404088020324707, Accuracy: 0.5693359375\n",
      "Batch: 141, Loss: 1.1773102283477783, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.215850830078125, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2727768421173096, Accuracy: 0.591796875\n",
      "Batch: 144, Loss: 1.3087226152420044, Accuracy: 0.5732421875\n",
      "Batch: 145, Loss: 1.3006906509399414, Accuracy: 0.5625\n",
      "Batch: 146, Loss: 1.2297435998916626, Accuracy: 0.5966796875\n",
      "Batch: 147, Loss: 1.24759840965271, Accuracy: 0.59765625\n",
      "Batch: 148, Loss: 1.2538065910339355, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.2201433181762695, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.235987663269043, Accuracy: 0.59375\n",
      "Batch: 151, Loss: 1.2048661708831787, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.2280030250549316, Accuracy: 0.625\n",
      "Batch: 153, Loss: 1.1884992122650146, Accuracy: 0.6103515625\n",
      "Batch: 154, Loss: 1.1676299571990967, Accuracy: 0.625\n",
      "Batch: 155, Loss: 1.172697901725769, Accuracy: 0.62109375\n",
      "Epoch 432/200\n",
      "Batch: 1, Loss: 1.2396817207336426, Accuracy: 0.625\n",
      "Batch: 2, Loss: 1.1026217937469482, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 1.0524485111236572, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.1105399131774902, Accuracy: 0.62109375\n",
      "Batch: 5, Loss: 1.04988694190979, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0482189655303955, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 1.1047859191894531, Accuracy: 0.62890625\n",
      "Batch: 8, Loss: 1.0321310758590698, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0129280090332031, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 1.0120269060134888, Accuracy: 0.6650390625\n",
      "Batch: 11, Loss: 1.042281150817871, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0671799182891846, Accuracy: 0.65625\n",
      "Batch: 13, Loss: 1.1302862167358398, Accuracy: 0.6201171875\n",
      "Batch: 14, Loss: 1.002976417541504, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 1.0201990604400635, Accuracy: 0.6416015625\n",
      "Batch: 16, Loss: 1.0615938901901245, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.116981029510498, Accuracy: 0.625\n",
      "Batch: 18, Loss: 1.1307637691497803, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2738285064697266, Accuracy: 0.5986328125\n",
      "Batch: 20, Loss: 1.1111218929290771, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.1445353031158447, Accuracy: 0.61328125\n",
      "Batch: 22, Loss: 1.230961799621582, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2487071752548218, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.1459054946899414, Accuracy: 0.6142578125\n",
      "Batch: 25, Loss: 1.1884949207305908, Accuracy: 0.6103515625\n",
      "Batch: 26, Loss: 1.2917513847351074, Accuracy: 0.576171875\n",
      "Batch: 27, Loss: 1.228019118309021, Accuracy: 0.5947265625\n",
      "Batch: 28, Loss: 1.1594412326812744, Accuracy: 0.6123046875\n",
      "Batch: 29, Loss: 1.0868293046951294, Accuracy: 0.6328125\n",
      "Batch: 30, Loss: 1.2390321493148804, Accuracy: 0.59765625\n",
      "Batch: 31, Loss: 1.187587022781372, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.103694200515747, Accuracy: 0.6337890625\n",
      "Batch: 33, Loss: 1.0431689023971558, Accuracy: 0.666015625\n",
      "Batch: 34, Loss: 1.098790168762207, Accuracy: 0.65625\n",
      "Batch: 35, Loss: 1.1809720993041992, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2228964567184448, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.28694748878479, Accuracy: 0.576171875\n",
      "Batch: 38, Loss: 1.2353965044021606, Accuracy: 0.591796875\n",
      "Batch: 39, Loss: 1.1294217109680176, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.1813372373580933, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.2032103538513184, Accuracy: 0.611328125\n",
      "Batch: 42, Loss: 1.0629390478134155, Accuracy: 0.6552734375\n",
      "Batch: 43, Loss: 1.1261593103408813, Accuracy: 0.626953125\n",
      "Batch: 44, Loss: 1.0829875469207764, Accuracy: 0.6318359375\n",
      "Batch: 45, Loss: 1.098178744316101, Accuracy: 0.6455078125\n",
      "Batch: 46, Loss: 1.1625555753707886, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.1352018117904663, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.1790039539337158, Accuracy: 0.6083984375\n",
      "Batch: 49, Loss: 1.2238595485687256, Accuracy: 0.6103515625\n",
      "Batch: 50, Loss: 1.2201513051986694, Accuracy: 0.61328125\n",
      "Batch: 51, Loss: 1.1916379928588867, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.2527512311935425, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.2782196998596191, Accuracy: 0.5634765625\n",
      "Batch: 54, Loss: 1.1900715827941895, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.2118299007415771, Accuracy: 0.6171875\n",
      "Batch: 56, Loss: 1.162362813949585, Accuracy: 0.615234375\n",
      "Batch: 57, Loss: 1.1748998165130615, Accuracy: 0.6162109375\n",
      "Batch: 58, Loss: 1.1874104738235474, Accuracy: 0.6318359375\n",
      "Batch: 59, Loss: 1.1976392269134521, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.3194646835327148, Accuracy: 0.5869140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 61, Loss: 1.203174114227295, Accuracy: 0.6025390625\n",
      "Batch: 62, Loss: 1.194460153579712, Accuracy: 0.595703125\n",
      "Batch: 63, Loss: 1.1711629629135132, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.2660388946533203, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.2604845762252808, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.1439933776855469, Accuracy: 0.6396484375\n",
      "Batch: 67, Loss: 1.2134053707122803, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.1184946298599243, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.2378628253936768, Accuracy: 0.5966796875\n",
      "Batch: 70, Loss: 1.175011157989502, Accuracy: 0.6025390625\n",
      "Batch: 71, Loss: 1.1755820512771606, Accuracy: 0.6201171875\n",
      "Batch: 72, Loss: 1.216851830482483, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.2280166149139404, Accuracy: 0.595703125\n",
      "Batch: 74, Loss: 1.1680681705474854, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.1603249311447144, Accuracy: 0.6083984375\n",
      "Batch: 76, Loss: 1.0865225791931152, Accuracy: 0.662109375\n",
      "Batch: 77, Loss: 1.0782463550567627, Accuracy: 0.6611328125\n",
      "Batch: 78, Loss: 1.126403570175171, Accuracy: 0.6318359375\n",
      "Batch: 79, Loss: 1.1221699714660645, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1732182502746582, Accuracy: 0.603515625\n",
      "Batch: 81, Loss: 1.1592493057250977, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.1771299839019775, Accuracy: 0.626953125\n",
      "Batch: 83, Loss: 1.2604714632034302, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.2288234233856201, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.156455636024475, Accuracy: 0.6416015625\n",
      "Batch: 86, Loss: 1.227647066116333, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.263850450515747, Accuracy: 0.591796875\n",
      "Batch: 88, Loss: 1.2911092042922974, Accuracy: 0.58203125\n",
      "Batch: 89, Loss: 1.217095136642456, Accuracy: 0.6123046875\n",
      "Batch: 90, Loss: 1.1589155197143555, Accuracy: 0.6259765625\n",
      "Batch: 91, Loss: 1.2025837898254395, Accuracy: 0.607421875\n",
      "Batch: 92, Loss: 1.1718859672546387, Accuracy: 0.63671875\n",
      "Batch: 93, Loss: 1.2368005514144897, Accuracy: 0.59375\n",
      "Batch: 94, Loss: 1.2131929397583008, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.2150328159332275, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.204749345779419, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.210883617401123, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1344940662384033, Accuracy: 0.63671875\n",
      "Batch: 99, Loss: 1.2335716485977173, Accuracy: 0.599609375\n",
      "Batch: 100, Loss: 1.08497953414917, Accuracy: 0.6435546875\n",
      "Batch: 101, Loss: 1.0876140594482422, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.2084498405456543, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.235163927078247, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.2011151313781738, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.274000883102417, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.239516019821167, Accuracy: 0.6123046875\n",
      "Batch: 107, Loss: 1.2932822704315186, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.251326322555542, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.2712836265563965, Accuracy: 0.5830078125\n",
      "Batch: 110, Loss: 1.1913907527923584, Accuracy: 0.6025390625\n",
      "Batch: 111, Loss: 1.171120047569275, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.1689702272415161, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.1624319553375244, Accuracy: 0.6123046875\n",
      "Batch: 114, Loss: 1.1784491539001465, Accuracy: 0.603515625\n",
      "Batch: 115, Loss: 1.2607778310775757, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2166736125946045, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.1894460916519165, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.2414003610610962, Accuracy: 0.58203125\n",
      "Batch: 119, Loss: 1.243092656135559, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.363384485244751, Accuracy: 0.578125\n",
      "Batch: 121, Loss: 1.2604174613952637, Accuracy: 0.59765625\n",
      "Batch: 122, Loss: 1.2250502109527588, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.1762747764587402, Accuracy: 0.6162109375\n",
      "Batch: 124, Loss: 1.273876428604126, Accuracy: 0.5908203125\n",
      "Batch: 125, Loss: 1.2349975109100342, Accuracy: 0.611328125\n",
      "Batch: 126, Loss: 1.266053557395935, Accuracy: 0.5869140625\n",
      "Batch: 127, Loss: 1.234804630279541, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.2723827362060547, Accuracy: 0.6015625\n",
      "Batch: 129, Loss: 1.2325987815856934, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.185639500617981, Accuracy: 0.619140625\n",
      "Batch: 131, Loss: 1.2126638889312744, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.1281083822250366, Accuracy: 0.6572265625\n",
      "Batch: 133, Loss: 1.217475175857544, Accuracy: 0.6083984375\n",
      "Batch: 134, Loss: 1.102710247039795, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.0535888671875, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.1390562057495117, Accuracy: 0.6279296875\n",
      "Batch: 137, Loss: 1.2067749500274658, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 1.2476882934570312, Accuracy: 0.5869140625\n",
      "Batch: 139, Loss: 1.2008084058761597, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.2397404909133911, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.2140401601791382, Accuracy: 0.6083984375\n",
      "Batch: 142, Loss: 1.2578160762786865, Accuracy: 0.5927734375\n",
      "Batch: 143, Loss: 1.2464364767074585, Accuracy: 0.5927734375\n",
      "Batch: 144, Loss: 1.2840564250946045, Accuracy: 0.6015625\n",
      "Batch: 145, Loss: 1.2572789192199707, Accuracy: 0.58203125\n",
      "Batch: 146, Loss: 1.2438971996307373, Accuracy: 0.5966796875\n",
      "Batch: 147, Loss: 1.2139757871627808, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.2796564102172852, Accuracy: 0.5810546875\n",
      "Batch: 149, Loss: 1.2160673141479492, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.1722570657730103, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.190399408340454, Accuracy: 0.625\n",
      "Batch: 152, Loss: 1.1544618606567383, Accuracy: 0.607421875\n",
      "Batch: 153, Loss: 1.1521015167236328, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1213258504867554, Accuracy: 0.6357421875\n",
      "Batch: 155, Loss: 1.1662781238555908, Accuracy: 0.6357421875\n",
      "Epoch 433/200\n",
      "Batch: 1, Loss: 1.272786259651184, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 1.108884334564209, Accuracy: 0.63671875\n",
      "Batch: 3, Loss: 1.073087453842163, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.1335079669952393, Accuracy: 0.62890625\n",
      "Batch: 5, Loss: 1.0763263702392578, Accuracy: 0.6484375\n",
      "Batch: 6, Loss: 1.06522536277771, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.1085686683654785, Accuracy: 0.63671875\n",
      "Batch: 8, Loss: 1.0369352102279663, Accuracy: 0.654296875\n",
      "Batch: 9, Loss: 1.0178357362747192, Accuracy: 0.6650390625\n",
      "Batch: 10, Loss: 0.9772075414657593, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 1.0722148418426514, Accuracy: 0.6533203125\n",
      "Batch: 12, Loss: 1.113274335861206, Accuracy: 0.619140625\n",
      "Batch: 13, Loss: 1.099122405052185, Accuracy: 0.6337890625\n",
      "Batch: 14, Loss: 1.0355420112609863, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 0.9576436281204224, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.0315430164337158, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.108879804611206, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.1585698127746582, Accuracy: 0.623046875\n",
      "Batch: 19, Loss: 1.2357332706451416, Accuracy: 0.6181640625\n",
      "Batch: 20, Loss: 1.1673271656036377, Accuracy: 0.6484375\n",
      "Batch: 21, Loss: 1.1207654476165771, Accuracy: 0.634765625\n",
      "Batch: 22, Loss: 1.2723495960235596, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.2981512546539307, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.2270874977111816, Accuracy: 0.58984375\n",
      "Batch: 25, Loss: 1.199758768081665, Accuracy: 0.62109375\n",
      "Batch: 26, Loss: 1.220731496810913, Accuracy: 0.59375\n",
      "Batch: 27, Loss: 1.164847731590271, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.125949501991272, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0637012720108032, Accuracy: 0.6396484375\n",
      "Batch: 30, Loss: 1.1540710926055908, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.2372058629989624, Accuracy: 0.591796875\n",
      "Batch: 32, Loss: 1.0796338319778442, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.0109491348266602, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.1071690320968628, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.1930091381072998, Accuracy: 0.5947265625\n",
      "Batch: 36, Loss: 1.2254862785339355, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.2411363124847412, Accuracy: 0.5966796875\n",
      "Batch: 38, Loss: 1.2269294261932373, Accuracy: 0.5908203125\n",
      "Batch: 39, Loss: 1.0906214714050293, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.0625793933868408, Accuracy: 0.6455078125\n",
      "Batch: 41, Loss: 1.1476476192474365, Accuracy: 0.619140625\n",
      "Batch: 42, Loss: 1.1276421546936035, Accuracy: 0.634765625\n",
      "Batch: 43, Loss: 1.1006901264190674, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.1222848892211914, Accuracy: 0.6123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 1.0909302234649658, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.1672179698944092, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.1155154705047607, Accuracy: 0.6669921875\n",
      "Batch: 48, Loss: 1.1985552310943604, Accuracy: 0.609375\n",
      "Batch: 49, Loss: 1.2192513942718506, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.208439588546753, Accuracy: 0.611328125\n",
      "Batch: 51, Loss: 1.215440034866333, Accuracy: 0.591796875\n",
      "Batch: 52, Loss: 1.2863397598266602, Accuracy: 0.5810546875\n",
      "Batch: 53, Loss: 1.2354366779327393, Accuracy: 0.58984375\n",
      "Batch: 54, Loss: 1.2638435363769531, Accuracy: 0.599609375\n",
      "Batch: 55, Loss: 1.176680326461792, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.1140503883361816, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.1945128440856934, Accuracy: 0.6201171875\n",
      "Batch: 58, Loss: 1.152003526687622, Accuracy: 0.599609375\n",
      "Batch: 59, Loss: 1.165630578994751, Accuracy: 0.62890625\n",
      "Batch: 60, Loss: 1.2356219291687012, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.1770904064178467, Accuracy: 0.6103515625\n",
      "Batch: 62, Loss: 1.1863951683044434, Accuracy: 0.6220703125\n",
      "Batch: 63, Loss: 1.214381456375122, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.2370455265045166, Accuracy: 0.6171875\n",
      "Batch: 65, Loss: 1.2339301109313965, Accuracy: 0.611328125\n",
      "Batch: 66, Loss: 1.2245928049087524, Accuracy: 0.609375\n",
      "Batch: 67, Loss: 1.1510443687438965, Accuracy: 0.625\n",
      "Batch: 68, Loss: 1.1624701023101807, Accuracy: 0.640625\n",
      "Batch: 69, Loss: 1.2101908922195435, Accuracy: 0.6201171875\n",
      "Batch: 70, Loss: 1.2181978225708008, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1708576679229736, Accuracy: 0.61328125\n",
      "Batch: 72, Loss: 1.2404279708862305, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.2043025493621826, Accuracy: 0.6201171875\n",
      "Batch: 74, Loss: 1.1289374828338623, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.1280568838119507, Accuracy: 0.615234375\n",
      "Batch: 76, Loss: 1.0572530031204224, Accuracy: 0.6669921875\n",
      "Batch: 77, Loss: 1.0986177921295166, Accuracy: 0.6396484375\n",
      "Batch: 78, Loss: 1.1042894124984741, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1826117038726807, Accuracy: 0.62890625\n",
      "Batch: 80, Loss: 1.2322087287902832, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1357823610305786, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.145134449005127, Accuracy: 0.625\n",
      "Batch: 83, Loss: 1.2248995304107666, Accuracy: 0.60546875\n",
      "Batch: 84, Loss: 1.216613531112671, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.2192304134368896, Accuracy: 0.59375\n",
      "Batch: 86, Loss: 1.2359657287597656, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.198678731918335, Accuracy: 0.6220703125\n",
      "Batch: 88, Loss: 1.201993465423584, Accuracy: 0.6142578125\n",
      "Batch: 89, Loss: 1.1688194274902344, Accuracy: 0.619140625\n",
      "Batch: 90, Loss: 1.1506760120391846, Accuracy: 0.619140625\n",
      "Batch: 91, Loss: 1.185589075088501, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.1990101337432861, Accuracy: 0.611328125\n",
      "Batch: 93, Loss: 1.2184028625488281, Accuracy: 0.6103515625\n",
      "Batch: 94, Loss: 1.3017871379852295, Accuracy: 0.576171875\n",
      "Batch: 95, Loss: 1.2106777429580688, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.2519853115081787, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.2060396671295166, Accuracy: 0.603515625\n",
      "Batch: 98, Loss: 1.1326868534088135, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.1529388427734375, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.1110925674438477, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.1360373497009277, Accuracy: 0.6298828125\n",
      "Batch: 102, Loss: 1.2100112438201904, Accuracy: 0.6162109375\n",
      "Batch: 103, Loss: 1.2535536289215088, Accuracy: 0.6025390625\n",
      "Batch: 104, Loss: 1.2607312202453613, Accuracy: 0.5859375\n",
      "Batch: 105, Loss: 1.29155433177948, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.2588818073272705, Accuracy: 0.58984375\n",
      "Batch: 107, Loss: 1.2639058828353882, Accuracy: 0.619140625\n",
      "Batch: 108, Loss: 1.2318401336669922, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.2597657442092896, Accuracy: 0.5771484375\n",
      "Batch: 110, Loss: 1.1575956344604492, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1665503978729248, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.1445908546447754, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1953436136245728, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.2284719944000244, Accuracy: 0.5849609375\n",
      "Batch: 115, Loss: 1.1841604709625244, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.2569482326507568, Accuracy: 0.5810546875\n",
      "Batch: 117, Loss: 1.2043949365615845, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.3031437397003174, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.3205771446228027, Accuracy: 0.5703125\n",
      "Batch: 120, Loss: 1.319435477256775, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.3140790462493896, Accuracy: 0.5751953125\n",
      "Batch: 122, Loss: 1.233761191368103, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.2124427556991577, Accuracy: 0.6064453125\n",
      "Batch: 124, Loss: 1.2847940921783447, Accuracy: 0.5791015625\n",
      "Batch: 125, Loss: 1.2381311655044556, Accuracy: 0.6044921875\n",
      "Batch: 126, Loss: 1.3433396816253662, Accuracy: 0.5625\n",
      "Batch: 127, Loss: 1.2744848728179932, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.1971251964569092, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.201634168624878, Accuracy: 0.6015625\n",
      "Batch: 130, Loss: 1.1653820276260376, Accuracy: 0.6181640625\n",
      "Batch: 131, Loss: 1.266235113143921, Accuracy: 0.5986328125\n",
      "Batch: 132, Loss: 1.1132280826568604, Accuracy: 0.62109375\n",
      "Batch: 133, Loss: 1.243624210357666, Accuracy: 0.609375\n",
      "Batch: 134, Loss: 1.1912460327148438, Accuracy: 0.6162109375\n",
      "Batch: 135, Loss: 1.0683560371398926, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.1132160425186157, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.18852698802948, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.232060432434082, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.1911094188690186, Accuracy: 0.607421875\n",
      "Batch: 140, Loss: 1.2954719066619873, Accuracy: 0.6123046875\n",
      "Batch: 141, Loss: 1.2001028060913086, Accuracy: 0.62109375\n",
      "Batch: 142, Loss: 1.2085330486297607, Accuracy: 0.6142578125\n",
      "Batch: 143, Loss: 1.275888442993164, Accuracy: 0.5859375\n",
      "Batch: 144, Loss: 1.3037809133529663, Accuracy: 0.5771484375\n",
      "Batch: 145, Loss: 1.3036913871765137, Accuracy: 0.5712890625\n",
      "Batch: 146, Loss: 1.2157503366470337, Accuracy: 0.58984375\n",
      "Batch: 147, Loss: 1.2644668817520142, Accuracy: 0.5751953125\n",
      "Batch: 148, Loss: 1.3058733940124512, Accuracy: 0.5908203125\n",
      "Batch: 149, Loss: 1.2019290924072266, Accuracy: 0.58984375\n",
      "Batch: 150, Loss: 1.164036750793457, Accuracy: 0.6201171875\n",
      "Batch: 151, Loss: 1.2133902311325073, Accuracy: 0.626953125\n",
      "Batch: 152, Loss: 1.1876482963562012, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.2490832805633545, Accuracy: 0.60546875\n",
      "Batch: 154, Loss: 1.188138484954834, Accuracy: 0.59765625\n",
      "Batch: 155, Loss: 1.1594767570495605, Accuracy: 0.6123046875\n",
      "Epoch 434/200\n",
      "Batch: 1, Loss: 1.275850772857666, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.1380559206008911, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.0639283657073975, Accuracy: 0.6474609375\n",
      "Batch: 4, Loss: 1.1287755966186523, Accuracy: 0.623046875\n",
      "Batch: 5, Loss: 1.0461450815200806, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.1098822355270386, Accuracy: 0.654296875\n",
      "Batch: 7, Loss: 1.0647474527359009, Accuracy: 0.62109375\n",
      "Batch: 8, Loss: 1.0479726791381836, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0753217935562134, Accuracy: 0.654296875\n",
      "Batch: 10, Loss: 1.0087532997131348, Accuracy: 0.6552734375\n",
      "Batch: 11, Loss: 1.0274349451065063, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.0312118530273438, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 1.0439879894256592, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 1.001462459564209, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.9836978316307068, Accuracy: 0.6796875\n",
      "Batch: 16, Loss: 1.0627292394638062, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.1679211854934692, Accuracy: 0.6220703125\n",
      "Batch: 18, Loss: 1.1812078952789307, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2966861724853516, Accuracy: 0.580078125\n",
      "Batch: 20, Loss: 1.163478136062622, Accuracy: 0.615234375\n",
      "Batch: 21, Loss: 1.0808637142181396, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.258608341217041, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.3193607330322266, Accuracy: 0.58203125\n",
      "Batch: 24, Loss: 1.147928237915039, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.1623685359954834, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.2636303901672363, Accuracy: 0.580078125\n",
      "Batch: 27, Loss: 1.1974506378173828, Accuracy: 0.6103515625\n",
      "Batch: 28, Loss: 1.1036958694458008, Accuracy: 0.623046875\n",
      "Batch: 29, Loss: 1.1268759965896606, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 1.1888790130615234, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.2289716005325317, Accuracy: 0.5966796875\n",
      "Batch: 32, Loss: 1.1017284393310547, Accuracy: 0.6328125\n",
      "Batch: 33, Loss: 1.0338411331176758, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.1466450691223145, Accuracy: 0.62890625\n",
      "Batch: 35, Loss: 1.1438663005828857, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.2379035949707031, Accuracy: 0.6103515625\n",
      "Batch: 37, Loss: 1.2645001411437988, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.2032999992370605, Accuracy: 0.607421875\n",
      "Batch: 39, Loss: 1.1378896236419678, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.142101764678955, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.2246546745300293, Accuracy: 0.6162109375\n",
      "Batch: 42, Loss: 1.1607979536056519, Accuracy: 0.6142578125\n",
      "Batch: 43, Loss: 1.1063872575759888, Accuracy: 0.6162109375\n",
      "Batch: 44, Loss: 1.084423303604126, Accuracy: 0.6484375\n",
      "Batch: 45, Loss: 1.0614690780639648, Accuracy: 0.630859375\n",
      "Batch: 46, Loss: 1.2054171562194824, Accuracy: 0.59375\n",
      "Batch: 47, Loss: 1.1526498794555664, Accuracy: 0.6142578125\n",
      "Batch: 48, Loss: 1.1769278049468994, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.2351388931274414, Accuracy: 0.61328125\n",
      "Batch: 50, Loss: 1.1769837141036987, Accuracy: 0.6162109375\n",
      "Batch: 51, Loss: 1.193664789199829, Accuracy: 0.595703125\n",
      "Batch: 52, Loss: 1.2922048568725586, Accuracy: 0.572265625\n",
      "Batch: 53, Loss: 1.2503917217254639, Accuracy: 0.5947265625\n",
      "Batch: 54, Loss: 1.2451720237731934, Accuracy: 0.6171875\n",
      "Batch: 55, Loss: 1.2457213401794434, Accuracy: 0.5908203125\n",
      "Batch: 56, Loss: 1.160890817642212, Accuracy: 0.62890625\n",
      "Batch: 57, Loss: 1.1651031970977783, Accuracy: 0.623046875\n",
      "Batch: 58, Loss: 1.1850104331970215, Accuracy: 0.6005859375\n",
      "Batch: 59, Loss: 1.168170690536499, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.2804255485534668, Accuracy: 0.5712890625\n",
      "Batch: 61, Loss: 1.1708321571350098, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1901352405548096, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.2215358018875122, Accuracy: 0.603515625\n",
      "Batch: 64, Loss: 1.2447752952575684, Accuracy: 0.5927734375\n",
      "Batch: 65, Loss: 1.2842845916748047, Accuracy: 0.603515625\n",
      "Batch: 66, Loss: 1.240319013595581, Accuracy: 0.5849609375\n",
      "Batch: 67, Loss: 1.2010159492492676, Accuracy: 0.611328125\n",
      "Batch: 68, Loss: 1.1240639686584473, Accuracy: 0.625\n",
      "Batch: 69, Loss: 1.3105709552764893, Accuracy: 0.580078125\n",
      "Batch: 70, Loss: 1.2564866542816162, Accuracy: 0.599609375\n",
      "Batch: 71, Loss: 1.1545350551605225, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.18877112865448, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.2186022996902466, Accuracy: 0.6005859375\n",
      "Batch: 74, Loss: 1.1478294134140015, Accuracy: 0.62890625\n",
      "Batch: 75, Loss: 1.127143383026123, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.1409283876419067, Accuracy: 0.619140625\n",
      "Batch: 77, Loss: 1.0996633768081665, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.1263900995254517, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.2225980758666992, Accuracy: 0.609375\n",
      "Batch: 80, Loss: 1.2639658451080322, Accuracy: 0.583984375\n",
      "Batch: 81, Loss: 1.1484768390655518, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 1.1489629745483398, Accuracy: 0.625\n",
      "Batch: 83, Loss: 1.2660166025161743, Accuracy: 0.58984375\n",
      "Batch: 84, Loss: 1.2141077518463135, Accuracy: 0.6044921875\n",
      "Batch: 85, Loss: 1.1909788846969604, Accuracy: 0.6083984375\n",
      "Batch: 86, Loss: 1.2765830755233765, Accuracy: 0.5927734375\n",
      "Batch: 87, Loss: 1.2345144748687744, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.1965806484222412, Accuracy: 0.6025390625\n",
      "Batch: 89, Loss: 1.2190277576446533, Accuracy: 0.6005859375\n",
      "Batch: 90, Loss: 1.160506010055542, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.145857334136963, Accuracy: 0.6298828125\n",
      "Batch: 92, Loss: 1.1939529180526733, Accuracy: 0.623046875\n",
      "Batch: 93, Loss: 1.2228753566741943, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.2298663854599, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.2016942501068115, Accuracy: 0.607421875\n",
      "Batch: 96, Loss: 1.33194899559021, Accuracy: 0.5751953125\n",
      "Batch: 97, Loss: 1.1632635593414307, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.1927034854888916, Accuracy: 0.615234375\n",
      "Batch: 99, Loss: 1.2488045692443848, Accuracy: 0.611328125\n",
      "Batch: 100, Loss: 1.1678924560546875, Accuracy: 0.60546875\n",
      "Batch: 101, Loss: 1.1223182678222656, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.2182430028915405, Accuracy: 0.6083984375\n",
      "Batch: 103, Loss: 1.2071759700775146, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.1682682037353516, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.3427777290344238, Accuracy: 0.5859375\n",
      "Batch: 106, Loss: 1.2069638967514038, Accuracy: 0.59375\n",
      "Batch: 107, Loss: 1.2776318788528442, Accuracy: 0.5712890625\n",
      "Batch: 108, Loss: 1.2527101039886475, Accuracy: 0.5859375\n",
      "Batch: 109, Loss: 1.2559449672698975, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.2327297925949097, Accuracy: 0.6015625\n",
      "Batch: 111, Loss: 1.184272289276123, Accuracy: 0.6162109375\n",
      "Batch: 112, Loss: 1.1726386547088623, Accuracy: 0.6220703125\n",
      "Batch: 113, Loss: 1.2069568634033203, Accuracy: 0.60546875\n",
      "Batch: 114, Loss: 1.2329318523406982, Accuracy: 0.58984375\n",
      "Batch: 115, Loss: 1.2243537902832031, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2300500869750977, Accuracy: 0.62109375\n",
      "Batch: 117, Loss: 1.1592624187469482, Accuracy: 0.61328125\n",
      "Batch: 118, Loss: 1.2610538005828857, Accuracy: 0.580078125\n",
      "Batch: 119, Loss: 1.2153983116149902, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.3542327880859375, Accuracy: 0.5751953125\n",
      "Batch: 121, Loss: 1.2756156921386719, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.2190405130386353, Accuracy: 0.6123046875\n",
      "Batch: 123, Loss: 1.1902753114700317, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.2733569145202637, Accuracy: 0.583984375\n",
      "Batch: 125, Loss: 1.2015254497528076, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.3225868940353394, Accuracy: 0.595703125\n",
      "Batch: 127, Loss: 1.282076120376587, Accuracy: 0.5927734375\n",
      "Batch: 128, Loss: 1.2940256595611572, Accuracy: 0.591796875\n",
      "Batch: 129, Loss: 1.2214412689208984, Accuracy: 0.6171875\n",
      "Batch: 130, Loss: 1.1543529033660889, Accuracy: 0.6123046875\n",
      "Batch: 131, Loss: 1.1868385076522827, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.1855175495147705, Accuracy: 0.6220703125\n",
      "Batch: 133, Loss: 1.2122979164123535, Accuracy: 0.6025390625\n",
      "Batch: 134, Loss: 1.1845169067382812, Accuracy: 0.638671875\n",
      "Batch: 135, Loss: 1.1051533222198486, Accuracy: 0.6572265625\n",
      "Batch: 136, Loss: 1.1163192987442017, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.1668801307678223, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 1.285905122756958, Accuracy: 0.599609375\n",
      "Batch: 139, Loss: 1.243269443511963, Accuracy: 0.5810546875\n",
      "Batch: 140, Loss: 1.372934341430664, Accuracy: 0.5732421875\n",
      "Batch: 141, Loss: 1.2117919921875, Accuracy: 0.6083984375\n",
      "Batch: 142, Loss: 1.2261788845062256, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2639018297195435, Accuracy: 0.5947265625\n",
      "Batch: 144, Loss: 1.3024661540985107, Accuracy: 0.5771484375\n",
      "Batch: 145, Loss: 1.2857871055603027, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.2854068279266357, Accuracy: 0.5751953125\n",
      "Batch: 147, Loss: 1.214616060256958, Accuracy: 0.625\n",
      "Batch: 148, Loss: 1.2719621658325195, Accuracy: 0.591796875\n",
      "Batch: 149, Loss: 1.2537952661514282, Accuracy: 0.5869140625\n",
      "Batch: 150, Loss: 1.1984753608703613, Accuracy: 0.6044921875\n",
      "Batch: 151, Loss: 1.221145510673523, Accuracy: 0.607421875\n",
      "Batch: 152, Loss: 1.2238905429840088, Accuracy: 0.599609375\n",
      "Batch: 153, Loss: 1.181089997291565, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.1502996683120728, Accuracy: 0.6240234375\n",
      "Batch: 155, Loss: 1.1380614042282104, Accuracy: 0.6328125\n",
      "Epoch 435/200\n",
      "Batch: 1, Loss: 1.2803411483764648, Accuracy: 0.6201171875\n",
      "Batch: 2, Loss: 1.1183292865753174, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.0656288862228394, Accuracy: 0.64453125\n",
      "Batch: 4, Loss: 1.0998921394348145, Accuracy: 0.6328125\n",
      "Batch: 5, Loss: 1.0336034297943115, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.1290864944458008, Accuracy: 0.6240234375\n",
      "Batch: 7, Loss: 1.084250807762146, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 1.0121504068374634, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 1.051558017730713, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 1.0066758394241333, Accuracy: 0.6572265625\n",
      "Batch: 11, Loss: 0.9993802309036255, Accuracy: 0.66796875\n",
      "Batch: 12, Loss: 1.0784436464309692, Accuracy: 0.6484375\n",
      "Batch: 13, Loss: 1.0384433269500732, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 1.0472304821014404, Accuracy: 0.671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 0.9842085838317871, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.056732416152954, Accuracy: 0.658203125\n",
      "Batch: 17, Loss: 1.1210696697235107, Accuracy: 0.6337890625\n",
      "Batch: 18, Loss: 1.1618708372116089, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.246064305305481, Accuracy: 0.591796875\n",
      "Batch: 20, Loss: 1.0729990005493164, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.143616795539856, Accuracy: 0.619140625\n",
      "Batch: 22, Loss: 1.2457797527313232, Accuracy: 0.591796875\n",
      "Batch: 23, Loss: 1.2957082986831665, Accuracy: 0.578125\n",
      "Batch: 24, Loss: 1.190464735031128, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.1805388927459717, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.2262685298919678, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.16013765335083, Accuracy: 0.60546875\n",
      "Batch: 28, Loss: 1.1398299932479858, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.135801076889038, Accuracy: 0.6279296875\n",
      "Batch: 30, Loss: 1.197044014930725, Accuracy: 0.5927734375\n",
      "Batch: 31, Loss: 1.2670764923095703, Accuracy: 0.599609375\n",
      "Batch: 32, Loss: 1.1161024570465088, Accuracy: 0.623046875\n",
      "Batch: 33, Loss: 1.0394244194030762, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.2037372589111328, Accuracy: 0.60546875\n",
      "Batch: 35, Loss: 1.1817846298217773, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.2197375297546387, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.2822223901748657, Accuracy: 0.58984375\n",
      "Batch: 38, Loss: 1.196176290512085, Accuracy: 0.615234375\n",
      "Batch: 39, Loss: 1.1179986000061035, Accuracy: 0.6279296875\n",
      "Batch: 40, Loss: 1.104565978050232, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.1761658191680908, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0932040214538574, Accuracy: 0.6455078125\n",
      "Batch: 43, Loss: 1.0781092643737793, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.1134779453277588, Accuracy: 0.6328125\n",
      "Batch: 45, Loss: 1.1160627603530884, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.1545827388763428, Accuracy: 0.615234375\n",
      "Batch: 47, Loss: 1.182265043258667, Accuracy: 0.62890625\n",
      "Batch: 48, Loss: 1.1216232776641846, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.2066080570220947, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.1909089088439941, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.1691570281982422, Accuracy: 0.6025390625\n",
      "Batch: 52, Loss: 1.2984400987625122, Accuracy: 0.5712890625\n",
      "Batch: 53, Loss: 1.2320525646209717, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.2332706451416016, Accuracy: 0.59765625\n",
      "Batch: 55, Loss: 1.169567346572876, Accuracy: 0.6220703125\n",
      "Batch: 56, Loss: 1.1795463562011719, Accuracy: 0.6259765625\n",
      "Batch: 57, Loss: 1.1195576190948486, Accuracy: 0.64453125\n",
      "Batch: 58, Loss: 1.248529076576233, Accuracy: 0.6123046875\n",
      "Batch: 59, Loss: 1.2282249927520752, Accuracy: 0.6044921875\n",
      "Batch: 60, Loss: 1.3062317371368408, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.1692936420440674, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.1475399732589722, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.2060558795928955, Accuracy: 0.62109375\n",
      "Batch: 64, Loss: 1.231656789779663, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.1745891571044922, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.2412505149841309, Accuracy: 0.59375\n",
      "Batch: 67, Loss: 1.1630903482437134, Accuracy: 0.625\n",
      "Batch: 68, Loss: 1.1510026454925537, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.24013090133667, Accuracy: 0.625\n",
      "Batch: 70, Loss: 1.2274620532989502, Accuracy: 0.6083984375\n",
      "Batch: 71, Loss: 1.15713369846344, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.2858269214630127, Accuracy: 0.583984375\n",
      "Batch: 73, Loss: 1.2642097473144531, Accuracy: 0.587890625\n",
      "Batch: 74, Loss: 1.130609154701233, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.1412196159362793, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.0823907852172852, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.1139583587646484, Accuracy: 0.64453125\n",
      "Batch: 78, Loss: 1.068235158920288, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1338409185409546, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.2158068418502808, Accuracy: 0.6015625\n",
      "Batch: 81, Loss: 1.1307919025421143, Accuracy: 0.654296875\n",
      "Batch: 82, Loss: 1.1810197830200195, Accuracy: 0.6201171875\n",
      "Batch: 83, Loss: 1.2267156839370728, Accuracy: 0.603515625\n",
      "Batch: 84, Loss: 1.198119878768921, Accuracy: 0.6064453125\n",
      "Batch: 85, Loss: 1.1841700077056885, Accuracy: 0.6220703125\n",
      "Batch: 86, Loss: 1.2370340824127197, Accuracy: 0.59375\n",
      "Batch: 87, Loss: 1.2288486957550049, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.2332632541656494, Accuracy: 0.595703125\n",
      "Batch: 89, Loss: 1.2135356664657593, Accuracy: 0.619140625\n",
      "Batch: 90, Loss: 1.1303784847259521, Accuracy: 0.6435546875\n",
      "Batch: 91, Loss: 1.2151864767074585, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.1917955875396729, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.1568143367767334, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.237335443496704, Accuracy: 0.60546875\n",
      "Batch: 95, Loss: 1.2316076755523682, Accuracy: 0.6005859375\n",
      "Batch: 96, Loss: 1.1711137294769287, Accuracy: 0.630859375\n",
      "Batch: 97, Loss: 1.2343332767486572, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.1293301582336426, Accuracy: 0.64453125\n",
      "Batch: 99, Loss: 1.2327204942703247, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.1226269006729126, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.1059621572494507, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.218583345413208, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.2414066791534424, Accuracy: 0.603515625\n",
      "Batch: 104, Loss: 1.1841037273406982, Accuracy: 0.61328125\n",
      "Batch: 105, Loss: 1.2394920587539673, Accuracy: 0.5908203125\n",
      "Batch: 106, Loss: 1.1403175592422485, Accuracy: 0.6357421875\n",
      "Batch: 107, Loss: 1.2907187938690186, Accuracy: 0.5927734375\n",
      "Batch: 108, Loss: 1.2321913242340088, Accuracy: 0.59765625\n",
      "Batch: 109, Loss: 1.2861268520355225, Accuracy: 0.568359375\n",
      "Batch: 110, Loss: 1.1760261058807373, Accuracy: 0.60546875\n",
      "Batch: 111, Loss: 1.2142964601516724, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.2280960083007812, Accuracy: 0.6171875\n",
      "Batch: 113, Loss: 1.2302275896072388, Accuracy: 0.6171875\n",
      "Batch: 114, Loss: 1.2214281558990479, Accuracy: 0.583984375\n",
      "Batch: 115, Loss: 1.2808966636657715, Accuracy: 0.5830078125\n",
      "Batch: 116, Loss: 1.24668288230896, Accuracy: 0.5927734375\n",
      "Batch: 117, Loss: 1.2170523405075073, Accuracy: 0.59765625\n",
      "Batch: 118, Loss: 1.2321796417236328, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.2850816249847412, Accuracy: 0.5927734375\n",
      "Batch: 120, Loss: 1.3063907623291016, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.222367525100708, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.232814908027649, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.1692206859588623, Accuracy: 0.62890625\n",
      "Batch: 124, Loss: 1.2621359825134277, Accuracy: 0.615234375\n",
      "Batch: 125, Loss: 1.2046700716018677, Accuracy: 0.6201171875\n",
      "Batch: 126, Loss: 1.3065476417541504, Accuracy: 0.58203125\n",
      "Batch: 127, Loss: 1.2733721733093262, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2003685235977173, Accuracy: 0.5966796875\n",
      "Batch: 129, Loss: 1.2916412353515625, Accuracy: 0.591796875\n",
      "Batch: 130, Loss: 1.1959261894226074, Accuracy: 0.6181640625\n",
      "Batch: 131, Loss: 1.230013132095337, Accuracy: 0.59765625\n",
      "Batch: 132, Loss: 1.1412060260772705, Accuracy: 0.6240234375\n",
      "Batch: 133, Loss: 1.1922366619110107, Accuracy: 0.61328125\n",
      "Batch: 134, Loss: 1.127586841583252, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.0813896656036377, Accuracy: 0.6416015625\n",
      "Batch: 136, Loss: 1.1505873203277588, Accuracy: 0.6259765625\n",
      "Batch: 137, Loss: 1.187793254852295, Accuracy: 0.60546875\n",
      "Batch: 138, Loss: 1.3043293952941895, Accuracy: 0.5712890625\n",
      "Batch: 139, Loss: 1.2134437561035156, Accuracy: 0.603515625\n",
      "Batch: 140, Loss: 1.333488941192627, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.1621469259262085, Accuracy: 0.6376953125\n",
      "Batch: 142, Loss: 1.1804273128509521, Accuracy: 0.6328125\n",
      "Batch: 143, Loss: 1.2889690399169922, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.280771255493164, Accuracy: 0.58203125\n",
      "Batch: 145, Loss: 1.3338513374328613, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.250593662261963, Accuracy: 0.5888671875\n",
      "Batch: 147, Loss: 1.2427871227264404, Accuracy: 0.591796875\n",
      "Batch: 148, Loss: 1.3388545513153076, Accuracy: 0.5771484375\n",
      "Batch: 149, Loss: 1.2533700466156006, Accuracy: 0.5556640625\n",
      "Batch: 150, Loss: 1.2186373472213745, Accuracy: 0.603515625\n",
      "Batch: 151, Loss: 1.2021639347076416, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.2009692192077637, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.1707184314727783, Accuracy: 0.630859375\n",
      "Batch: 154, Loss: 1.149595022201538, Accuracy: 0.6162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 155, Loss: 1.1302282810211182, Accuracy: 0.619140625\n",
      "Epoch 436/200\n",
      "Batch: 1, Loss: 1.2120447158813477, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.113678216934204, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 1.0255587100982666, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 1.127638339996338, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 1.0969074964523315, Accuracy: 0.6494140625\n",
      "Batch: 6, Loss: 1.1184227466583252, Accuracy: 0.638671875\n",
      "Batch: 7, Loss: 1.0394165515899658, Accuracy: 0.671875\n",
      "Batch: 8, Loss: 1.0402324199676514, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0721439123153687, Accuracy: 0.646484375\n",
      "Batch: 10, Loss: 0.979745626449585, Accuracy: 0.6953125\n",
      "Batch: 11, Loss: 1.00278902053833, Accuracy: 0.66015625\n",
      "Batch: 12, Loss: 1.054704189300537, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.042167067527771, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 1.0192320346832275, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.9576976299285889, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0678398609161377, Accuracy: 0.6484375\n",
      "Batch: 17, Loss: 1.0886552333831787, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.1672353744506836, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.2545926570892334, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.1738171577453613, Accuracy: 0.619140625\n",
      "Batch: 21, Loss: 1.1439242362976074, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.2690088748931885, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.242630958557129, Accuracy: 0.6025390625\n",
      "Batch: 24, Loss: 1.1580761671066284, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.1890900135040283, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.201404333114624, Accuracy: 0.5869140625\n",
      "Batch: 27, Loss: 1.1921637058258057, Accuracy: 0.6064453125\n",
      "Batch: 28, Loss: 1.071917176246643, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.0867319107055664, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.2339961528778076, Accuracy: 0.595703125\n",
      "Batch: 31, Loss: 1.2603046894073486, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.0391018390655518, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 1.047856092453003, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.1491191387176514, Accuracy: 0.62890625\n",
      "Batch: 35, Loss: 1.1330727338790894, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.2345163822174072, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.3017733097076416, Accuracy: 0.5703125\n",
      "Batch: 38, Loss: 1.1679614782333374, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.1490743160247803, Accuracy: 0.6220703125\n",
      "Batch: 40, Loss: 1.1488113403320312, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.210042953491211, Accuracy: 0.6025390625\n",
      "Batch: 42, Loss: 1.1144039630889893, Accuracy: 0.6396484375\n",
      "Batch: 43, Loss: 1.1026959419250488, Accuracy: 0.626953125\n",
      "Batch: 44, Loss: 1.063164472579956, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 1.0634231567382812, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.184190034866333, Accuracy: 0.6162109375\n",
      "Batch: 47, Loss: 1.1567813158035278, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.1624152660369873, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.1804935932159424, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.175673007965088, Accuracy: 0.6064453125\n",
      "Batch: 51, Loss: 1.2140401601791382, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.3399198055267334, Accuracy: 0.5751953125\n",
      "Batch: 53, Loss: 1.1908750534057617, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.2462862730026245, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.1873979568481445, Accuracy: 0.630859375\n",
      "Batch: 56, Loss: 1.1979740858078003, Accuracy: 0.630859375\n",
      "Batch: 57, Loss: 1.2177984714508057, Accuracy: 0.62109375\n",
      "Batch: 58, Loss: 1.1434048414230347, Accuracy: 0.6279296875\n",
      "Batch: 59, Loss: 1.1725704669952393, Accuracy: 0.62109375\n",
      "Batch: 60, Loss: 1.3121225833892822, Accuracy: 0.578125\n",
      "Batch: 61, Loss: 1.1989259719848633, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.2143738269805908, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.2516775131225586, Accuracy: 0.5830078125\n",
      "Batch: 64, Loss: 1.3043252229690552, Accuracy: 0.5771484375\n",
      "Batch: 65, Loss: 1.2480193376541138, Accuracy: 0.59765625\n",
      "Batch: 66, Loss: 1.1767818927764893, Accuracy: 0.6259765625\n",
      "Batch: 67, Loss: 1.1879388093948364, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.1671333312988281, Accuracy: 0.619140625\n",
      "Batch: 69, Loss: 1.2212891578674316, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.22867751121521, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.2049624919891357, Accuracy: 0.6015625\n",
      "Batch: 72, Loss: 1.245504379272461, Accuracy: 0.5986328125\n",
      "Batch: 73, Loss: 1.1907511949539185, Accuracy: 0.607421875\n",
      "Batch: 74, Loss: 1.143757700920105, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.1083095073699951, Accuracy: 0.6376953125\n",
      "Batch: 76, Loss: 1.1408860683441162, Accuracy: 0.62890625\n",
      "Batch: 77, Loss: 1.0888084173202515, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.1216025352478027, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.1942696571350098, Accuracy: 0.609375\n",
      "Batch: 80, Loss: 1.1838345527648926, Accuracy: 0.5888671875\n",
      "Batch: 81, Loss: 1.1229095458984375, Accuracy: 0.654296875\n",
      "Batch: 82, Loss: 1.1633832454681396, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.293757438659668, Accuracy: 0.58203125\n",
      "Batch: 84, Loss: 1.1839182376861572, Accuracy: 0.5986328125\n",
      "Batch: 85, Loss: 1.1853107213974, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.272557020187378, Accuracy: 0.591796875\n",
      "Batch: 87, Loss: 1.2821215391159058, Accuracy: 0.5869140625\n",
      "Batch: 88, Loss: 1.2300180196762085, Accuracy: 0.603515625\n",
      "Batch: 89, Loss: 1.2033936977386475, Accuracy: 0.6083984375\n",
      "Batch: 90, Loss: 1.158524990081787, Accuracy: 0.615234375\n",
      "Batch: 91, Loss: 1.2175017595291138, Accuracy: 0.5986328125\n",
      "Batch: 92, Loss: 1.2200148105621338, Accuracy: 0.609375\n",
      "Batch: 93, Loss: 1.1919314861297607, Accuracy: 0.60546875\n",
      "Batch: 94, Loss: 1.2366834878921509, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.2102572917938232, Accuracy: 0.6181640625\n",
      "Batch: 96, Loss: 1.2159593105316162, Accuracy: 0.6123046875\n",
      "Batch: 97, Loss: 1.1982018947601318, Accuracy: 0.6015625\n",
      "Batch: 98, Loss: 1.1867561340332031, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.2150137424468994, Accuracy: 0.619140625\n",
      "Batch: 100, Loss: 1.1283485889434814, Accuracy: 0.59765625\n",
      "Batch: 101, Loss: 1.1960407495498657, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.2310574054718018, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.2555556297302246, Accuracy: 0.6025390625\n",
      "Batch: 104, Loss: 1.1660635471343994, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.2827165126800537, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.2756496667861938, Accuracy: 0.572265625\n",
      "Batch: 107, Loss: 1.2967841625213623, Accuracy: 0.59375\n",
      "Batch: 108, Loss: 1.2179920673370361, Accuracy: 0.60546875\n",
      "Batch: 109, Loss: 1.256344199180603, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 1.2209641933441162, Accuracy: 0.6064453125\n",
      "Batch: 111, Loss: 1.1567195653915405, Accuracy: 0.6298828125\n",
      "Batch: 112, Loss: 1.108996868133545, Accuracy: 0.623046875\n",
      "Batch: 113, Loss: 1.2206867933273315, Accuracy: 0.5947265625\n",
      "Batch: 114, Loss: 1.149411916732788, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.2351181507110596, Accuracy: 0.59765625\n",
      "Batch: 116, Loss: 1.264709234237671, Accuracy: 0.59375\n",
      "Batch: 117, Loss: 1.2318313121795654, Accuracy: 0.6044921875\n",
      "Batch: 118, Loss: 1.253068447113037, Accuracy: 0.572265625\n",
      "Batch: 119, Loss: 1.344730019569397, Accuracy: 0.568359375\n",
      "Batch: 120, Loss: 1.3172721862792969, Accuracy: 0.578125\n",
      "Batch: 121, Loss: 1.254443645477295, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2722067832946777, Accuracy: 0.59375\n",
      "Batch: 123, Loss: 1.2204052209854126, Accuracy: 0.6201171875\n",
      "Batch: 124, Loss: 1.2381174564361572, Accuracy: 0.6044921875\n",
      "Batch: 125, Loss: 1.186952829360962, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.2930915355682373, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.2320722341537476, Accuracy: 0.6015625\n",
      "Batch: 128, Loss: 1.2777941226959229, Accuracy: 0.59375\n",
      "Batch: 129, Loss: 1.1962647438049316, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.2102787494659424, Accuracy: 0.5966796875\n",
      "Batch: 131, Loss: 1.3067268133163452, Accuracy: 0.5634765625\n",
      "Batch: 132, Loss: 1.114317774772644, Accuracy: 0.62890625\n",
      "Batch: 133, Loss: 1.2002170085906982, Accuracy: 0.625\n",
      "Batch: 134, Loss: 1.182520866394043, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 1.031599521636963, Accuracy: 0.6826171875\n",
      "Batch: 136, Loss: 1.1668914556503296, Accuracy: 0.6337890625\n",
      "Batch: 137, Loss: 1.1694790124893188, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.267739176750183, Accuracy: 0.59375\n",
      "Batch: 139, Loss: 1.2146754264831543, Accuracy: 0.60546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 1.2869189977645874, Accuracy: 0.6005859375\n",
      "Batch: 141, Loss: 1.2191219329833984, Accuracy: 0.6123046875\n",
      "Batch: 142, Loss: 1.1873559951782227, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.2987174987792969, Accuracy: 0.57421875\n",
      "Batch: 144, Loss: 1.3245429992675781, Accuracy: 0.5751953125\n",
      "Batch: 145, Loss: 1.3567157983779907, Accuracy: 0.5654296875\n",
      "Batch: 146, Loss: 1.2474775314331055, Accuracy: 0.6064453125\n",
      "Batch: 147, Loss: 1.2520649433135986, Accuracy: 0.5693359375\n",
      "Batch: 148, Loss: 1.2900333404541016, Accuracy: 0.5712890625\n",
      "Batch: 149, Loss: 1.285027027130127, Accuracy: 0.57421875\n",
      "Batch: 150, Loss: 1.2231626510620117, Accuracy: 0.5966796875\n",
      "Batch: 151, Loss: 1.164827585220337, Accuracy: 0.6142578125\n",
      "Batch: 152, Loss: 1.1819539070129395, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.1104347705841064, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1433511972427368, Accuracy: 0.6416015625\n",
      "Batch: 155, Loss: 1.1666574478149414, Accuracy: 0.6181640625\n",
      "Epoch 437/200\n",
      "Batch: 1, Loss: 1.196058988571167, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 1.1205741167068481, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 1.1046481132507324, Accuracy: 0.623046875\n",
      "Batch: 4, Loss: 1.1217843294143677, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 1.0269314050674438, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0688362121582031, Accuracy: 0.65234375\n",
      "Batch: 7, Loss: 1.0766774415969849, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 1.0095113515853882, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0431221723556519, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 0.9565019607543945, Accuracy: 0.685546875\n",
      "Batch: 11, Loss: 1.038464069366455, Accuracy: 0.662109375\n",
      "Batch: 12, Loss: 1.0691331624984741, Accuracy: 0.6337890625\n",
      "Batch: 13, Loss: 1.0588760375976562, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9999904632568359, Accuracy: 0.681640625\n",
      "Batch: 15, Loss: 0.9994538426399231, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.071251630783081, Accuracy: 0.634765625\n",
      "Batch: 17, Loss: 1.0865345001220703, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.1511811017990112, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.2221202850341797, Accuracy: 0.5966796875\n",
      "Batch: 20, Loss: 1.1246209144592285, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0887141227722168, Accuracy: 0.6474609375\n",
      "Batch: 22, Loss: 1.2784849405288696, Accuracy: 0.583984375\n",
      "Batch: 23, Loss: 1.2737791538238525, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1817705631256104, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.2286967039108276, Accuracy: 0.603515625\n",
      "Batch: 26, Loss: 1.1954963207244873, Accuracy: 0.59765625\n",
      "Batch: 27, Loss: 1.148775339126587, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.1024532318115234, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.1009483337402344, Accuracy: 0.6220703125\n",
      "Batch: 30, Loss: 1.1845753192901611, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.231372356414795, Accuracy: 0.578125\n",
      "Batch: 32, Loss: 1.1059174537658691, Accuracy: 0.6201171875\n",
      "Batch: 33, Loss: 1.0455498695373535, Accuracy: 0.658203125\n",
      "Batch: 34, Loss: 1.1481952667236328, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1524587869644165, Accuracy: 0.6220703125\n",
      "Batch: 36, Loss: 1.2046993970870972, Accuracy: 0.615234375\n",
      "Batch: 37, Loss: 1.2029744386672974, Accuracy: 0.6103515625\n",
      "Batch: 38, Loss: 1.1857872009277344, Accuracy: 0.59765625\n",
      "Batch: 39, Loss: 1.1108161211013794, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.154911756515503, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.127537488937378, Accuracy: 0.6435546875\n",
      "Batch: 42, Loss: 1.0681774616241455, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.1165719032287598, Accuracy: 0.6376953125\n",
      "Batch: 44, Loss: 1.067802906036377, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.1313613653182983, Accuracy: 0.6103515625\n",
      "Batch: 46, Loss: 1.169015645980835, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.1251460313796997, Accuracy: 0.646484375\n",
      "Batch: 48, Loss: 1.1548972129821777, Accuracy: 0.5966796875\n",
      "Batch: 49, Loss: 1.1725635528564453, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.2766331434249878, Accuracy: 0.59375\n",
      "Batch: 51, Loss: 1.186037540435791, Accuracy: 0.615234375\n",
      "Batch: 52, Loss: 1.2926831245422363, Accuracy: 0.5791015625\n",
      "Batch: 53, Loss: 1.2385516166687012, Accuracy: 0.5966796875\n",
      "Batch: 54, Loss: 1.1717541217803955, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.1348620653152466, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.127079725265503, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.1705455780029297, Accuracy: 0.6240234375\n",
      "Batch: 58, Loss: 1.1597614288330078, Accuracy: 0.6220703125\n",
      "Batch: 59, Loss: 1.215252161026001, Accuracy: 0.6123046875\n",
      "Batch: 60, Loss: 1.2464184761047363, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.2115991115570068, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.2112505435943604, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.2159193754196167, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.2005603313446045, Accuracy: 0.6083984375\n",
      "Batch: 65, Loss: 1.2337307929992676, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.1869442462921143, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.2037513256072998, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.1511669158935547, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.1894161701202393, Accuracy: 0.611328125\n",
      "Batch: 70, Loss: 1.2241653203964233, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1804628372192383, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.2249003648757935, Accuracy: 0.5859375\n",
      "Batch: 73, Loss: 1.205527424812317, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.171264410018921, Accuracy: 0.625\n",
      "Batch: 75, Loss: 1.143502950668335, Accuracy: 0.623046875\n",
      "Batch: 76, Loss: 1.0991263389587402, Accuracy: 0.623046875\n",
      "Batch: 77, Loss: 1.0826919078826904, Accuracy: 0.6416015625\n",
      "Batch: 78, Loss: 1.1357684135437012, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.1760607957839966, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.1890244483947754, Accuracy: 0.6123046875\n",
      "Batch: 81, Loss: 1.1766772270202637, Accuracy: 0.62890625\n",
      "Batch: 82, Loss: 1.147552490234375, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.2513411045074463, Accuracy: 0.5791015625\n",
      "Batch: 84, Loss: 1.1626381874084473, Accuracy: 0.623046875\n",
      "Batch: 85, Loss: 1.1812996864318848, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.262725591659546, Accuracy: 0.578125\n",
      "Batch: 87, Loss: 1.207060694694519, Accuracy: 0.603515625\n",
      "Batch: 88, Loss: 1.2169333696365356, Accuracy: 0.6005859375\n",
      "Batch: 89, Loss: 1.1695353984832764, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.1688332557678223, Accuracy: 0.609375\n",
      "Batch: 91, Loss: 1.1701815128326416, Accuracy: 0.634765625\n",
      "Batch: 92, Loss: 1.1698999404907227, Accuracy: 0.6181640625\n",
      "Batch: 93, Loss: 1.2406810522079468, Accuracy: 0.60546875\n",
      "Batch: 94, Loss: 1.2310566902160645, Accuracy: 0.5927734375\n",
      "Batch: 95, Loss: 1.225158929824829, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.2744938135147095, Accuracy: 0.5986328125\n",
      "Batch: 97, Loss: 1.2557424306869507, Accuracy: 0.5927734375\n",
      "Batch: 98, Loss: 1.2197874784469604, Accuracy: 0.6005859375\n",
      "Batch: 99, Loss: 1.2198472023010254, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.1230380535125732, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.1399120092391968, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.2632874250411987, Accuracy: 0.5810546875\n",
      "Batch: 103, Loss: 1.2305793762207031, Accuracy: 0.6025390625\n",
      "Batch: 104, Loss: 1.1935995817184448, Accuracy: 0.6318359375\n",
      "Batch: 105, Loss: 1.2748879194259644, Accuracy: 0.5908203125\n",
      "Batch: 106, Loss: 1.1736088991165161, Accuracy: 0.6435546875\n",
      "Batch: 107, Loss: 1.300032377243042, Accuracy: 0.5732421875\n",
      "Batch: 108, Loss: 1.2182366847991943, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.2230706214904785, Accuracy: 0.6005859375\n",
      "Batch: 110, Loss: 1.1829077005386353, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1243042945861816, Accuracy: 0.642578125\n",
      "Batch: 112, Loss: 1.1182584762573242, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.197224736213684, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.2395292520523071, Accuracy: 0.578125\n",
      "Batch: 115, Loss: 1.2382231950759888, Accuracy: 0.58203125\n",
      "Batch: 116, Loss: 1.2213431596755981, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.2478032112121582, Accuracy: 0.578125\n",
      "Batch: 118, Loss: 1.2381703853607178, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.2185063362121582, Accuracy: 0.6142578125\n",
      "Batch: 120, Loss: 1.367484450340271, Accuracy: 0.5732421875\n",
      "Batch: 121, Loss: 1.2361986637115479, Accuracy: 0.60546875\n",
      "Batch: 122, Loss: 1.2489073276519775, Accuracy: 0.58984375\n",
      "Batch: 123, Loss: 1.1708780527114868, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 1.3024053573608398, Accuracy: 0.5966796875\n",
      "Batch: 125, Loss: 1.2366431951522827, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.2737263441085815, Accuracy: 0.6044921875\n",
      "Batch: 127, Loss: 1.3081889152526855, Accuracy: 0.5791015625\n",
      "Batch: 128, Loss: 1.266042709350586, Accuracy: 0.6220703125\n",
      "Batch: 129, Loss: 1.2172236442565918, Accuracy: 0.6103515625\n",
      "Batch: 130, Loss: 1.1763370037078857, Accuracy: 0.6171875\n",
      "Batch: 131, Loss: 1.2617809772491455, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.1215523481369019, Accuracy: 0.654296875\n",
      "Batch: 133, Loss: 1.2300140857696533, Accuracy: 0.6201171875\n",
      "Batch: 134, Loss: 1.1842598915100098, Accuracy: 0.625\n",
      "Batch: 135, Loss: 1.1300673484802246, Accuracy: 0.6318359375\n",
      "Batch: 136, Loss: 1.1338083744049072, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.2078479528427124, Accuracy: 0.6025390625\n",
      "Batch: 138, Loss: 1.248281717300415, Accuracy: 0.5810546875\n",
      "Batch: 139, Loss: 1.2395920753479004, Accuracy: 0.5888671875\n",
      "Batch: 140, Loss: 1.3065943717956543, Accuracy: 0.5869140625\n",
      "Batch: 141, Loss: 1.2112207412719727, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.2415885925292969, Accuracy: 0.611328125\n",
      "Batch: 143, Loss: 1.2246320247650146, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.330045223236084, Accuracy: 0.578125\n",
      "Batch: 145, Loss: 1.3595370054244995, Accuracy: 0.568359375\n",
      "Batch: 146, Loss: 1.2585086822509766, Accuracy: 0.5927734375\n",
      "Batch: 147, Loss: 1.2465283870697021, Accuracy: 0.6005859375\n",
      "Batch: 148, Loss: 1.2146217823028564, Accuracy: 0.6123046875\n",
      "Batch: 149, Loss: 1.2288355827331543, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.1591193675994873, Accuracy: 0.6171875\n",
      "Batch: 151, Loss: 1.1923420429229736, Accuracy: 0.6171875\n",
      "Batch: 152, Loss: 1.1621140241622925, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1441562175750732, Accuracy: 0.6171875\n",
      "Batch: 154, Loss: 1.1497416496276855, Accuracy: 0.6279296875\n",
      "Batch: 155, Loss: 1.1568245887756348, Accuracy: 0.6201171875\n",
      "Epoch 438/200\n",
      "Batch: 1, Loss: 1.2439560890197754, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.0978105068206787, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 1.0102261304855347, Accuracy: 0.6591796875\n",
      "Batch: 4, Loss: 1.0837030410766602, Accuracy: 0.6455078125\n",
      "Batch: 5, Loss: 1.060091257095337, Accuracy: 0.6513671875\n",
      "Batch: 6, Loss: 1.069887399673462, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.0519185066223145, Accuracy: 0.646484375\n",
      "Batch: 8, Loss: 1.0516202449798584, Accuracy: 0.6650390625\n",
      "Batch: 9, Loss: 1.0331361293792725, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 1.0180644989013672, Accuracy: 0.6796875\n",
      "Batch: 11, Loss: 1.0170245170593262, Accuracy: 0.6748046875\n",
      "Batch: 12, Loss: 1.0478276014328003, Accuracy: 0.6474609375\n",
      "Batch: 13, Loss: 1.0484013557434082, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 1.0365722179412842, Accuracy: 0.66796875\n",
      "Batch: 15, Loss: 0.9606754779815674, Accuracy: 0.6748046875\n",
      "Batch: 16, Loss: 1.048216700553894, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.1278150081634521, Accuracy: 0.6337890625\n",
      "Batch: 18, Loss: 1.140631079673767, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2330607175827026, Accuracy: 0.599609375\n",
      "Batch: 20, Loss: 1.142759084701538, Accuracy: 0.640625\n",
      "Batch: 21, Loss: 1.0941162109375, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.2262611389160156, Accuracy: 0.619140625\n",
      "Batch: 23, Loss: 1.3150928020477295, Accuracy: 0.5859375\n",
      "Batch: 24, Loss: 1.1455073356628418, Accuracy: 0.64453125\n",
      "Batch: 25, Loss: 1.2269806861877441, Accuracy: 0.6083984375\n",
      "Batch: 26, Loss: 1.258373737335205, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.1537225246429443, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 1.0991463661193848, Accuracy: 0.6416015625\n",
      "Batch: 29, Loss: 1.0522449016571045, Accuracy: 0.6494140625\n",
      "Batch: 30, Loss: 1.1847277879714966, Accuracy: 0.6220703125\n",
      "Batch: 31, Loss: 1.2201286554336548, Accuracy: 0.5927734375\n",
      "Batch: 32, Loss: 1.0749037265777588, Accuracy: 0.6474609375\n",
      "Batch: 33, Loss: 1.007417917251587, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.1178297996520996, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1634422540664673, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.2262883186340332, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.2292206287384033, Accuracy: 0.6005859375\n",
      "Batch: 38, Loss: 1.2034929990768433, Accuracy: 0.59765625\n",
      "Batch: 39, Loss: 1.0813021659851074, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.1549911499023438, Accuracy: 0.6201171875\n",
      "Batch: 41, Loss: 1.1571717262268066, Accuracy: 0.6142578125\n",
      "Batch: 42, Loss: 1.0897629261016846, Accuracy: 0.6357421875\n",
      "Batch: 43, Loss: 1.0917770862579346, Accuracy: 0.62109375\n",
      "Batch: 44, Loss: 1.097252368927002, Accuracy: 0.6455078125\n",
      "Batch: 45, Loss: 1.0474920272827148, Accuracy: 0.6318359375\n",
      "Batch: 46, Loss: 1.173192024230957, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.1301071643829346, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.1467581987380981, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.240280032157898, Accuracy: 0.60546875\n",
      "Batch: 50, Loss: 1.1420848369598389, Accuracy: 0.6279296875\n",
      "Batch: 51, Loss: 1.1671054363250732, Accuracy: 0.6015625\n",
      "Batch: 52, Loss: 1.281389594078064, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.2279285192489624, Accuracy: 0.6044921875\n",
      "Batch: 54, Loss: 1.1996147632598877, Accuracy: 0.6240234375\n",
      "Batch: 55, Loss: 1.1566846370697021, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.135270118713379, Accuracy: 0.6259765625\n",
      "Batch: 57, Loss: 1.21585214138031, Accuracy: 0.5927734375\n",
      "Batch: 58, Loss: 1.152014136314392, Accuracy: 0.6259765625\n",
      "Batch: 59, Loss: 1.1425328254699707, Accuracy: 0.638671875\n",
      "Batch: 60, Loss: 1.2498897314071655, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.2100342512130737, Accuracy: 0.580078125\n",
      "Batch: 62, Loss: 1.1817657947540283, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.1780977249145508, Accuracy: 0.6083984375\n",
      "Batch: 64, Loss: 1.2585368156433105, Accuracy: 0.580078125\n",
      "Batch: 65, Loss: 1.2384960651397705, Accuracy: 0.6015625\n",
      "Batch: 66, Loss: 1.1957136392593384, Accuracy: 0.609375\n",
      "Batch: 67, Loss: 1.1833857297897339, Accuracy: 0.6005859375\n",
      "Batch: 68, Loss: 1.125998854637146, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.2362618446350098, Accuracy: 0.607421875\n",
      "Batch: 70, Loss: 1.2271265983581543, Accuracy: 0.5966796875\n",
      "Batch: 71, Loss: 1.2068827152252197, Accuracy: 0.6181640625\n",
      "Batch: 72, Loss: 1.2758190631866455, Accuracy: 0.5947265625\n",
      "Batch: 73, Loss: 1.2134908437728882, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.0766786336898804, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.155764102935791, Accuracy: 0.611328125\n",
      "Batch: 76, Loss: 1.1424356698989868, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.1736994981765747, Accuracy: 0.6240234375\n",
      "Batch: 78, Loss: 1.0878782272338867, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.1803691387176514, Accuracy: 0.6318359375\n",
      "Batch: 80, Loss: 1.1809204816818237, Accuracy: 0.6103515625\n",
      "Batch: 81, Loss: 1.1169575452804565, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 1.156775712966919, Accuracy: 0.623046875\n",
      "Batch: 83, Loss: 1.2608091831207275, Accuracy: 0.5849609375\n",
      "Batch: 84, Loss: 1.2071213722229004, Accuracy: 0.6083984375\n",
      "Batch: 85, Loss: 1.2323877811431885, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.2574769258499146, Accuracy: 0.59375\n",
      "Batch: 87, Loss: 1.2719879150390625, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.2491377592086792, Accuracy: 0.6015625\n",
      "Batch: 89, Loss: 1.1932199001312256, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.1720893383026123, Accuracy: 0.6103515625\n",
      "Batch: 91, Loss: 1.1374702453613281, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1716434955596924, Accuracy: 0.63671875\n",
      "Batch: 93, Loss: 1.2117798328399658, Accuracy: 0.6064453125\n",
      "Batch: 94, Loss: 1.293708324432373, Accuracy: 0.572265625\n",
      "Batch: 95, Loss: 1.262221097946167, Accuracy: 0.6044921875\n",
      "Batch: 96, Loss: 1.2427148818969727, Accuracy: 0.603515625\n",
      "Batch: 97, Loss: 1.275247573852539, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.1924571990966797, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.1967706680297852, Accuracy: 0.6240234375\n",
      "Batch: 100, Loss: 1.097170352935791, Accuracy: 0.6298828125\n",
      "Batch: 101, Loss: 1.1428723335266113, Accuracy: 0.6337890625\n",
      "Batch: 102, Loss: 1.1809357404708862, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.1982568502426147, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.2168673276901245, Accuracy: 0.6123046875\n",
      "Batch: 105, Loss: 1.2919492721557617, Accuracy: 0.5966796875\n",
      "Batch: 106, Loss: 1.182572841644287, Accuracy: 0.623046875\n",
      "Batch: 107, Loss: 1.2513874769210815, Accuracy: 0.587890625\n",
      "Batch: 108, Loss: 1.2133066654205322, Accuracy: 0.5869140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 109, Loss: 1.284212589263916, Accuracy: 0.5869140625\n",
      "Batch: 110, Loss: 1.176268219947815, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1320326328277588, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.1443963050842285, Accuracy: 0.625\n",
      "Batch: 113, Loss: 1.2223870754241943, Accuracy: 0.619140625\n",
      "Batch: 114, Loss: 1.1920000314712524, Accuracy: 0.6044921875\n",
      "Batch: 115, Loss: 1.26466965675354, Accuracy: 0.58203125\n",
      "Batch: 116, Loss: 1.2006844282150269, Accuracy: 0.6015625\n",
      "Batch: 117, Loss: 1.2274351119995117, Accuracy: 0.6162109375\n",
      "Batch: 118, Loss: 1.2520079612731934, Accuracy: 0.58984375\n",
      "Batch: 119, Loss: 1.2653956413269043, Accuracy: 0.591796875\n",
      "Batch: 120, Loss: 1.2915067672729492, Accuracy: 0.5751953125\n",
      "Batch: 121, Loss: 1.2611867189407349, Accuracy: 0.6015625\n",
      "Batch: 122, Loss: 1.2752143144607544, Accuracy: 0.5849609375\n",
      "Batch: 123, Loss: 1.2265987396240234, Accuracy: 0.609375\n",
      "Batch: 124, Loss: 1.3037225008010864, Accuracy: 0.5810546875\n",
      "Batch: 125, Loss: 1.1610321998596191, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.2897554636001587, Accuracy: 0.578125\n",
      "Batch: 127, Loss: 1.2685410976409912, Accuracy: 0.5859375\n",
      "Batch: 128, Loss: 1.2698423862457275, Accuracy: 0.599609375\n",
      "Batch: 129, Loss: 1.1873961687088013, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.128482460975647, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.2710734605789185, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.1191256046295166, Accuracy: 0.63671875\n",
      "Batch: 133, Loss: 1.2190114259719849, Accuracy: 0.6142578125\n",
      "Batch: 134, Loss: 1.1500108242034912, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.061294436454773, Accuracy: 0.6494140625\n",
      "Batch: 136, Loss: 1.1089766025543213, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.2029188871383667, Accuracy: 0.6083984375\n",
      "Batch: 138, Loss: 1.336652398109436, Accuracy: 0.578125\n",
      "Batch: 139, Loss: 1.2348742485046387, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.272993564605713, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.1982505321502686, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.2188220024108887, Accuracy: 0.599609375\n",
      "Batch: 143, Loss: 1.2015345096588135, Accuracy: 0.6162109375\n",
      "Batch: 144, Loss: 1.2926796674728394, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.3067901134490967, Accuracy: 0.5791015625\n",
      "Batch: 146, Loss: 1.24183988571167, Accuracy: 0.6015625\n",
      "Batch: 147, Loss: 1.227750301361084, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.292349100112915, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.2541823387145996, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.1995291709899902, Accuracy: 0.6044921875\n",
      "Batch: 151, Loss: 1.210505723953247, Accuracy: 0.6064453125\n",
      "Batch: 152, Loss: 1.168623685836792, Accuracy: 0.6103515625\n",
      "Batch: 153, Loss: 1.205042839050293, Accuracy: 0.6064453125\n",
      "Batch: 154, Loss: 1.1395294666290283, Accuracy: 0.6162109375\n",
      "Batch: 155, Loss: 1.1435317993164062, Accuracy: 0.6279296875\n",
      "Epoch 439/200\n",
      "Batch: 1, Loss: 1.3374865055084229, Accuracy: 0.6083984375\n",
      "Batch: 2, Loss: 1.159836769104004, Accuracy: 0.6298828125\n",
      "Batch: 3, Loss: 1.0832487344741821, Accuracy: 0.646484375\n",
      "Batch: 4, Loss: 1.1342390775680542, Accuracy: 0.62890625\n",
      "Batch: 5, Loss: 1.0468508005142212, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.0439335107803345, Accuracy: 0.66015625\n",
      "Batch: 7, Loss: 1.0495662689208984, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 1.0513412952423096, Accuracy: 0.6611328125\n",
      "Batch: 9, Loss: 1.0244696140289307, Accuracy: 0.6474609375\n",
      "Batch: 10, Loss: 1.025460958480835, Accuracy: 0.6474609375\n",
      "Batch: 11, Loss: 0.9816697239875793, Accuracy: 0.6689453125\n",
      "Batch: 12, Loss: 1.0379397869110107, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.049451470375061, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 1.061079978942871, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.9746454954147339, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0754361152648926, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.0820484161376953, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.1571917533874512, Accuracy: 0.619140625\n",
      "Batch: 19, Loss: 1.2634844779968262, Accuracy: 0.5849609375\n",
      "Batch: 20, Loss: 1.077596664428711, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.1402466297149658, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.2277297973632812, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.284179449081421, Accuracy: 0.5859375\n",
      "Batch: 24, Loss: 1.143553376197815, Accuracy: 0.6298828125\n",
      "Batch: 25, Loss: 1.1959048509597778, Accuracy: 0.609375\n",
      "Batch: 26, Loss: 1.2553253173828125, Accuracy: 0.5869140625\n",
      "Batch: 27, Loss: 1.1955238580703735, Accuracy: 0.5849609375\n",
      "Batch: 28, Loss: 1.1129074096679688, Accuracy: 0.6259765625\n",
      "Batch: 29, Loss: 1.0827667713165283, Accuracy: 0.6455078125\n",
      "Batch: 30, Loss: 1.2210841178894043, Accuracy: 0.5927734375\n",
      "Batch: 31, Loss: 1.2353280782699585, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.0859384536743164, Accuracy: 0.630859375\n",
      "Batch: 33, Loss: 1.032985806465149, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.094508409500122, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 1.1567106246948242, Accuracy: 0.615234375\n",
      "Batch: 36, Loss: 1.234331488609314, Accuracy: 0.6201171875\n",
      "Batch: 37, Loss: 1.2673500776290894, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.2196145057678223, Accuracy: 0.599609375\n",
      "Batch: 39, Loss: 1.1322991847991943, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 1.1297119855880737, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1808260679244995, Accuracy: 0.619140625\n",
      "Batch: 42, Loss: 1.1215355396270752, Accuracy: 0.6337890625\n",
      "Batch: 43, Loss: 1.0825159549713135, Accuracy: 0.6279296875\n",
      "Batch: 44, Loss: 1.0302132368087769, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 1.0942933559417725, Accuracy: 0.650390625\n",
      "Batch: 46, Loss: 1.1291449069976807, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.0966373682022095, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 1.1386959552764893, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.2210779190063477, Accuracy: 0.6298828125\n",
      "Batch: 50, Loss: 1.2323431968688965, Accuracy: 0.607421875\n",
      "Batch: 51, Loss: 1.2083630561828613, Accuracy: 0.5966796875\n",
      "Batch: 52, Loss: 1.2861716747283936, Accuracy: 0.5849609375\n",
      "Batch: 53, Loss: 1.2452691793441772, Accuracy: 0.5966796875\n",
      "Batch: 54, Loss: 1.239197015762329, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.139906883239746, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.0954108238220215, Accuracy: 0.646484375\n",
      "Batch: 57, Loss: 1.1596834659576416, Accuracy: 0.62109375\n",
      "Batch: 58, Loss: 1.15120267868042, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.1729176044464111, Accuracy: 0.6123046875\n",
      "Batch: 60, Loss: 1.2982174158096313, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.1919138431549072, Accuracy: 0.6123046875\n",
      "Batch: 62, Loss: 1.1510145664215088, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.2482014894485474, Accuracy: 0.5966796875\n",
      "Batch: 64, Loss: 1.2276512384414673, Accuracy: 0.5810546875\n",
      "Batch: 65, Loss: 1.223149061203003, Accuracy: 0.6103515625\n",
      "Batch: 66, Loss: 1.1718202829360962, Accuracy: 0.6181640625\n",
      "Batch: 67, Loss: 1.213012456893921, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.1533749103546143, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.189051628112793, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.2578611373901367, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.142181158065796, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.2497801780700684, Accuracy: 0.6005859375\n",
      "Batch: 73, Loss: 1.22395658493042, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.1359782218933105, Accuracy: 0.626953125\n",
      "Batch: 75, Loss: 1.1466110944747925, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.0906845331192017, Accuracy: 0.6494140625\n",
      "Batch: 77, Loss: 1.1108324527740479, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.1361066102981567, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.154191255569458, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.173797607421875, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1578829288482666, Accuracy: 0.6142578125\n",
      "Batch: 82, Loss: 1.1591544151306152, Accuracy: 0.6337890625\n",
      "Batch: 83, Loss: 1.1916614770889282, Accuracy: 0.6123046875\n",
      "Batch: 84, Loss: 1.1665611267089844, Accuracy: 0.6201171875\n",
      "Batch: 85, Loss: 1.1396493911743164, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.155822515487671, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1878615617752075, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.2348819971084595, Accuracy: 0.591796875\n",
      "Batch: 89, Loss: 1.1769250631332397, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.183293104171753, Accuracy: 0.609375\n",
      "Batch: 91, Loss: 1.1273488998413086, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.191578984260559, Accuracy: 0.6318359375\n",
      "Batch: 93, Loss: 1.220270037651062, Accuracy: 0.607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 1.2473042011260986, Accuracy: 0.599609375\n",
      "Batch: 95, Loss: 1.204350233078003, Accuracy: 0.6318359375\n",
      "Batch: 96, Loss: 1.241115927696228, Accuracy: 0.607421875\n",
      "Batch: 97, Loss: 1.196437120437622, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.1561235189437866, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.2009283304214478, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.1137751340866089, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.1954913139343262, Accuracy: 0.623046875\n",
      "Batch: 102, Loss: 1.2327120304107666, Accuracy: 0.587890625\n",
      "Batch: 103, Loss: 1.252792477607727, Accuracy: 0.5966796875\n",
      "Batch: 104, Loss: 1.2500110864639282, Accuracy: 0.5859375\n",
      "Batch: 105, Loss: 1.2536256313323975, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.2067171335220337, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.2690956592559814, Accuracy: 0.59375\n",
      "Batch: 108, Loss: 1.2173144817352295, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.2269504070281982, Accuracy: 0.60546875\n",
      "Batch: 110, Loss: 1.1727371215820312, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1610777378082275, Accuracy: 0.62109375\n",
      "Batch: 112, Loss: 1.1606968641281128, Accuracy: 0.6298828125\n",
      "Batch: 113, Loss: 1.1938939094543457, Accuracy: 0.6171875\n",
      "Batch: 114, Loss: 1.1957192420959473, Accuracy: 0.599609375\n",
      "Batch: 115, Loss: 1.2617599964141846, Accuracy: 0.60546875\n",
      "Batch: 116, Loss: 1.2578904628753662, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.2112503051757812, Accuracy: 0.6064453125\n",
      "Batch: 118, Loss: 1.2907923460006714, Accuracy: 0.5849609375\n",
      "Batch: 119, Loss: 1.2951736450195312, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.3378443717956543, Accuracy: 0.591796875\n",
      "Batch: 121, Loss: 1.211193323135376, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.2343024015426636, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.2206969261169434, Accuracy: 0.626953125\n",
      "Batch: 124, Loss: 1.2088747024536133, Accuracy: 0.6064453125\n",
      "Batch: 125, Loss: 1.195927381515503, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.2493247985839844, Accuracy: 0.583984375\n",
      "Batch: 127, Loss: 1.2428394556045532, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.267458200454712, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.2084729671478271, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.1744439601898193, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.22213613986969, Accuracy: 0.595703125\n",
      "Batch: 132, Loss: 1.1147918701171875, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 1.2067780494689941, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.152758002281189, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.0742111206054688, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.095846176147461, Accuracy: 0.66015625\n",
      "Batch: 137, Loss: 1.220368504524231, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.3061872720718384, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.215704083442688, Accuracy: 0.611328125\n",
      "Batch: 140, Loss: 1.2701590061187744, Accuracy: 0.5927734375\n",
      "Batch: 141, Loss: 1.2210862636566162, Accuracy: 0.61328125\n",
      "Batch: 142, Loss: 1.184527039527893, Accuracy: 0.634765625\n",
      "Batch: 143, Loss: 1.2213294506072998, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.2650730609893799, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.2910839319229126, Accuracy: 0.59375\n",
      "Batch: 146, Loss: 1.2330150604248047, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.214531421661377, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.2225573062896729, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.2227410078048706, Accuracy: 0.5849609375\n",
      "Batch: 150, Loss: 1.1749866008758545, Accuracy: 0.6162109375\n",
      "Batch: 151, Loss: 1.2093636989593506, Accuracy: 0.6220703125\n",
      "Batch: 152, Loss: 1.213616132736206, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.154509425163269, Accuracy: 0.6328125\n",
      "Batch: 154, Loss: 1.194250464439392, Accuracy: 0.611328125\n",
      "Batch: 155, Loss: 1.1682109832763672, Accuracy: 0.63671875\n",
      "Epoch 440/200\n",
      "Batch: 1, Loss: 1.2672855854034424, Accuracy: 0.6181640625\n",
      "Batch: 2, Loss: 1.1337618827819824, Accuracy: 0.625\n",
      "Batch: 3, Loss: 1.0630812644958496, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.0903890132904053, Accuracy: 0.6142578125\n",
      "Batch: 5, Loss: 1.0628364086151123, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.0907859802246094, Accuracy: 0.6318359375\n",
      "Batch: 7, Loss: 1.0571460723876953, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 1.0310454368591309, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0008864402770996, Accuracy: 0.6552734375\n",
      "Batch: 10, Loss: 1.0046964883804321, Accuracy: 0.67578125\n",
      "Batch: 11, Loss: 1.0079787969589233, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0391932725906372, Accuracy: 0.662109375\n",
      "Batch: 13, Loss: 1.0423516035079956, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9791717529296875, Accuracy: 0.6748046875\n",
      "Batch: 15, Loss: 0.9905328154563904, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0726324319839478, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 1.117871880531311, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.1602718830108643, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2321964502334595, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.151198148727417, Accuracy: 0.6298828125\n",
      "Batch: 21, Loss: 1.1125850677490234, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.3117704391479492, Accuracy: 0.5771484375\n",
      "Batch: 23, Loss: 1.2809762954711914, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.1545026302337646, Accuracy: 0.6337890625\n",
      "Batch: 25, Loss: 1.124868392944336, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.2252283096313477, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.1849348545074463, Accuracy: 0.611328125\n",
      "Batch: 28, Loss: 1.0837212800979614, Accuracy: 0.6513671875\n",
      "Batch: 29, Loss: 1.101372480392456, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.210667371749878, Accuracy: 0.6044921875\n",
      "Batch: 31, Loss: 1.2972018718719482, Accuracy: 0.5751953125\n",
      "Batch: 32, Loss: 1.0423955917358398, Accuracy: 0.65234375\n",
      "Batch: 33, Loss: 1.0678038597106934, Accuracy: 0.6396484375\n",
      "Batch: 34, Loss: 1.1189935207366943, Accuracy: 0.6396484375\n",
      "Batch: 35, Loss: 1.1353309154510498, Accuracy: 0.638671875\n",
      "Batch: 36, Loss: 1.248608946800232, Accuracy: 0.595703125\n",
      "Batch: 37, Loss: 1.2104768753051758, Accuracy: 0.6142578125\n",
      "Batch: 38, Loss: 1.194146990776062, Accuracy: 0.6025390625\n",
      "Batch: 39, Loss: 1.110661506652832, Accuracy: 0.6357421875\n",
      "Batch: 40, Loss: 1.0734202861785889, Accuracy: 0.6376953125\n",
      "Batch: 41, Loss: 1.1643824577331543, Accuracy: 0.6259765625\n",
      "Batch: 42, Loss: 1.1156480312347412, Accuracy: 0.6279296875\n",
      "Batch: 43, Loss: 1.0689990520477295, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0803022384643555, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.1218442916870117, Accuracy: 0.6142578125\n",
      "Batch: 46, Loss: 1.1539525985717773, Accuracy: 0.61328125\n",
      "Batch: 47, Loss: 1.1780085563659668, Accuracy: 0.62890625\n",
      "Batch: 48, Loss: 1.2123206853866577, Accuracy: 0.60546875\n",
      "Batch: 49, Loss: 1.2126539945602417, Accuracy: 0.6044921875\n",
      "Batch: 50, Loss: 1.196410059928894, Accuracy: 0.59375\n",
      "Batch: 51, Loss: 1.2023866176605225, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.2526917457580566, Accuracy: 0.5849609375\n",
      "Batch: 53, Loss: 1.2927751541137695, Accuracy: 0.5791015625\n",
      "Batch: 54, Loss: 1.2484512329101562, Accuracy: 0.5966796875\n",
      "Batch: 55, Loss: 1.1625120639801025, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.084568977355957, Accuracy: 0.65234375\n",
      "Batch: 57, Loss: 1.1566095352172852, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.199015498161316, Accuracy: 0.603515625\n",
      "Batch: 59, Loss: 1.1535935401916504, Accuracy: 0.6318359375\n",
      "Batch: 60, Loss: 1.2994186878204346, Accuracy: 0.5908203125\n",
      "Batch: 61, Loss: 1.2344629764556885, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.157770037651062, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.214642882347107, Accuracy: 0.5869140625\n",
      "Batch: 64, Loss: 1.1984232664108276, Accuracy: 0.6064453125\n",
      "Batch: 65, Loss: 1.249535083770752, Accuracy: 0.5849609375\n",
      "Batch: 66, Loss: 1.163133144378662, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.149556279182434, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.1245273351669312, Accuracy: 0.642578125\n",
      "Batch: 69, Loss: 1.1740309000015259, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.2120461463928223, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1785695552825928, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.285644292831421, Accuracy: 0.59375\n",
      "Batch: 73, Loss: 1.2065438032150269, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.1665353775024414, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.1385059356689453, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.1498734951019287, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.1021647453308105, Accuracy: 0.65234375\n",
      "Batch: 78, Loss: 1.115445852279663, Accuracy: 0.634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 79, Loss: 1.1552672386169434, Accuracy: 0.6279296875\n",
      "Batch: 80, Loss: 1.1893444061279297, Accuracy: 0.6220703125\n",
      "Batch: 81, Loss: 1.159683346748352, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1593648195266724, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 1.259071946144104, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1937001943588257, Accuracy: 0.6005859375\n",
      "Batch: 85, Loss: 1.1924071311950684, Accuracy: 0.6142578125\n",
      "Batch: 86, Loss: 1.260524868965149, Accuracy: 0.5927734375\n",
      "Batch: 87, Loss: 1.1845166683197021, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.300410270690918, Accuracy: 0.5908203125\n",
      "Batch: 89, Loss: 1.194840908050537, Accuracy: 0.607421875\n",
      "Batch: 90, Loss: 1.1905393600463867, Accuracy: 0.630859375\n",
      "Batch: 91, Loss: 1.1979650259017944, Accuracy: 0.609375\n",
      "Batch: 92, Loss: 1.167048692703247, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.2051211595535278, Accuracy: 0.6181640625\n",
      "Batch: 94, Loss: 1.2352094650268555, Accuracy: 0.607421875\n",
      "Batch: 95, Loss: 1.2558058500289917, Accuracy: 0.5927734375\n",
      "Batch: 96, Loss: 1.1994974613189697, Accuracy: 0.619140625\n",
      "Batch: 97, Loss: 1.2272112369537354, Accuracy: 0.595703125\n",
      "Batch: 98, Loss: 1.2039295434951782, Accuracy: 0.6142578125\n",
      "Batch: 99, Loss: 1.2157793045043945, Accuracy: 0.6083984375\n",
      "Batch: 100, Loss: 1.131733775138855, Accuracy: 0.640625\n",
      "Batch: 101, Loss: 1.1254137754440308, Accuracy: 0.626953125\n",
      "Batch: 102, Loss: 1.175581455230713, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.2148144245147705, Accuracy: 0.5986328125\n",
      "Batch: 104, Loss: 1.2098429203033447, Accuracy: 0.607421875\n",
      "Batch: 105, Loss: 1.2980518341064453, Accuracy: 0.5810546875\n",
      "Batch: 106, Loss: 1.181386947631836, Accuracy: 0.6171875\n",
      "Batch: 107, Loss: 1.3241056203842163, Accuracy: 0.5869140625\n",
      "Batch: 108, Loss: 1.1906954050064087, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.26945960521698, Accuracy: 0.5888671875\n",
      "Batch: 110, Loss: 1.2063101530075073, Accuracy: 0.6103515625\n",
      "Batch: 111, Loss: 1.1563377380371094, Accuracy: 0.619140625\n",
      "Batch: 112, Loss: 1.1459786891937256, Accuracy: 0.62890625\n",
      "Batch: 113, Loss: 1.1510965824127197, Accuracy: 0.6123046875\n",
      "Batch: 114, Loss: 1.2061519622802734, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.1860922574996948, Accuracy: 0.625\n",
      "Batch: 116, Loss: 1.2638542652130127, Accuracy: 0.603515625\n",
      "Batch: 117, Loss: 1.202314853668213, Accuracy: 0.599609375\n",
      "Batch: 118, Loss: 1.262068271636963, Accuracy: 0.5849609375\n",
      "Batch: 119, Loss: 1.2900826930999756, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.3292715549468994, Accuracy: 0.580078125\n",
      "Batch: 121, Loss: 1.2641284465789795, Accuracy: 0.5966796875\n",
      "Batch: 122, Loss: 1.240558385848999, Accuracy: 0.607421875\n",
      "Batch: 123, Loss: 1.2626148462295532, Accuracy: 0.5888671875\n",
      "Batch: 124, Loss: 1.2486371994018555, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.156720519065857, Accuracy: 0.642578125\n",
      "Batch: 126, Loss: 1.279453992843628, Accuracy: 0.599609375\n",
      "Batch: 127, Loss: 1.2767860889434814, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2686114311218262, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.2472951412200928, Accuracy: 0.583984375\n",
      "Batch: 130, Loss: 1.1973955631256104, Accuracy: 0.6162109375\n",
      "Batch: 131, Loss: 1.1716599464416504, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.1110069751739502, Accuracy: 0.6376953125\n",
      "Batch: 133, Loss: 1.1922712326049805, Accuracy: 0.6044921875\n",
      "Batch: 134, Loss: 1.159834861755371, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.0559327602386475, Accuracy: 0.65234375\n",
      "Batch: 136, Loss: 1.122078537940979, Accuracy: 0.642578125\n",
      "Batch: 137, Loss: 1.2064673900604248, Accuracy: 0.6064453125\n",
      "Batch: 138, Loss: 1.2930984497070312, Accuracy: 0.58203125\n",
      "Batch: 139, Loss: 1.2626464366912842, Accuracy: 0.5966796875\n",
      "Batch: 140, Loss: 1.2564420700073242, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.224989652633667, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2139405012130737, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2602626085281372, Accuracy: 0.6025390625\n",
      "Batch: 144, Loss: 1.289566993713379, Accuracy: 0.583984375\n",
      "Batch: 145, Loss: 1.2764259576797485, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.2583659887313843, Accuracy: 0.5986328125\n",
      "Batch: 147, Loss: 1.2306386232376099, Accuracy: 0.59375\n",
      "Batch: 148, Loss: 1.226119041442871, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.1898820400238037, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.2103850841522217, Accuracy: 0.6123046875\n",
      "Batch: 151, Loss: 1.2148301601409912, Accuracy: 0.6123046875\n",
      "Batch: 152, Loss: 1.2031668424606323, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1458091735839844, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.0771467685699463, Accuracy: 0.6591796875\n",
      "Batch: 155, Loss: 1.12751042842865, Accuracy: 0.6337890625\n",
      "Saved Weights at epoch 440 to file Weights_440.h5\n",
      "Epoch 441/200\n",
      "Batch: 1, Loss: 1.238806962966919, Accuracy: 0.619140625\n",
      "Batch: 2, Loss: 1.1216362714767456, Accuracy: 0.634765625\n",
      "Batch: 3, Loss: 1.1013866662979126, Accuracy: 0.626953125\n",
      "Batch: 4, Loss: 1.135526418685913, Accuracy: 0.6220703125\n",
      "Batch: 5, Loss: 1.0496292114257812, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 1.015580415725708, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 1.0361882448196411, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0137439966201782, Accuracy: 0.66796875\n",
      "Batch: 9, Loss: 0.9945008754730225, Accuracy: 0.6865234375\n",
      "Batch: 10, Loss: 0.9571871757507324, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.9966346621513367, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 1.0194183588027954, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 1.025927186012268, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.0055639743804932, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 0.9978009462356567, Accuracy: 0.669921875\n",
      "Batch: 16, Loss: 1.0299981832504272, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.0725830793380737, Accuracy: 0.646484375\n",
      "Batch: 18, Loss: 1.1968646049499512, Accuracy: 0.6103515625\n",
      "Batch: 19, Loss: 1.2726246118545532, Accuracy: 0.5830078125\n",
      "Batch: 20, Loss: 1.1239088773727417, Accuracy: 0.6396484375\n",
      "Batch: 21, Loss: 1.1007177829742432, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.268123984336853, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.2451834678649902, Accuracy: 0.6015625\n",
      "Batch: 24, Loss: 1.147838830947876, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.1705130338668823, Accuracy: 0.6494140625\n",
      "Batch: 26, Loss: 1.2257840633392334, Accuracy: 0.595703125\n",
      "Batch: 27, Loss: 1.1649069786071777, Accuracy: 0.6142578125\n",
      "Batch: 28, Loss: 1.099799633026123, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.101799726486206, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.1749846935272217, Accuracy: 0.609375\n",
      "Batch: 31, Loss: 1.2606371641159058, Accuracy: 0.56640625\n",
      "Batch: 32, Loss: 1.0627838373184204, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.0082628726959229, Accuracy: 0.6845703125\n",
      "Batch: 34, Loss: 1.1600375175476074, Accuracy: 0.6240234375\n",
      "Batch: 35, Loss: 1.1390397548675537, Accuracy: 0.634765625\n",
      "Batch: 36, Loss: 1.186877727508545, Accuracy: 0.63671875\n",
      "Batch: 37, Loss: 1.2736101150512695, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.217066764831543, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.1161909103393555, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.1247156858444214, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.1380877494812012, Accuracy: 0.6201171875\n",
      "Batch: 42, Loss: 1.0847907066345215, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.081122636795044, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0865068435668945, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 1.1616473197937012, Accuracy: 0.625\n",
      "Batch: 46, Loss: 1.176755666732788, Accuracy: 0.5947265625\n",
      "Batch: 47, Loss: 1.1191421747207642, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.192425012588501, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.227518081665039, Accuracy: 0.5927734375\n",
      "Batch: 50, Loss: 1.1940710544586182, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.2143369913101196, Accuracy: 0.578125\n",
      "Batch: 52, Loss: 1.2966059446334839, Accuracy: 0.58984375\n",
      "Batch: 53, Loss: 1.265367865562439, Accuracy: 0.5859375\n",
      "Batch: 54, Loss: 1.235853910446167, Accuracy: 0.6005859375\n",
      "Batch: 55, Loss: 1.1844922304153442, Accuracy: 0.615234375\n",
      "Batch: 56, Loss: 1.1913751363754272, Accuracy: 0.6083984375\n",
      "Batch: 57, Loss: 1.1575725078582764, Accuracy: 0.630859375\n",
      "Batch: 58, Loss: 1.1943747997283936, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.1631827354431152, Accuracy: 0.623046875\n",
      "Batch: 60, Loss: 1.3238177299499512, Accuracy: 0.5927734375\n",
      "Batch: 61, Loss: 1.2068935632705688, Accuracy: 0.6005859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 1.1607749462127686, Accuracy: 0.623046875\n",
      "Batch: 63, Loss: 1.163354516029358, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.2686243057250977, Accuracy: 0.5732421875\n",
      "Batch: 65, Loss: 1.2779725790023804, Accuracy: 0.5859375\n",
      "Batch: 66, Loss: 1.1385581493377686, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1795153617858887, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.1095465421676636, Accuracy: 0.640625\n",
      "Batch: 69, Loss: 1.342000961303711, Accuracy: 0.578125\n",
      "Batch: 70, Loss: 1.186464548110962, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.151003360748291, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.227761149406433, Accuracy: 0.6025390625\n",
      "Batch: 73, Loss: 1.216170072555542, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.118617296218872, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.1534476280212402, Accuracy: 0.640625\n",
      "Batch: 76, Loss: 1.1713902950286865, Accuracy: 0.625\n",
      "Batch: 77, Loss: 1.1171824932098389, Accuracy: 0.6416015625\n",
      "Batch: 78, Loss: 1.1059644222259521, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.1485795974731445, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.211329698562622, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.1580636501312256, Accuracy: 0.6103515625\n",
      "Batch: 82, Loss: 1.1411902904510498, Accuracy: 0.62890625\n",
      "Batch: 83, Loss: 1.1962671279907227, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.1606324911117554, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.223402738571167, Accuracy: 0.5986328125\n",
      "Batch: 86, Loss: 1.2142049074172974, Accuracy: 0.6142578125\n",
      "Batch: 87, Loss: 1.2333569526672363, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.241559624671936, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.2347056865692139, Accuracy: 0.607421875\n",
      "Batch: 90, Loss: 1.2214947938919067, Accuracy: 0.6064453125\n",
      "Batch: 91, Loss: 1.1763418912887573, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1520817279815674, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.192224144935608, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.2515182495117188, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.2519962787628174, Accuracy: 0.6123046875\n",
      "Batch: 96, Loss: 1.2467970848083496, Accuracy: 0.6240234375\n",
      "Batch: 97, Loss: 1.192896842956543, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.1997606754302979, Accuracy: 0.603515625\n",
      "Batch: 99, Loss: 1.200130820274353, Accuracy: 0.62109375\n",
      "Batch: 100, Loss: 1.0909167528152466, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.1629111766815186, Accuracy: 0.6083984375\n",
      "Batch: 102, Loss: 1.198386549949646, Accuracy: 0.6103515625\n",
      "Batch: 103, Loss: 1.2157124280929565, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.148486614227295, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.267044186592102, Accuracy: 0.587890625\n",
      "Batch: 106, Loss: 1.2372573614120483, Accuracy: 0.6123046875\n",
      "Batch: 107, Loss: 1.2633575201034546, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.2340937852859497, Accuracy: 0.583984375\n",
      "Batch: 109, Loss: 1.2541401386260986, Accuracy: 0.6015625\n",
      "Batch: 110, Loss: 1.1524118185043335, Accuracy: 0.6318359375\n",
      "Batch: 111, Loss: 1.1417994499206543, Accuracy: 0.6455078125\n",
      "Batch: 112, Loss: 1.1177699565887451, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.2285010814666748, Accuracy: 0.595703125\n",
      "Batch: 114, Loss: 1.2086304426193237, Accuracy: 0.5927734375\n",
      "Batch: 115, Loss: 1.246166467666626, Accuracy: 0.5859375\n",
      "Batch: 116, Loss: 1.2205662727355957, Accuracy: 0.5732421875\n",
      "Batch: 117, Loss: 1.2108837366104126, Accuracy: 0.587890625\n",
      "Batch: 118, Loss: 1.2523822784423828, Accuracy: 0.5703125\n",
      "Batch: 119, Loss: 1.3157639503479004, Accuracy: 0.578125\n",
      "Batch: 120, Loss: 1.3479866981506348, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.245868444442749, Accuracy: 0.6015625\n",
      "Batch: 122, Loss: 1.2623047828674316, Accuracy: 0.5888671875\n",
      "Batch: 123, Loss: 1.2411777973175049, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.2343227863311768, Accuracy: 0.5830078125\n",
      "Batch: 125, Loss: 1.202895164489746, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.3148777484893799, Accuracy: 0.595703125\n",
      "Batch: 127, Loss: 1.3167686462402344, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.250260829925537, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.2291618585586548, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.2417759895324707, Accuracy: 0.5830078125\n",
      "Batch: 131, Loss: 1.222757339477539, Accuracy: 0.611328125\n",
      "Batch: 132, Loss: 1.0792800188064575, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.1859164237976074, Accuracy: 0.6279296875\n",
      "Batch: 134, Loss: 1.102553129196167, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 1.0813426971435547, Accuracy: 0.658203125\n",
      "Batch: 136, Loss: 1.135160207748413, Accuracy: 0.630859375\n",
      "Batch: 137, Loss: 1.2573320865631104, Accuracy: 0.5908203125\n",
      "Batch: 138, Loss: 1.3087739944458008, Accuracy: 0.5673828125\n",
      "Batch: 139, Loss: 1.2481820583343506, Accuracy: 0.587890625\n",
      "Batch: 140, Loss: 1.3339754343032837, Accuracy: 0.5888671875\n",
      "Batch: 141, Loss: 1.2033681869506836, Accuracy: 0.6005859375\n",
      "Batch: 142, Loss: 1.2882869243621826, Accuracy: 0.5859375\n",
      "Batch: 143, Loss: 1.227340817451477, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.3013579845428467, Accuracy: 0.58203125\n",
      "Batch: 145, Loss: 1.3120061159133911, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.2123301029205322, Accuracy: 0.6025390625\n",
      "Batch: 147, Loss: 1.2451175451278687, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.219242811203003, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.1963239908218384, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.19879150390625, Accuracy: 0.609375\n",
      "Batch: 151, Loss: 1.160880446434021, Accuracy: 0.6484375\n",
      "Batch: 152, Loss: 1.2395766973495483, Accuracy: 0.5859375\n",
      "Batch: 153, Loss: 1.1724252700805664, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.1663180589675903, Accuracy: 0.619140625\n",
      "Batch: 155, Loss: 1.1298391819000244, Accuracy: 0.60546875\n",
      "Epoch 442/200\n",
      "Batch: 1, Loss: 1.2310407161712646, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.0912799835205078, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.0448670387268066, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.1148650646209717, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 1.0549191236495972, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 1.0547593832015991, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.100299596786499, Accuracy: 0.625\n",
      "Batch: 8, Loss: 1.062607765197754, Accuracy: 0.6591796875\n",
      "Batch: 9, Loss: 1.0232369899749756, Accuracy: 0.671875\n",
      "Batch: 10, Loss: 0.9698031544685364, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 0.9906648397445679, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 1.0530991554260254, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 1.0429015159606934, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 0.9890822768211365, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.9764281511306763, Accuracy: 0.681640625\n",
      "Batch: 16, Loss: 1.076791524887085, Accuracy: 0.6552734375\n",
      "Batch: 17, Loss: 1.107539176940918, Accuracy: 0.6162109375\n",
      "Batch: 18, Loss: 1.1307164430618286, Accuracy: 0.6396484375\n",
      "Batch: 19, Loss: 1.2345316410064697, Accuracy: 0.6064453125\n",
      "Batch: 20, Loss: 1.1455698013305664, Accuracy: 0.6328125\n",
      "Batch: 21, Loss: 1.1433069705963135, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.204545259475708, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.300775408744812, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.1628658771514893, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.175798773765564, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.249901294708252, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.1710853576660156, Accuracy: 0.6083984375\n",
      "Batch: 28, Loss: 1.1279865503311157, Accuracy: 0.615234375\n",
      "Batch: 29, Loss: 1.0998444557189941, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.1857080459594727, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.240488052368164, Accuracy: 0.591796875\n",
      "Batch: 32, Loss: 1.0836178064346313, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.0355815887451172, Accuracy: 0.6552734375\n",
      "Batch: 34, Loss: 1.124817132949829, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1869356632232666, Accuracy: 0.6123046875\n",
      "Batch: 36, Loss: 1.207984447479248, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.220782995223999, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.2107045650482178, Accuracy: 0.61328125\n",
      "Batch: 39, Loss: 1.1494084596633911, Accuracy: 0.6298828125\n",
      "Batch: 40, Loss: 1.1067583560943604, Accuracy: 0.63671875\n",
      "Batch: 41, Loss: 1.1638059616088867, Accuracy: 0.61328125\n",
      "Batch: 42, Loss: 1.156245470046997, Accuracy: 0.6103515625\n",
      "Batch: 43, Loss: 1.122671127319336, Accuracy: 0.62109375\n",
      "Batch: 44, Loss: 1.104331135749817, Accuracy: 0.6337890625\n",
      "Batch: 45, Loss: 1.073065161705017, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 1.198868751525879, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 47, Loss: 1.1746368408203125, Accuracy: 0.6259765625\n",
      "Batch: 48, Loss: 1.172082543373108, Accuracy: 0.6142578125\n",
      "Batch: 49, Loss: 1.148996353149414, Accuracy: 0.6201171875\n",
      "Batch: 50, Loss: 1.1497507095336914, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.1593656539916992, Accuracy: 0.59375\n",
      "Batch: 52, Loss: 1.237581491470337, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.202418327331543, Accuracy: 0.5849609375\n",
      "Batch: 54, Loss: 1.2038607597351074, Accuracy: 0.615234375\n",
      "Batch: 55, Loss: 1.1109108924865723, Accuracy: 0.65625\n",
      "Batch: 56, Loss: 1.1475838422775269, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.1469337940216064, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.1777184009552002, Accuracy: 0.626953125\n",
      "Batch: 59, Loss: 1.1460769176483154, Accuracy: 0.6357421875\n",
      "Batch: 60, Loss: 1.2382426261901855, Accuracy: 0.583984375\n",
      "Batch: 61, Loss: 1.249402403831482, Accuracy: 0.58984375\n",
      "Batch: 62, Loss: 1.2168561220169067, Accuracy: 0.61328125\n",
      "Batch: 63, Loss: 1.1696380376815796, Accuracy: 0.62109375\n",
      "Batch: 64, Loss: 1.291572093963623, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.215583324432373, Accuracy: 0.6201171875\n",
      "Batch: 66, Loss: 1.2063217163085938, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.1971551179885864, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.131143569946289, Accuracy: 0.6357421875\n",
      "Batch: 69, Loss: 1.2044579982757568, Accuracy: 0.61328125\n",
      "Batch: 70, Loss: 1.2258578538894653, Accuracy: 0.6015625\n",
      "Batch: 71, Loss: 1.1643649339675903, Accuracy: 0.615234375\n",
      "Batch: 72, Loss: 1.183159589767456, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.1852598190307617, Accuracy: 0.591796875\n",
      "Batch: 74, Loss: 1.1445859670639038, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.1725550889968872, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.065198540687561, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.1125895977020264, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.1667466163635254, Accuracy: 0.603515625\n",
      "Batch: 79, Loss: 1.1926124095916748, Accuracy: 0.6259765625\n",
      "Batch: 80, Loss: 1.1549147367477417, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.081909418106079, Accuracy: 0.66015625\n",
      "Batch: 82, Loss: 1.2064499855041504, Accuracy: 0.6044921875\n",
      "Batch: 83, Loss: 1.2259478569030762, Accuracy: 0.591796875\n",
      "Batch: 84, Loss: 1.2180311679840088, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.172000765800476, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.2158232927322388, Accuracy: 0.578125\n",
      "Batch: 87, Loss: 1.1993660926818848, Accuracy: 0.599609375\n",
      "Batch: 88, Loss: 1.1715078353881836, Accuracy: 0.623046875\n",
      "Batch: 89, Loss: 1.2045390605926514, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.1621599197387695, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.1891703605651855, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.2160894870758057, Accuracy: 0.625\n",
      "Batch: 93, Loss: 1.2232120037078857, Accuracy: 0.5986328125\n",
      "Batch: 94, Loss: 1.252386212348938, Accuracy: 0.6083984375\n",
      "Batch: 95, Loss: 1.2077722549438477, Accuracy: 0.609375\n",
      "Batch: 96, Loss: 1.2323698997497559, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.2504328489303589, Accuracy: 0.595703125\n",
      "Batch: 98, Loss: 1.1838486194610596, Accuracy: 0.6298828125\n",
      "Batch: 99, Loss: 1.2006628513336182, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 1.0538667440414429, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.1293787956237793, Accuracy: 0.6416015625\n",
      "Batch: 102, Loss: 1.1892768144607544, Accuracy: 0.5986328125\n",
      "Batch: 103, Loss: 1.234446406364441, Accuracy: 0.611328125\n",
      "Batch: 104, Loss: 1.1462428569793701, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.1896705627441406, Accuracy: 0.626953125\n",
      "Batch: 106, Loss: 1.1473404169082642, Accuracy: 0.62109375\n",
      "Batch: 107, Loss: 1.2471503019332886, Accuracy: 0.6064453125\n",
      "Batch: 108, Loss: 1.2327601909637451, Accuracy: 0.578125\n",
      "Batch: 109, Loss: 1.2261590957641602, Accuracy: 0.625\n",
      "Batch: 110, Loss: 1.1733763217926025, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.173574686050415, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.1541754007339478, Accuracy: 0.623046875\n",
      "Batch: 113, Loss: 1.137729525566101, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.224261999130249, Accuracy: 0.5927734375\n",
      "Batch: 115, Loss: 1.2492430210113525, Accuracy: 0.595703125\n",
      "Batch: 116, Loss: 1.1950523853302002, Accuracy: 0.5947265625\n",
      "Batch: 117, Loss: 1.213287591934204, Accuracy: 0.5947265625\n",
      "Batch: 118, Loss: 1.2397959232330322, Accuracy: 0.599609375\n",
      "Batch: 119, Loss: 1.2849946022033691, Accuracy: 0.5947265625\n",
      "Batch: 120, Loss: 1.3249962329864502, Accuracy: 0.5908203125\n",
      "Batch: 121, Loss: 1.2305467128753662, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.2503554821014404, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.203018069267273, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2259469032287598, Accuracy: 0.62109375\n",
      "Batch: 125, Loss: 1.2152807712554932, Accuracy: 0.6064453125\n",
      "Batch: 126, Loss: 1.2738474607467651, Accuracy: 0.59765625\n",
      "Batch: 127, Loss: 1.3026000261306763, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2629284858703613, Accuracy: 0.5849609375\n",
      "Batch: 129, Loss: 1.253584384918213, Accuracy: 0.59765625\n",
      "Batch: 130, Loss: 1.137336015701294, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.259806513786316, Accuracy: 0.58984375\n",
      "Batch: 132, Loss: 1.093483567237854, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.222275972366333, Accuracy: 0.607421875\n",
      "Batch: 134, Loss: 1.1406724452972412, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.0671955347061157, Accuracy: 0.6455078125\n",
      "Batch: 136, Loss: 1.0937895774841309, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.1714890003204346, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 1.2057795524597168, Accuracy: 0.6142578125\n",
      "Batch: 139, Loss: 1.2144653797149658, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.3229527473449707, Accuracy: 0.56640625\n",
      "Batch: 141, Loss: 1.2144570350646973, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2518869638442993, Accuracy: 0.6015625\n",
      "Batch: 143, Loss: 1.28324556350708, Accuracy: 0.591796875\n",
      "Batch: 144, Loss: 1.309760332107544, Accuracy: 0.576171875\n",
      "Batch: 145, Loss: 1.2648144960403442, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.2150330543518066, Accuracy: 0.587890625\n",
      "Batch: 147, Loss: 1.235391616821289, Accuracy: 0.6171875\n",
      "Batch: 148, Loss: 1.2527960538864136, Accuracy: 0.6005859375\n",
      "Batch: 149, Loss: 1.2389907836914062, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.19645094871521, Accuracy: 0.6201171875\n",
      "Batch: 151, Loss: 1.201047420501709, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.1426975727081299, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1914710998535156, Accuracy: 0.6025390625\n",
      "Batch: 154, Loss: 1.1360785961151123, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.0991970300674438, Accuracy: 0.6328125\n",
      "Epoch 443/200\n",
      "Batch: 1, Loss: 1.2524614334106445, Accuracy: 0.623046875\n",
      "Batch: 2, Loss: 1.0756275653839111, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.0842174291610718, Accuracy: 0.6396484375\n",
      "Batch: 4, Loss: 1.1218459606170654, Accuracy: 0.640625\n",
      "Batch: 5, Loss: 1.0689804553985596, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.0772520303726196, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.089357614517212, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 1.0389583110809326, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0615663528442383, Accuracy: 0.65625\n",
      "Batch: 10, Loss: 0.9711830615997314, Accuracy: 0.669921875\n",
      "Batch: 11, Loss: 1.0178970098495483, Accuracy: 0.666015625\n",
      "Batch: 12, Loss: 1.0593374967575073, Accuracy: 0.650390625\n",
      "Batch: 13, Loss: 1.0716067552566528, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 1.0103423595428467, Accuracy: 0.654296875\n",
      "Batch: 15, Loss: 0.9590474367141724, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.1071993112564087, Accuracy: 0.6533203125\n",
      "Batch: 17, Loss: 1.0743526220321655, Accuracy: 0.6552734375\n",
      "Batch: 18, Loss: 1.1402145624160767, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.229151725769043, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.1442086696624756, Accuracy: 0.6328125\n",
      "Batch: 21, Loss: 1.051123857498169, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.278226375579834, Accuracy: 0.5849609375\n",
      "Batch: 23, Loss: 1.2869019508361816, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.1470344066619873, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.1825320720672607, Accuracy: 0.611328125\n",
      "Batch: 26, Loss: 1.1956956386566162, Accuracy: 0.60546875\n",
      "Batch: 27, Loss: 1.1983460187911987, Accuracy: 0.6025390625\n",
      "Batch: 28, Loss: 1.090635895729065, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.1006042957305908, Accuracy: 0.626953125\n",
      "Batch: 30, Loss: 1.1901273727416992, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.2421293258666992, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 1.068176507949829, Accuracy: 0.6396484375\n",
      "Batch: 33, Loss: 1.0538121461868286, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.0851998329162598, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 1.1699604988098145, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2571933269500732, Accuracy: 0.578125\n",
      "Batch: 37, Loss: 1.2627198696136475, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.2109427452087402, Accuracy: 0.5927734375\n",
      "Batch: 39, Loss: 1.1222646236419678, Accuracy: 0.6201171875\n",
      "Batch: 40, Loss: 1.1271649599075317, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.189091682434082, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.109825611114502, Accuracy: 0.6318359375\n",
      "Batch: 43, Loss: 1.1112974882125854, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.0670711994171143, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0758616924285889, Accuracy: 0.65625\n",
      "Batch: 46, Loss: 1.1844053268432617, Accuracy: 0.6064453125\n",
      "Batch: 47, Loss: 1.1168829202651978, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.1624314785003662, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.2776762247085571, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.136871099472046, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.2134495973587036, Accuracy: 0.5859375\n",
      "Batch: 52, Loss: 1.2269973754882812, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.2349807024002075, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.1721854209899902, Accuracy: 0.625\n",
      "Batch: 55, Loss: 1.1523456573486328, Accuracy: 0.625\n",
      "Batch: 56, Loss: 1.13510000705719, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.1882753372192383, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.1153546571731567, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.1299524307250977, Accuracy: 0.6357421875\n",
      "Batch: 60, Loss: 1.2780113220214844, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.206498622894287, Accuracy: 0.57421875\n",
      "Batch: 62, Loss: 1.1795811653137207, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.2017842531204224, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.2317880392074585, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.2568862438201904, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.178297758102417, Accuracy: 0.603515625\n",
      "Batch: 67, Loss: 1.195082664489746, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.128063678741455, Accuracy: 0.6552734375\n",
      "Batch: 69, Loss: 1.1814488172531128, Accuracy: 0.6220703125\n",
      "Batch: 70, Loss: 1.244231939315796, Accuracy: 0.5966796875\n",
      "Batch: 71, Loss: 1.1735621690750122, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.22468101978302, Accuracy: 0.60546875\n",
      "Batch: 73, Loss: 1.2045378684997559, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.1270169019699097, Accuracy: 0.62890625\n",
      "Batch: 75, Loss: 1.1006429195404053, Accuracy: 0.6484375\n",
      "Batch: 76, Loss: 1.1183096170425415, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.1002225875854492, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.1094778776168823, Accuracy: 0.6259765625\n",
      "Batch: 79, Loss: 1.1519049406051636, Accuracy: 0.63671875\n",
      "Batch: 80, Loss: 1.1911495923995972, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.176440715789795, Accuracy: 0.6396484375\n",
      "Batch: 82, Loss: 1.1406540870666504, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.231048583984375, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.1653790473937988, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.188464879989624, Accuracy: 0.6298828125\n",
      "Batch: 86, Loss: 1.2184193134307861, Accuracy: 0.6044921875\n",
      "Batch: 87, Loss: 1.2220830917358398, Accuracy: 0.626953125\n",
      "Batch: 88, Loss: 1.2665071487426758, Accuracy: 0.59765625\n",
      "Batch: 89, Loss: 1.2330137491226196, Accuracy: 0.5947265625\n",
      "Batch: 90, Loss: 1.1930019855499268, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.2114078998565674, Accuracy: 0.6005859375\n",
      "Batch: 92, Loss: 1.1920256614685059, Accuracy: 0.6171875\n",
      "Batch: 93, Loss: 1.214301586151123, Accuracy: 0.611328125\n",
      "Batch: 94, Loss: 1.295180320739746, Accuracy: 0.591796875\n",
      "Batch: 95, Loss: 1.1978623867034912, Accuracy: 0.607421875\n",
      "Batch: 96, Loss: 1.2719908952713013, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.2290091514587402, Accuracy: 0.599609375\n",
      "Batch: 98, Loss: 1.1483550071716309, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.159149169921875, Accuracy: 0.6376953125\n",
      "Batch: 100, Loss: 1.0894482135772705, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.13951575756073, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2333933115005493, Accuracy: 0.630859375\n",
      "Batch: 103, Loss: 1.1405839920043945, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.1875076293945312, Accuracy: 0.62109375\n",
      "Batch: 105, Loss: 1.2157635688781738, Accuracy: 0.5986328125\n",
      "Batch: 106, Loss: 1.2423901557922363, Accuracy: 0.5966796875\n",
      "Batch: 107, Loss: 1.2961702346801758, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.2395343780517578, Accuracy: 0.587890625\n",
      "Batch: 109, Loss: 1.22725248336792, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 1.172095537185669, Accuracy: 0.6083984375\n",
      "Batch: 111, Loss: 1.1562925577163696, Accuracy: 0.623046875\n",
      "Batch: 112, Loss: 1.1684491634368896, Accuracy: 0.6201171875\n",
      "Batch: 113, Loss: 1.1512559652328491, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.2322381734848022, Accuracy: 0.5771484375\n",
      "Batch: 115, Loss: 1.269538402557373, Accuracy: 0.5849609375\n",
      "Batch: 116, Loss: 1.2554891109466553, Accuracy: 0.6005859375\n",
      "Batch: 117, Loss: 1.1815745830535889, Accuracy: 0.609375\n",
      "Batch: 118, Loss: 1.2493131160736084, Accuracy: 0.576171875\n",
      "Batch: 119, Loss: 1.2718368768692017, Accuracy: 0.5966796875\n",
      "Batch: 120, Loss: 1.3247652053833008, Accuracy: 0.5888671875\n",
      "Batch: 121, Loss: 1.2555646896362305, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.226535439491272, Accuracy: 0.6064453125\n",
      "Batch: 123, Loss: 1.182785987854004, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2314823865890503, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1734819412231445, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.2744290828704834, Accuracy: 0.599609375\n",
      "Batch: 127, Loss: 1.2625759840011597, Accuracy: 0.58984375\n",
      "Batch: 128, Loss: 1.2732946872711182, Accuracy: 0.587890625\n",
      "Batch: 129, Loss: 1.2760529518127441, Accuracy: 0.599609375\n",
      "Batch: 130, Loss: 1.1725002527236938, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.2318106889724731, Accuracy: 0.5927734375\n",
      "Batch: 132, Loss: 1.0587635040283203, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.2069435119628906, Accuracy: 0.6015625\n",
      "Batch: 134, Loss: 1.123556137084961, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.1003843545913696, Accuracy: 0.6572265625\n",
      "Batch: 136, Loss: 1.0807735919952393, Accuracy: 0.6630859375\n",
      "Batch: 137, Loss: 1.222691297531128, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.2722663879394531, Accuracy: 0.5810546875\n",
      "Batch: 139, Loss: 1.2143945693969727, Accuracy: 0.61328125\n",
      "Batch: 140, Loss: 1.2855792045593262, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.2042267322540283, Accuracy: 0.6005859375\n",
      "Batch: 142, Loss: 1.2170275449752808, Accuracy: 0.5966796875\n",
      "Batch: 143, Loss: 1.3288756608963013, Accuracy: 0.587890625\n",
      "Batch: 144, Loss: 1.3228988647460938, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.3275246620178223, Accuracy: 0.5654296875\n",
      "Batch: 146, Loss: 1.2380661964416504, Accuracy: 0.6025390625\n",
      "Batch: 147, Loss: 1.2403945922851562, Accuracy: 0.611328125\n",
      "Batch: 148, Loss: 1.2428362369537354, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.2045648097991943, Accuracy: 0.6015625\n",
      "Batch: 150, Loss: 1.213720440864563, Accuracy: 0.591796875\n",
      "Batch: 151, Loss: 1.2362308502197266, Accuracy: 0.6162109375\n",
      "Batch: 152, Loss: 1.1624455451965332, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1739814281463623, Accuracy: 0.626953125\n",
      "Batch: 154, Loss: 1.141855239868164, Accuracy: 0.6337890625\n",
      "Batch: 155, Loss: 1.1446962356567383, Accuracy: 0.6435546875\n",
      "Epoch 444/200\n",
      "Batch: 1, Loss: 1.2861833572387695, Accuracy: 0.6142578125\n",
      "Batch: 2, Loss: 1.1054143905639648, Accuracy: 0.6318359375\n",
      "Batch: 3, Loss: 1.0896282196044922, Accuracy: 0.62890625\n",
      "Batch: 4, Loss: 1.0599905252456665, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 1.0147960186004639, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.095517635345459, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.0476628541946411, Accuracy: 0.6552734375\n",
      "Batch: 8, Loss: 0.967403769493103, Accuracy: 0.697265625\n",
      "Batch: 9, Loss: 1.0240139961242676, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 1.0708374977111816, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.0280424356460571, Accuracy: 0.662109375\n",
      "Batch: 12, Loss: 1.0706956386566162, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.079322099685669, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 0.9717954397201538, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9459709525108337, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0782701969146729, Accuracy: 0.65234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17, Loss: 1.1000181436538696, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.19045889377594, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.23505437374115, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.1653600931167603, Accuracy: 0.6259765625\n",
      "Batch: 21, Loss: 1.1362731456756592, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.2295520305633545, Accuracy: 0.603515625\n",
      "Batch: 23, Loss: 1.2961475849151611, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.19535493850708, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.1852648258209229, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.2223939895629883, Accuracy: 0.6005859375\n",
      "Batch: 27, Loss: 1.1277697086334229, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.0896320343017578, Accuracy: 0.625\n",
      "Batch: 29, Loss: 1.114258050918579, Accuracy: 0.638671875\n",
      "Batch: 30, Loss: 1.1570425033569336, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.2056407928466797, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0650181770324707, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.0456215143203735, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.0909903049468994, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1489388942718506, Accuracy: 0.6044921875\n",
      "Batch: 36, Loss: 1.2104072570800781, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.2230720520019531, Accuracy: 0.5966796875\n",
      "Batch: 38, Loss: 1.2033454179763794, Accuracy: 0.6044921875\n",
      "Batch: 39, Loss: 1.12444269657135, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.168982982635498, Accuracy: 0.6162109375\n",
      "Batch: 41, Loss: 1.1921155452728271, Accuracy: 0.6083984375\n",
      "Batch: 42, Loss: 1.1046621799468994, Accuracy: 0.640625\n",
      "Batch: 43, Loss: 1.1159822940826416, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.1159065961837769, Accuracy: 0.6259765625\n",
      "Batch: 45, Loss: 1.133041262626648, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.1293587684631348, Accuracy: 0.6171875\n",
      "Batch: 47, Loss: 1.1222589015960693, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.1583657264709473, Accuracy: 0.623046875\n",
      "Batch: 49, Loss: 1.2713184356689453, Accuracy: 0.578125\n",
      "Batch: 50, Loss: 1.1825839281082153, Accuracy: 0.5986328125\n",
      "Batch: 51, Loss: 1.1695868968963623, Accuracy: 0.6318359375\n",
      "Batch: 52, Loss: 1.2870808839797974, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.2242443561553955, Accuracy: 0.58984375\n",
      "Batch: 54, Loss: 1.2317774295806885, Accuracy: 0.6044921875\n",
      "Batch: 55, Loss: 1.1209958791732788, Accuracy: 0.642578125\n",
      "Batch: 56, Loss: 1.1465603113174438, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.10966157913208, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.138211727142334, Accuracy: 0.6337890625\n",
      "Batch: 59, Loss: 1.1634175777435303, Accuracy: 0.611328125\n",
      "Batch: 60, Loss: 1.2756423950195312, Accuracy: 0.5712890625\n",
      "Batch: 61, Loss: 1.2239385843276978, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1607964038848877, Accuracy: 0.6259765625\n",
      "Batch: 63, Loss: 1.1703863143920898, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.27490234375, Accuracy: 0.5556640625\n",
      "Batch: 65, Loss: 1.2322056293487549, Accuracy: 0.58984375\n",
      "Batch: 66, Loss: 1.1700767278671265, Accuracy: 0.6201171875\n",
      "Batch: 67, Loss: 1.148521065711975, Accuracy: 0.6318359375\n",
      "Batch: 68, Loss: 1.1565577983856201, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.2579920291900635, Accuracy: 0.5830078125\n",
      "Batch: 70, Loss: 1.2485613822937012, Accuracy: 0.603515625\n",
      "Batch: 71, Loss: 1.2316499948501587, Accuracy: 0.5966796875\n",
      "Batch: 72, Loss: 1.2698469161987305, Accuracy: 0.6015625\n",
      "Batch: 73, Loss: 1.184420108795166, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.1745586395263672, Accuracy: 0.6318359375\n",
      "Batch: 75, Loss: 1.1388797760009766, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.1267285346984863, Accuracy: 0.623046875\n",
      "Batch: 77, Loss: 1.1381694078445435, Accuracy: 0.6259765625\n",
      "Batch: 78, Loss: 1.0775599479675293, Accuracy: 0.6552734375\n",
      "Batch: 79, Loss: 1.1827101707458496, Accuracy: 0.61328125\n",
      "Batch: 80, Loss: 1.1760233640670776, Accuracy: 0.6103515625\n",
      "Batch: 81, Loss: 1.1685872077941895, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1731412410736084, Accuracy: 0.6162109375\n",
      "Batch: 83, Loss: 1.2689036130905151, Accuracy: 0.591796875\n",
      "Batch: 84, Loss: 1.1590709686279297, Accuracy: 0.611328125\n",
      "Batch: 85, Loss: 1.2065410614013672, Accuracy: 0.615234375\n",
      "Batch: 86, Loss: 1.247602939605713, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.2141194343566895, Accuracy: 0.615234375\n",
      "Batch: 88, Loss: 1.2076843976974487, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1746199131011963, Accuracy: 0.6328125\n",
      "Batch: 90, Loss: 1.1866223812103271, Accuracy: 0.6142578125\n",
      "Batch: 91, Loss: 1.2020714282989502, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.1771211624145508, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.18806791305542, Accuracy: 0.6103515625\n",
      "Batch: 94, Loss: 1.2319536209106445, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.211014986038208, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.2830878496170044, Accuracy: 0.5986328125\n",
      "Batch: 97, Loss: 1.2369213104248047, Accuracy: 0.6162109375\n",
      "Batch: 98, Loss: 1.1132159233093262, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.1741358041763306, Accuracy: 0.6171875\n",
      "Batch: 100, Loss: 1.0927245616912842, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.1385347843170166, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.2205865383148193, Accuracy: 0.6123046875\n",
      "Batch: 103, Loss: 1.209061861038208, Accuracy: 0.607421875\n",
      "Batch: 104, Loss: 1.151961326599121, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.3115233182907104, Accuracy: 0.58984375\n",
      "Batch: 106, Loss: 1.2099705934524536, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.2872482538223267, Accuracy: 0.587890625\n",
      "Batch: 108, Loss: 1.1633236408233643, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.265911340713501, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.1681665182113647, Accuracy: 0.6279296875\n",
      "Batch: 111, Loss: 1.1864755153656006, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.0996490716934204, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.1558427810668945, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.1873911619186401, Accuracy: 0.5966796875\n",
      "Batch: 115, Loss: 1.236506700515747, Accuracy: 0.59765625\n",
      "Batch: 116, Loss: 1.2201206684112549, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.2216874361038208, Accuracy: 0.5947265625\n",
      "Batch: 118, Loss: 1.2109726667404175, Accuracy: 0.6044921875\n",
      "Batch: 119, Loss: 1.286301851272583, Accuracy: 0.5927734375\n",
      "Batch: 120, Loss: 1.2670724391937256, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.2136200666427612, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.2295496463775635, Accuracy: 0.615234375\n",
      "Batch: 123, Loss: 1.1733942031860352, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2989147901535034, Accuracy: 0.5732421875\n",
      "Batch: 125, Loss: 1.238527774810791, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.233047366142273, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.2953546047210693, Accuracy: 0.578125\n",
      "Batch: 128, Loss: 1.237797737121582, Accuracy: 0.603515625\n",
      "Batch: 129, Loss: 1.228905439376831, Accuracy: 0.603515625\n",
      "Batch: 130, Loss: 1.192351222038269, Accuracy: 0.60546875\n",
      "Batch: 131, Loss: 1.2060147523880005, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.1068602800369263, Accuracy: 0.6494140625\n",
      "Batch: 133, Loss: 1.1664762496948242, Accuracy: 0.6201171875\n",
      "Batch: 134, Loss: 1.0855786800384521, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.0662775039672852, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.0992045402526855, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.193993330001831, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.2971118688583374, Accuracy: 0.578125\n",
      "Batch: 139, Loss: 1.187710165977478, Accuracy: 0.6103515625\n",
      "Batch: 140, Loss: 1.2547104358673096, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.26710045337677, Accuracy: 0.6142578125\n",
      "Batch: 142, Loss: 1.219472885131836, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2463643550872803, Accuracy: 0.603515625\n",
      "Batch: 144, Loss: 1.2321186065673828, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2965705394744873, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.1717586517333984, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.2667148113250732, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.2512154579162598, Accuracy: 0.5927734375\n",
      "Batch: 149, Loss: 1.1658052206039429, Accuracy: 0.626953125\n",
      "Batch: 150, Loss: 1.2096058130264282, Accuracy: 0.5947265625\n",
      "Batch: 151, Loss: 1.177299976348877, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.2373743057250977, Accuracy: 0.578125\n",
      "Batch: 153, Loss: 1.1091983318328857, Accuracy: 0.6328125\n",
      "Batch: 154, Loss: 1.1234512329101562, Accuracy: 0.623046875\n",
      "Batch: 155, Loss: 1.1762220859527588, Accuracy: 0.6240234375\n",
      "Epoch 445/200\n",
      "Batch: 1, Loss: 1.2622179985046387, Accuracy: 0.6357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 1.0533382892608643, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 1.0692038536071777, Accuracy: 0.6474609375\n",
      "Batch: 4, Loss: 1.1431090831756592, Accuracy: 0.6416015625\n",
      "Batch: 5, Loss: 1.0424222946166992, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.0564138889312744, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 1.0107694864273071, Accuracy: 0.6689453125\n",
      "Batch: 8, Loss: 1.0280998945236206, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 1.048463225364685, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 1.0777992010116577, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.0037511587142944, Accuracy: 0.6630859375\n",
      "Batch: 12, Loss: 1.0553703308105469, Accuracy: 0.6435546875\n",
      "Batch: 13, Loss: 1.0585918426513672, Accuracy: 0.6435546875\n",
      "Batch: 14, Loss: 0.9792290925979614, Accuracy: 0.6962890625\n",
      "Batch: 15, Loss: 1.0227899551391602, Accuracy: 0.66015625\n",
      "Batch: 16, Loss: 1.0978929996490479, Accuracy: 0.630859375\n",
      "Batch: 17, Loss: 1.0943405628204346, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.140466332435608, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.238844394683838, Accuracy: 0.5947265625\n",
      "Batch: 20, Loss: 1.1628166437149048, Accuracy: 0.6181640625\n",
      "Batch: 21, Loss: 1.1118781566619873, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.2353670597076416, Accuracy: 0.6015625\n",
      "Batch: 23, Loss: 1.2818920612335205, Accuracy: 0.5869140625\n",
      "Batch: 24, Loss: 1.182525396347046, Accuracy: 0.62109375\n",
      "Batch: 25, Loss: 1.1698169708251953, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.2185921669006348, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.1629045009613037, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.0673503875732422, Accuracy: 0.6376953125\n",
      "Batch: 29, Loss: 1.0872752666473389, Accuracy: 0.6279296875\n",
      "Batch: 30, Loss: 1.20857834815979, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.2838237285614014, Accuracy: 0.5771484375\n",
      "Batch: 32, Loss: 1.0730564594268799, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.0495586395263672, Accuracy: 0.6474609375\n",
      "Batch: 34, Loss: 1.1687673330307007, Accuracy: 0.6279296875\n",
      "Batch: 35, Loss: 1.1156930923461914, Accuracy: 0.6181640625\n",
      "Batch: 36, Loss: 1.2477322816848755, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.2380608320236206, Accuracy: 0.587890625\n",
      "Batch: 38, Loss: 1.1737029552459717, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.115335464477539, Accuracy: 0.6357421875\n",
      "Batch: 40, Loss: 1.0784177780151367, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1873409748077393, Accuracy: 0.59375\n",
      "Batch: 42, Loss: 1.087183952331543, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.1268560886383057, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.1072168350219727, Accuracy: 0.6162109375\n",
      "Batch: 45, Loss: 1.0548369884490967, Accuracy: 0.650390625\n",
      "Batch: 46, Loss: 1.1619802713394165, Accuracy: 0.6337890625\n",
      "Batch: 47, Loss: 1.0893597602844238, Accuracy: 0.66015625\n",
      "Batch: 48, Loss: 1.2025095224380493, Accuracy: 0.5947265625\n",
      "Batch: 49, Loss: 1.252451777458191, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.140868902206421, Accuracy: 0.619140625\n",
      "Batch: 51, Loss: 1.1546690464019775, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.2628190517425537, Accuracy: 0.5869140625\n",
      "Batch: 53, Loss: 1.226222038269043, Accuracy: 0.5927734375\n",
      "Batch: 54, Loss: 1.191070318222046, Accuracy: 0.59765625\n",
      "Batch: 55, Loss: 1.1985384225845337, Accuracy: 0.615234375\n",
      "Batch: 56, Loss: 1.0964031219482422, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.1114225387573242, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.1833391189575195, Accuracy: 0.615234375\n",
      "Batch: 59, Loss: 1.1758606433868408, Accuracy: 0.626953125\n",
      "Batch: 60, Loss: 1.249659538269043, Accuracy: 0.5859375\n",
      "Batch: 61, Loss: 1.185105800628662, Accuracy: 0.6025390625\n",
      "Batch: 62, Loss: 1.2377852201461792, Accuracy: 0.599609375\n",
      "Batch: 63, Loss: 1.198899269104004, Accuracy: 0.5947265625\n",
      "Batch: 64, Loss: 1.2452300786972046, Accuracy: 0.5869140625\n",
      "Batch: 65, Loss: 1.2845344543457031, Accuracy: 0.5712890625\n",
      "Batch: 66, Loss: 1.1825227737426758, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.1733789443969727, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.1373753547668457, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.1824133396148682, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.2085349559783936, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.2255792617797852, Accuracy: 0.6064453125\n",
      "Batch: 72, Loss: 1.22602117061615, Accuracy: 0.576171875\n",
      "Batch: 73, Loss: 1.2404102087020874, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.1620168685913086, Accuracy: 0.615234375\n",
      "Batch: 75, Loss: 1.0417132377624512, Accuracy: 0.65234375\n",
      "Batch: 76, Loss: 1.0977346897125244, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.080206036567688, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.1470164060592651, Accuracy: 0.62109375\n",
      "Batch: 79, Loss: 1.1576859951019287, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.2149615287780762, Accuracy: 0.6015625\n",
      "Batch: 81, Loss: 1.1661568880081177, Accuracy: 0.62890625\n",
      "Batch: 82, Loss: 1.2531328201293945, Accuracy: 0.5947265625\n",
      "Batch: 83, Loss: 1.221100091934204, Accuracy: 0.62109375\n",
      "Batch: 84, Loss: 1.1791293621063232, Accuracy: 0.626953125\n",
      "Batch: 85, Loss: 1.241851568222046, Accuracy: 0.6083984375\n",
      "Batch: 86, Loss: 1.1777207851409912, Accuracy: 0.625\n",
      "Batch: 87, Loss: 1.1576104164123535, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.2256014347076416, Accuracy: 0.591796875\n",
      "Batch: 89, Loss: 1.169938564300537, Accuracy: 0.626953125\n",
      "Batch: 90, Loss: 1.1742594242095947, Accuracy: 0.603515625\n",
      "Batch: 91, Loss: 1.210092306137085, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.18276047706604, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.1685740947723389, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.2450374364852905, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.271923303604126, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.2899839878082275, Accuracy: 0.6142578125\n",
      "Batch: 97, Loss: 1.2189736366271973, Accuracy: 0.595703125\n",
      "Batch: 98, Loss: 1.1219780445098877, Accuracy: 0.650390625\n",
      "Batch: 99, Loss: 1.1664143800735474, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.0994977951049805, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.1161385774612427, Accuracy: 0.65625\n",
      "Batch: 102, Loss: 1.205884337425232, Accuracy: 0.60546875\n",
      "Batch: 103, Loss: 1.170470952987671, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.211404800415039, Accuracy: 0.59765625\n",
      "Batch: 105, Loss: 1.2367305755615234, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.2258179187774658, Accuracy: 0.60546875\n",
      "Batch: 107, Loss: 1.2266075611114502, Accuracy: 0.5830078125\n",
      "Batch: 108, Loss: 1.1456077098846436, Accuracy: 0.6064453125\n",
      "Batch: 109, Loss: 1.2670347690582275, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.2178008556365967, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1534113883972168, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0794790983200073, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.1918935775756836, Accuracy: 0.6103515625\n",
      "Batch: 114, Loss: 1.2018531560897827, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.2044832706451416, Accuracy: 0.59765625\n",
      "Batch: 116, Loss: 1.1867924928665161, Accuracy: 0.6142578125\n",
      "Batch: 117, Loss: 1.2027733325958252, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.1895098686218262, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.2977328300476074, Accuracy: 0.5859375\n",
      "Batch: 120, Loss: 1.303246259689331, Accuracy: 0.5771484375\n",
      "Batch: 121, Loss: 1.1915464401245117, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.2572903633117676, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.183258295059204, Accuracy: 0.62890625\n",
      "Batch: 124, Loss: 1.2480300664901733, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.1784049272537231, Accuracy: 0.6181640625\n",
      "Batch: 126, Loss: 1.285848617553711, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.3114430904388428, Accuracy: 0.5859375\n",
      "Batch: 128, Loss: 1.27285635471344, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.2382361888885498, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.1264936923980713, Accuracy: 0.62109375\n",
      "Batch: 131, Loss: 1.2319543361663818, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.1034934520721436, Accuracy: 0.6298828125\n",
      "Batch: 133, Loss: 1.1904327869415283, Accuracy: 0.626953125\n",
      "Batch: 134, Loss: 1.2272857427597046, Accuracy: 0.626953125\n",
      "Batch: 135, Loss: 1.1176687479019165, Accuracy: 0.630859375\n",
      "Batch: 136, Loss: 1.1045888662338257, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 1.2070529460906982, Accuracy: 0.611328125\n",
      "Batch: 138, Loss: 1.2940702438354492, Accuracy: 0.5751953125\n",
      "Batch: 139, Loss: 1.2238283157348633, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.2369275093078613, Accuracy: 0.6171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 1.2195035219192505, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.2444965839385986, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.2361657619476318, Accuracy: 0.6083984375\n",
      "Batch: 144, Loss: 1.346710205078125, Accuracy: 0.578125\n",
      "Batch: 145, Loss: 1.3348644971847534, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.2686002254486084, Accuracy: 0.5849609375\n",
      "Batch: 147, Loss: 1.2308799028396606, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.245152473449707, Accuracy: 0.61328125\n",
      "Batch: 149, Loss: 1.1839896440505981, Accuracy: 0.609375\n",
      "Batch: 150, Loss: 1.2150198221206665, Accuracy: 0.6083984375\n",
      "Batch: 151, Loss: 1.2027335166931152, Accuracy: 0.6123046875\n",
      "Batch: 152, Loss: 1.1841259002685547, Accuracy: 0.611328125\n",
      "Batch: 153, Loss: 1.1607439517974854, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.1222400665283203, Accuracy: 0.6611328125\n",
      "Batch: 155, Loss: 1.102267861366272, Accuracy: 0.62890625\n",
      "Epoch 446/200\n",
      "Batch: 1, Loss: 1.26523756980896, Accuracy: 0.6103515625\n",
      "Batch: 2, Loss: 1.1065144538879395, Accuracy: 0.6376953125\n",
      "Batch: 3, Loss: 1.0971152782440186, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.085625171661377, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 1.0315611362457275, Accuracy: 0.6650390625\n",
      "Batch: 6, Loss: 1.0320820808410645, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.040086269378662, Accuracy: 0.6484375\n",
      "Batch: 8, Loss: 1.0134339332580566, Accuracy: 0.671875\n",
      "Batch: 9, Loss: 1.021268606185913, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 1.0205274820327759, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 0.9739113450050354, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 0.9929801225662231, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 1.0783445835113525, Accuracy: 0.6435546875\n",
      "Batch: 14, Loss: 1.0443158149719238, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.9701555967330933, Accuracy: 0.6845703125\n",
      "Batch: 16, Loss: 1.052293300628662, Accuracy: 0.6669921875\n",
      "Batch: 17, Loss: 1.0969223976135254, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.1386783123016357, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.2209529876708984, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.1204349994659424, Accuracy: 0.63671875\n",
      "Batch: 21, Loss: 1.1185553073883057, Accuracy: 0.6318359375\n",
      "Batch: 22, Loss: 1.2227809429168701, Accuracy: 0.5869140625\n",
      "Batch: 23, Loss: 1.2690720558166504, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.1220073699951172, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.175581932067871, Accuracy: 0.625\n",
      "Batch: 26, Loss: 1.2160139083862305, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.1916723251342773, Accuracy: 0.6083984375\n",
      "Batch: 28, Loss: 1.0848207473754883, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.049525499343872, Accuracy: 0.662109375\n",
      "Batch: 30, Loss: 1.1538269519805908, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.2430568933486938, Accuracy: 0.5859375\n",
      "Batch: 32, Loss: 1.0263320207595825, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 1.0299251079559326, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1150200366973877, Accuracy: 0.63671875\n",
      "Batch: 35, Loss: 1.1849408149719238, Accuracy: 0.6015625\n",
      "Batch: 36, Loss: 1.2275547981262207, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.2843414545059204, Accuracy: 0.580078125\n",
      "Batch: 38, Loss: 1.1823952198028564, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.1498887538909912, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.140183687210083, Accuracy: 0.6240234375\n",
      "Batch: 41, Loss: 1.1783239841461182, Accuracy: 0.62109375\n",
      "Batch: 42, Loss: 1.1100873947143555, Accuracy: 0.6337890625\n",
      "Batch: 43, Loss: 1.1254615783691406, Accuracy: 0.615234375\n",
      "Batch: 44, Loss: 1.0895991325378418, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0622304677963257, Accuracy: 0.658203125\n",
      "Batch: 46, Loss: 1.187535047531128, Accuracy: 0.603515625\n",
      "Batch: 47, Loss: 1.1461292505264282, Accuracy: 0.6279296875\n",
      "Batch: 48, Loss: 1.1859970092773438, Accuracy: 0.6025390625\n",
      "Batch: 49, Loss: 1.1987500190734863, Accuracy: 0.60546875\n",
      "Batch: 50, Loss: 1.13348388671875, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.2091858386993408, Accuracy: 0.6103515625\n",
      "Batch: 52, Loss: 1.3162117004394531, Accuracy: 0.5849609375\n",
      "Batch: 53, Loss: 1.1747777462005615, Accuracy: 0.6103515625\n",
      "Batch: 54, Loss: 1.2111886739730835, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.1890090703964233, Accuracy: 0.6318359375\n",
      "Batch: 56, Loss: 1.1589444875717163, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.1475465297698975, Accuracy: 0.61328125\n",
      "Batch: 58, Loss: 1.1543946266174316, Accuracy: 0.6279296875\n",
      "Batch: 59, Loss: 1.164707899093628, Accuracy: 0.619140625\n",
      "Batch: 60, Loss: 1.2977895736694336, Accuracy: 0.5927734375\n",
      "Batch: 61, Loss: 1.2388298511505127, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.191127061843872, Accuracy: 0.6103515625\n",
      "Batch: 63, Loss: 1.181199550628662, Accuracy: 0.578125\n",
      "Batch: 64, Loss: 1.205663800239563, Accuracy: 0.595703125\n",
      "Batch: 65, Loss: 1.2125388383865356, Accuracy: 0.6162109375\n",
      "Batch: 66, Loss: 1.1961479187011719, Accuracy: 0.6123046875\n",
      "Batch: 67, Loss: 1.19606351852417, Accuracy: 0.6005859375\n",
      "Batch: 68, Loss: 1.1374247074127197, Accuracy: 0.6513671875\n",
      "Batch: 69, Loss: 1.2283703088760376, Accuracy: 0.60546875\n",
      "Batch: 70, Loss: 1.1759791374206543, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.189361572265625, Accuracy: 0.6103515625\n",
      "Batch: 72, Loss: 1.2678418159484863, Accuracy: 0.5908203125\n",
      "Batch: 73, Loss: 1.202509880065918, Accuracy: 0.6044921875\n",
      "Batch: 74, Loss: 1.1516053676605225, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.150223731994629, Accuracy: 0.6123046875\n",
      "Batch: 76, Loss: 1.1179099082946777, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 1.0800821781158447, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.1669894456863403, Accuracy: 0.6220703125\n",
      "Batch: 79, Loss: 1.2284297943115234, Accuracy: 0.6201171875\n",
      "Batch: 80, Loss: 1.214911937713623, Accuracy: 0.6171875\n",
      "Batch: 81, Loss: 1.147959589958191, Accuracy: 0.6181640625\n",
      "Batch: 82, Loss: 1.177886962890625, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 1.2440446615219116, Accuracy: 0.5927734375\n",
      "Batch: 84, Loss: 1.1511297225952148, Accuracy: 0.6201171875\n",
      "Batch: 85, Loss: 1.2060359716415405, Accuracy: 0.611328125\n",
      "Batch: 86, Loss: 1.1683731079101562, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.231940507888794, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1870343685150146, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.2387678623199463, Accuracy: 0.6025390625\n",
      "Batch: 90, Loss: 1.1577649116516113, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1550955772399902, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.1781576871871948, Accuracy: 0.6083984375\n",
      "Batch: 93, Loss: 1.215498447418213, Accuracy: 0.5986328125\n",
      "Batch: 94, Loss: 1.2296823263168335, Accuracy: 0.5966796875\n",
      "Batch: 95, Loss: 1.238750696182251, Accuracy: 0.59375\n",
      "Batch: 96, Loss: 1.2507400512695312, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.2357959747314453, Accuracy: 0.5947265625\n",
      "Batch: 98, Loss: 1.142383337020874, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.1591399908065796, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.1197457313537598, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.1429991722106934, Accuracy: 0.6279296875\n",
      "Batch: 102, Loss: 1.1913022994995117, Accuracy: 0.599609375\n",
      "Batch: 103, Loss: 1.1629306077957153, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.1963342428207397, Accuracy: 0.607421875\n",
      "Batch: 105, Loss: 1.303910732269287, Accuracy: 0.587890625\n",
      "Batch: 106, Loss: 1.2059168815612793, Accuracy: 0.623046875\n",
      "Batch: 107, Loss: 1.2675609588623047, Accuracy: 0.5869140625\n",
      "Batch: 108, Loss: 1.2051867246627808, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.2501718997955322, Accuracy: 0.5791015625\n",
      "Batch: 110, Loss: 1.1725726127624512, Accuracy: 0.62109375\n",
      "Batch: 111, Loss: 1.1733719110488892, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.1348401308059692, Accuracy: 0.6220703125\n",
      "Batch: 113, Loss: 1.200688362121582, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.2140647172927856, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.2395174503326416, Accuracy: 0.583984375\n",
      "Batch: 116, Loss: 1.1712590456008911, Accuracy: 0.6259765625\n",
      "Batch: 117, Loss: 1.1662434339523315, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.2538702487945557, Accuracy: 0.60546875\n",
      "Batch: 119, Loss: 1.254042625427246, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.2621707916259766, Accuracy: 0.6025390625\n",
      "Batch: 121, Loss: 1.2851344347000122, Accuracy: 0.5830078125\n",
      "Batch: 122, Loss: 1.2290277481079102, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.1959424018859863, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.257497787475586, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.248079776763916, Accuracy: 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 126, Loss: 1.2520220279693604, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.278334140777588, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.1974095106124878, Accuracy: 0.5947265625\n",
      "Batch: 129, Loss: 1.2154395580291748, Accuracy: 0.607421875\n",
      "Batch: 130, Loss: 1.1810625791549683, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.228832721710205, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.0889414548873901, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.2234994173049927, Accuracy: 0.611328125\n",
      "Batch: 134, Loss: 1.1269662380218506, Accuracy: 0.634765625\n",
      "Batch: 135, Loss: 1.0670404434204102, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.1911630630493164, Accuracy: 0.6259765625\n",
      "Batch: 137, Loss: 1.2014782428741455, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.2762441635131836, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.185901403427124, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.2696446180343628, Accuracy: 0.595703125\n",
      "Batch: 141, Loss: 1.261415958404541, Accuracy: 0.59765625\n",
      "Batch: 142, Loss: 1.1659892797470093, Accuracy: 0.62109375\n",
      "Batch: 143, Loss: 1.2527282238006592, Accuracy: 0.6025390625\n",
      "Batch: 144, Loss: 1.2809730768203735, Accuracy: 0.6005859375\n",
      "Batch: 145, Loss: 1.3226916790008545, Accuracy: 0.5791015625\n",
      "Batch: 146, Loss: 1.226844310760498, Accuracy: 0.5888671875\n",
      "Batch: 147, Loss: 1.2573623657226562, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.2163949012756348, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.1900862455368042, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.2142250537872314, Accuracy: 0.61328125\n",
      "Batch: 151, Loss: 1.160512924194336, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.1874102354049683, Accuracy: 0.599609375\n",
      "Batch: 153, Loss: 1.1557214260101318, Accuracy: 0.6171875\n",
      "Batch: 154, Loss: 1.1198395490646362, Accuracy: 0.6357421875\n",
      "Batch: 155, Loss: 1.1343705654144287, Accuracy: 0.6279296875\n",
      "Epoch 447/200\n",
      "Batch: 1, Loss: 1.2570786476135254, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.0950720310211182, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 1.055820345878601, Accuracy: 0.64453125\n",
      "Batch: 4, Loss: 1.1777842044830322, Accuracy: 0.615234375\n",
      "Batch: 5, Loss: 0.9840405583381653, Accuracy: 0.677734375\n",
      "Batch: 6, Loss: 1.0800890922546387, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.0778075456619263, Accuracy: 0.638671875\n",
      "Batch: 8, Loss: 0.9922482967376709, Accuracy: 0.6796875\n",
      "Batch: 9, Loss: 1.0472018718719482, Accuracy: 0.6474609375\n",
      "Batch: 10, Loss: 0.9955337047576904, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 0.9944416880607605, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 1.0531179904937744, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 1.0661509037017822, Accuracy: 0.6474609375\n",
      "Batch: 14, Loss: 1.0134034156799316, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.9794970750808716, Accuracy: 0.66796875\n",
      "Batch: 16, Loss: 1.0619274377822876, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.1256047487258911, Accuracy: 0.626953125\n",
      "Batch: 18, Loss: 1.213289737701416, Accuracy: 0.6181640625\n",
      "Batch: 19, Loss: 1.2479150295257568, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.132612943649292, Accuracy: 0.646484375\n",
      "Batch: 21, Loss: 1.0837407112121582, Accuracy: 0.64453125\n",
      "Batch: 22, Loss: 1.2389440536499023, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2786463499069214, Accuracy: 0.5859375\n",
      "Batch: 24, Loss: 1.111466646194458, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1477470397949219, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.2103849649429321, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.157928466796875, Accuracy: 0.6259765625\n",
      "Batch: 28, Loss: 1.0567646026611328, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 1.089377522468567, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1987340450286865, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.202211856842041, Accuracy: 0.609375\n",
      "Batch: 32, Loss: 1.075782060623169, Accuracy: 0.6591796875\n",
      "Batch: 33, Loss: 1.0093430280685425, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.1307387351989746, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1548705101013184, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.164308786392212, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.1996819972991943, Accuracy: 0.6005859375\n",
      "Batch: 38, Loss: 1.2143211364746094, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.1408087015151978, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.1402995586395264, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.2035785913467407, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0856115818023682, Accuracy: 0.6181640625\n",
      "Batch: 43, Loss: 1.0919097661972046, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.0760633945465088, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.1305843591690063, Accuracy: 0.62109375\n",
      "Batch: 46, Loss: 1.1574105024337769, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.097057819366455, Accuracy: 0.66796875\n",
      "Batch: 48, Loss: 1.163191318511963, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.189772367477417, Accuracy: 0.623046875\n",
      "Batch: 50, Loss: 1.1575875282287598, Accuracy: 0.615234375\n",
      "Batch: 51, Loss: 1.2095986604690552, Accuracy: 0.5947265625\n",
      "Batch: 52, Loss: 1.2870712280273438, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.2155081033706665, Accuracy: 0.6015625\n",
      "Batch: 54, Loss: 1.2560920715332031, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.1733739376068115, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.1736500263214111, Accuracy: 0.6171875\n",
      "Batch: 57, Loss: 1.144891381263733, Accuracy: 0.6416015625\n",
      "Batch: 58, Loss: 1.1202287673950195, Accuracy: 0.6279296875\n",
      "Batch: 59, Loss: 1.162036418914795, Accuracy: 0.62890625\n",
      "Batch: 60, Loss: 1.2816791534423828, Accuracy: 0.5849609375\n",
      "Batch: 61, Loss: 1.2332885265350342, Accuracy: 0.595703125\n",
      "Batch: 62, Loss: 1.138399600982666, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.0885790586471558, Accuracy: 0.63671875\n",
      "Batch: 64, Loss: 1.2530303001403809, Accuracy: 0.5888671875\n",
      "Batch: 65, Loss: 1.2747007608413696, Accuracy: 0.5791015625\n",
      "Batch: 66, Loss: 1.2292053699493408, Accuracy: 0.6181640625\n",
      "Batch: 67, Loss: 1.209664225578308, Accuracy: 0.603515625\n",
      "Batch: 68, Loss: 1.1272001266479492, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.2274174690246582, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.207491159439087, Accuracy: 0.6103515625\n",
      "Batch: 71, Loss: 1.1857866048812866, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.303787350654602, Accuracy: 0.5849609375\n",
      "Batch: 73, Loss: 1.1890947818756104, Accuracy: 0.603515625\n",
      "Batch: 74, Loss: 1.1249134540557861, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.1278553009033203, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.0668611526489258, Accuracy: 0.6591796875\n",
      "Batch: 77, Loss: 1.1124985218048096, Accuracy: 0.6357421875\n",
      "Batch: 78, Loss: 1.110364556312561, Accuracy: 0.62890625\n",
      "Batch: 79, Loss: 1.129345178604126, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.2052950859069824, Accuracy: 0.6044921875\n",
      "Batch: 81, Loss: 1.1657150983810425, Accuracy: 0.626953125\n",
      "Batch: 82, Loss: 1.1492830514907837, Accuracy: 0.62109375\n",
      "Batch: 83, Loss: 1.2194817066192627, Accuracy: 0.5927734375\n",
      "Batch: 84, Loss: 1.1430304050445557, Accuracy: 0.6181640625\n",
      "Batch: 85, Loss: 1.2091823816299438, Accuracy: 0.5966796875\n",
      "Batch: 86, Loss: 1.1578071117401123, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.2466082572937012, Accuracy: 0.59375\n",
      "Batch: 88, Loss: 1.2304857969284058, Accuracy: 0.6142578125\n",
      "Batch: 89, Loss: 1.143966794013977, Accuracy: 0.646484375\n",
      "Batch: 90, Loss: 1.201900839805603, Accuracy: 0.615234375\n",
      "Batch: 91, Loss: 1.1306812763214111, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1817872524261475, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.2204458713531494, Accuracy: 0.595703125\n",
      "Batch: 94, Loss: 1.251246452331543, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.243227243423462, Accuracy: 0.6171875\n",
      "Batch: 96, Loss: 1.2694988250732422, Accuracy: 0.59375\n",
      "Batch: 97, Loss: 1.2488445043563843, Accuracy: 0.6064453125\n",
      "Batch: 98, Loss: 1.2181081771850586, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.1726194620132446, Accuracy: 0.6171875\n",
      "Batch: 100, Loss: 1.0897266864776611, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.1264301538467407, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.2161754369735718, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.1954782009124756, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.1928305625915527, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.3331727981567383, Accuracy: 0.6083984375\n",
      "Batch: 106, Loss: 1.2398598194122314, Accuracy: 0.6005859375\n",
      "Batch: 107, Loss: 1.2408010959625244, Accuracy: 0.578125\n",
      "Batch: 108, Loss: 1.2719109058380127, Accuracy: 0.583984375\n",
      "Batch: 109, Loss: 1.1973611116409302, Accuracy: 0.5966796875\n",
      "Batch: 110, Loss: 1.171331524848938, Accuracy: 0.61328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 1.1745599508285522, Accuracy: 0.619140625\n",
      "Batch: 112, Loss: 1.1866796016693115, Accuracy: 0.6103515625\n",
      "Batch: 113, Loss: 1.1904053688049316, Accuracy: 0.6171875\n",
      "Batch: 114, Loss: 1.158707618713379, Accuracy: 0.6142578125\n",
      "Batch: 115, Loss: 1.2293874025344849, Accuracy: 0.587890625\n",
      "Batch: 116, Loss: 1.2203843593597412, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.1730380058288574, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.2259770631790161, Accuracy: 0.5888671875\n",
      "Batch: 119, Loss: 1.29356050491333, Accuracy: 0.5947265625\n",
      "Batch: 120, Loss: 1.3271477222442627, Accuracy: 0.58203125\n",
      "Batch: 121, Loss: 1.2372701168060303, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.280645489692688, Accuracy: 0.5810546875\n",
      "Batch: 123, Loss: 1.1879903078079224, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.2783203125, Accuracy: 0.5859375\n",
      "Batch: 125, Loss: 1.2179207801818848, Accuracy: 0.6064453125\n",
      "Batch: 126, Loss: 1.32972252368927, Accuracy: 0.58203125\n",
      "Batch: 127, Loss: 1.2437255382537842, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.280691385269165, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.1742727756500244, Accuracy: 0.6484375\n",
      "Batch: 130, Loss: 1.1902456283569336, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.2149523496627808, Accuracy: 0.607421875\n",
      "Batch: 132, Loss: 1.1529085636138916, Accuracy: 0.619140625\n",
      "Batch: 133, Loss: 1.1608006954193115, Accuracy: 0.640625\n",
      "Batch: 134, Loss: 1.2004454135894775, Accuracy: 0.62109375\n",
      "Batch: 135, Loss: 1.0816452503204346, Accuracy: 0.634765625\n",
      "Batch: 136, Loss: 1.1154053211212158, Accuracy: 0.6376953125\n",
      "Batch: 137, Loss: 1.1988153457641602, Accuracy: 0.6103515625\n",
      "Batch: 138, Loss: 1.251098871231079, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.2008681297302246, Accuracy: 0.611328125\n",
      "Batch: 140, Loss: 1.3840925693511963, Accuracy: 0.5439453125\n",
      "Batch: 141, Loss: 1.2014285326004028, Accuracy: 0.6025390625\n",
      "Batch: 142, Loss: 1.19626784324646, Accuracy: 0.611328125\n",
      "Batch: 143, Loss: 1.2537283897399902, Accuracy: 0.583984375\n",
      "Batch: 144, Loss: 1.3195500373840332, Accuracy: 0.5732421875\n",
      "Batch: 145, Loss: 1.333162546157837, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.2421337366104126, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.2106428146362305, Accuracy: 0.5751953125\n",
      "Batch: 148, Loss: 1.2568464279174805, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.2267248630523682, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.2136523723602295, Accuracy: 0.62890625\n",
      "Batch: 151, Loss: 1.1832761764526367, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.1656086444854736, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.191391944885254, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.1533920764923096, Accuracy: 0.6220703125\n",
      "Batch: 155, Loss: 1.1753761768341064, Accuracy: 0.626953125\n",
      "Epoch 448/200\n",
      "Batch: 1, Loss: 1.2424561977386475, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.1049113273620605, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0819357633590698, Accuracy: 0.65234375\n",
      "Batch: 4, Loss: 1.1307560205459595, Accuracy: 0.6201171875\n",
      "Batch: 5, Loss: 1.0231578350067139, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0589017868041992, Accuracy: 0.66796875\n",
      "Batch: 7, Loss: 1.0933762788772583, Accuracy: 0.6240234375\n",
      "Batch: 8, Loss: 0.9728537797927856, Accuracy: 0.701171875\n",
      "Batch: 9, Loss: 1.0718867778778076, Accuracy: 0.658203125\n",
      "Batch: 10, Loss: 1.034380316734314, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 1.0247316360473633, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0765641927719116, Accuracy: 0.6396484375\n",
      "Batch: 13, Loss: 1.06093430519104, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 1.0304811000823975, Accuracy: 0.6572265625\n",
      "Batch: 15, Loss: 0.9761474132537842, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.0587449073791504, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.1340395212173462, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1639798879623413, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.1918056011199951, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.1326966285705566, Accuracy: 0.6328125\n",
      "Batch: 21, Loss: 1.1440434455871582, Accuracy: 0.6181640625\n",
      "Batch: 22, Loss: 1.2642841339111328, Accuracy: 0.591796875\n",
      "Batch: 23, Loss: 1.2779825925827026, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.1690911054611206, Accuracy: 0.6318359375\n",
      "Batch: 25, Loss: 1.186476707458496, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.2018604278564453, Accuracy: 0.59765625\n",
      "Batch: 27, Loss: 1.1545542478561401, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.111407995223999, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0835392475128174, Accuracy: 0.6455078125\n",
      "Batch: 30, Loss: 1.201945185661316, Accuracy: 0.6064453125\n",
      "Batch: 31, Loss: 1.212746024131775, Accuracy: 0.59765625\n",
      "Batch: 32, Loss: 1.0966863632202148, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 0.9909614324569702, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.104616403579712, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.1412420272827148, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.2188822031021118, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.2090709209442139, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.2691459655761719, Accuracy: 0.580078125\n",
      "Batch: 39, Loss: 1.1469120979309082, Accuracy: 0.6240234375\n",
      "Batch: 40, Loss: 1.1190121173858643, Accuracy: 0.638671875\n",
      "Batch: 41, Loss: 1.178884744644165, Accuracy: 0.599609375\n",
      "Batch: 42, Loss: 1.0690109729766846, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.081819772720337, Accuracy: 0.640625\n",
      "Batch: 44, Loss: 1.0649678707122803, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.078916311264038, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.102475643157959, Accuracy: 0.6455078125\n",
      "Batch: 47, Loss: 1.175701379776001, Accuracy: 0.6181640625\n",
      "Batch: 48, Loss: 1.1277272701263428, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.2424355745315552, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.1496672630310059, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.197954535484314, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.3090121746063232, Accuracy: 0.5654296875\n",
      "Batch: 53, Loss: 1.206404209136963, Accuracy: 0.595703125\n",
      "Batch: 54, Loss: 1.2175770998001099, Accuracy: 0.6025390625\n",
      "Batch: 55, Loss: 1.1116251945495605, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.1181724071502686, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.169445514678955, Accuracy: 0.6279296875\n",
      "Batch: 58, Loss: 1.1100499629974365, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 1.175315022468567, Accuracy: 0.6259765625\n",
      "Batch: 60, Loss: 1.2895526885986328, Accuracy: 0.576171875\n",
      "Batch: 61, Loss: 1.2160977125167847, Accuracy: 0.603515625\n",
      "Batch: 62, Loss: 1.2303617000579834, Accuracy: 0.603515625\n",
      "Batch: 63, Loss: 1.1793866157531738, Accuracy: 0.6328125\n",
      "Batch: 64, Loss: 1.2727882862091064, Accuracy: 0.572265625\n",
      "Batch: 65, Loss: 1.2359397411346436, Accuracy: 0.6005859375\n",
      "Batch: 66, Loss: 1.1400920152664185, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.1865694522857666, Accuracy: 0.599609375\n",
      "Batch: 68, Loss: 1.1547818183898926, Accuracy: 0.6279296875\n",
      "Batch: 69, Loss: 1.1962631940841675, Accuracy: 0.6201171875\n",
      "Batch: 70, Loss: 1.2239563465118408, Accuracy: 0.6142578125\n",
      "Batch: 71, Loss: 1.201963186264038, Accuracy: 0.609375\n",
      "Batch: 72, Loss: 1.209499716758728, Accuracy: 0.595703125\n",
      "Batch: 73, Loss: 1.1787910461425781, Accuracy: 0.615234375\n",
      "Batch: 74, Loss: 1.0770987272262573, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.1564140319824219, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.0999209880828857, Accuracy: 0.630859375\n",
      "Batch: 77, Loss: 1.1119868755340576, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.1490734815597534, Accuracy: 0.61328125\n",
      "Batch: 79, Loss: 1.1343333721160889, Accuracy: 0.630859375\n",
      "Batch: 80, Loss: 1.2255475521087646, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.127722978591919, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.2135887145996094, Accuracy: 0.607421875\n",
      "Batch: 83, Loss: 1.2607133388519287, Accuracy: 0.58984375\n",
      "Batch: 84, Loss: 1.2231168746948242, Accuracy: 0.5966796875\n",
      "Batch: 85, Loss: 1.1917288303375244, Accuracy: 0.6005859375\n",
      "Batch: 86, Loss: 1.242211937904358, Accuracy: 0.6005859375\n",
      "Batch: 87, Loss: 1.216773271560669, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.1974416971206665, Accuracy: 0.607421875\n",
      "Batch: 89, Loss: 1.1257258653640747, Accuracy: 0.666015625\n",
      "Batch: 90, Loss: 1.1506620645523071, Accuracy: 0.6064453125\n",
      "Batch: 91, Loss: 1.1662081480026245, Accuracy: 0.62890625\n",
      "Batch: 92, Loss: 1.2122676372528076, Accuracy: 0.6181640625\n",
      "Batch: 93, Loss: 1.0806697607040405, Accuracy: 0.6396484375\n",
      "Batch: 94, Loss: 1.2401161193847656, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.203465461730957, Accuracy: 0.5966796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 1.2603864669799805, Accuracy: 0.6103515625\n",
      "Batch: 97, Loss: 1.16762375831604, Accuracy: 0.62109375\n",
      "Batch: 98, Loss: 1.1453354358673096, Accuracy: 0.62890625\n",
      "Batch: 99, Loss: 1.1783558130264282, Accuracy: 0.6181640625\n",
      "Batch: 100, Loss: 1.0801410675048828, Accuracy: 0.6591796875\n",
      "Batch: 101, Loss: 1.1404238939285278, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.2353715896606445, Accuracy: 0.5859375\n",
      "Batch: 103, Loss: 1.1571398973464966, Accuracy: 0.6279296875\n",
      "Batch: 104, Loss: 1.1741187572479248, Accuracy: 0.62109375\n",
      "Batch: 105, Loss: 1.2429466247558594, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.2063299417495728, Accuracy: 0.5986328125\n",
      "Batch: 107, Loss: 1.2665562629699707, Accuracy: 0.5849609375\n",
      "Batch: 108, Loss: 1.2140746116638184, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.2593159675598145, Accuracy: 0.5966796875\n",
      "Batch: 110, Loss: 1.149942398071289, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1388128995895386, Accuracy: 0.642578125\n",
      "Batch: 112, Loss: 1.082028865814209, Accuracy: 0.6572265625\n",
      "Batch: 113, Loss: 1.1792619228363037, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.1978933811187744, Accuracy: 0.578125\n",
      "Batch: 115, Loss: 1.224958896636963, Accuracy: 0.6025390625\n",
      "Batch: 116, Loss: 1.1777622699737549, Accuracy: 0.6123046875\n",
      "Batch: 117, Loss: 1.2053247690200806, Accuracy: 0.603515625\n",
      "Batch: 118, Loss: 1.2571600675582886, Accuracy: 0.6005859375\n",
      "Batch: 119, Loss: 1.278456687927246, Accuracy: 0.5830078125\n",
      "Batch: 120, Loss: 1.34326171875, Accuracy: 0.591796875\n",
      "Batch: 121, Loss: 1.2412656545639038, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.2801532745361328, Accuracy: 0.58984375\n",
      "Batch: 123, Loss: 1.2040152549743652, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.281198263168335, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.1395174264907837, Accuracy: 0.6298828125\n",
      "Batch: 126, Loss: 1.309165120124817, Accuracy: 0.5986328125\n",
      "Batch: 127, Loss: 1.2427449226379395, Accuracy: 0.6171875\n",
      "Batch: 128, Loss: 1.2120814323425293, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.2225342988967896, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.1711828708648682, Accuracy: 0.6201171875\n",
      "Batch: 131, Loss: 1.230334758758545, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.1054704189300537, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.2057833671569824, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.188977837562561, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.099888563156128, Accuracy: 0.6328125\n",
      "Batch: 136, Loss: 1.1291522979736328, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.1794469356536865, Accuracy: 0.6171875\n",
      "Batch: 138, Loss: 1.290940523147583, Accuracy: 0.59375\n",
      "Batch: 139, Loss: 1.2169874906539917, Accuracy: 0.6142578125\n",
      "Batch: 140, Loss: 1.223487377166748, Accuracy: 0.60546875\n",
      "Batch: 141, Loss: 1.2451581954956055, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.219414472579956, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.269900918006897, Accuracy: 0.5927734375\n",
      "Batch: 144, Loss: 1.2731733322143555, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.292916178703308, Accuracy: 0.607421875\n",
      "Batch: 146, Loss: 1.2721099853515625, Accuracy: 0.5810546875\n",
      "Batch: 147, Loss: 1.2277956008911133, Accuracy: 0.6005859375\n",
      "Batch: 148, Loss: 1.2646135091781616, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.25491201877594, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.215186595916748, Accuracy: 0.595703125\n",
      "Batch: 151, Loss: 1.20796537399292, Accuracy: 0.6015625\n",
      "Batch: 152, Loss: 1.1784648895263672, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1441054344177246, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.1895382404327393, Accuracy: 0.61328125\n",
      "Batch: 155, Loss: 1.1335769891738892, Accuracy: 0.630859375\n",
      "Epoch 449/200\n",
      "Batch: 1, Loss: 1.2196500301361084, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.073310375213623, Accuracy: 0.65234375\n",
      "Batch: 3, Loss: 1.0727936029434204, Accuracy: 0.6640625\n",
      "Batch: 4, Loss: 1.085932970046997, Accuracy: 0.6513671875\n",
      "Batch: 5, Loss: 1.079187035560608, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 1.0575664043426514, Accuracy: 0.666015625\n",
      "Batch: 7, Loss: 1.032512903213501, Accuracy: 0.65625\n",
      "Batch: 8, Loss: 1.02638840675354, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 1.0204657316207886, Accuracy: 0.6787109375\n",
      "Batch: 10, Loss: 0.986336350440979, Accuracy: 0.671875\n",
      "Batch: 11, Loss: 1.0200510025024414, Accuracy: 0.650390625\n",
      "Batch: 12, Loss: 1.0319819450378418, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 1.0251281261444092, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 1.0075716972351074, Accuracy: 0.662109375\n",
      "Batch: 15, Loss: 0.9665052890777588, Accuracy: 0.6689453125\n",
      "Batch: 16, Loss: 1.0621984004974365, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 1.125320553779602, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.115148901939392, Accuracy: 0.6201171875\n",
      "Batch: 19, Loss: 1.2529876232147217, Accuracy: 0.58203125\n",
      "Batch: 20, Loss: 1.1117515563964844, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.1102454662322998, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.2023248672485352, Accuracy: 0.6240234375\n",
      "Batch: 23, Loss: 1.2575106620788574, Accuracy: 0.5830078125\n",
      "Batch: 24, Loss: 1.156965732574463, Accuracy: 0.611328125\n",
      "Batch: 25, Loss: 1.123464584350586, Accuracy: 0.625\n",
      "Batch: 26, Loss: 1.2015025615692139, Accuracy: 0.5859375\n",
      "Batch: 27, Loss: 1.088456153869629, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.067885398864746, Accuracy: 0.6513671875\n",
      "Batch: 29, Loss: 1.11687433719635, Accuracy: 0.642578125\n",
      "Batch: 30, Loss: 1.1795482635498047, Accuracy: 0.6103515625\n",
      "Batch: 31, Loss: 1.217289686203003, Accuracy: 0.6044921875\n",
      "Batch: 32, Loss: 1.0600566864013672, Accuracy: 0.6435546875\n",
      "Batch: 33, Loss: 1.0583369731903076, Accuracy: 0.650390625\n",
      "Batch: 34, Loss: 1.1730482578277588, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.161427617073059, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.277665376663208, Accuracy: 0.5859375\n",
      "Batch: 37, Loss: 1.2578608989715576, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.1633988618850708, Accuracy: 0.6357421875\n",
      "Batch: 39, Loss: 1.1085541248321533, Accuracy: 0.6455078125\n",
      "Batch: 40, Loss: 1.1319470405578613, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.2428810596466064, Accuracy: 0.615234375\n",
      "Batch: 42, Loss: 1.075407862663269, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.0760600566864014, Accuracy: 0.6396484375\n",
      "Batch: 44, Loss: 1.0613263845443726, Accuracy: 0.669921875\n",
      "Batch: 45, Loss: 1.0993504524230957, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.1824419498443604, Accuracy: 0.6142578125\n",
      "Batch: 47, Loss: 1.1598328351974487, Accuracy: 0.6279296875\n",
      "Batch: 48, Loss: 1.1880357265472412, Accuracy: 0.60546875\n",
      "Batch: 49, Loss: 1.17190420627594, Accuracy: 0.6201171875\n",
      "Batch: 50, Loss: 1.1678478717803955, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.1720044612884521, Accuracy: 0.6083984375\n",
      "Batch: 52, Loss: 1.285414457321167, Accuracy: 0.583984375\n",
      "Batch: 53, Loss: 1.2053487300872803, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.214719295501709, Accuracy: 0.6142578125\n",
      "Batch: 55, Loss: 1.0994319915771484, Accuracy: 0.6416015625\n",
      "Batch: 56, Loss: 1.1548693180084229, Accuracy: 0.6318359375\n",
      "Batch: 57, Loss: 1.1659536361694336, Accuracy: 0.6220703125\n",
      "Batch: 58, Loss: 1.1655898094177246, Accuracy: 0.619140625\n",
      "Batch: 59, Loss: 1.2510595321655273, Accuracy: 0.607421875\n",
      "Batch: 60, Loss: 1.2628381252288818, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.2527554035186768, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.1901023387908936, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.1738523244857788, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.268038272857666, Accuracy: 0.57421875\n",
      "Batch: 65, Loss: 1.2346274852752686, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1869354248046875, Accuracy: 0.630859375\n",
      "Batch: 67, Loss: 1.1762018203735352, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.0962878465652466, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.2417782545089722, Accuracy: 0.5908203125\n",
      "Batch: 70, Loss: 1.2387659549713135, Accuracy: 0.6015625\n",
      "Batch: 71, Loss: 1.1663105487823486, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.2198398113250732, Accuracy: 0.6123046875\n",
      "Batch: 73, Loss: 1.1825709342956543, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.12283194065094, Accuracy: 0.626953125\n",
      "Batch: 75, Loss: 1.1454592943191528, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.1054980754852295, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.068617820739746, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.1273036003112793, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.1319091320037842, Accuracy: 0.6162109375\n",
      "Batch: 80, Loss: 1.1928629875183105, Accuracy: 0.6025390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 1.1572866439819336, Accuracy: 0.61328125\n",
      "Batch: 82, Loss: 1.1972076892852783, Accuracy: 0.61328125\n",
      "Batch: 83, Loss: 1.1848411560058594, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.1472389698028564, Accuracy: 0.6259765625\n",
      "Batch: 85, Loss: 1.1796733140945435, Accuracy: 0.63671875\n",
      "Batch: 86, Loss: 1.2257882356643677, Accuracy: 0.59765625\n",
      "Batch: 87, Loss: 1.2432496547698975, Accuracy: 0.607421875\n",
      "Batch: 88, Loss: 1.200974941253662, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.1784169673919678, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.1503729820251465, Accuracy: 0.6318359375\n",
      "Batch: 91, Loss: 1.1762619018554688, Accuracy: 0.611328125\n",
      "Batch: 92, Loss: 1.1732537746429443, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.1631271839141846, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.2603093385696411, Accuracy: 0.5927734375\n",
      "Batch: 95, Loss: 1.2280142307281494, Accuracy: 0.6005859375\n",
      "Batch: 96, Loss: 1.2570767402648926, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.1699559688568115, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.1820483207702637, Accuracy: 0.6025390625\n",
      "Batch: 99, Loss: 1.2291522026062012, Accuracy: 0.6015625\n",
      "Batch: 100, Loss: 1.1039657592773438, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.124312162399292, Accuracy: 0.63671875\n",
      "Batch: 102, Loss: 1.2030258178710938, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.1733852624893188, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1652582883834839, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.2544920444488525, Accuracy: 0.6103515625\n",
      "Batch: 106, Loss: 1.2367998361587524, Accuracy: 0.59765625\n",
      "Batch: 107, Loss: 1.2867869138717651, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.1847161054611206, Accuracy: 0.595703125\n",
      "Batch: 109, Loss: 1.2989848852157593, Accuracy: 0.572265625\n",
      "Batch: 110, Loss: 1.2183313369750977, Accuracy: 0.5947265625\n",
      "Batch: 111, Loss: 1.1629455089569092, Accuracy: 0.6103515625\n",
      "Batch: 112, Loss: 1.1408734321594238, Accuracy: 0.634765625\n",
      "Batch: 113, Loss: 1.2194195985794067, Accuracy: 0.595703125\n",
      "Batch: 114, Loss: 1.1732940673828125, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.200011968612671, Accuracy: 0.61328125\n",
      "Batch: 116, Loss: 1.2577085494995117, Accuracy: 0.583984375\n",
      "Batch: 117, Loss: 1.2007497549057007, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.209947109222412, Accuracy: 0.5986328125\n",
      "Batch: 119, Loss: 1.2703402042388916, Accuracy: 0.6015625\n",
      "Batch: 120, Loss: 1.2899715900421143, Accuracy: 0.609375\n",
      "Batch: 121, Loss: 1.231237530708313, Accuracy: 0.6015625\n",
      "Batch: 122, Loss: 1.2130186557769775, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.2342864274978638, Accuracy: 0.5888671875\n",
      "Batch: 124, Loss: 1.2486391067504883, Accuracy: 0.6064453125\n",
      "Batch: 125, Loss: 1.2361845970153809, Accuracy: 0.6201171875\n",
      "Batch: 126, Loss: 1.2157256603240967, Accuracy: 0.6201171875\n",
      "Batch: 127, Loss: 1.284285306930542, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.2358262538909912, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.2338566780090332, Accuracy: 0.599609375\n",
      "Batch: 130, Loss: 1.1515161991119385, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.314955472946167, Accuracy: 0.58984375\n",
      "Batch: 132, Loss: 1.1424634456634521, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.182384729385376, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.1281421184539795, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 1.0376355648040771, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.1544201374053955, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.2117294073104858, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.2574973106384277, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.2011595964431763, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.2746996879577637, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.2958779335021973, Accuracy: 0.578125\n",
      "Batch: 142, Loss: 1.2974398136138916, Accuracy: 0.5712890625\n",
      "Batch: 143, Loss: 1.2878060340881348, Accuracy: 0.5947265625\n",
      "Batch: 144, Loss: 1.328644871711731, Accuracy: 0.5634765625\n",
      "Batch: 145, Loss: 1.3643205165863037, Accuracy: 0.5595703125\n",
      "Batch: 146, Loss: 1.224656581878662, Accuracy: 0.6044921875\n",
      "Batch: 147, Loss: 1.2243576049804688, Accuracy: 0.60546875\n",
      "Batch: 148, Loss: 1.2688319683074951, Accuracy: 0.5849609375\n",
      "Batch: 149, Loss: 1.2269535064697266, Accuracy: 0.6044921875\n",
      "Batch: 150, Loss: 1.2293226718902588, Accuracy: 0.609375\n",
      "Batch: 151, Loss: 1.189860463142395, Accuracy: 0.6181640625\n",
      "Batch: 152, Loss: 1.1735954284667969, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.136497139930725, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1965689659118652, Accuracy: 0.619140625\n",
      "Batch: 155, Loss: 1.1318211555480957, Accuracy: 0.6328125\n",
      "Epoch 450/200\n",
      "Batch: 1, Loss: 1.2382259368896484, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.1262397766113281, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.085726261138916, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.1114609241485596, Accuracy: 0.6298828125\n",
      "Batch: 5, Loss: 1.0417424440383911, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.0689942836761475, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0937403440475464, Accuracy: 0.642578125\n",
      "Batch: 8, Loss: 1.004504919052124, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0015909671783447, Accuracy: 0.6884765625\n",
      "Batch: 10, Loss: 1.0043495893478394, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 0.9817832708358765, Accuracy: 0.6767578125\n",
      "Batch: 12, Loss: 1.0049103498458862, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 0.9802958965301514, Accuracy: 0.6806640625\n",
      "Batch: 14, Loss: 0.9929541945457458, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 1.0013220310211182, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.0940457582473755, Accuracy: 0.6630859375\n",
      "Batch: 17, Loss: 1.1213154792785645, Accuracy: 0.625\n",
      "Batch: 18, Loss: 1.1581737995147705, Accuracy: 0.619140625\n",
      "Batch: 19, Loss: 1.2383809089660645, Accuracy: 0.5947265625\n",
      "Batch: 20, Loss: 1.1521496772766113, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.119140386581421, Accuracy: 0.638671875\n",
      "Batch: 22, Loss: 1.2409133911132812, Accuracy: 0.6103515625\n",
      "Batch: 23, Loss: 1.2864763736724854, Accuracy: 0.587890625\n",
      "Batch: 24, Loss: 1.1446157693862915, Accuracy: 0.623046875\n",
      "Batch: 25, Loss: 1.1778442859649658, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.2131752967834473, Accuracy: 0.6162109375\n",
      "Batch: 27, Loss: 1.158949613571167, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.1029716730117798, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.0522555112838745, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.1942112445831299, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.236990213394165, Accuracy: 0.59375\n",
      "Batch: 32, Loss: 1.0299838781356812, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.0496442317962646, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.132598638534546, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.173445224761963, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.1421403884887695, Accuracy: 0.6337890625\n",
      "Batch: 37, Loss: 1.2616875171661377, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.1535615921020508, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0861799716949463, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 1.1050375699996948, Accuracy: 0.6337890625\n",
      "Batch: 41, Loss: 1.1654980182647705, Accuracy: 0.6015625\n",
      "Batch: 42, Loss: 1.0869449377059937, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.054260492324829, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0399240255355835, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 1.0787193775177002, Accuracy: 0.6337890625\n",
      "Batch: 46, Loss: 1.203920841217041, Accuracy: 0.6083984375\n",
      "Batch: 47, Loss: 1.1366775035858154, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.17296302318573, Accuracy: 0.6162109375\n",
      "Batch: 49, Loss: 1.2476519346237183, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.148013710975647, Accuracy: 0.634765625\n",
      "Batch: 51, Loss: 1.1867544651031494, Accuracy: 0.59375\n",
      "Batch: 52, Loss: 1.299249291419983, Accuracy: 0.5927734375\n",
      "Batch: 53, Loss: 1.2206571102142334, Accuracy: 0.57421875\n",
      "Batch: 54, Loss: 1.137007474899292, Accuracy: 0.62890625\n",
      "Batch: 55, Loss: 1.1181527376174927, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.087095856666565, Accuracy: 0.6640625\n",
      "Batch: 57, Loss: 1.108514666557312, Accuracy: 0.6318359375\n",
      "Batch: 58, Loss: 1.1704750061035156, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 1.132219910621643, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.2844948768615723, Accuracy: 0.578125\n",
      "Batch: 61, Loss: 1.1847617626190186, Accuracy: 0.599609375\n",
      "Batch: 62, Loss: 1.1574691534042358, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.1744663715362549, Accuracy: 0.619140625\n",
      "Batch: 64, Loss: 1.2277456521987915, Accuracy: 0.6083984375\n",
      "Batch: 65, Loss: 1.2381523847579956, Accuracy: 0.615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 66, Loss: 1.231614351272583, Accuracy: 0.6025390625\n",
      "Batch: 67, Loss: 1.1470816135406494, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.0888599157333374, Accuracy: 0.6650390625\n",
      "Batch: 69, Loss: 1.248942494392395, Accuracy: 0.6015625\n",
      "Batch: 70, Loss: 1.1902751922607422, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1503418684005737, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.221088171005249, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.2412033081054688, Accuracy: 0.599609375\n",
      "Batch: 74, Loss: 1.0882012844085693, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.1405000686645508, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.1034541130065918, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0531389713287354, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0869977474212646, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.1609008312225342, Accuracy: 0.6220703125\n",
      "Batch: 80, Loss: 1.1880788803100586, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.1454192399978638, Accuracy: 0.6083984375\n",
      "Batch: 82, Loss: 1.2062146663665771, Accuracy: 0.6171875\n",
      "Batch: 83, Loss: 1.1873323917388916, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.1708556413650513, Accuracy: 0.603515625\n",
      "Batch: 85, Loss: 1.1728172302246094, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.22634756565094, Accuracy: 0.6083984375\n",
      "Batch: 87, Loss: 1.2298288345336914, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.2063370943069458, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1981909275054932, Accuracy: 0.6201171875\n",
      "Batch: 90, Loss: 1.1632659435272217, Accuracy: 0.6240234375\n",
      "Batch: 91, Loss: 1.1713870763778687, Accuracy: 0.61328125\n",
      "Batch: 92, Loss: 1.1416152715682983, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.1594645977020264, Accuracy: 0.6162109375\n",
      "Batch: 94, Loss: 1.240968942642212, Accuracy: 0.60546875\n",
      "Batch: 95, Loss: 1.1310428380966187, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.231313705444336, Accuracy: 0.609375\n",
      "Batch: 97, Loss: 1.1797642707824707, Accuracy: 0.619140625\n",
      "Batch: 98, Loss: 1.1240586042404175, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.1543300151824951, Accuracy: 0.630859375\n",
      "Batch: 100, Loss: 1.1234101057052612, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.1434223651885986, Accuracy: 0.619140625\n",
      "Batch: 102, Loss: 1.1806139945983887, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.1756093502044678, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.17624831199646, Accuracy: 0.62109375\n",
      "Batch: 105, Loss: 1.2357509136199951, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.215174913406372, Accuracy: 0.58984375\n",
      "Batch: 107, Loss: 1.229799747467041, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.2385655641555786, Accuracy: 0.59375\n",
      "Batch: 109, Loss: 1.2225632667541504, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.1940840482711792, Accuracy: 0.609375\n",
      "Batch: 111, Loss: 1.1485066413879395, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.1077975034713745, Accuracy: 0.6376953125\n",
      "Batch: 113, Loss: 1.2161662578582764, Accuracy: 0.5986328125\n",
      "Batch: 114, Loss: 1.204244613647461, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.1766810417175293, Accuracy: 0.6328125\n",
      "Batch: 116, Loss: 1.2117252349853516, Accuracy: 0.61328125\n",
      "Batch: 117, Loss: 1.1390528678894043, Accuracy: 0.62890625\n",
      "Batch: 118, Loss: 1.2856342792510986, Accuracy: 0.5869140625\n",
      "Batch: 119, Loss: 1.330698013305664, Accuracy: 0.5869140625\n",
      "Batch: 120, Loss: 1.3635199069976807, Accuracy: 0.587890625\n",
      "Batch: 121, Loss: 1.2582429647445679, Accuracy: 0.5908203125\n",
      "Batch: 122, Loss: 1.2596837282180786, Accuracy: 0.587890625\n",
      "Batch: 123, Loss: 1.1781812906265259, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.2401857376098633, Accuracy: 0.599609375\n",
      "Batch: 125, Loss: 1.238973617553711, Accuracy: 0.61328125\n",
      "Batch: 126, Loss: 1.2514214515686035, Accuracy: 0.62109375\n",
      "Batch: 127, Loss: 1.2554606199264526, Accuracy: 0.599609375\n",
      "Batch: 128, Loss: 1.2435204982757568, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.204908847808838, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.1629893779754639, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.1848336458206177, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 1.1072587966918945, Accuracy: 0.646484375\n",
      "Batch: 133, Loss: 1.1420745849609375, Accuracy: 0.626953125\n",
      "Batch: 134, Loss: 1.1022083759307861, Accuracy: 0.6728515625\n",
      "Batch: 135, Loss: 1.0722638368606567, Accuracy: 0.642578125\n",
      "Batch: 136, Loss: 1.1539926528930664, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.1937538385391235, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.2580199241638184, Accuracy: 0.59375\n",
      "Batch: 139, Loss: 1.2056751251220703, Accuracy: 0.603515625\n",
      "Batch: 140, Loss: 1.2905855178833008, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.1616814136505127, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.2140817642211914, Accuracy: 0.60546875\n",
      "Batch: 143, Loss: 1.2252426147460938, Accuracy: 0.6044921875\n",
      "Batch: 144, Loss: 1.3062858581542969, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2574504613876343, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.1939386129379272, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.2747235298156738, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.217865228652954, Accuracy: 0.603515625\n",
      "Batch: 149, Loss: 1.1634293794631958, Accuracy: 0.599609375\n",
      "Batch: 150, Loss: 1.1739470958709717, Accuracy: 0.5966796875\n",
      "Batch: 151, Loss: 1.165365219116211, Accuracy: 0.6142578125\n",
      "Batch: 152, Loss: 1.2189877033233643, Accuracy: 0.5927734375\n",
      "Batch: 153, Loss: 1.1638739109039307, Accuracy: 0.630859375\n",
      "Batch: 154, Loss: 1.1572840213775635, Accuracy: 0.6318359375\n",
      "Batch: 155, Loss: 1.0620701313018799, Accuracy: 0.654296875\n",
      "Saved Weights at epoch 450 to file Weights_450.h5\n",
      "Epoch 451/200\n",
      "Batch: 1, Loss: 1.1897690296173096, Accuracy: 0.6376953125\n",
      "Batch: 2, Loss: 1.0857298374176025, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.0290586948394775, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.0997109413146973, Accuracy: 0.6318359375\n",
      "Batch: 5, Loss: 1.045135736465454, Accuracy: 0.6484375\n",
      "Batch: 6, Loss: 1.0400596857070923, Accuracy: 0.66015625\n",
      "Batch: 7, Loss: 1.068099021911621, Accuracy: 0.6435546875\n",
      "Batch: 8, Loss: 1.0235450267791748, Accuracy: 0.6630859375\n",
      "Batch: 9, Loss: 1.0275717973709106, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 1.0023545026779175, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 0.9516687393188477, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 1.0081377029418945, Accuracy: 0.6689453125\n",
      "Batch: 13, Loss: 1.0426084995269775, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 1.0261859893798828, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 1.0012080669403076, Accuracy: 0.6689453125\n",
      "Batch: 16, Loss: 1.0848934650421143, Accuracy: 0.6416015625\n",
      "Batch: 17, Loss: 1.0796922445297241, Accuracy: 0.6318359375\n",
      "Batch: 18, Loss: 1.17221999168396, Accuracy: 0.6279296875\n",
      "Batch: 19, Loss: 1.2182590961456299, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 1.0980162620544434, Accuracy: 0.6630859375\n",
      "Batch: 21, Loss: 1.0564743280410767, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.2718753814697266, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.225366234779358, Accuracy: 0.5966796875\n",
      "Batch: 24, Loss: 1.151261568069458, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.22102952003479, Accuracy: 0.59375\n",
      "Batch: 26, Loss: 1.2225520610809326, Accuracy: 0.58203125\n",
      "Batch: 27, Loss: 1.1577253341674805, Accuracy: 0.6005859375\n",
      "Batch: 28, Loss: 1.0990856885910034, Accuracy: 0.6171875\n",
      "Batch: 29, Loss: 1.0901150703430176, Accuracy: 0.6474609375\n",
      "Batch: 30, Loss: 1.1829619407653809, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.2758179903030396, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.1014002561569214, Accuracy: 0.6357421875\n",
      "Batch: 33, Loss: 1.082216739654541, Accuracy: 0.6513671875\n",
      "Batch: 34, Loss: 1.1033451557159424, Accuracy: 0.6435546875\n",
      "Batch: 35, Loss: 1.1330225467681885, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.2105138301849365, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.2150237560272217, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.1523133516311646, Accuracy: 0.61328125\n",
      "Batch: 39, Loss: 1.135284423828125, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 1.1625053882598877, Accuracy: 0.623046875\n",
      "Batch: 41, Loss: 1.1445510387420654, Accuracy: 0.6064453125\n",
      "Batch: 42, Loss: 1.1173045635223389, Accuracy: 0.6298828125\n",
      "Batch: 43, Loss: 1.0797539949417114, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.031761884689331, Accuracy: 0.6455078125\n",
      "Batch: 45, Loss: 1.1150305271148682, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.1836724281311035, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.1410703659057617, Accuracy: 0.646484375\n",
      "Batch: 48, Loss: 1.1765425205230713, Accuracy: 0.603515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 49, Loss: 1.227616310119629, Accuracy: 0.5947265625\n",
      "Batch: 50, Loss: 1.1774966716766357, Accuracy: 0.6005859375\n",
      "Batch: 51, Loss: 1.142122507095337, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.293105125427246, Accuracy: 0.5771484375\n",
      "Batch: 53, Loss: 1.174726963043213, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.2835692167282104, Accuracy: 0.578125\n",
      "Batch: 55, Loss: 1.138255000114441, Accuracy: 0.6220703125\n",
      "Batch: 56, Loss: 1.1306908130645752, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.1613740921020508, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.1383180618286133, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1371160745620728, Accuracy: 0.638671875\n",
      "Batch: 60, Loss: 1.215833067893982, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.1583741903305054, Accuracy: 0.6015625\n",
      "Batch: 62, Loss: 1.1699390411376953, Accuracy: 0.62109375\n",
      "Batch: 63, Loss: 1.1867938041687012, Accuracy: 0.6005859375\n",
      "Batch: 64, Loss: 1.2484469413757324, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.2181780338287354, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.078456163406372, Accuracy: 0.6494140625\n",
      "Batch: 67, Loss: 1.1681745052337646, Accuracy: 0.638671875\n",
      "Batch: 68, Loss: 1.1177772283554077, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.2451552152633667, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.2108341455459595, Accuracy: 0.6064453125\n",
      "Batch: 71, Loss: 1.1696844100952148, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.2344573736190796, Accuracy: 0.5927734375\n",
      "Batch: 73, Loss: 1.1948387622833252, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.1104395389556885, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.1504108905792236, Accuracy: 0.6337890625\n",
      "Batch: 76, Loss: 1.1125351190567017, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.0637286901474, Accuracy: 0.654296875\n",
      "Batch: 78, Loss: 1.0800460577011108, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.149205207824707, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.198655605316162, Accuracy: 0.607421875\n",
      "Batch: 81, Loss: 1.1415297985076904, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.138735294342041, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.2497236728668213, Accuracy: 0.609375\n",
      "Batch: 84, Loss: 1.1998181343078613, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.1762876510620117, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.2051684856414795, Accuracy: 0.603515625\n",
      "Batch: 87, Loss: 1.2118229866027832, Accuracy: 0.6123046875\n",
      "Batch: 88, Loss: 1.2086479663848877, Accuracy: 0.6064453125\n",
      "Batch: 89, Loss: 1.2439348697662354, Accuracy: 0.595703125\n",
      "Batch: 90, Loss: 1.1759588718414307, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.1629700660705566, Accuracy: 0.6201171875\n",
      "Batch: 92, Loss: 1.151343822479248, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.2187035083770752, Accuracy: 0.6005859375\n",
      "Batch: 94, Loss: 1.2761859893798828, Accuracy: 0.5888671875\n",
      "Batch: 95, Loss: 1.2159086465835571, Accuracy: 0.5888671875\n",
      "Batch: 96, Loss: 1.1776740550994873, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.1341605186462402, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.159947395324707, Accuracy: 0.6220703125\n",
      "Batch: 99, Loss: 1.1738529205322266, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.104987382888794, Accuracy: 0.6279296875\n",
      "Batch: 101, Loss: 1.1374468803405762, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.1708619594573975, Accuracy: 0.6083984375\n",
      "Batch: 103, Loss: 1.2267459630966187, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.2068424224853516, Accuracy: 0.6201171875\n",
      "Batch: 105, Loss: 1.27153742313385, Accuracy: 0.5947265625\n",
      "Batch: 106, Loss: 1.1863594055175781, Accuracy: 0.607421875\n",
      "Batch: 107, Loss: 1.2255034446716309, Accuracy: 0.607421875\n",
      "Batch: 108, Loss: 1.2014933824539185, Accuracy: 0.61328125\n",
      "Batch: 109, Loss: 1.2247068881988525, Accuracy: 0.591796875\n",
      "Batch: 110, Loss: 1.1491093635559082, Accuracy: 0.6435546875\n",
      "Batch: 111, Loss: 1.158882975578308, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.1535879373550415, Accuracy: 0.615234375\n",
      "Batch: 113, Loss: 1.1775367259979248, Accuracy: 0.625\n",
      "Batch: 114, Loss: 1.212320327758789, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.2374601364135742, Accuracy: 0.5859375\n",
      "Batch: 116, Loss: 1.2310914993286133, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.1783486604690552, Accuracy: 0.62890625\n",
      "Batch: 118, Loss: 1.1872336864471436, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.202709436416626, Accuracy: 0.6025390625\n",
      "Batch: 120, Loss: 1.3540356159210205, Accuracy: 0.564453125\n",
      "Batch: 121, Loss: 1.2537847757339478, Accuracy: 0.5927734375\n",
      "Batch: 122, Loss: 1.3135727643966675, Accuracy: 0.5869140625\n",
      "Batch: 123, Loss: 1.2435619831085205, Accuracy: 0.5908203125\n",
      "Batch: 124, Loss: 1.21204674243927, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1892186403274536, Accuracy: 0.60546875\n",
      "Batch: 126, Loss: 1.296203851699829, Accuracy: 0.57421875\n",
      "Batch: 127, Loss: 1.2567787170410156, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.2760961055755615, Accuracy: 0.5859375\n",
      "Batch: 129, Loss: 1.2258628606796265, Accuracy: 0.6015625\n",
      "Batch: 130, Loss: 1.2049888372421265, Accuracy: 0.6015625\n",
      "Batch: 131, Loss: 1.2959059476852417, Accuracy: 0.5888671875\n",
      "Batch: 132, Loss: 1.0765935182571411, Accuracy: 0.6572265625\n",
      "Batch: 133, Loss: 1.296521544456482, Accuracy: 0.572265625\n",
      "Batch: 134, Loss: 1.1727399826049805, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.0488225221633911, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.1085879802703857, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.205784559249878, Accuracy: 0.6220703125\n",
      "Batch: 138, Loss: 1.2520411014556885, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.1984174251556396, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.274308204650879, Accuracy: 0.59765625\n",
      "Batch: 141, Loss: 1.2330970764160156, Accuracy: 0.59765625\n",
      "Batch: 142, Loss: 1.1955984830856323, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.267255425453186, Accuracy: 0.59375\n",
      "Batch: 144, Loss: 1.367849588394165, Accuracy: 0.5673828125\n",
      "Batch: 145, Loss: 1.2659332752227783, Accuracy: 0.5703125\n",
      "Batch: 146, Loss: 1.2369877099990845, Accuracy: 0.5869140625\n",
      "Batch: 147, Loss: 1.283231496810913, Accuracy: 0.57421875\n",
      "Batch: 148, Loss: 1.1769421100616455, Accuracy: 0.6337890625\n",
      "Batch: 149, Loss: 1.20941162109375, Accuracy: 0.5986328125\n",
      "Batch: 150, Loss: 1.156095027923584, Accuracy: 0.599609375\n",
      "Batch: 151, Loss: 1.2630789279937744, Accuracy: 0.603515625\n",
      "Batch: 152, Loss: 1.2122279405593872, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1853046417236328, Accuracy: 0.62109375\n",
      "Batch: 154, Loss: 1.195884346961975, Accuracy: 0.62109375\n",
      "Batch: 155, Loss: 1.1089801788330078, Accuracy: 0.6298828125\n",
      "Epoch 452/200\n",
      "Batch: 1, Loss: 1.2739603519439697, Accuracy: 0.6240234375\n",
      "Batch: 2, Loss: 1.117927074432373, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 1.072303056716919, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.1177735328674316, Accuracy: 0.6318359375\n",
      "Batch: 5, Loss: 1.0388654470443726, Accuracy: 0.6689453125\n",
      "Batch: 6, Loss: 1.07719087600708, Accuracy: 0.64453125\n",
      "Batch: 7, Loss: 1.0879504680633545, Accuracy: 0.646484375\n",
      "Batch: 8, Loss: 1.0036147832870483, Accuracy: 0.68359375\n",
      "Batch: 9, Loss: 1.008091926574707, Accuracy: 0.662109375\n",
      "Batch: 10, Loss: 1.0074238777160645, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 0.9867068529129028, Accuracy: 0.6787109375\n",
      "Batch: 12, Loss: 1.0850176811218262, Accuracy: 0.646484375\n",
      "Batch: 13, Loss: 1.0592138767242432, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 1.0015283823013306, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9372772574424744, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0325599908828735, Accuracy: 0.677734375\n",
      "Batch: 17, Loss: 1.118004560470581, Accuracy: 0.6259765625\n",
      "Batch: 18, Loss: 1.1360722780227661, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.2303282022476196, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.1047017574310303, Accuracy: 0.650390625\n",
      "Batch: 21, Loss: 1.098721981048584, Accuracy: 0.638671875\n",
      "Batch: 22, Loss: 1.2662687301635742, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.2347102165222168, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.1644810438156128, Accuracy: 0.6298828125\n",
      "Batch: 25, Loss: 1.183470606803894, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.2164608240127563, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.1873323917388916, Accuracy: 0.62109375\n",
      "Batch: 28, Loss: 1.1124942302703857, Accuracy: 0.63671875\n",
      "Batch: 29, Loss: 1.1221866607666016, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.1858770847320557, Accuracy: 0.619140625\n",
      "Batch: 31, Loss: 1.2339684963226318, Accuracy: 0.609375\n",
      "Batch: 32, Loss: 1.078979253768921, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 1.0701837539672852, Accuracy: 0.658203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.1864500045776367, Accuracy: 0.6162109375\n",
      "Batch: 35, Loss: 1.144867181777954, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.2214531898498535, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.2380688190460205, Accuracy: 0.5986328125\n",
      "Batch: 38, Loss: 1.199054479598999, Accuracy: 0.6171875\n",
      "Batch: 39, Loss: 1.1387499570846558, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.1031625270843506, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.134263038635254, Accuracy: 0.62890625\n",
      "Batch: 42, Loss: 1.144315242767334, Accuracy: 0.6103515625\n",
      "Batch: 43, Loss: 1.033423662185669, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.0566530227661133, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.0829756259918213, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.180063009262085, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.1337156295776367, Accuracy: 0.63671875\n",
      "Batch: 48, Loss: 1.2013750076293945, Accuracy: 0.5986328125\n",
      "Batch: 49, Loss: 1.2180399894714355, Accuracy: 0.623046875\n",
      "Batch: 50, Loss: 1.161496877670288, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.153151035308838, Accuracy: 0.6103515625\n",
      "Batch: 52, Loss: 1.268134593963623, Accuracy: 0.5869140625\n",
      "Batch: 53, Loss: 1.1989110708236694, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.2200772762298584, Accuracy: 0.6025390625\n",
      "Batch: 55, Loss: 1.1408195495605469, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.1858670711517334, Accuracy: 0.6328125\n",
      "Batch: 57, Loss: 1.112151861190796, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.2085227966308594, Accuracy: 0.609375\n",
      "Batch: 59, Loss: 1.181577444076538, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.284746766090393, Accuracy: 0.5859375\n",
      "Batch: 61, Loss: 1.2174941301345825, Accuracy: 0.6044921875\n",
      "Batch: 62, Loss: 1.1515144109725952, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.1757198572158813, Accuracy: 0.6318359375\n",
      "Batch: 64, Loss: 1.276505947113037, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.2415249347686768, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.1782034635543823, Accuracy: 0.6240234375\n",
      "Batch: 67, Loss: 1.195877194404602, Accuracy: 0.6025390625\n",
      "Batch: 68, Loss: 1.1290323734283447, Accuracy: 0.6328125\n",
      "Batch: 69, Loss: 1.2134826183319092, Accuracy: 0.6005859375\n",
      "Batch: 70, Loss: 1.152070164680481, Accuracy: 0.6279296875\n",
      "Batch: 71, Loss: 1.1730719804763794, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.2698907852172852, Accuracy: 0.587890625\n",
      "Batch: 73, Loss: 1.1848042011260986, Accuracy: 0.6279296875\n",
      "Batch: 74, Loss: 1.110152244567871, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.166581153869629, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.1140204668045044, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0973079204559326, Accuracy: 0.6396484375\n",
      "Batch: 78, Loss: 1.0884623527526855, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.1962273120880127, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.2097409963607788, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.1623274087905884, Accuracy: 0.603515625\n",
      "Batch: 82, Loss: 1.1329666376113892, Accuracy: 0.6259765625\n",
      "Batch: 83, Loss: 1.2617874145507812, Accuracy: 0.59375\n",
      "Batch: 84, Loss: 1.156202793121338, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.1544564962387085, Accuracy: 0.62109375\n",
      "Batch: 86, Loss: 1.17103111743927, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.1694613695144653, Accuracy: 0.6220703125\n",
      "Batch: 88, Loss: 1.213376522064209, Accuracy: 0.6083984375\n",
      "Batch: 89, Loss: 1.198868989944458, Accuracy: 0.6142578125\n",
      "Batch: 90, Loss: 1.1521722078323364, Accuracy: 0.6044921875\n",
      "Batch: 91, Loss: 1.1499872207641602, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.139765977859497, Accuracy: 0.646484375\n",
      "Batch: 93, Loss: 1.1284159421920776, Accuracy: 0.638671875\n",
      "Batch: 94, Loss: 1.2644765377044678, Accuracy: 0.5947265625\n",
      "Batch: 95, Loss: 1.2583508491516113, Accuracy: 0.5986328125\n",
      "Batch: 96, Loss: 1.2534279823303223, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.2161166667938232, Accuracy: 0.599609375\n",
      "Batch: 98, Loss: 1.1391475200653076, Accuracy: 0.63671875\n",
      "Batch: 99, Loss: 1.1479212045669556, Accuracy: 0.6396484375\n",
      "Batch: 100, Loss: 1.0795872211456299, Accuracy: 0.6484375\n",
      "Batch: 101, Loss: 1.0917267799377441, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 1.2543275356292725, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.1957554817199707, Accuracy: 0.6103515625\n",
      "Batch: 104, Loss: 1.178022027015686, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.2508530616760254, Accuracy: 0.58984375\n",
      "Batch: 106, Loss: 1.1987202167510986, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.2951574325561523, Accuracy: 0.5927734375\n",
      "Batch: 108, Loss: 1.1879682540893555, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.2603974342346191, Accuracy: 0.59765625\n",
      "Batch: 110, Loss: 1.1651206016540527, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.18128502368927, Accuracy: 0.6103515625\n",
      "Batch: 112, Loss: 1.0905169248580933, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.2449800968170166, Accuracy: 0.61328125\n",
      "Batch: 114, Loss: 1.2251315116882324, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.1642098426818848, Accuracy: 0.6259765625\n",
      "Batch: 116, Loss: 1.2008469104766846, Accuracy: 0.6142578125\n",
      "Batch: 117, Loss: 1.1755608320236206, Accuracy: 0.62109375\n",
      "Batch: 118, Loss: 1.2319719791412354, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.2341055870056152, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.2906383275985718, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.2388577461242676, Accuracy: 0.6005859375\n",
      "Batch: 122, Loss: 1.2359693050384521, Accuracy: 0.5927734375\n",
      "Batch: 123, Loss: 1.2157052755355835, Accuracy: 0.599609375\n",
      "Batch: 124, Loss: 1.2564295530319214, Accuracy: 0.59375\n",
      "Batch: 125, Loss: 1.1938563585281372, Accuracy: 0.6142578125\n",
      "Batch: 126, Loss: 1.2530205249786377, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.302462100982666, Accuracy: 0.578125\n",
      "Batch: 128, Loss: 1.231433391571045, Accuracy: 0.5927734375\n",
      "Batch: 129, Loss: 1.1989312171936035, Accuracy: 0.6015625\n",
      "Batch: 130, Loss: 1.1846060752868652, Accuracy: 0.60546875\n",
      "Batch: 131, Loss: 1.281203269958496, Accuracy: 0.5654296875\n",
      "Batch: 132, Loss: 1.1107642650604248, Accuracy: 0.63671875\n",
      "Batch: 133, Loss: 1.1653413772583008, Accuracy: 0.6142578125\n",
      "Batch: 134, Loss: 1.1265194416046143, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.0511045455932617, Accuracy: 0.66796875\n",
      "Batch: 136, Loss: 1.1101596355438232, Accuracy: 0.6455078125\n",
      "Batch: 137, Loss: 1.21656334400177, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.2322944402694702, Accuracy: 0.5869140625\n",
      "Batch: 139, Loss: 1.1767420768737793, Accuracy: 0.634765625\n",
      "Batch: 140, Loss: 1.2381986379623413, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.1611812114715576, Accuracy: 0.6376953125\n",
      "Batch: 142, Loss: 1.185563564300537, Accuracy: 0.623046875\n",
      "Batch: 143, Loss: 1.2249295711517334, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.26913321018219, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.2739629745483398, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.2349350452423096, Accuracy: 0.5849609375\n",
      "Batch: 147, Loss: 1.271817922592163, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.1692813634872437, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.2274188995361328, Accuracy: 0.6044921875\n",
      "Batch: 150, Loss: 1.2090184688568115, Accuracy: 0.6083984375\n",
      "Batch: 151, Loss: 1.238023042678833, Accuracy: 0.599609375\n",
      "Batch: 152, Loss: 1.1574357748031616, Accuracy: 0.6220703125\n",
      "Batch: 153, Loss: 1.194563388824463, Accuracy: 0.62890625\n",
      "Batch: 154, Loss: 1.1498091220855713, Accuracy: 0.6123046875\n",
      "Batch: 155, Loss: 1.1652867794036865, Accuracy: 0.6298828125\n",
      "Epoch 453/200\n",
      "Batch: 1, Loss: 1.2295986413955688, Accuracy: 0.615234375\n",
      "Batch: 2, Loss: 1.1448893547058105, Accuracy: 0.63671875\n",
      "Batch: 3, Loss: 1.1301438808441162, Accuracy: 0.6298828125\n",
      "Batch: 4, Loss: 1.1065499782562256, Accuracy: 0.6318359375\n",
      "Batch: 5, Loss: 0.9656212329864502, Accuracy: 0.6787109375\n",
      "Batch: 6, Loss: 1.0634019374847412, Accuracy: 0.65234375\n",
      "Batch: 7, Loss: 1.0528448820114136, Accuracy: 0.6337890625\n",
      "Batch: 8, Loss: 1.0627620220184326, Accuracy: 0.671875\n",
      "Batch: 9, Loss: 1.0229498147964478, Accuracy: 0.6826171875\n",
      "Batch: 10, Loss: 1.0136325359344482, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 0.9634602069854736, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 1.0099616050720215, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 1.067669153213501, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 0.9920661449432373, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 1.0094144344329834, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0395455360412598, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.1099421977996826, Accuracy: 0.65625\n",
      "Batch: 18, Loss: 1.1499602794647217, Accuracy: 0.6103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 1.2155349254608154, Accuracy: 0.599609375\n",
      "Batch: 20, Loss: 1.1561706066131592, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.1148624420166016, Accuracy: 0.6279296875\n",
      "Batch: 22, Loss: 1.2112219333648682, Accuracy: 0.623046875\n",
      "Batch: 23, Loss: 1.3084434270858765, Accuracy: 0.5771484375\n",
      "Batch: 24, Loss: 1.173059105873108, Accuracy: 0.626953125\n",
      "Batch: 25, Loss: 1.1576848030090332, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.1820303201675415, Accuracy: 0.6240234375\n",
      "Batch: 27, Loss: 1.1705915927886963, Accuracy: 0.626953125\n",
      "Batch: 28, Loss: 1.1018304824829102, Accuracy: 0.6298828125\n",
      "Batch: 29, Loss: 1.1113070249557495, Accuracy: 0.626953125\n",
      "Batch: 30, Loss: 1.1318901777267456, Accuracy: 0.630859375\n",
      "Batch: 31, Loss: 1.2361421585083008, Accuracy: 0.5869140625\n",
      "Batch: 32, Loss: 1.1135659217834473, Accuracy: 0.6376953125\n",
      "Batch: 33, Loss: 1.0512516498565674, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.1243093013763428, Accuracy: 0.63671875\n",
      "Batch: 35, Loss: 1.1515032052993774, Accuracy: 0.615234375\n",
      "Batch: 36, Loss: 1.2229893207550049, Accuracy: 0.6005859375\n",
      "Batch: 37, Loss: 1.222485899925232, Accuracy: 0.6005859375\n",
      "Batch: 38, Loss: 1.1975328922271729, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.1261043548583984, Accuracy: 0.62109375\n",
      "Batch: 40, Loss: 1.1230878829956055, Accuracy: 0.63671875\n",
      "Batch: 41, Loss: 1.1518254280090332, Accuracy: 0.6171875\n",
      "Batch: 42, Loss: 1.106701135635376, Accuracy: 0.64453125\n",
      "Batch: 43, Loss: 1.0521087646484375, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.0543582439422607, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 1.134082555770874, Accuracy: 0.6201171875\n",
      "Batch: 46, Loss: 1.1835955381393433, Accuracy: 0.5966796875\n",
      "Batch: 47, Loss: 1.1276336908340454, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.1457542181015015, Accuracy: 0.62109375\n",
      "Batch: 49, Loss: 1.1809663772583008, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.1689749956130981, Accuracy: 0.6005859375\n",
      "Batch: 51, Loss: 1.2028993368148804, Accuracy: 0.599609375\n",
      "Batch: 52, Loss: 1.2803361415863037, Accuracy: 0.5712890625\n",
      "Batch: 53, Loss: 1.2589454650878906, Accuracy: 0.5869140625\n",
      "Batch: 54, Loss: 1.2340501546859741, Accuracy: 0.6025390625\n",
      "Batch: 55, Loss: 1.159355878829956, Accuracy: 0.6328125\n",
      "Batch: 56, Loss: 1.1074399948120117, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.1332471370697021, Accuracy: 0.634765625\n",
      "Batch: 58, Loss: 1.1869499683380127, Accuracy: 0.61328125\n",
      "Batch: 59, Loss: 1.1560074090957642, Accuracy: 0.634765625\n",
      "Batch: 60, Loss: 1.3146573305130005, Accuracy: 0.5791015625\n",
      "Batch: 61, Loss: 1.1884784698486328, Accuracy: 0.5966796875\n",
      "Batch: 62, Loss: 1.236344575881958, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.18367338180542, Accuracy: 0.6025390625\n",
      "Batch: 64, Loss: 1.255479097366333, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.1826547384262085, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.1898061037063599, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.188438892364502, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.1125638484954834, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.18339204788208, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.2304298877716064, Accuracy: 0.6083984375\n",
      "Batch: 71, Loss: 1.1814351081848145, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.2866427898406982, Accuracy: 0.5810546875\n",
      "Batch: 73, Loss: 1.2145848274230957, Accuracy: 0.5830078125\n",
      "Batch: 74, Loss: 1.1416027545928955, Accuracy: 0.6318359375\n",
      "Batch: 75, Loss: 1.1352579593658447, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.0904062986373901, Accuracy: 0.611328125\n",
      "Batch: 77, Loss: 1.081512689590454, Accuracy: 0.6376953125\n",
      "Batch: 78, Loss: 1.1107635498046875, Accuracy: 0.6328125\n",
      "Batch: 79, Loss: 1.1704416275024414, Accuracy: 0.6279296875\n",
      "Batch: 80, Loss: 1.1924831867218018, Accuracy: 0.609375\n",
      "Batch: 81, Loss: 1.161523461341858, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.1582213640213013, Accuracy: 0.609375\n",
      "Batch: 83, Loss: 1.2570421695709229, Accuracy: 0.6142578125\n",
      "Batch: 84, Loss: 1.1677402257919312, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.181354284286499, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.2341731786727905, Accuracy: 0.5869140625\n",
      "Batch: 87, Loss: 1.222245216369629, Accuracy: 0.6103515625\n",
      "Batch: 88, Loss: 1.273796558380127, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.1629431247711182, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.119248390197754, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.152099370956421, Accuracy: 0.6259765625\n",
      "Batch: 92, Loss: 1.1219632625579834, Accuracy: 0.6513671875\n",
      "Batch: 93, Loss: 1.1796265840530396, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.217317819595337, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.2259984016418457, Accuracy: 0.6015625\n",
      "Batch: 96, Loss: 1.2599108219146729, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.145392656326294, Accuracy: 0.6396484375\n",
      "Batch: 98, Loss: 1.1201300621032715, Accuracy: 0.6298828125\n",
      "Batch: 99, Loss: 1.1287450790405273, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.065856695175171, Accuracy: 0.6650390625\n",
      "Batch: 101, Loss: 1.1569526195526123, Accuracy: 0.62109375\n",
      "Batch: 102, Loss: 1.1991455554962158, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.1780420541763306, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1547434329986572, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.2399623394012451, Accuracy: 0.6025390625\n",
      "Batch: 106, Loss: 1.2188518047332764, Accuracy: 0.599609375\n",
      "Batch: 107, Loss: 1.3056209087371826, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.1354461908340454, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.2504992485046387, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 1.1435205936431885, Accuracy: 0.6201171875\n",
      "Batch: 111, Loss: 1.124352216720581, Accuracy: 0.630859375\n",
      "Batch: 112, Loss: 1.1100116968154907, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.1903023719787598, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.1965690851211548, Accuracy: 0.6142578125\n",
      "Batch: 115, Loss: 1.1811455488204956, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.210111141204834, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.2187232971191406, Accuracy: 0.60546875\n",
      "Batch: 118, Loss: 1.2148463726043701, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.2401593923568726, Accuracy: 0.5849609375\n",
      "Batch: 120, Loss: 1.3129360675811768, Accuracy: 0.57421875\n",
      "Batch: 121, Loss: 1.2317748069763184, Accuracy: 0.611328125\n",
      "Batch: 122, Loss: 1.2613670825958252, Accuracy: 0.6083984375\n",
      "Batch: 123, Loss: 1.1684870719909668, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.207167625427246, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.1967217922210693, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.2321722507476807, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.2336716651916504, Accuracy: 0.6171875\n",
      "Batch: 128, Loss: 1.2069603204727173, Accuracy: 0.6103515625\n",
      "Batch: 129, Loss: 1.2249929904937744, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.1608625650405884, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.1907579898834229, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.1679131984710693, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.2482532262802124, Accuracy: 0.6025390625\n",
      "Batch: 134, Loss: 1.1321289539337158, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.0922186374664307, Accuracy: 0.6328125\n",
      "Batch: 136, Loss: 1.116825819015503, Accuracy: 0.6513671875\n",
      "Batch: 137, Loss: 1.2075047492980957, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.2872021198272705, Accuracy: 0.58203125\n",
      "Batch: 139, Loss: 1.258827805519104, Accuracy: 0.5869140625\n",
      "Batch: 140, Loss: 1.2801990509033203, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.179947853088379, Accuracy: 0.6220703125\n",
      "Batch: 142, Loss: 1.168778419494629, Accuracy: 0.626953125\n",
      "Batch: 143, Loss: 1.225412368774414, Accuracy: 0.59375\n",
      "Batch: 144, Loss: 1.3316514492034912, Accuracy: 0.564453125\n",
      "Batch: 145, Loss: 1.2782835960388184, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.2128748893737793, Accuracy: 0.5986328125\n",
      "Batch: 147, Loss: 1.2851158380508423, Accuracy: 0.5927734375\n",
      "Batch: 148, Loss: 1.1969521045684814, Accuracy: 0.5986328125\n",
      "Batch: 149, Loss: 1.176635980606079, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.2356131076812744, Accuracy: 0.6005859375\n",
      "Batch: 151, Loss: 1.1527012586593628, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.1744451522827148, Accuracy: 0.6064453125\n",
      "Batch: 153, Loss: 1.15129554271698, Accuracy: 0.6181640625\n",
      "Batch: 154, Loss: 1.1346038579940796, Accuracy: 0.625\n",
      "Batch: 155, Loss: 1.106306791305542, Accuracy: 0.6435546875\n",
      "Epoch 454/200\n",
      "Batch: 1, Loss: 1.2159245014190674, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 1.1053617000579834, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3, Loss: 1.0582976341247559, Accuracy: 0.646484375\n",
      "Batch: 4, Loss: 1.132434368133545, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 1.060903787612915, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.1009032726287842, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.044224739074707, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.9862029552459717, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 1.043114185333252, Accuracy: 0.6552734375\n",
      "Batch: 10, Loss: 0.9684053063392639, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 1.0108320713043213, Accuracy: 0.677734375\n",
      "Batch: 12, Loss: 1.0408904552459717, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0540366172790527, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 1.0729979276657104, Accuracy: 0.642578125\n",
      "Batch: 15, Loss: 0.9692922234535217, Accuracy: 0.6689453125\n",
      "Batch: 16, Loss: 1.0909792184829712, Accuracy: 0.646484375\n",
      "Batch: 17, Loss: 1.105116367340088, Accuracy: 0.6298828125\n",
      "Batch: 18, Loss: 1.098645567893982, Accuracy: 0.6416015625\n",
      "Batch: 19, Loss: 1.1815340518951416, Accuracy: 0.6318359375\n",
      "Batch: 20, Loss: 1.1391246318817139, Accuracy: 0.6318359375\n",
      "Batch: 21, Loss: 1.099163293838501, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.2517852783203125, Accuracy: 0.59375\n",
      "Batch: 23, Loss: 1.275883436203003, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.1861244440078735, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.1238248348236084, Accuracy: 0.6337890625\n",
      "Batch: 26, Loss: 1.1975007057189941, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.1628010272979736, Accuracy: 0.599609375\n",
      "Batch: 28, Loss: 1.123218059539795, Accuracy: 0.62890625\n",
      "Batch: 29, Loss: 1.09356689453125, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.1879148483276367, Accuracy: 0.599609375\n",
      "Batch: 31, Loss: 1.2439541816711426, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.0702998638153076, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 1.0351486206054688, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.1559817790985107, Accuracy: 0.626953125\n",
      "Batch: 35, Loss: 1.2064735889434814, Accuracy: 0.607421875\n",
      "Batch: 36, Loss: 1.239661693572998, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.2576900720596313, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.1923785209655762, Accuracy: 0.607421875\n",
      "Batch: 39, Loss: 1.0769832134246826, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.1340094804763794, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1420176029205322, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.064823865890503, Accuracy: 0.6689453125\n",
      "Batch: 43, Loss: 1.0452210903167725, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0013240575790405, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.0798401832580566, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.1176029443740845, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.0978057384490967, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1415328979492188, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.2175556421279907, Accuracy: 0.603515625\n",
      "Batch: 50, Loss: 1.1296019554138184, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.199904203414917, Accuracy: 0.599609375\n",
      "Batch: 52, Loss: 1.282935619354248, Accuracy: 0.5888671875\n",
      "Batch: 53, Loss: 1.1711680889129639, Accuracy: 0.6171875\n",
      "Batch: 54, Loss: 1.2158491611480713, Accuracy: 0.5966796875\n",
      "Batch: 55, Loss: 1.1682806015014648, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.136808156967163, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.1105815172195435, Accuracy: 0.6455078125\n",
      "Batch: 58, Loss: 1.174034833908081, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.1709132194519043, Accuracy: 0.6181640625\n",
      "Batch: 60, Loss: 1.2846593856811523, Accuracy: 0.5791015625\n",
      "Batch: 61, Loss: 1.1642649173736572, Accuracy: 0.6455078125\n",
      "Batch: 62, Loss: 1.188985824584961, Accuracy: 0.6201171875\n",
      "Batch: 63, Loss: 1.194388508796692, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.209578514099121, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.2019593715667725, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.2031102180480957, Accuracy: 0.615234375\n",
      "Batch: 67, Loss: 1.1779241561889648, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.0703694820404053, Accuracy: 0.65234375\n",
      "Batch: 69, Loss: 1.1771469116210938, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.1786999702453613, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.1749889850616455, Accuracy: 0.62109375\n",
      "Batch: 72, Loss: 1.241923451423645, Accuracy: 0.60546875\n",
      "Batch: 73, Loss: 1.2255134582519531, Accuracy: 0.609375\n",
      "Batch: 74, Loss: 1.1168034076690674, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.1386488676071167, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.0953913927078247, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.13704252243042, Accuracy: 0.630859375\n",
      "Batch: 78, Loss: 1.0765531063079834, Accuracy: 0.6533203125\n",
      "Batch: 79, Loss: 1.163914680480957, Accuracy: 0.6435546875\n",
      "Batch: 80, Loss: 1.2128156423568726, Accuracy: 0.6064453125\n",
      "Batch: 81, Loss: 1.126213788986206, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.125974178314209, Accuracy: 0.6259765625\n",
      "Batch: 83, Loss: 1.185471773147583, Accuracy: 0.6142578125\n",
      "Batch: 84, Loss: 1.1534900665283203, Accuracy: 0.62890625\n",
      "Batch: 85, Loss: 1.1706271171569824, Accuracy: 0.6240234375\n",
      "Batch: 86, Loss: 1.2179957628250122, Accuracy: 0.60546875\n",
      "Batch: 87, Loss: 1.245511531829834, Accuracy: 0.5908203125\n",
      "Batch: 88, Loss: 1.2075068950653076, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.1443848609924316, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.1384515762329102, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.1758650541305542, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.1669511795043945, Accuracy: 0.6240234375\n",
      "Batch: 93, Loss: 1.152050495147705, Accuracy: 0.615234375\n",
      "Batch: 94, Loss: 1.208577036857605, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.1886992454528809, Accuracy: 0.623046875\n",
      "Batch: 96, Loss: 1.2113910913467407, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.2093541622161865, Accuracy: 0.5908203125\n",
      "Batch: 98, Loss: 1.1119041442871094, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.1746671199798584, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.098022222518921, Accuracy: 0.6337890625\n",
      "Batch: 101, Loss: 1.1308307647705078, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2421214580535889, Accuracy: 0.5966796875\n",
      "Batch: 103, Loss: 1.1560640335083008, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.230887532234192, Accuracy: 0.61328125\n",
      "Batch: 105, Loss: 1.2201812267303467, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.2474380731582642, Accuracy: 0.58984375\n",
      "Batch: 107, Loss: 1.27725088596344, Accuracy: 0.5927734375\n",
      "Batch: 108, Loss: 1.1801583766937256, Accuracy: 0.5908203125\n",
      "Batch: 109, Loss: 1.1836458444595337, Accuracy: 0.6220703125\n",
      "Batch: 110, Loss: 1.2311899662017822, Accuracy: 0.5888671875\n",
      "Batch: 111, Loss: 1.1391050815582275, Accuracy: 0.6298828125\n",
      "Batch: 112, Loss: 1.1156436204910278, Accuracy: 0.6494140625\n",
      "Batch: 113, Loss: 1.212864637374878, Accuracy: 0.6005859375\n",
      "Batch: 114, Loss: 1.1856117248535156, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.164837121963501, Accuracy: 0.6142578125\n",
      "Batch: 116, Loss: 1.250981092453003, Accuracy: 0.607421875\n",
      "Batch: 117, Loss: 1.1767058372497559, Accuracy: 0.6103515625\n",
      "Batch: 118, Loss: 1.2506380081176758, Accuracy: 0.5859375\n",
      "Batch: 119, Loss: 1.2240509986877441, Accuracy: 0.5888671875\n",
      "Batch: 120, Loss: 1.3478789329528809, Accuracy: 0.578125\n",
      "Batch: 121, Loss: 1.2580735683441162, Accuracy: 0.603515625\n",
      "Batch: 122, Loss: 1.2287017107009888, Accuracy: 0.5966796875\n",
      "Batch: 123, Loss: 1.1712520122528076, Accuracy: 0.62890625\n",
      "Batch: 124, Loss: 1.2445564270019531, Accuracy: 0.5966796875\n",
      "Batch: 125, Loss: 1.1497814655303955, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.2471027374267578, Accuracy: 0.6162109375\n",
      "Batch: 127, Loss: 1.2520115375518799, Accuracy: 0.5869140625\n",
      "Batch: 128, Loss: 1.2578473091125488, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.155454397201538, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.165747880935669, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.2167500257492065, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.135787010192871, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.2080632448196411, Accuracy: 0.6015625\n",
      "Batch: 134, Loss: 1.1173713207244873, Accuracy: 0.64453125\n",
      "Batch: 135, Loss: 1.0555130243301392, Accuracy: 0.6533203125\n",
      "Batch: 136, Loss: 1.1301851272583008, Accuracy: 0.6318359375\n",
      "Batch: 137, Loss: 1.1945347785949707, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.2883565425872803, Accuracy: 0.568359375\n",
      "Batch: 139, Loss: 1.2036330699920654, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.2539671659469604, Accuracy: 0.6181640625\n",
      "Batch: 141, Loss: 1.1871440410614014, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 142, Loss: 1.2051851749420166, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.213278889656067, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.311606764793396, Accuracy: 0.578125\n",
      "Batch: 145, Loss: 1.2296719551086426, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.1982645988464355, Accuracy: 0.6162109375\n",
      "Batch: 147, Loss: 1.2093021869659424, Accuracy: 0.6103515625\n",
      "Batch: 148, Loss: 1.285341501235962, Accuracy: 0.5888671875\n",
      "Batch: 149, Loss: 1.2060682773590088, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.218177080154419, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.1717827320098877, Accuracy: 0.6171875\n",
      "Batch: 152, Loss: 1.2054662704467773, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.1752738952636719, Accuracy: 0.6259765625\n",
      "Batch: 154, Loss: 1.1980056762695312, Accuracy: 0.5966796875\n",
      "Batch: 155, Loss: 1.1528587341308594, Accuracy: 0.60546875\n",
      "Epoch 455/200\n",
      "Batch: 1, Loss: 1.2493878602981567, Accuracy: 0.626953125\n",
      "Batch: 2, Loss: 1.1051685810089111, Accuracy: 0.6171875\n",
      "Batch: 3, Loss: 1.077157974243164, Accuracy: 0.6474609375\n",
      "Batch: 4, Loss: 1.0919625759124756, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 0.9973648190498352, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.1097309589385986, Accuracy: 0.6376953125\n",
      "Batch: 7, Loss: 1.0591386556625366, Accuracy: 0.642578125\n",
      "Batch: 8, Loss: 1.016782283782959, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0116792917251587, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 1.0022083520889282, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 0.9754005670547485, Accuracy: 0.6689453125\n",
      "Batch: 12, Loss: 1.0163415670394897, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 1.0855382680892944, Accuracy: 0.6435546875\n",
      "Batch: 14, Loss: 1.0093655586242676, Accuracy: 0.666015625\n",
      "Batch: 15, Loss: 0.9800069332122803, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0264919996261597, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.1466357707977295, Accuracy: 0.619140625\n",
      "Batch: 18, Loss: 1.1257094144821167, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2451870441436768, Accuracy: 0.5966796875\n",
      "Batch: 20, Loss: 1.1103355884552002, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.1066927909851074, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.2989206314086914, Accuracy: 0.57421875\n",
      "Batch: 23, Loss: 1.2661020755767822, Accuracy: 0.5791015625\n",
      "Batch: 24, Loss: 1.1271532773971558, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.2008638381958008, Accuracy: 0.595703125\n",
      "Batch: 26, Loss: 1.2342443466186523, Accuracy: 0.5966796875\n",
      "Batch: 27, Loss: 1.1430531740188599, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.1248258352279663, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.1342966556549072, Accuracy: 0.6328125\n",
      "Batch: 30, Loss: 1.2017855644226074, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.246537446975708, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.0756531953811646, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 1.0417400598526, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.1158246994018555, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1719433069229126, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.2060108184814453, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.209747314453125, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.1260679960250854, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.1186590194702148, Accuracy: 0.6416015625\n",
      "Batch: 40, Loss: 1.1274442672729492, Accuracy: 0.6396484375\n",
      "Batch: 41, Loss: 1.1294775009155273, Accuracy: 0.64453125\n",
      "Batch: 42, Loss: 1.0485007762908936, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.062467336654663, Accuracy: 0.6611328125\n",
      "Batch: 44, Loss: 1.1094318628311157, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.0537983179092407, Accuracy: 0.6748046875\n",
      "Batch: 46, Loss: 1.1541730165481567, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.0799627304077148, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.1632072925567627, Accuracy: 0.6103515625\n",
      "Batch: 49, Loss: 1.1592624187469482, Accuracy: 0.6201171875\n",
      "Batch: 50, Loss: 1.1587015390396118, Accuracy: 0.6396484375\n",
      "Batch: 51, Loss: 1.1525440216064453, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.2947301864624023, Accuracy: 0.5751953125\n",
      "Batch: 53, Loss: 1.2067934274673462, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.1761292219161987, Accuracy: 0.62109375\n",
      "Batch: 55, Loss: 1.1949129104614258, Accuracy: 0.615234375\n",
      "Batch: 56, Loss: 1.1142959594726562, Accuracy: 0.6279296875\n",
      "Batch: 57, Loss: 1.0988506078720093, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.0892574787139893, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1843152046203613, Accuracy: 0.6083984375\n",
      "Batch: 60, Loss: 1.2106983661651611, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.1592334508895874, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.1104518175125122, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.179844617843628, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.2794197797775269, Accuracy: 0.5927734375\n",
      "Batch: 65, Loss: 1.257908582687378, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.0703651905059814, Accuracy: 0.6435546875\n",
      "Batch: 67, Loss: 1.211295485496521, Accuracy: 0.6064453125\n",
      "Batch: 68, Loss: 1.118239164352417, Accuracy: 0.64453125\n",
      "Batch: 69, Loss: 1.2237887382507324, Accuracy: 0.6064453125\n",
      "Batch: 70, Loss: 1.2113142013549805, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.213712453842163, Accuracy: 0.609375\n",
      "Batch: 72, Loss: 1.1806318759918213, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.2284523248672485, Accuracy: 0.609375\n",
      "Batch: 74, Loss: 1.1465566158294678, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.1259959936141968, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.1078894138336182, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.0908102989196777, Accuracy: 0.64453125\n",
      "Batch: 78, Loss: 1.1156096458435059, Accuracy: 0.6181640625\n",
      "Batch: 79, Loss: 1.1491734981536865, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.144005298614502, Accuracy: 0.6298828125\n",
      "Batch: 81, Loss: 1.2039713859558105, Accuracy: 0.6259765625\n",
      "Batch: 82, Loss: 1.1435412168502808, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.2464892864227295, Accuracy: 0.5986328125\n",
      "Batch: 84, Loss: 1.2029452323913574, Accuracy: 0.611328125\n",
      "Batch: 85, Loss: 1.2130610942840576, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.1724859476089478, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 1.1939525604248047, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.187232494354248, Accuracy: 0.6337890625\n",
      "Batch: 89, Loss: 1.1745202541351318, Accuracy: 0.611328125\n",
      "Batch: 90, Loss: 1.1253888607025146, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.2021585702896118, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.1325929164886475, Accuracy: 0.64453125\n",
      "Batch: 93, Loss: 1.1679766178131104, Accuracy: 0.6279296875\n",
      "Batch: 94, Loss: 1.2310436964035034, Accuracy: 0.6064453125\n",
      "Batch: 95, Loss: 1.1903046369552612, Accuracy: 0.625\n",
      "Batch: 96, Loss: 1.2300395965576172, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.1427676677703857, Accuracy: 0.638671875\n",
      "Batch: 98, Loss: 1.1433993577957153, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.1431641578674316, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.1218534708023071, Accuracy: 0.6357421875\n",
      "Batch: 101, Loss: 1.1254347562789917, Accuracy: 0.64453125\n",
      "Batch: 102, Loss: 1.2219483852386475, Accuracy: 0.5966796875\n",
      "Batch: 103, Loss: 1.156811237335205, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.1487059593200684, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.2480347156524658, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.211097002029419, Accuracy: 0.595703125\n",
      "Batch: 107, Loss: 1.2823853492736816, Accuracy: 0.5869140625\n",
      "Batch: 108, Loss: 1.2108657360076904, Accuracy: 0.6123046875\n",
      "Batch: 109, Loss: 1.2235095500946045, Accuracy: 0.6328125\n",
      "Batch: 110, Loss: 1.1842252016067505, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.1341943740844727, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0847408771514893, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.2253955602645874, Accuracy: 0.6162109375\n",
      "Batch: 114, Loss: 1.171692967414856, Accuracy: 0.6103515625\n",
      "Batch: 115, Loss: 1.1763321161270142, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.218705654144287, Accuracy: 0.6064453125\n",
      "Batch: 117, Loss: 1.2117143869400024, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.228888988494873, Accuracy: 0.5859375\n",
      "Batch: 119, Loss: 1.2799041271209717, Accuracy: 0.5849609375\n",
      "Batch: 120, Loss: 1.349424123764038, Accuracy: 0.5732421875\n",
      "Batch: 121, Loss: 1.2506968975067139, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.2137064933776855, Accuracy: 0.6142578125\n",
      "Batch: 123, Loss: 1.243079662322998, Accuracy: 0.6044921875\n",
      "Batch: 124, Loss: 1.2351505756378174, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.2455430030822754, Accuracy: 0.595703125\n",
      "Batch: 126, Loss: 1.295861005783081, Accuracy: 0.5869140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127, Loss: 1.312131643295288, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.2484374046325684, Accuracy: 0.6044921875\n",
      "Batch: 129, Loss: 1.219477891921997, Accuracy: 0.6083984375\n",
      "Batch: 130, Loss: 1.2044687271118164, Accuracy: 0.6181640625\n",
      "Batch: 131, Loss: 1.228644609451294, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.126407504081726, Accuracy: 0.6376953125\n",
      "Batch: 133, Loss: 1.1716538667678833, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.1432912349700928, Accuracy: 0.638671875\n",
      "Batch: 135, Loss: 1.0613688230514526, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.160668134689331, Accuracy: 0.6201171875\n",
      "Batch: 137, Loss: 1.1542036533355713, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.2935130596160889, Accuracy: 0.576171875\n",
      "Batch: 139, Loss: 1.226990818977356, Accuracy: 0.595703125\n",
      "Batch: 140, Loss: 1.237595796585083, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.2153966426849365, Accuracy: 0.609375\n",
      "Batch: 142, Loss: 1.1977492570877075, Accuracy: 0.6396484375\n",
      "Batch: 143, Loss: 1.2667324542999268, Accuracy: 0.5830078125\n",
      "Batch: 144, Loss: 1.2372021675109863, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.2839528322219849, Accuracy: 0.5869140625\n",
      "Batch: 146, Loss: 1.2406394481658936, Accuracy: 0.595703125\n",
      "Batch: 147, Loss: 1.2020407915115356, Accuracy: 0.6171875\n",
      "Batch: 148, Loss: 1.2994194030761719, Accuracy: 0.5908203125\n",
      "Batch: 149, Loss: 1.2083821296691895, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.177669882774353, Accuracy: 0.6240234375\n",
      "Batch: 151, Loss: 1.1795161962509155, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.2271342277526855, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.141892433166504, Accuracy: 0.623046875\n",
      "Batch: 154, Loss: 1.1761802434921265, Accuracy: 0.62109375\n",
      "Batch: 155, Loss: 1.1494537591934204, Accuracy: 0.634765625\n",
      "Epoch 456/200\n",
      "Batch: 1, Loss: 1.2809760570526123, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.1343258619308472, Accuracy: 0.638671875\n",
      "Batch: 3, Loss: 1.0384283065795898, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.0591843128204346, Accuracy: 0.634765625\n",
      "Batch: 5, Loss: 1.0455636978149414, Accuracy: 0.638671875\n",
      "Batch: 6, Loss: 1.0839552879333496, Accuracy: 0.6455078125\n",
      "Batch: 7, Loss: 1.0732017755508423, Accuracy: 0.630859375\n",
      "Batch: 8, Loss: 0.9684234261512756, Accuracy: 0.6806640625\n",
      "Batch: 9, Loss: 1.0140355825424194, Accuracy: 0.671875\n",
      "Batch: 10, Loss: 1.0338220596313477, Accuracy: 0.65234375\n",
      "Batch: 11, Loss: 0.9954551458358765, Accuracy: 0.66015625\n",
      "Batch: 12, Loss: 1.0179882049560547, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.0361502170562744, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.0307577848434448, Accuracy: 0.6533203125\n",
      "Batch: 15, Loss: 0.9615767002105713, Accuracy: 0.6806640625\n",
      "Batch: 16, Loss: 1.0373640060424805, Accuracy: 0.6513671875\n",
      "Batch: 17, Loss: 1.083869457244873, Accuracy: 0.62890625\n",
      "Batch: 18, Loss: 1.1509325504302979, Accuracy: 0.6142578125\n",
      "Batch: 19, Loss: 1.1956298351287842, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.1263446807861328, Accuracy: 0.642578125\n",
      "Batch: 21, Loss: 1.111377239227295, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.251737356185913, Accuracy: 0.595703125\n",
      "Batch: 23, Loss: 1.2859605550765991, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1805692911148071, Accuracy: 0.6201171875\n",
      "Batch: 25, Loss: 1.208418846130371, Accuracy: 0.5908203125\n",
      "Batch: 26, Loss: 1.1725873947143555, Accuracy: 0.6259765625\n",
      "Batch: 27, Loss: 1.1669244766235352, Accuracy: 0.6181640625\n",
      "Batch: 28, Loss: 1.110114574432373, Accuracy: 0.6298828125\n",
      "Batch: 29, Loss: 1.1051479578018188, Accuracy: 0.62890625\n",
      "Batch: 30, Loss: 1.2089741230010986, Accuracy: 0.5986328125\n",
      "Batch: 31, Loss: 1.2046658992767334, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.064767837524414, Accuracy: 0.6435546875\n",
      "Batch: 33, Loss: 1.0340604782104492, Accuracy: 0.6728515625\n",
      "Batch: 34, Loss: 1.1163969039916992, Accuracy: 0.6318359375\n",
      "Batch: 35, Loss: 1.1152334213256836, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.243687629699707, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.283099889755249, Accuracy: 0.568359375\n",
      "Batch: 38, Loss: 1.1651811599731445, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.1453866958618164, Accuracy: 0.6318359375\n",
      "Batch: 40, Loss: 1.147012710571289, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.173429250717163, Accuracy: 0.6083984375\n",
      "Batch: 42, Loss: 1.0858867168426514, Accuracy: 0.6298828125\n",
      "Batch: 43, Loss: 1.0964237451553345, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.122057318687439, Accuracy: 0.6328125\n",
      "Batch: 45, Loss: 1.1041651964187622, Accuracy: 0.638671875\n",
      "Batch: 46, Loss: 1.201737403869629, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.1461026668548584, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.178830862045288, Accuracy: 0.6064453125\n",
      "Batch: 49, Loss: 1.2488911151885986, Accuracy: 0.6064453125\n",
      "Batch: 50, Loss: 1.1440833806991577, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.164992094039917, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.3118314743041992, Accuracy: 0.5771484375\n",
      "Batch: 53, Loss: 1.2185888290405273, Accuracy: 0.6083984375\n",
      "Batch: 54, Loss: 1.212083339691162, Accuracy: 0.599609375\n",
      "Batch: 55, Loss: 1.103092908859253, Accuracy: 0.623046875\n",
      "Batch: 56, Loss: 1.0878654718399048, Accuracy: 0.6650390625\n",
      "Batch: 57, Loss: 1.118201732635498, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.1988970041275024, Accuracy: 0.603515625\n",
      "Batch: 59, Loss: 1.1589723825454712, Accuracy: 0.6142578125\n",
      "Batch: 60, Loss: 1.2874531745910645, Accuracy: 0.5791015625\n",
      "Batch: 61, Loss: 1.1926360130310059, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.1701557636260986, Accuracy: 0.6064453125\n",
      "Batch: 63, Loss: 1.2010760307312012, Accuracy: 0.6083984375\n",
      "Batch: 64, Loss: 1.2074875831604004, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.2167963981628418, Accuracy: 0.5947265625\n",
      "Batch: 66, Loss: 1.1848206520080566, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.1858460903167725, Accuracy: 0.6455078125\n",
      "Batch: 68, Loss: 1.1217896938323975, Accuracy: 0.6337890625\n",
      "Batch: 69, Loss: 1.2099566459655762, Accuracy: 0.599609375\n",
      "Batch: 70, Loss: 1.1678967475891113, Accuracy: 0.6220703125\n",
      "Batch: 71, Loss: 1.2051116228103638, Accuracy: 0.603515625\n",
      "Batch: 72, Loss: 1.20002281665802, Accuracy: 0.609375\n",
      "Batch: 73, Loss: 1.1970800161361694, Accuracy: 0.6201171875\n",
      "Batch: 74, Loss: 1.1180150508880615, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.125874400138855, Accuracy: 0.6376953125\n",
      "Batch: 76, Loss: 1.14576256275177, Accuracy: 0.625\n",
      "Batch: 77, Loss: 1.068329095840454, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.097304344177246, Accuracy: 0.6572265625\n",
      "Batch: 79, Loss: 1.1960207223892212, Accuracy: 0.6259765625\n",
      "Batch: 80, Loss: 1.1596254110336304, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.1820284128189087, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.1360509395599365, Accuracy: 0.6376953125\n",
      "Batch: 83, Loss: 1.241351842880249, Accuracy: 0.595703125\n",
      "Batch: 84, Loss: 1.2140419483184814, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.2023546695709229, Accuracy: 0.6083984375\n",
      "Batch: 86, Loss: 1.2390855550765991, Accuracy: 0.6044921875\n",
      "Batch: 87, Loss: 1.1582422256469727, Accuracy: 0.6279296875\n",
      "Batch: 88, Loss: 1.210922122001648, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.1468846797943115, Accuracy: 0.630859375\n",
      "Batch: 90, Loss: 1.160775065422058, Accuracy: 0.611328125\n",
      "Batch: 91, Loss: 1.1705753803253174, Accuracy: 0.6103515625\n",
      "Batch: 92, Loss: 1.145740270614624, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.1299748420715332, Accuracy: 0.6328125\n",
      "Batch: 94, Loss: 1.2462050914764404, Accuracy: 0.59765625\n",
      "Batch: 95, Loss: 1.2084197998046875, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.2196011543273926, Accuracy: 0.6142578125\n",
      "Batch: 97, Loss: 1.2075204849243164, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1090238094329834, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.150153398513794, Accuracy: 0.6240234375\n",
      "Batch: 100, Loss: 1.108847975730896, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.1338205337524414, Accuracy: 0.630859375\n",
      "Batch: 102, Loss: 1.1509010791778564, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.193225622177124, Accuracy: 0.6015625\n",
      "Batch: 104, Loss: 1.1583633422851562, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.2337723970413208, Accuracy: 0.615234375\n",
      "Batch: 106, Loss: 1.1860053539276123, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.2605379819869995, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.2027153968811035, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.2671520709991455, Accuracy: 0.5712890625\n",
      "Batch: 110, Loss: 1.1449620723724365, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 1.1472660303115845, Accuracy: 0.6162109375\n",
      "Batch: 112, Loss: 1.1604135036468506, Accuracy: 0.62109375\n",
      "Batch: 113, Loss: 1.1754555702209473, Accuracy: 0.6142578125\n",
      "Batch: 114, Loss: 1.2134971618652344, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.2339379787445068, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.2232427597045898, Accuracy: 0.6044921875\n",
      "Batch: 117, Loss: 1.220086693763733, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.2657215595245361, Accuracy: 0.5869140625\n",
      "Batch: 119, Loss: 1.3282146453857422, Accuracy: 0.5576171875\n",
      "Batch: 120, Loss: 1.3008908033370972, Accuracy: 0.5771484375\n",
      "Batch: 121, Loss: 1.1786887645721436, Accuracy: 0.59765625\n",
      "Batch: 122, Loss: 1.2407097816467285, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.1844816207885742, Accuracy: 0.6337890625\n",
      "Batch: 124, Loss: 1.2775156497955322, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.194498062133789, Accuracy: 0.626953125\n",
      "Batch: 126, Loss: 1.2831730842590332, Accuracy: 0.5927734375\n",
      "Batch: 127, Loss: 1.248065710067749, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.2165348529815674, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.1672859191894531, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.1348247528076172, Accuracy: 0.634765625\n",
      "Batch: 131, Loss: 1.2533860206604004, Accuracy: 0.6015625\n",
      "Batch: 132, Loss: 1.1109068393707275, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.2103233337402344, Accuracy: 0.6064453125\n",
      "Batch: 134, Loss: 1.1580621004104614, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.0601980686187744, Accuracy: 0.66015625\n",
      "Batch: 136, Loss: 1.1421537399291992, Accuracy: 0.6318359375\n",
      "Batch: 137, Loss: 1.1996725797653198, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.2981288433074951, Accuracy: 0.578125\n",
      "Batch: 139, Loss: 1.1819285154342651, Accuracy: 0.62890625\n",
      "Batch: 140, Loss: 1.2285356521606445, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.229743480682373, Accuracy: 0.6025390625\n",
      "Batch: 142, Loss: 1.172857642173767, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.2190840244293213, Accuracy: 0.615234375\n",
      "Batch: 144, Loss: 1.286858320236206, Accuracy: 0.5947265625\n",
      "Batch: 145, Loss: 1.3100688457489014, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.203149437904358, Accuracy: 0.6220703125\n",
      "Batch: 147, Loss: 1.1756832599639893, Accuracy: 0.623046875\n",
      "Batch: 148, Loss: 1.2486841678619385, Accuracy: 0.5859375\n",
      "Batch: 149, Loss: 1.1775538921356201, Accuracy: 0.611328125\n",
      "Batch: 150, Loss: 1.2152438163757324, Accuracy: 0.6103515625\n",
      "Batch: 151, Loss: 1.138415813446045, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.1545766592025757, Accuracy: 0.6123046875\n",
      "Batch: 153, Loss: 1.1546046733856201, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.0802290439605713, Accuracy: 0.646484375\n",
      "Batch: 155, Loss: 1.1421326398849487, Accuracy: 0.630859375\n",
      "Epoch 457/200\n",
      "Batch: 1, Loss: 1.2804205417633057, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.0937154293060303, Accuracy: 0.6416015625\n",
      "Batch: 3, Loss: 1.0563549995422363, Accuracy: 0.6376953125\n",
      "Batch: 4, Loss: 1.2005468606948853, Accuracy: 0.60546875\n",
      "Batch: 5, Loss: 1.0478410720825195, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.1160109043121338, Accuracy: 0.6494140625\n",
      "Batch: 7, Loss: 1.0333728790283203, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9941869974136353, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 1.071677803993225, Accuracy: 0.6494140625\n",
      "Batch: 10, Loss: 0.9665436744689941, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 1.0378532409667969, Accuracy: 0.6611328125\n",
      "Batch: 12, Loss: 1.09018874168396, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0352981090545654, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 1.0104694366455078, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 1.030105710029602, Accuracy: 0.6630859375\n",
      "Batch: 16, Loss: 1.0616225004196167, Accuracy: 0.6513671875\n",
      "Batch: 17, Loss: 1.1080154180526733, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.1634039878845215, Accuracy: 0.6201171875\n",
      "Batch: 19, Loss: 1.2835227251052856, Accuracy: 0.560546875\n",
      "Batch: 20, Loss: 1.1164250373840332, Accuracy: 0.6201171875\n",
      "Batch: 21, Loss: 1.0717577934265137, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.2023608684539795, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.3032715320587158, Accuracy: 0.5830078125\n",
      "Batch: 24, Loss: 1.170920491218567, Accuracy: 0.603515625\n",
      "Batch: 25, Loss: 1.1713203191757202, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.230989694595337, Accuracy: 0.6162109375\n",
      "Batch: 27, Loss: 1.1809908151626587, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.0559104681015015, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.0621483325958252, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.2046273946762085, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.2770198583602905, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.0433133840560913, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 1.0232980251312256, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.1605819463729858, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1756699085235596, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.2382497787475586, Accuracy: 0.591796875\n",
      "Batch: 37, Loss: 1.302781581878662, Accuracy: 0.587890625\n",
      "Batch: 38, Loss: 1.207668662071228, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.1423722505569458, Accuracy: 0.625\n",
      "Batch: 40, Loss: 1.1218807697296143, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1904418468475342, Accuracy: 0.6083984375\n",
      "Batch: 42, Loss: 1.0646766424179077, Accuracy: 0.6396484375\n",
      "Batch: 43, Loss: 1.088682770729065, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 1.0942363739013672, Accuracy: 0.6298828125\n",
      "Batch: 45, Loss: 1.0791388750076294, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1844713687896729, Accuracy: 0.587890625\n",
      "Batch: 47, Loss: 1.090446949005127, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.1518466472625732, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1547002792358398, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.2148761749267578, Accuracy: 0.61328125\n",
      "Batch: 51, Loss: 1.1511929035186768, Accuracy: 0.6083984375\n",
      "Batch: 52, Loss: 1.3247212171554565, Accuracy: 0.5595703125\n",
      "Batch: 53, Loss: 1.1954283714294434, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.2099144458770752, Accuracy: 0.595703125\n",
      "Batch: 55, Loss: 1.1480854749679565, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.1703256368637085, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.1920894384384155, Accuracy: 0.61328125\n",
      "Batch: 58, Loss: 1.1640136241912842, Accuracy: 0.61328125\n",
      "Batch: 59, Loss: 1.1476482152938843, Accuracy: 0.6591796875\n",
      "Batch: 60, Loss: 1.304020643234253, Accuracy: 0.59375\n",
      "Batch: 61, Loss: 1.1705677509307861, Accuracy: 0.6220703125\n",
      "Batch: 62, Loss: 1.1641072034835815, Accuracy: 0.619140625\n",
      "Batch: 63, Loss: 1.165642261505127, Accuracy: 0.615234375\n",
      "Batch: 64, Loss: 1.20125412940979, Accuracy: 0.591796875\n",
      "Batch: 65, Loss: 1.153985619544983, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.198591709136963, Accuracy: 0.6083984375\n",
      "Batch: 67, Loss: 1.1545236110687256, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.115901231765747, Accuracy: 0.6513671875\n",
      "Batch: 69, Loss: 1.2163928747177124, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.1872422695159912, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1753227710723877, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.2627506256103516, Accuracy: 0.6005859375\n",
      "Batch: 73, Loss: 1.1839276552200317, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.115018367767334, Accuracy: 0.650390625\n",
      "Batch: 75, Loss: 1.1440908908843994, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.104452133178711, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.065418004989624, Accuracy: 0.6396484375\n",
      "Batch: 78, Loss: 1.1231344938278198, Accuracy: 0.615234375\n",
      "Batch: 79, Loss: 1.1322689056396484, Accuracy: 0.638671875\n",
      "Batch: 80, Loss: 1.1859121322631836, Accuracy: 0.5947265625\n",
      "Batch: 81, Loss: 1.119147539138794, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.1529123783111572, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 1.26375150680542, Accuracy: 0.5927734375\n",
      "Batch: 84, Loss: 1.167156457901001, Accuracy: 0.6171875\n",
      "Batch: 85, Loss: 1.1384357213974, Accuracy: 0.638671875\n",
      "Batch: 86, Loss: 1.266398310661316, Accuracy: 0.58203125\n",
      "Batch: 87, Loss: 1.237565040588379, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.2336814403533936, Accuracy: 0.58984375\n",
      "Batch: 89, Loss: 1.1533846855163574, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.1721806526184082, Accuracy: 0.6123046875\n",
      "Batch: 91, Loss: 1.195460557937622, Accuracy: 0.62109375\n",
      "Batch: 92, Loss: 1.1835591793060303, Accuracy: 0.6298828125\n",
      "Batch: 93, Loss: 1.1535820960998535, Accuracy: 0.625\n",
      "Batch: 94, Loss: 1.1914803981781006, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.264609456062317, Accuracy: 0.59765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 1.2259825468063354, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.1647543907165527, Accuracy: 0.611328125\n",
      "Batch: 98, Loss: 1.152155876159668, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.1288130283355713, Accuracy: 0.63671875\n",
      "Batch: 100, Loss: 1.0960816144943237, Accuracy: 0.6240234375\n",
      "Batch: 101, Loss: 1.1346155405044556, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.1548585891723633, Accuracy: 0.6328125\n",
      "Batch: 103, Loss: 1.2289313077926636, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.1368358135223389, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.2540521621704102, Accuracy: 0.5830078125\n",
      "Batch: 106, Loss: 1.214250922203064, Accuracy: 0.59375\n",
      "Batch: 107, Loss: 1.2369914054870605, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.2072052955627441, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.223818063735962, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 1.1208531856536865, Accuracy: 0.6298828125\n",
      "Batch: 111, Loss: 1.143186330795288, Accuracy: 0.6455078125\n",
      "Batch: 112, Loss: 1.1182315349578857, Accuracy: 0.6513671875\n",
      "Batch: 113, Loss: 1.2181499004364014, Accuracy: 0.6142578125\n",
      "Batch: 114, Loss: 1.1692883968353271, Accuracy: 0.6103515625\n",
      "Batch: 115, Loss: 1.2206754684448242, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.2023756504058838, Accuracy: 0.58984375\n",
      "Batch: 117, Loss: 1.1576156616210938, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.2796361446380615, Accuracy: 0.5888671875\n",
      "Batch: 119, Loss: 1.2186636924743652, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.3220176696777344, Accuracy: 0.5830078125\n",
      "Batch: 121, Loss: 1.2224853038787842, Accuracy: 0.603515625\n",
      "Batch: 122, Loss: 1.2331655025482178, Accuracy: 0.6005859375\n",
      "Batch: 123, Loss: 1.174182653427124, Accuracy: 0.6123046875\n",
      "Batch: 124, Loss: 1.3047902584075928, Accuracy: 0.6025390625\n",
      "Batch: 125, Loss: 1.1747208833694458, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.289426565170288, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.2442954778671265, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2015575170516968, Accuracy: 0.6123046875\n",
      "Batch: 129, Loss: 1.1957213878631592, Accuracy: 0.6259765625\n",
      "Batch: 130, Loss: 1.1362804174423218, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.2561372518539429, Accuracy: 0.5849609375\n",
      "Batch: 132, Loss: 1.1006333827972412, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.1449919939041138, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1754381656646729, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.0956649780273438, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.0832695960998535, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.2037208080291748, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.2356772422790527, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.2219328880310059, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.2745622396469116, Accuracy: 0.5947265625\n",
      "Batch: 141, Loss: 1.2239421606063843, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.191279649734497, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.2058970928192139, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.272916555404663, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.2530487775802612, Accuracy: 0.611328125\n",
      "Batch: 146, Loss: 1.2149724960327148, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.217523455619812, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.1939400434494019, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 1.21540105342865, Accuracy: 0.58203125\n",
      "Batch: 150, Loss: 1.1688722372055054, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.1543552875518799, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.201561450958252, Accuracy: 0.6162109375\n",
      "Batch: 153, Loss: 1.1747949123382568, Accuracy: 0.6474609375\n",
      "Batch: 154, Loss: 1.1527483463287354, Accuracy: 0.6162109375\n",
      "Batch: 155, Loss: 1.1138511896133423, Accuracy: 0.642578125\n",
      "Epoch 458/200\n",
      "Batch: 1, Loss: 1.2987711429595947, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.0634649991989136, Accuracy: 0.6650390625\n",
      "Batch: 3, Loss: 1.0420860052108765, Accuracy: 0.6484375\n",
      "Batch: 4, Loss: 1.081055760383606, Accuracy: 0.6474609375\n",
      "Batch: 5, Loss: 1.0547250509262085, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.0802006721496582, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 1.0635404586791992, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0202257633209229, Accuracy: 0.6728515625\n",
      "Batch: 9, Loss: 1.0796451568603516, Accuracy: 0.6552734375\n",
      "Batch: 10, Loss: 1.0243664979934692, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.0748658180236816, Accuracy: 0.654296875\n",
      "Batch: 12, Loss: 1.0627110004425049, Accuracy: 0.65625\n",
      "Batch: 13, Loss: 1.085578441619873, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.0159506797790527, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 1.0719021558761597, Accuracy: 0.646484375\n",
      "Batch: 16, Loss: 1.088474154472351, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0680841207504272, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.1726226806640625, Accuracy: 0.6298828125\n",
      "Batch: 19, Loss: 1.2435016632080078, Accuracy: 0.6005859375\n",
      "Batch: 20, Loss: 1.1334545612335205, Accuracy: 0.6376953125\n",
      "Batch: 21, Loss: 1.1254414319992065, Accuracy: 0.625\n",
      "Batch: 22, Loss: 1.2103278636932373, Accuracy: 0.6103515625\n",
      "Batch: 23, Loss: 1.271447777748108, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.133987545967102, Accuracy: 0.6318359375\n",
      "Batch: 25, Loss: 1.1921143531799316, Accuracy: 0.6103515625\n",
      "Batch: 26, Loss: 1.2008545398712158, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.1443984508514404, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.1704058647155762, Accuracy: 0.6103515625\n",
      "Batch: 29, Loss: 1.1342952251434326, Accuracy: 0.6328125\n",
      "Batch: 30, Loss: 1.2381294965744019, Accuracy: 0.599609375\n",
      "Batch: 31, Loss: 1.207775354385376, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 1.0598427057266235, Accuracy: 0.6513671875\n",
      "Batch: 33, Loss: 1.0460655689239502, Accuracy: 0.6484375\n",
      "Batch: 34, Loss: 1.0506370067596436, Accuracy: 0.6669921875\n",
      "Batch: 35, Loss: 1.1908843517303467, Accuracy: 0.603515625\n",
      "Batch: 36, Loss: 1.242652177810669, Accuracy: 0.6044921875\n",
      "Batch: 37, Loss: 1.2438486814498901, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.2042512893676758, Accuracy: 0.6240234375\n",
      "Batch: 39, Loss: 1.1240899562835693, Accuracy: 0.623046875\n",
      "Batch: 40, Loss: 1.1346147060394287, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1955686807632446, Accuracy: 0.6220703125\n",
      "Batch: 42, Loss: 1.134047269821167, Accuracy: 0.6259765625\n",
      "Batch: 43, Loss: 1.1203055381774902, Accuracy: 0.6201171875\n",
      "Batch: 44, Loss: 1.1240686178207397, Accuracy: 0.634765625\n",
      "Batch: 45, Loss: 1.116149663925171, Accuracy: 0.6298828125\n",
      "Batch: 46, Loss: 1.205336332321167, Accuracy: 0.599609375\n",
      "Batch: 47, Loss: 1.1303822994232178, Accuracy: 0.646484375\n",
      "Batch: 48, Loss: 1.1977934837341309, Accuracy: 0.6142578125\n",
      "Batch: 49, Loss: 1.1708300113677979, Accuracy: 0.625\n",
      "Batch: 50, Loss: 1.136732578277588, Accuracy: 0.6259765625\n",
      "Batch: 51, Loss: 1.1964964866638184, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.2552008628845215, Accuracy: 0.5859375\n",
      "Batch: 53, Loss: 1.2168529033660889, Accuracy: 0.587890625\n",
      "Batch: 54, Loss: 1.206083059310913, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.1476340293884277, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.156515121459961, Accuracy: 0.6376953125\n",
      "Batch: 57, Loss: 1.1524837017059326, Accuracy: 0.6376953125\n",
      "Batch: 58, Loss: 1.1240648031234741, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.2077178955078125, Accuracy: 0.599609375\n",
      "Batch: 60, Loss: 1.259425401687622, Accuracy: 0.5869140625\n",
      "Batch: 61, Loss: 1.1722099781036377, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.1950109004974365, Accuracy: 0.62109375\n",
      "Batch: 63, Loss: 1.2373991012573242, Accuracy: 0.6015625\n",
      "Batch: 64, Loss: 1.2473294734954834, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.197441577911377, Accuracy: 0.6181640625\n",
      "Batch: 66, Loss: 1.1718939542770386, Accuracy: 0.6142578125\n",
      "Batch: 67, Loss: 1.187134027481079, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.1560068130493164, Accuracy: 0.634765625\n",
      "Batch: 69, Loss: 1.2676461935043335, Accuracy: 0.58984375\n",
      "Batch: 70, Loss: 1.18584406375885, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.209668517112732, Accuracy: 0.6005859375\n",
      "Batch: 72, Loss: 1.2655515670776367, Accuracy: 0.5888671875\n",
      "Batch: 73, Loss: 1.204304814338684, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.1138969659805298, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.1483662128448486, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0981576442718506, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.0901578664779663, Accuracy: 0.6533203125\n",
      "Batch: 78, Loss: 1.1330444812774658, Accuracy: 0.6298828125\n",
      "Batch: 79, Loss: 1.1671661138534546, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.2172718048095703, Accuracy: 0.59765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 1.1823450326919556, Accuracy: 0.60546875\n",
      "Batch: 82, Loss: 1.1427602767944336, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.2451403141021729, Accuracy: 0.6044921875\n",
      "Batch: 84, Loss: 1.1930123567581177, Accuracy: 0.599609375\n",
      "Batch: 85, Loss: 1.2080206871032715, Accuracy: 0.6142578125\n",
      "Batch: 86, Loss: 1.2440345287322998, Accuracy: 0.587890625\n",
      "Batch: 87, Loss: 1.2134959697723389, Accuracy: 0.609375\n",
      "Batch: 88, Loss: 1.1910035610198975, Accuracy: 0.6083984375\n",
      "Batch: 89, Loss: 1.2049309015274048, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.158886432647705, Accuracy: 0.619140625\n",
      "Batch: 91, Loss: 1.1593527793884277, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1724187135696411, Accuracy: 0.640625\n",
      "Batch: 93, Loss: 1.1767313480377197, Accuracy: 0.6044921875\n",
      "Batch: 94, Loss: 1.232079267501831, Accuracy: 0.6181640625\n",
      "Batch: 95, Loss: 1.1601654291152954, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.2097034454345703, Accuracy: 0.6005859375\n",
      "Batch: 97, Loss: 1.2219321727752686, Accuracy: 0.591796875\n",
      "Batch: 98, Loss: 1.169083595275879, Accuracy: 0.62109375\n",
      "Batch: 99, Loss: 1.2040164470672607, Accuracy: 0.6240234375\n",
      "Batch: 100, Loss: 1.070652723312378, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.1048791408538818, Accuracy: 0.6328125\n",
      "Batch: 102, Loss: 1.2290260791778564, Accuracy: 0.5869140625\n",
      "Batch: 103, Loss: 1.2304701805114746, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1595478057861328, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.2204160690307617, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.1364065408706665, Accuracy: 0.6337890625\n",
      "Batch: 107, Loss: 1.2540607452392578, Accuracy: 0.5888671875\n",
      "Batch: 108, Loss: 1.231959342956543, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.2540905475616455, Accuracy: 0.603515625\n",
      "Batch: 110, Loss: 1.1618454456329346, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1154780387878418, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.1295087337493896, Accuracy: 0.623046875\n",
      "Batch: 113, Loss: 1.2077486515045166, Accuracy: 0.5966796875\n",
      "Batch: 114, Loss: 1.1734566688537598, Accuracy: 0.619140625\n",
      "Batch: 115, Loss: 1.2297983169555664, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2386325597763062, Accuracy: 0.599609375\n",
      "Batch: 117, Loss: 1.229933500289917, Accuracy: 0.6064453125\n",
      "Batch: 118, Loss: 1.1882519721984863, Accuracy: 0.6123046875\n",
      "Batch: 119, Loss: 1.2519856691360474, Accuracy: 0.59765625\n",
      "Batch: 120, Loss: 1.277546763420105, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.2352161407470703, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.2429728507995605, Accuracy: 0.5966796875\n",
      "Batch: 123, Loss: 1.1750500202178955, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.28822660446167, Accuracy: 0.603515625\n",
      "Batch: 125, Loss: 1.1942414045333862, Accuracy: 0.6181640625\n",
      "Batch: 126, Loss: 1.2602192163467407, Accuracy: 0.60546875\n",
      "Batch: 127, Loss: 1.2568812370300293, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.227750301361084, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.24683678150177, Accuracy: 0.599609375\n",
      "Batch: 130, Loss: 1.1426270008087158, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.2502846717834473, Accuracy: 0.5908203125\n",
      "Batch: 132, Loss: 1.1056780815124512, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.170039415359497, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1399662494659424, Accuracy: 0.6591796875\n",
      "Batch: 135, Loss: 1.0754106044769287, Accuracy: 0.6650390625\n",
      "Batch: 136, Loss: 1.1349189281463623, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.1830217838287354, Accuracy: 0.609375\n",
      "Batch: 138, Loss: 1.229407548904419, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.2988169193267822, Accuracy: 0.5830078125\n",
      "Batch: 140, Loss: 1.2324384450912476, Accuracy: 0.61328125\n",
      "Batch: 141, Loss: 1.1428996324539185, Accuracy: 0.6279296875\n",
      "Batch: 142, Loss: 1.1835122108459473, Accuracy: 0.611328125\n",
      "Batch: 143, Loss: 1.2367088794708252, Accuracy: 0.5966796875\n",
      "Batch: 144, Loss: 1.2655795812606812, Accuracy: 0.5927734375\n",
      "Batch: 145, Loss: 1.2231853008270264, Accuracy: 0.6064453125\n",
      "Batch: 146, Loss: 1.194359302520752, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.2402431964874268, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.2549612522125244, Accuracy: 0.58984375\n",
      "Batch: 149, Loss: 1.1581740379333496, Accuracy: 0.6181640625\n",
      "Batch: 150, Loss: 1.219625473022461, Accuracy: 0.6162109375\n",
      "Batch: 151, Loss: 1.1138103008270264, Accuracy: 0.6513671875\n",
      "Batch: 152, Loss: 1.1970241069793701, Accuracy: 0.6103515625\n",
      "Batch: 153, Loss: 1.135132908821106, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1174473762512207, Accuracy: 0.6328125\n",
      "Batch: 155, Loss: 1.1751278638839722, Accuracy: 0.640625\n",
      "Epoch 459/200\n",
      "Batch: 1, Loss: 1.2725520133972168, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.062647819519043, Accuracy: 0.6357421875\n",
      "Batch: 3, Loss: 1.024035096168518, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.081312894821167, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.0686461925506592, Accuracy: 0.6474609375\n",
      "Batch: 6, Loss: 1.053253173828125, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 1.069992184638977, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 1.0790728330612183, Accuracy: 0.642578125\n",
      "Batch: 9, Loss: 1.0302878618240356, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 1.013371229171753, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 1.0557934045791626, Accuracy: 0.6572265625\n",
      "Batch: 12, Loss: 1.0684630870819092, Accuracy: 0.6337890625\n",
      "Batch: 13, Loss: 0.9979971647262573, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 0.9690560698509216, Accuracy: 0.6787109375\n",
      "Batch: 15, Loss: 0.9683856964111328, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0459067821502686, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.1098577976226807, Accuracy: 0.634765625\n",
      "Batch: 18, Loss: 1.1051380634307861, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.2384898662567139, Accuracy: 0.5927734375\n",
      "Batch: 20, Loss: 1.077070951461792, Accuracy: 0.6533203125\n",
      "Batch: 21, Loss: 1.0536673069000244, Accuracy: 0.666015625\n",
      "Batch: 22, Loss: 1.2533820867538452, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.264106273651123, Accuracy: 0.5830078125\n",
      "Batch: 24, Loss: 1.14292573928833, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.1674383878707886, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.2297046184539795, Accuracy: 0.6083984375\n",
      "Batch: 27, Loss: 1.162097692489624, Accuracy: 0.626953125\n",
      "Batch: 28, Loss: 1.106607437133789, Accuracy: 0.630859375\n",
      "Batch: 29, Loss: 1.1384059190750122, Accuracy: 0.607421875\n",
      "Batch: 30, Loss: 1.1906726360321045, Accuracy: 0.60546875\n",
      "Batch: 31, Loss: 1.1832256317138672, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0332220792770386, Accuracy: 0.671875\n",
      "Batch: 33, Loss: 1.0203182697296143, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.1263030767440796, Accuracy: 0.6279296875\n",
      "Batch: 35, Loss: 1.1845016479492188, Accuracy: 0.609375\n",
      "Batch: 36, Loss: 1.2030677795410156, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.231049656867981, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.1853463649749756, Accuracy: 0.58984375\n",
      "Batch: 39, Loss: 1.1279096603393555, Accuracy: 0.6259765625\n",
      "Batch: 40, Loss: 1.1313042640686035, Accuracy: 0.623046875\n",
      "Batch: 41, Loss: 1.1369761228561401, Accuracy: 0.623046875\n",
      "Batch: 42, Loss: 1.116243839263916, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.1226999759674072, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.0247893333435059, Accuracy: 0.666015625\n",
      "Batch: 45, Loss: 1.0886099338531494, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1791517734527588, Accuracy: 0.6171875\n",
      "Batch: 47, Loss: 1.1147196292877197, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.1777061223983765, Accuracy: 0.58984375\n",
      "Batch: 49, Loss: 1.1834694147109985, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.1574311256408691, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1690590381622314, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2826738357543945, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.1819148063659668, Accuracy: 0.6025390625\n",
      "Batch: 54, Loss: 1.2217631340026855, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.134844183921814, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.163386344909668, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1511951684951782, Accuracy: 0.6376953125\n",
      "Batch: 58, Loss: 1.1793808937072754, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.1585912704467773, Accuracy: 0.6171875\n",
      "Batch: 60, Loss: 1.2595670223236084, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.2077804803848267, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.1885643005371094, Accuracy: 0.6064453125\n",
      "Batch: 63, Loss: 1.2029485702514648, Accuracy: 0.60546875\n",
      "Batch: 64, Loss: 1.206996202468872, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.2108430862426758, Accuracy: 0.5908203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 66, Loss: 1.163184404373169, Accuracy: 0.634765625\n",
      "Batch: 67, Loss: 1.0992482900619507, Accuracy: 0.6318359375\n",
      "Batch: 68, Loss: 1.087325096130371, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.220836877822876, Accuracy: 0.611328125\n",
      "Batch: 70, Loss: 1.230100154876709, Accuracy: 0.607421875\n",
      "Batch: 71, Loss: 1.15543794631958, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.2267109155654907, Accuracy: 0.6103515625\n",
      "Batch: 73, Loss: 1.174206018447876, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.061016321182251, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.1178555488586426, Accuracy: 0.6357421875\n",
      "Batch: 76, Loss: 1.1567625999450684, Accuracy: 0.623046875\n",
      "Batch: 77, Loss: 1.0835094451904297, Accuracy: 0.65625\n",
      "Batch: 78, Loss: 1.1175999641418457, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.1654376983642578, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.165107250213623, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.1179673671722412, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.1250333786010742, Accuracy: 0.6376953125\n",
      "Batch: 83, Loss: 1.1894376277923584, Accuracy: 0.6298828125\n",
      "Batch: 84, Loss: 1.194223403930664, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.2213730812072754, Accuracy: 0.61328125\n",
      "Batch: 86, Loss: 1.1705400943756104, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.212810754776001, Accuracy: 0.59765625\n",
      "Batch: 88, Loss: 1.2029051780700684, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.1397448778152466, Accuracy: 0.650390625\n",
      "Batch: 90, Loss: 1.1577179431915283, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.1543183326721191, Accuracy: 0.6318359375\n",
      "Batch: 92, Loss: 1.15895676612854, Accuracy: 0.6240234375\n",
      "Batch: 93, Loss: 1.1508772373199463, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.1386990547180176, Accuracy: 0.642578125\n",
      "Batch: 95, Loss: 1.207541584968567, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.2452030181884766, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.1741983890533447, Accuracy: 0.626953125\n",
      "Batch: 98, Loss: 1.1300004720687866, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.11073637008667, Accuracy: 0.6328125\n",
      "Batch: 100, Loss: 1.0985872745513916, Accuracy: 0.6357421875\n",
      "Batch: 101, Loss: 1.1087883710861206, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.2430803775787354, Accuracy: 0.6015625\n",
      "Batch: 103, Loss: 1.1661577224731445, Accuracy: 0.63671875\n",
      "Batch: 104, Loss: 1.1528668403625488, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.28981614112854, Accuracy: 0.5888671875\n",
      "Batch: 106, Loss: 1.1703448295593262, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.2944214344024658, Accuracy: 0.578125\n",
      "Batch: 108, Loss: 1.2497127056121826, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.2850613594055176, Accuracy: 0.58203125\n",
      "Batch: 110, Loss: 1.125072717666626, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1353155374526978, Accuracy: 0.6328125\n",
      "Batch: 112, Loss: 1.125693440437317, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.132880687713623, Accuracy: 0.62890625\n",
      "Batch: 114, Loss: 1.1883127689361572, Accuracy: 0.6220703125\n",
      "Batch: 115, Loss: 1.2400178909301758, Accuracy: 0.59375\n",
      "Batch: 116, Loss: 1.1681363582611084, Accuracy: 0.6318359375\n",
      "Batch: 117, Loss: 1.2155537605285645, Accuracy: 0.5869140625\n",
      "Batch: 118, Loss: 1.2752550840377808, Accuracy: 0.587890625\n",
      "Batch: 119, Loss: 1.2807605266571045, Accuracy: 0.5947265625\n",
      "Batch: 120, Loss: 1.2587966918945312, Accuracy: 0.603515625\n",
      "Batch: 121, Loss: 1.2046678066253662, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.211818814277649, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.1453962326049805, Accuracy: 0.6513671875\n",
      "Batch: 124, Loss: 1.2305169105529785, Accuracy: 0.6142578125\n",
      "Batch: 125, Loss: 1.1995820999145508, Accuracy: 0.619140625\n",
      "Batch: 126, Loss: 1.2034916877746582, Accuracy: 0.642578125\n",
      "Batch: 127, Loss: 1.2697149515151978, Accuracy: 0.6083984375\n",
      "Batch: 128, Loss: 1.2243990898132324, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.21665620803833, Accuracy: 0.6318359375\n",
      "Batch: 130, Loss: 1.191516637802124, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.24288010597229, Accuracy: 0.578125\n",
      "Batch: 132, Loss: 1.095870018005371, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.208362102508545, Accuracy: 0.60546875\n",
      "Batch: 134, Loss: 1.1322412490844727, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.0325651168823242, Accuracy: 0.6689453125\n",
      "Batch: 136, Loss: 1.0949606895446777, Accuracy: 0.6513671875\n",
      "Batch: 137, Loss: 1.1948981285095215, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.305020809173584, Accuracy: 0.5888671875\n",
      "Batch: 139, Loss: 1.1946038007736206, Accuracy: 0.607421875\n",
      "Batch: 140, Loss: 1.2355797290802002, Accuracy: 0.5947265625\n",
      "Batch: 141, Loss: 1.1750662326812744, Accuracy: 0.60546875\n",
      "Batch: 142, Loss: 1.2083967924118042, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.2886600494384766, Accuracy: 0.5859375\n",
      "Batch: 144, Loss: 1.269376277923584, Accuracy: 0.58984375\n",
      "Batch: 145, Loss: 1.2862722873687744, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.2648178339004517, Accuracy: 0.5830078125\n",
      "Batch: 147, Loss: 1.2092270851135254, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.2638916969299316, Accuracy: 0.5869140625\n",
      "Batch: 149, Loss: 1.2314960956573486, Accuracy: 0.595703125\n",
      "Batch: 150, Loss: 1.1404237747192383, Accuracy: 0.634765625\n",
      "Batch: 151, Loss: 1.2008835077285767, Accuracy: 0.6064453125\n",
      "Batch: 152, Loss: 1.2245668172836304, Accuracy: 0.5888671875\n",
      "Batch: 153, Loss: 1.1328920125961304, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.166706919670105, Accuracy: 0.5966796875\n",
      "Batch: 155, Loss: 1.12127685546875, Accuracy: 0.642578125\n",
      "Epoch 460/200\n",
      "Batch: 1, Loss: 1.2646088600158691, Accuracy: 0.609375\n",
      "Batch: 2, Loss: 1.0576412677764893, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.094651699066162, Accuracy: 0.638671875\n",
      "Batch: 4, Loss: 1.1469237804412842, Accuracy: 0.6162109375\n",
      "Batch: 5, Loss: 1.0767254829406738, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.0783748626708984, Accuracy: 0.64453125\n",
      "Batch: 7, Loss: 1.0874130725860596, Accuracy: 0.63671875\n",
      "Batch: 8, Loss: 1.0419707298278809, Accuracy: 0.658203125\n",
      "Batch: 9, Loss: 1.012763500213623, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 1.037521243095398, Accuracy: 0.658203125\n",
      "Batch: 11, Loss: 1.0121561288833618, Accuracy: 0.66796875\n",
      "Batch: 12, Loss: 1.066310167312622, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0496208667755127, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 1.0232768058776855, Accuracy: 0.65234375\n",
      "Batch: 15, Loss: 0.9528087377548218, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0462141036987305, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.081495761871338, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1145415306091309, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.1838093996047974, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.0888683795928955, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.105410099029541, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.215076208114624, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.2460335493087769, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.0944924354553223, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1525307893753052, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1866430044174194, Accuracy: 0.595703125\n",
      "Batch: 27, Loss: 1.1473225355148315, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.174633502960205, Accuracy: 0.625\n",
      "Batch: 29, Loss: 1.0577958822250366, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1593728065490723, Accuracy: 0.6298828125\n",
      "Batch: 31, Loss: 1.2229557037353516, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.024022102355957, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.0034122467041016, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.1034247875213623, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1354188919067383, Accuracy: 0.6337890625\n",
      "Batch: 36, Loss: 1.2144033908843994, Accuracy: 0.5986328125\n",
      "Batch: 37, Loss: 1.233534574508667, Accuracy: 0.576171875\n",
      "Batch: 38, Loss: 1.1785738468170166, Accuracy: 0.607421875\n",
      "Batch: 39, Loss: 1.083128809928894, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.0997987985610962, Accuracy: 0.6259765625\n",
      "Batch: 41, Loss: 1.0947706699371338, Accuracy: 0.6552734375\n",
      "Batch: 42, Loss: 1.084891438484192, Accuracy: 0.646484375\n",
      "Batch: 43, Loss: 1.053611159324646, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0652225017547607, Accuracy: 0.6455078125\n",
      "Batch: 45, Loss: 1.1064496040344238, Accuracy: 0.6279296875\n",
      "Batch: 46, Loss: 1.1120359897613525, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.1037819385528564, Accuracy: 0.65234375\n",
      "Batch: 48, Loss: 1.1363811492919922, Accuracy: 0.6025390625\n",
      "Batch: 49, Loss: 1.220447063446045, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.1753299236297607, Accuracy: 0.6123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 51, Loss: 1.1147712469100952, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.2830907106399536, Accuracy: 0.5810546875\n",
      "Batch: 53, Loss: 1.1859537363052368, Accuracy: 0.60546875\n",
      "Batch: 54, Loss: 1.1925697326660156, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.141958236694336, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.1344002485275269, Accuracy: 0.62890625\n",
      "Batch: 57, Loss: 1.1411991119384766, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.1403523683547974, Accuracy: 0.626953125\n",
      "Batch: 59, Loss: 1.1358864307403564, Accuracy: 0.638671875\n",
      "Batch: 60, Loss: 1.244781494140625, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1818835735321045, Accuracy: 0.634765625\n",
      "Batch: 62, Loss: 1.1831721067428589, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.2063090801239014, Accuracy: 0.5927734375\n",
      "Batch: 64, Loss: 1.2581006288528442, Accuracy: 0.595703125\n",
      "Batch: 65, Loss: 1.242466926574707, Accuracy: 0.583984375\n",
      "Batch: 66, Loss: 1.152653694152832, Accuracy: 0.626953125\n",
      "Batch: 67, Loss: 1.1152886152267456, Accuracy: 0.6455078125\n",
      "Batch: 68, Loss: 1.1093385219573975, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.1977527141571045, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.1485896110534668, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.1731009483337402, Accuracy: 0.6201171875\n",
      "Batch: 72, Loss: 1.2148133516311646, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.2223095893859863, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.1485905647277832, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.1032516956329346, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.1037846803665161, Accuracy: 0.64453125\n",
      "Batch: 77, Loss: 1.0599536895751953, Accuracy: 0.666015625\n",
      "Batch: 78, Loss: 1.0833382606506348, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.1505498886108398, Accuracy: 0.6298828125\n",
      "Batch: 80, Loss: 1.138047456741333, Accuracy: 0.63671875\n",
      "Batch: 81, Loss: 1.1404848098754883, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.1278057098388672, Accuracy: 0.65234375\n",
      "Batch: 83, Loss: 1.2229068279266357, Accuracy: 0.6005859375\n",
      "Batch: 84, Loss: 1.2183191776275635, Accuracy: 0.6025390625\n",
      "Batch: 85, Loss: 1.2077056169509888, Accuracy: 0.6103515625\n",
      "Batch: 86, Loss: 1.2178212404251099, Accuracy: 0.591796875\n",
      "Batch: 87, Loss: 1.1844011545181274, Accuracy: 0.6162109375\n",
      "Batch: 88, Loss: 1.1674667596817017, Accuracy: 0.615234375\n",
      "Batch: 89, Loss: 1.1990827322006226, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.1292847394943237, Accuracy: 0.63671875\n",
      "Batch: 91, Loss: 1.178469181060791, Accuracy: 0.6083984375\n",
      "Batch: 92, Loss: 1.1859748363494873, Accuracy: 0.6259765625\n",
      "Batch: 93, Loss: 1.1681382656097412, Accuracy: 0.6103515625\n",
      "Batch: 94, Loss: 1.2300307750701904, Accuracy: 0.5927734375\n",
      "Batch: 95, Loss: 1.2276867628097534, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.1758012771606445, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.2100569009780884, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.1203913688659668, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.1613519191741943, Accuracy: 0.61328125\n",
      "Batch: 100, Loss: 1.0482244491577148, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.108079195022583, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.1882011890411377, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.2252256870269775, Accuracy: 0.62890625\n",
      "Batch: 104, Loss: 1.1514554023742676, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.2135285139083862, Accuracy: 0.619140625\n",
      "Batch: 106, Loss: 1.1478614807128906, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2599833011627197, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.244994878768921, Accuracy: 0.5927734375\n",
      "Batch: 109, Loss: 1.201970100402832, Accuracy: 0.61328125\n",
      "Batch: 110, Loss: 1.1499595642089844, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1672345399856567, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.1108216047286987, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.166593313217163, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.2139613628387451, Accuracy: 0.595703125\n",
      "Batch: 115, Loss: 1.1924268007278442, Accuracy: 0.623046875\n",
      "Batch: 116, Loss: 1.258394718170166, Accuracy: 0.587890625\n",
      "Batch: 117, Loss: 1.1982300281524658, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.2053122520446777, Accuracy: 0.6044921875\n",
      "Batch: 119, Loss: 1.266884446144104, Accuracy: 0.5849609375\n",
      "Batch: 120, Loss: 1.3145313262939453, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.241868495941162, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.1972551345825195, Accuracy: 0.6142578125\n",
      "Batch: 123, Loss: 1.1975736618041992, Accuracy: 0.61328125\n",
      "Batch: 124, Loss: 1.2432732582092285, Accuracy: 0.6083984375\n",
      "Batch: 125, Loss: 1.2018802165985107, Accuracy: 0.6162109375\n",
      "Batch: 126, Loss: 1.2632827758789062, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.2903915643692017, Accuracy: 0.599609375\n",
      "Batch: 128, Loss: 1.1622898578643799, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.173396348953247, Accuracy: 0.640625\n",
      "Batch: 130, Loss: 1.1829254627227783, Accuracy: 0.61328125\n",
      "Batch: 131, Loss: 1.2123050689697266, Accuracy: 0.626953125\n",
      "Batch: 132, Loss: 1.0990750789642334, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.1668514013290405, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1737565994262695, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.0671252012252808, Accuracy: 0.6494140625\n",
      "Batch: 136, Loss: 1.114149808883667, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.1917061805725098, Accuracy: 0.625\n",
      "Batch: 138, Loss: 1.2535240650177002, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.1838017702102661, Accuracy: 0.623046875\n",
      "Batch: 140, Loss: 1.2085585594177246, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.223191261291504, Accuracy: 0.6103515625\n",
      "Batch: 142, Loss: 1.2156672477722168, Accuracy: 0.6083984375\n",
      "Batch: 143, Loss: 1.245042085647583, Accuracy: 0.5966796875\n",
      "Batch: 144, Loss: 1.2497341632843018, Accuracy: 0.591796875\n",
      "Batch: 145, Loss: 1.2698625326156616, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.214398980140686, Accuracy: 0.5869140625\n",
      "Batch: 147, Loss: 1.2110655307769775, Accuracy: 0.6318359375\n",
      "Batch: 148, Loss: 1.2490202188491821, Accuracy: 0.5947265625\n",
      "Batch: 149, Loss: 1.1855790615081787, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.2168372869491577, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.2021077871322632, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.1648756265640259, Accuracy: 0.5966796875\n",
      "Batch: 153, Loss: 1.1705963611602783, Accuracy: 0.6240234375\n",
      "Batch: 154, Loss: 1.2040983438491821, Accuracy: 0.6015625\n",
      "Batch: 155, Loss: 1.0788449048995972, Accuracy: 0.6435546875\n",
      "Saved Weights at epoch 460 to file Weights_460.h5\n",
      "Epoch 461/200\n",
      "Batch: 1, Loss: 1.216414451599121, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0941301584243774, Accuracy: 0.6357421875\n",
      "Batch: 3, Loss: 1.1166582107543945, Accuracy: 0.62109375\n",
      "Batch: 4, Loss: 1.077434778213501, Accuracy: 0.6416015625\n",
      "Batch: 5, Loss: 1.0264668464660645, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.0883245468139648, Accuracy: 0.6474609375\n",
      "Batch: 7, Loss: 1.0190882682800293, Accuracy: 0.6552734375\n",
      "Batch: 8, Loss: 0.9772590398788452, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0116227865219116, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.0130174160003662, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 0.9826798439025879, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.0080151557922363, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 1.0206685066223145, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 1.0117045640945435, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.9880784749984741, Accuracy: 0.669921875\n",
      "Batch: 16, Loss: 1.052593469619751, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.116917371749878, Accuracy: 0.61328125\n",
      "Batch: 18, Loss: 1.1227245330810547, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.2479565143585205, Accuracy: 0.5888671875\n",
      "Batch: 20, Loss: 1.1534762382507324, Accuracy: 0.6142578125\n",
      "Batch: 21, Loss: 1.094484806060791, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.2247474193572998, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.2812724113464355, Accuracy: 0.5849609375\n",
      "Batch: 24, Loss: 1.1893155574798584, Accuracy: 0.6005859375\n",
      "Batch: 25, Loss: 1.2051535844802856, Accuracy: 0.603515625\n",
      "Batch: 26, Loss: 1.272652506828308, Accuracy: 0.583984375\n",
      "Batch: 27, Loss: 1.1817092895507812, Accuracy: 0.6025390625\n",
      "Batch: 28, Loss: 1.033381462097168, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.0776593685150146, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.1836365461349487, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2542184591293335, Accuracy: 0.5693359375\n",
      "Batch: 32, Loss: 1.0332036018371582, Accuracy: 0.66796875\n",
      "Batch: 33, Loss: 1.0182431936264038, Accuracy: 0.6552734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.0886996984481812, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.1964739561080933, Accuracy: 0.5986328125\n",
      "Batch: 36, Loss: 1.2162950038909912, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.2532840967178345, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.1725941896438599, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.122647762298584, Accuracy: 0.640625\n",
      "Batch: 40, Loss: 1.1291875839233398, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.1551969051361084, Accuracy: 0.6025390625\n",
      "Batch: 42, Loss: 1.0773707628250122, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.1073877811431885, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.0738357305526733, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.0547881126403809, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.2024056911468506, Accuracy: 0.6025390625\n",
      "Batch: 47, Loss: 1.1001174449920654, Accuracy: 0.6376953125\n",
      "Batch: 48, Loss: 1.1408926248550415, Accuracy: 0.650390625\n",
      "Batch: 49, Loss: 1.2495766878128052, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.1553585529327393, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.1730222702026367, Accuracy: 0.59765625\n",
      "Batch: 52, Loss: 1.2026851177215576, Accuracy: 0.6181640625\n",
      "Batch: 53, Loss: 1.187593698501587, Accuracy: 0.60546875\n",
      "Batch: 54, Loss: 1.1886738538742065, Accuracy: 0.623046875\n",
      "Batch: 55, Loss: 1.1497042179107666, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.1137778759002686, Accuracy: 0.6376953125\n",
      "Batch: 57, Loss: 1.117783784866333, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.1524302959442139, Accuracy: 0.626953125\n",
      "Batch: 59, Loss: 1.193064570426941, Accuracy: 0.611328125\n",
      "Batch: 60, Loss: 1.2508585453033447, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.1986875534057617, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.2199788093566895, Accuracy: 0.6142578125\n",
      "Batch: 63, Loss: 1.160085916519165, Accuracy: 0.6181640625\n",
      "Batch: 64, Loss: 1.2484135627746582, Accuracy: 0.609375\n",
      "Batch: 65, Loss: 1.2439152002334595, Accuracy: 0.5947265625\n",
      "Batch: 66, Loss: 1.185428261756897, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.1914637088775635, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.113279104232788, Accuracy: 0.6552734375\n",
      "Batch: 69, Loss: 1.2363760471343994, Accuracy: 0.61328125\n",
      "Batch: 70, Loss: 1.178829550743103, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1827807426452637, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.1669862270355225, Accuracy: 0.6044921875\n",
      "Batch: 73, Loss: 1.1776562929153442, Accuracy: 0.6005859375\n",
      "Batch: 74, Loss: 1.1161987781524658, Accuracy: 0.625\n",
      "Batch: 75, Loss: 1.1618940830230713, Accuracy: 0.6328125\n",
      "Batch: 76, Loss: 1.0937392711639404, Accuracy: 0.6533203125\n",
      "Batch: 77, Loss: 1.1513619422912598, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.1195827722549438, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1434589624404907, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1835379600524902, Accuracy: 0.59765625\n",
      "Batch: 81, Loss: 1.1684273481369019, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.189546823501587, Accuracy: 0.6240234375\n",
      "Batch: 83, Loss: 1.1655700206756592, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.1296956539154053, Accuracy: 0.6318359375\n",
      "Batch: 85, Loss: 1.17778480052948, Accuracy: 0.6005859375\n",
      "Batch: 86, Loss: 1.1706160306930542, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.2350130081176758, Accuracy: 0.5986328125\n",
      "Batch: 88, Loss: 1.202759027481079, Accuracy: 0.60546875\n",
      "Batch: 89, Loss: 1.199784517288208, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.138551950454712, Accuracy: 0.6318359375\n",
      "Batch: 91, Loss: 1.2005302906036377, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.2093265056610107, Accuracy: 0.62109375\n",
      "Batch: 93, Loss: 1.1975575685501099, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.2208819389343262, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.2025678157806396, Accuracy: 0.60546875\n",
      "Batch: 96, Loss: 1.2783656120300293, Accuracy: 0.609375\n",
      "Batch: 97, Loss: 1.227376937866211, Accuracy: 0.6005859375\n",
      "Batch: 98, Loss: 1.1856839656829834, Accuracy: 0.603515625\n",
      "Batch: 99, Loss: 1.1521834135055542, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.059800624847412, Accuracy: 0.6484375\n",
      "Batch: 101, Loss: 1.0915502309799194, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.1730265617370605, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.2253165245056152, Accuracy: 0.603515625\n",
      "Batch: 104, Loss: 1.199061632156372, Accuracy: 0.611328125\n",
      "Batch: 105, Loss: 1.2305281162261963, Accuracy: 0.60546875\n",
      "Batch: 106, Loss: 1.1579090356826782, Accuracy: 0.6484375\n",
      "Batch: 107, Loss: 1.2408106327056885, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.1913608312606812, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.1883344650268555, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.1363779306411743, Accuracy: 0.634765625\n",
      "Batch: 111, Loss: 1.0977703332901, Accuracy: 0.6455078125\n",
      "Batch: 112, Loss: 1.1013219356536865, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1266423463821411, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.1724857091903687, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.172397494316101, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.2814462184906006, Accuracy: 0.5673828125\n",
      "Batch: 117, Loss: 1.1777654886245728, Accuracy: 0.6044921875\n",
      "Batch: 118, Loss: 1.2266656160354614, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2538347244262695, Accuracy: 0.595703125\n",
      "Batch: 120, Loss: 1.352855920791626, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.1922671794891357, Accuracy: 0.6044921875\n",
      "Batch: 122, Loss: 1.247987151145935, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.1445304155349731, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.2540624141693115, Accuracy: 0.6142578125\n",
      "Batch: 125, Loss: 1.1590301990509033, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.2929577827453613, Accuracy: 0.587890625\n",
      "Batch: 127, Loss: 1.2837779521942139, Accuracy: 0.5927734375\n",
      "Batch: 128, Loss: 1.1698484420776367, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.2001936435699463, Accuracy: 0.5986328125\n",
      "Batch: 130, Loss: 1.1579408645629883, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.2212519645690918, Accuracy: 0.6171875\n",
      "Batch: 132, Loss: 1.0498857498168945, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.1712876558303833, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1009066104888916, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.0955922603607178, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.1362777948379517, Accuracy: 0.62109375\n",
      "Batch: 137, Loss: 1.1722067594528198, Accuracy: 0.6162109375\n",
      "Batch: 138, Loss: 1.2547968626022339, Accuracy: 0.5830078125\n",
      "Batch: 139, Loss: 1.1985102891921997, Accuracy: 0.603515625\n",
      "Batch: 140, Loss: 1.2567843198776245, Accuracy: 0.611328125\n",
      "Batch: 141, Loss: 1.1502091884613037, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.219233751296997, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2114534378051758, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.2780474424362183, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.2888920307159424, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.210014820098877, Accuracy: 0.6162109375\n",
      "Batch: 147, Loss: 1.2174708843231201, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1990611553192139, Accuracy: 0.6259765625\n",
      "Batch: 149, Loss: 1.1870588064193726, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1448793411254883, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.2154161930084229, Accuracy: 0.62109375\n",
      "Batch: 152, Loss: 1.226435899734497, Accuracy: 0.6005859375\n",
      "Batch: 153, Loss: 1.1345560550689697, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1705957651138306, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0820624828338623, Accuracy: 0.62890625\n",
      "Epoch 462/200\n",
      "Batch: 1, Loss: 1.1927831172943115, Accuracy: 0.6455078125\n",
      "Batch: 2, Loss: 1.087971806526184, Accuracy: 0.6318359375\n",
      "Batch: 3, Loss: 1.0288513898849487, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.0463104248046875, Accuracy: 0.6513671875\n",
      "Batch: 5, Loss: 1.05930495262146, Accuracy: 0.6484375\n",
      "Batch: 6, Loss: 1.0600945949554443, Accuracy: 0.6416015625\n",
      "Batch: 7, Loss: 1.0598077774047852, Accuracy: 0.6328125\n",
      "Batch: 8, Loss: 1.040411353111267, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0444974899291992, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 0.9522708654403687, Accuracy: 0.693359375\n",
      "Batch: 11, Loss: 0.9907540082931519, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.050275444984436, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 1.0350708961486816, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 1.0467712879180908, Accuracy: 0.662109375\n",
      "Batch: 15, Loss: 0.9809942841529846, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.101061224937439, Accuracy: 0.6474609375\n",
      "Batch: 17, Loss: 1.090361475944519, Accuracy: 0.6357421875\n",
      "Batch: 18, Loss: 1.063474178314209, Accuracy: 0.66015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 1.2025820016860962, Accuracy: 0.5947265625\n",
      "Batch: 20, Loss: 1.1735503673553467, Accuracy: 0.626953125\n",
      "Batch: 21, Loss: 1.1101655960083008, Accuracy: 0.6435546875\n",
      "Batch: 22, Loss: 1.2536399364471436, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.2679564952850342, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.1383566856384277, Accuracy: 0.6357421875\n",
      "Batch: 25, Loss: 1.1163336038589478, Accuracy: 0.6240234375\n",
      "Batch: 26, Loss: 1.2445859909057617, Accuracy: 0.5927734375\n",
      "Batch: 27, Loss: 1.1571509838104248, Accuracy: 0.626953125\n",
      "Batch: 28, Loss: 1.074291467666626, Accuracy: 0.6455078125\n",
      "Batch: 29, Loss: 1.0636463165283203, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1200995445251465, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.224855661392212, Accuracy: 0.6015625\n",
      "Batch: 32, Loss: 1.096541404724121, Accuracy: 0.65625\n",
      "Batch: 33, Loss: 0.9978187084197998, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.0867741107940674, Accuracy: 0.654296875\n",
      "Batch: 35, Loss: 1.1522574424743652, Accuracy: 0.6162109375\n",
      "Batch: 36, Loss: 1.2314667701721191, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1835570335388184, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.115797758102417, Accuracy: 0.6435546875\n",
      "Batch: 39, Loss: 1.0891671180725098, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.0772463083267212, Accuracy: 0.66015625\n",
      "Batch: 41, Loss: 1.1515134572982788, Accuracy: 0.607421875\n",
      "Batch: 42, Loss: 1.085094928741455, Accuracy: 0.6318359375\n",
      "Batch: 43, Loss: 1.0305620431900024, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.094022512435913, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0695750713348389, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 1.1529346704483032, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1091312170028687, Accuracy: 0.63671875\n",
      "Batch: 48, Loss: 1.1424016952514648, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.1588178873062134, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.1258342266082764, Accuracy: 0.630859375\n",
      "Batch: 51, Loss: 1.1974401473999023, Accuracy: 0.6005859375\n",
      "Batch: 52, Loss: 1.3012185096740723, Accuracy: 0.5791015625\n",
      "Batch: 53, Loss: 1.2220840454101562, Accuracy: 0.59375\n",
      "Batch: 54, Loss: 1.2345716953277588, Accuracy: 0.61328125\n",
      "Batch: 55, Loss: 1.1684119701385498, Accuracy: 0.62109375\n",
      "Batch: 56, Loss: 1.1098970174789429, Accuracy: 0.6279296875\n",
      "Batch: 57, Loss: 1.1160309314727783, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.1463110446929932, Accuracy: 0.6103515625\n",
      "Batch: 59, Loss: 1.1480809450149536, Accuracy: 0.6220703125\n",
      "Batch: 60, Loss: 1.249004602432251, Accuracy: 0.5888671875\n",
      "Batch: 61, Loss: 1.1713786125183105, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.1608552932739258, Accuracy: 0.638671875\n",
      "Batch: 63, Loss: 1.1643365621566772, Accuracy: 0.619140625\n",
      "Batch: 64, Loss: 1.2161917686462402, Accuracy: 0.6005859375\n",
      "Batch: 65, Loss: 1.1983221769332886, Accuracy: 0.5869140625\n",
      "Batch: 66, Loss: 1.1634292602539062, Accuracy: 0.61328125\n",
      "Batch: 67, Loss: 1.1819331645965576, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.1019737720489502, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.2066807746887207, Accuracy: 0.6220703125\n",
      "Batch: 70, Loss: 1.199783205986023, Accuracy: 0.61328125\n",
      "Batch: 71, Loss: 1.1254385709762573, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.2223072052001953, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.2080601453781128, Accuracy: 0.625\n",
      "Batch: 74, Loss: 1.0936741828918457, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.153369426727295, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.0845072269439697, Accuracy: 0.6650390625\n",
      "Batch: 77, Loss: 1.0778043270111084, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.1250624656677246, Accuracy: 0.63671875\n",
      "Batch: 79, Loss: 1.2270126342773438, Accuracy: 0.6318359375\n",
      "Batch: 80, Loss: 1.1984624862670898, Accuracy: 0.591796875\n",
      "Batch: 81, Loss: 1.1408851146697998, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.1582505702972412, Accuracy: 0.6240234375\n",
      "Batch: 83, Loss: 1.1965771913528442, Accuracy: 0.62109375\n",
      "Batch: 84, Loss: 1.1680530309677124, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.213003396987915, Accuracy: 0.6083984375\n",
      "Batch: 86, Loss: 1.2045435905456543, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.2104626893997192, Accuracy: 0.6220703125\n",
      "Batch: 88, Loss: 1.1857473850250244, Accuracy: 0.6103515625\n",
      "Batch: 89, Loss: 1.2190203666687012, Accuracy: 0.6171875\n",
      "Batch: 90, Loss: 1.0750865936279297, Accuracy: 0.650390625\n",
      "Batch: 91, Loss: 1.138085961341858, Accuracy: 0.6298828125\n",
      "Batch: 92, Loss: 1.1646778583526611, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.1689352989196777, Accuracy: 0.6357421875\n",
      "Batch: 94, Loss: 1.2194939851760864, Accuracy: 0.599609375\n",
      "Batch: 95, Loss: 1.2025834321975708, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.2186883687973022, Accuracy: 0.619140625\n",
      "Batch: 97, Loss: 1.2135924100875854, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1582884788513184, Accuracy: 0.6240234375\n",
      "Batch: 99, Loss: 1.1830580234527588, Accuracy: 0.615234375\n",
      "Batch: 100, Loss: 1.1004445552825928, Accuracy: 0.638671875\n",
      "Batch: 101, Loss: 1.115187406539917, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2028913497924805, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.194478988647461, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.130792498588562, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.2260098457336426, Accuracy: 0.59765625\n",
      "Batch: 106, Loss: 1.1718571186065674, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.2395315170288086, Accuracy: 0.6083984375\n",
      "Batch: 108, Loss: 1.235013484954834, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.1776949167251587, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 1.131681203842163, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.1793429851531982, Accuracy: 0.61328125\n",
      "Batch: 112, Loss: 1.1164209842681885, Accuracy: 0.6435546875\n",
      "Batch: 113, Loss: 1.173671007156372, Accuracy: 0.6171875\n",
      "Batch: 114, Loss: 1.172210693359375, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.2112407684326172, Accuracy: 0.6025390625\n",
      "Batch: 116, Loss: 1.2151784896850586, Accuracy: 0.6201171875\n",
      "Batch: 117, Loss: 1.2006638050079346, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.2527072429656982, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.2225584983825684, Accuracy: 0.603515625\n",
      "Batch: 120, Loss: 1.2866029739379883, Accuracy: 0.59765625\n",
      "Batch: 121, Loss: 1.1952764987945557, Accuracy: 0.6259765625\n",
      "Batch: 122, Loss: 1.1975553035736084, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.1573495864868164, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2623921632766724, Accuracy: 0.5947265625\n",
      "Batch: 125, Loss: 1.1359050273895264, Accuracy: 0.634765625\n",
      "Batch: 126, Loss: 1.2655538320541382, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.2250375747680664, Accuracy: 0.6015625\n",
      "Batch: 128, Loss: 1.2072564363479614, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.2116832733154297, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.1678646802902222, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.1743077039718628, Accuracy: 0.6328125\n",
      "Batch: 132, Loss: 1.0637236833572388, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 1.143453598022461, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.1629071235656738, Accuracy: 0.65234375\n",
      "Batch: 135, Loss: 1.0258152484893799, Accuracy: 0.669921875\n",
      "Batch: 136, Loss: 1.0972462892532349, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.249834656715393, Accuracy: 0.59375\n",
      "Batch: 138, Loss: 1.2619138956069946, Accuracy: 0.5966796875\n",
      "Batch: 139, Loss: 1.140728235244751, Accuracy: 0.642578125\n",
      "Batch: 140, Loss: 1.2366341352462769, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.1488053798675537, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.167556881904602, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.2326607704162598, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.2861278057098389, Accuracy: 0.580078125\n",
      "Batch: 145, Loss: 1.2743498086929321, Accuracy: 0.5869140625\n",
      "Batch: 146, Loss: 1.1952447891235352, Accuracy: 0.6337890625\n",
      "Batch: 147, Loss: 1.159630298614502, Accuracy: 0.630859375\n",
      "Batch: 148, Loss: 1.236903429031372, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.1735482215881348, Accuracy: 0.6162109375\n",
      "Batch: 150, Loss: 1.152021884918213, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.1633689403533936, Accuracy: 0.626953125\n",
      "Batch: 152, Loss: 1.2086355686187744, Accuracy: 0.595703125\n",
      "Batch: 153, Loss: 1.1561145782470703, Accuracy: 0.6279296875\n",
      "Batch: 154, Loss: 1.1722675561904907, Accuracy: 0.63671875\n",
      "Batch: 155, Loss: 1.0790126323699951, Accuracy: 0.658203125\n",
      "Epoch 463/200\n",
      "Batch: 1, Loss: 1.209714651107788, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 1.134576678276062, Accuracy: 0.6376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3, Loss: 1.131461262702942, Accuracy: 0.6318359375\n",
      "Batch: 4, Loss: 1.0934052467346191, Accuracy: 0.6357421875\n",
      "Batch: 5, Loss: 1.0282127857208252, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0553158521652222, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 1.0330750942230225, Accuracy: 0.642578125\n",
      "Batch: 8, Loss: 0.9865245223045349, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 1.0185346603393555, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 0.9550687074661255, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 0.9858629107475281, Accuracy: 0.6787109375\n",
      "Batch: 12, Loss: 1.0360138416290283, Accuracy: 0.6572265625\n",
      "Batch: 13, Loss: 1.0509469509124756, Accuracy: 0.642578125\n",
      "Batch: 14, Loss: 1.013108730316162, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.978534460067749, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.046252727508545, Accuracy: 0.6689453125\n",
      "Batch: 17, Loss: 1.1147263050079346, Accuracy: 0.6357421875\n",
      "Batch: 18, Loss: 1.1392405033111572, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.1985516548156738, Accuracy: 0.625\n",
      "Batch: 20, Loss: 1.1096522808074951, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.0909669399261475, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.2497718334197998, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.2032523155212402, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.1476207971572876, Accuracy: 0.6474609375\n",
      "Batch: 25, Loss: 1.1051762104034424, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.2631049156188965, Accuracy: 0.587890625\n",
      "Batch: 27, Loss: 1.1806330680847168, Accuracy: 0.6201171875\n",
      "Batch: 28, Loss: 1.0939033031463623, Accuracy: 0.62109375\n",
      "Batch: 29, Loss: 1.058100700378418, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.1599527597427368, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.2133924961090088, Accuracy: 0.5830078125\n",
      "Batch: 32, Loss: 1.0295093059539795, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 1.0287175178527832, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.0765736103057861, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.1509950160980225, Accuracy: 0.62890625\n",
      "Batch: 36, Loss: 1.1799311637878418, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.2386711835861206, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.1869213581085205, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.1188304424285889, Accuracy: 0.623046875\n",
      "Batch: 40, Loss: 1.1378483772277832, Accuracy: 0.6298828125\n",
      "Batch: 41, Loss: 1.1925530433654785, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.0835390090942383, Accuracy: 0.6533203125\n",
      "Batch: 43, Loss: 1.0650144815444946, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.0720577239990234, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 1.109128713607788, Accuracy: 0.6376953125\n",
      "Batch: 46, Loss: 1.1874113082885742, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.1237448453903198, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.1813172101974487, Accuracy: 0.6171875\n",
      "Batch: 49, Loss: 1.2248549461364746, Accuracy: 0.60546875\n",
      "Batch: 50, Loss: 1.1146053075790405, Accuracy: 0.638671875\n",
      "Batch: 51, Loss: 1.1578669548034668, Accuracy: 0.6181640625\n",
      "Batch: 52, Loss: 1.2207154035568237, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.1997804641723633, Accuracy: 0.591796875\n",
      "Batch: 54, Loss: 1.22367525100708, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.2135121822357178, Accuracy: 0.6181640625\n",
      "Batch: 56, Loss: 1.1159312725067139, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.156660795211792, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.0954551696777344, Accuracy: 0.65234375\n",
      "Batch: 59, Loss: 1.1978743076324463, Accuracy: 0.61328125\n",
      "Batch: 60, Loss: 1.270143985748291, Accuracy: 0.58984375\n",
      "Batch: 61, Loss: 1.195388913154602, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.2115669250488281, Accuracy: 0.6142578125\n",
      "Batch: 63, Loss: 1.1964436769485474, Accuracy: 0.6201171875\n",
      "Batch: 64, Loss: 1.2201640605926514, Accuracy: 0.5986328125\n",
      "Batch: 65, Loss: 1.1936960220336914, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.145639181137085, Accuracy: 0.6474609375\n",
      "Batch: 67, Loss: 1.1876617670059204, Accuracy: 0.58984375\n",
      "Batch: 68, Loss: 1.105553150177002, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.218299388885498, Accuracy: 0.607421875\n",
      "Batch: 70, Loss: 1.224157452583313, Accuracy: 0.591796875\n",
      "Batch: 71, Loss: 1.177197813987732, Accuracy: 0.6162109375\n",
      "Batch: 72, Loss: 1.2202953100204468, Accuracy: 0.61328125\n",
      "Batch: 73, Loss: 1.250362753868103, Accuracy: 0.5849609375\n",
      "Batch: 74, Loss: 1.1570621728897095, Accuracy: 0.6201171875\n",
      "Batch: 75, Loss: 1.1306827068328857, Accuracy: 0.6220703125\n",
      "Batch: 76, Loss: 1.0995759963989258, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.090693712234497, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.101534128189087, Accuracy: 0.65234375\n",
      "Batch: 79, Loss: 1.170055627822876, Accuracy: 0.6083984375\n",
      "Batch: 80, Loss: 1.2139276266098022, Accuracy: 0.5888671875\n",
      "Batch: 81, Loss: 1.1210228204727173, Accuracy: 0.640625\n",
      "Batch: 82, Loss: 1.137148380279541, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.227818489074707, Accuracy: 0.6123046875\n",
      "Batch: 84, Loss: 1.2008391618728638, Accuracy: 0.6123046875\n",
      "Batch: 85, Loss: 1.162914514541626, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.1740883588790894, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.214634895324707, Accuracy: 0.62109375\n",
      "Batch: 88, Loss: 1.1895816326141357, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.2015550136566162, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.15036940574646, Accuracy: 0.6328125\n",
      "Batch: 91, Loss: 1.1777262687683105, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.186516523361206, Accuracy: 0.625\n",
      "Batch: 93, Loss: 1.1343936920166016, Accuracy: 0.6416015625\n",
      "Batch: 94, Loss: 1.2049481868743896, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.2599613666534424, Accuracy: 0.603515625\n",
      "Batch: 96, Loss: 1.2546929121017456, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.189997673034668, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.1819976568222046, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.136706829071045, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.0980756282806396, Accuracy: 0.6357421875\n",
      "Batch: 101, Loss: 1.137298345565796, Accuracy: 0.626953125\n",
      "Batch: 102, Loss: 1.116837978363037, Accuracy: 0.6435546875\n",
      "Batch: 103, Loss: 1.1513153314590454, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.160900592803955, Accuracy: 0.6220703125\n",
      "Batch: 105, Loss: 1.1835854053497314, Accuracy: 0.6171875\n",
      "Batch: 106, Loss: 1.157712459564209, Accuracy: 0.6298828125\n",
      "Batch: 107, Loss: 1.2719261646270752, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.1603349447250366, Accuracy: 0.60546875\n",
      "Batch: 109, Loss: 1.172853946685791, Accuracy: 0.6259765625\n",
      "Batch: 110, Loss: 1.1355834007263184, Accuracy: 0.6318359375\n",
      "Batch: 111, Loss: 1.1677350997924805, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.0897397994995117, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.1974986791610718, Accuracy: 0.5986328125\n",
      "Batch: 114, Loss: 1.1610050201416016, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.1543159484863281, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.1618647575378418, Accuracy: 0.619140625\n",
      "Batch: 117, Loss: 1.2084269523620605, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.2436555624008179, Accuracy: 0.5771484375\n",
      "Batch: 119, Loss: 1.2055124044418335, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.2708537578582764, Accuracy: 0.6103515625\n",
      "Batch: 121, Loss: 1.2374125719070435, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2137888669967651, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.1889376640319824, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.274320363998413, Accuracy: 0.5869140625\n",
      "Batch: 125, Loss: 1.1634528636932373, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.3048198223114014, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.3059736490249634, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.238163948059082, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.1656343936920166, Accuracy: 0.62109375\n",
      "Batch: 130, Loss: 1.1060454845428467, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.163316011428833, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.0623811483383179, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.1833860874176025, Accuracy: 0.6259765625\n",
      "Batch: 134, Loss: 1.0792052745819092, Accuracy: 0.66015625\n",
      "Batch: 135, Loss: 1.0897247791290283, Accuracy: 0.6396484375\n",
      "Batch: 136, Loss: 1.1107430458068848, Accuracy: 0.6552734375\n",
      "Batch: 137, Loss: 1.1380672454833984, Accuracy: 0.6328125\n",
      "Batch: 138, Loss: 1.2602193355560303, Accuracy: 0.580078125\n",
      "Batch: 139, Loss: 1.1566407680511475, Accuracy: 0.6337890625\n",
      "Batch: 140, Loss: 1.2448078393936157, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.1155641078948975, Accuracy: 0.640625\n",
      "Batch: 142, Loss: 1.2523622512817383, Accuracy: 0.6083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 1.2418535947799683, Accuracy: 0.58984375\n",
      "Batch: 144, Loss: 1.2922840118408203, Accuracy: 0.58984375\n",
      "Batch: 145, Loss: 1.2806849479675293, Accuracy: 0.58203125\n",
      "Batch: 146, Loss: 1.2369585037231445, Accuracy: 0.5966796875\n",
      "Batch: 147, Loss: 1.2140858173370361, Accuracy: 0.609375\n",
      "Batch: 148, Loss: 1.191375970840454, Accuracy: 0.62109375\n",
      "Batch: 149, Loss: 1.215103268623352, Accuracy: 0.6142578125\n",
      "Batch: 150, Loss: 1.133804440498352, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.1452348232269287, Accuracy: 0.6298828125\n",
      "Batch: 152, Loss: 1.1774084568023682, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.1593637466430664, Accuracy: 0.626953125\n",
      "Batch: 154, Loss: 1.1218664646148682, Accuracy: 0.6240234375\n",
      "Batch: 155, Loss: 1.1167176961898804, Accuracy: 0.6259765625\n",
      "Epoch 464/200\n",
      "Batch: 1, Loss: 1.1902174949645996, Accuracy: 0.66015625\n",
      "Batch: 2, Loss: 1.0898773670196533, Accuracy: 0.646484375\n",
      "Batch: 3, Loss: 1.070410966873169, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 1.059337854385376, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0351256132125854, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0568573474884033, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.0186612606048584, Accuracy: 0.6572265625\n",
      "Batch: 8, Loss: 1.0050150156021118, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 0.9847376346588135, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 1.0170756578445435, Accuracy: 0.6650390625\n",
      "Batch: 11, Loss: 0.9317110180854797, Accuracy: 0.6962890625\n",
      "Batch: 12, Loss: 1.0277962684631348, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0576050281524658, Accuracy: 0.646484375\n",
      "Batch: 14, Loss: 0.9935632944107056, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.948925793170929, Accuracy: 0.705078125\n",
      "Batch: 16, Loss: 1.0263034105300903, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 1.0986303091049194, Accuracy: 0.6318359375\n",
      "Batch: 18, Loss: 1.1516916751861572, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.2137815952301025, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.1480536460876465, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.1245431900024414, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2407846450805664, Accuracy: 0.5986328125\n",
      "Batch: 23, Loss: 1.2444664239883423, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.1108288764953613, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.166944146156311, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.2408888339996338, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.124464511871338, Accuracy: 0.61328125\n",
      "Batch: 28, Loss: 1.0916982889175415, Accuracy: 0.6376953125\n",
      "Batch: 29, Loss: 1.0536553859710693, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1740388870239258, Accuracy: 0.609375\n",
      "Batch: 31, Loss: 1.2718507051467896, Accuracy: 0.5908203125\n",
      "Batch: 32, Loss: 1.0370328426361084, Accuracy: 0.658203125\n",
      "Batch: 33, Loss: 0.9998582601547241, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.1049363613128662, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.1370673179626465, Accuracy: 0.6298828125\n",
      "Batch: 36, Loss: 1.23311185836792, Accuracy: 0.6005859375\n",
      "Batch: 37, Loss: 1.256674885749817, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.1689753532409668, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.105747938156128, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.128716230392456, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1564018726348877, Accuracy: 0.615234375\n",
      "Batch: 42, Loss: 1.0607783794403076, Accuracy: 0.646484375\n",
      "Batch: 43, Loss: 1.0780138969421387, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.0364450216293335, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0697524547576904, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.1438586711883545, Accuracy: 0.6298828125\n",
      "Batch: 47, Loss: 1.1298964023590088, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.1390596628189087, Accuracy: 0.6171875\n",
      "Batch: 49, Loss: 1.2595701217651367, Accuracy: 0.5986328125\n",
      "Batch: 50, Loss: 1.1982495784759521, Accuracy: 0.6162109375\n",
      "Batch: 51, Loss: 1.1691243648529053, Accuracy: 0.5869140625\n",
      "Batch: 52, Loss: 1.2709623575210571, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.1497654914855957, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.2265138626098633, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.1634132862091064, Accuracy: 0.630859375\n",
      "Batch: 56, Loss: 1.1448850631713867, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.175560474395752, Accuracy: 0.63671875\n",
      "Batch: 58, Loss: 1.118997573852539, Accuracy: 0.615234375\n",
      "Batch: 59, Loss: 1.120011806488037, Accuracy: 0.6259765625\n",
      "Batch: 60, Loss: 1.2459828853607178, Accuracy: 0.607421875\n",
      "Batch: 61, Loss: 1.186091661453247, Accuracy: 0.611328125\n",
      "Batch: 62, Loss: 1.1317390203475952, Accuracy: 0.6455078125\n",
      "Batch: 63, Loss: 1.165317416191101, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2291972637176514, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.26703679561615, Accuracy: 0.576171875\n",
      "Batch: 66, Loss: 1.1694514751434326, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.1429853439331055, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.1143746376037598, Accuracy: 0.6416015625\n",
      "Batch: 69, Loss: 1.229569673538208, Accuracy: 0.5947265625\n",
      "Batch: 70, Loss: 1.1671943664550781, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.142052412033081, Accuracy: 0.6083984375\n",
      "Batch: 72, Loss: 1.1803736686706543, Accuracy: 0.6083984375\n",
      "Batch: 73, Loss: 1.1866788864135742, Accuracy: 0.6044921875\n",
      "Batch: 74, Loss: 1.1244330406188965, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.1334714889526367, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.1032845973968506, Accuracy: 0.6259765625\n",
      "Batch: 77, Loss: 1.0537731647491455, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0541073083877563, Accuracy: 0.6650390625\n",
      "Batch: 79, Loss: 1.1819509267807007, Accuracy: 0.5986328125\n",
      "Batch: 80, Loss: 1.12959623336792, Accuracy: 0.6240234375\n",
      "Batch: 81, Loss: 1.1169350147247314, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.1555111408233643, Accuracy: 0.62109375\n",
      "Batch: 83, Loss: 1.2198197841644287, Accuracy: 0.603515625\n",
      "Batch: 84, Loss: 1.168866753578186, Accuracy: 0.626953125\n",
      "Batch: 85, Loss: 1.2096567153930664, Accuracy: 0.6220703125\n",
      "Batch: 86, Loss: 1.2513506412506104, Accuracy: 0.58984375\n",
      "Batch: 87, Loss: 1.217411756515503, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.1748402118682861, Accuracy: 0.6171875\n",
      "Batch: 89, Loss: 1.1160433292388916, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.188689947128296, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.1465022563934326, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.1483664512634277, Accuracy: 0.6259765625\n",
      "Batch: 93, Loss: 1.1664468050003052, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.2059528827667236, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.145595669746399, Accuracy: 0.638671875\n",
      "Batch: 96, Loss: 1.2431976795196533, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.196537971496582, Accuracy: 0.609375\n",
      "Batch: 98, Loss: 1.112703561782837, Accuracy: 0.6328125\n",
      "Batch: 99, Loss: 1.1523802280426025, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.0689494609832764, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.0968201160430908, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.1559433937072754, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.2038562297821045, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.1249430179595947, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.236590027809143, Accuracy: 0.6162109375\n",
      "Batch: 106, Loss: 1.1768907308578491, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.2854068279266357, Accuracy: 0.583984375\n",
      "Batch: 108, Loss: 1.1677807569503784, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.2483351230621338, Accuracy: 0.5927734375\n",
      "Batch: 110, Loss: 1.145304560661316, Accuracy: 0.6171875\n",
      "Batch: 111, Loss: 1.1899254322052002, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.1129658222198486, Accuracy: 0.6435546875\n",
      "Batch: 113, Loss: 1.216996431350708, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.1866576671600342, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.1945194005966187, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.2070999145507812, Accuracy: 0.599609375\n",
      "Batch: 117, Loss: 1.167680025100708, Accuracy: 0.6220703125\n",
      "Batch: 118, Loss: 1.2254596948623657, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.2592402696609497, Accuracy: 0.5869140625\n",
      "Batch: 120, Loss: 1.2983421087265015, Accuracy: 0.6044921875\n",
      "Batch: 121, Loss: 1.246445655822754, Accuracy: 0.5947265625\n",
      "Batch: 122, Loss: 1.2581617832183838, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.1762818098068237, Accuracy: 0.6181640625\n",
      "Batch: 124, Loss: 1.2328553199768066, Accuracy: 0.6083984375\n",
      "Batch: 125, Loss: 1.1897586584091187, Accuracy: 0.6123046875\n",
      "Batch: 126, Loss: 1.268235445022583, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127, Loss: 1.2832424640655518, Accuracy: 0.59375\n",
      "Batch: 128, Loss: 1.2533090114593506, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.2299723625183105, Accuracy: 0.611328125\n",
      "Batch: 130, Loss: 1.1859917640686035, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.2793035507202148, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.098327398300171, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.1696163415908813, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.1592724323272705, Accuracy: 0.642578125\n",
      "Batch: 135, Loss: 1.0829830169677734, Accuracy: 0.6357421875\n",
      "Batch: 136, Loss: 1.1343600749969482, Accuracy: 0.6181640625\n",
      "Batch: 137, Loss: 1.1984775066375732, Accuracy: 0.6201171875\n",
      "Batch: 138, Loss: 1.216582179069519, Accuracy: 0.6103515625\n",
      "Batch: 139, Loss: 1.1662588119506836, Accuracy: 0.6416015625\n",
      "Batch: 140, Loss: 1.2618014812469482, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.2262747287750244, Accuracy: 0.6015625\n",
      "Batch: 142, Loss: 1.197221040725708, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.253048300743103, Accuracy: 0.6005859375\n",
      "Batch: 144, Loss: 1.2440178394317627, Accuracy: 0.591796875\n",
      "Batch: 145, Loss: 1.2648229598999023, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.2145113945007324, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.2023940086364746, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.2101964950561523, Accuracy: 0.59375\n",
      "Batch: 149, Loss: 1.1821246147155762, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.1872715950012207, Accuracy: 0.6123046875\n",
      "Batch: 151, Loss: 1.1544926166534424, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.2407656908035278, Accuracy: 0.5888671875\n",
      "Batch: 153, Loss: 1.1281177997589111, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1641979217529297, Accuracy: 0.615234375\n",
      "Batch: 155, Loss: 1.1146001815795898, Accuracy: 0.6455078125\n",
      "Epoch 465/200\n",
      "Batch: 1, Loss: 1.2441649436950684, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.060638189315796, Accuracy: 0.6728515625\n",
      "Batch: 3, Loss: 1.0233074426651, Accuracy: 0.6708984375\n",
      "Batch: 4, Loss: 1.0580620765686035, Accuracy: 0.6484375\n",
      "Batch: 5, Loss: 1.0216642618179321, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.0361170768737793, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 1.0449005365371704, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0060985088348389, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9996986389160156, Accuracy: 0.6904296875\n",
      "Batch: 10, Loss: 1.011430025100708, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 1.0040110349655151, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.040047526359558, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 1.048811674118042, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 0.9940129518508911, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.9521762132644653, Accuracy: 0.6796875\n",
      "Batch: 16, Loss: 1.0495753288269043, Accuracy: 0.662109375\n",
      "Batch: 17, Loss: 1.0802693367004395, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1517009735107422, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2752379179000854, Accuracy: 0.5859375\n",
      "Batch: 20, Loss: 1.1116749048233032, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0868725776672363, Accuracy: 0.634765625\n",
      "Batch: 22, Loss: 1.2133371829986572, Accuracy: 0.6162109375\n",
      "Batch: 23, Loss: 1.2868289947509766, Accuracy: 0.5751953125\n",
      "Batch: 24, Loss: 1.1243312358856201, Accuracy: 0.6298828125\n",
      "Batch: 25, Loss: 1.169903039932251, Accuracy: 0.61328125\n",
      "Batch: 26, Loss: 1.1858259439468384, Accuracy: 0.623046875\n",
      "Batch: 27, Loss: 1.1218156814575195, Accuracy: 0.6484375\n",
      "Batch: 28, Loss: 1.087442398071289, Accuracy: 0.6552734375\n",
      "Batch: 29, Loss: 1.0647668838500977, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.1632452011108398, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.2123692035675049, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.0762939453125, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.0435290336608887, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.12571382522583, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.1507256031036377, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.1759319305419922, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.2223129272460938, Accuracy: 0.599609375\n",
      "Batch: 38, Loss: 1.1764867305755615, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.0772957801818848, Accuracy: 0.634765625\n",
      "Batch: 40, Loss: 1.1489259004592896, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.1705799102783203, Accuracy: 0.611328125\n",
      "Batch: 42, Loss: 1.0654091835021973, Accuracy: 0.64453125\n",
      "Batch: 43, Loss: 1.0568662881851196, Accuracy: 0.6328125\n",
      "Batch: 44, Loss: 1.0484898090362549, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.0104687213897705, Accuracy: 0.66796875\n",
      "Batch: 46, Loss: 1.1172515153884888, Accuracy: 0.6416015625\n",
      "Batch: 47, Loss: 1.0976738929748535, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.1160829067230225, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.2040432691574097, Accuracy: 0.61328125\n",
      "Batch: 50, Loss: 1.142404556274414, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.1212968826293945, Accuracy: 0.6123046875\n",
      "Batch: 52, Loss: 1.2212061882019043, Accuracy: 0.6142578125\n",
      "Batch: 53, Loss: 1.1892225742340088, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.1616473197937012, Accuracy: 0.625\n",
      "Batch: 55, Loss: 1.1628310680389404, Accuracy: 0.6279296875\n",
      "Batch: 56, Loss: 1.1216561794281006, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.0934183597564697, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.1044642925262451, Accuracy: 0.6484375\n",
      "Batch: 59, Loss: 1.128150224685669, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.2269384860992432, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.1626646518707275, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.1758313179016113, Accuracy: 0.6318359375\n",
      "Batch: 63, Loss: 1.1809072494506836, Accuracy: 0.60546875\n",
      "Batch: 64, Loss: 1.2922477722167969, Accuracy: 0.5771484375\n",
      "Batch: 65, Loss: 1.2216789722442627, Accuracy: 0.5947265625\n",
      "Batch: 66, Loss: 1.205169916152954, Accuracy: 0.615234375\n",
      "Batch: 67, Loss: 1.1820478439331055, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.1054301261901855, Accuracy: 0.6494140625\n",
      "Batch: 69, Loss: 1.159591555595398, Accuracy: 0.6328125\n",
      "Batch: 70, Loss: 1.164015293121338, Accuracy: 0.619140625\n",
      "Batch: 71, Loss: 1.1082379817962646, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.223790168762207, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.1937397718429565, Accuracy: 0.59375\n",
      "Batch: 74, Loss: 1.1006789207458496, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.1430542469024658, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.1415966749191284, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.0962846279144287, Accuracy: 0.6455078125\n",
      "Batch: 78, Loss: 1.1263779401779175, Accuracy: 0.63671875\n",
      "Batch: 79, Loss: 1.163553237915039, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.1468274593353271, Accuracy: 0.6396484375\n",
      "Batch: 81, Loss: 1.159491777420044, Accuracy: 0.6142578125\n",
      "Batch: 82, Loss: 1.1623777151107788, Accuracy: 0.6396484375\n",
      "Batch: 83, Loss: 1.2223165035247803, Accuracy: 0.6044921875\n",
      "Batch: 84, Loss: 1.1863036155700684, Accuracy: 0.619140625\n",
      "Batch: 85, Loss: 1.1759090423583984, Accuracy: 0.619140625\n",
      "Batch: 86, Loss: 1.1906158924102783, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.1832265853881836, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.2232495546340942, Accuracy: 0.6005859375\n",
      "Batch: 89, Loss: 1.1734250783920288, Accuracy: 0.61328125\n",
      "Batch: 90, Loss: 1.1607387065887451, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.1906764507293701, Accuracy: 0.6201171875\n",
      "Batch: 92, Loss: 1.0966724157333374, Accuracy: 0.6494140625\n",
      "Batch: 93, Loss: 1.2066173553466797, Accuracy: 0.6064453125\n",
      "Batch: 94, Loss: 1.2071797847747803, Accuracy: 0.62109375\n",
      "Batch: 95, Loss: 1.1828806400299072, Accuracy: 0.6123046875\n",
      "Batch: 96, Loss: 1.2628296613693237, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.2049822807312012, Accuracy: 0.59375\n",
      "Batch: 98, Loss: 1.1957257986068726, Accuracy: 0.6162109375\n",
      "Batch: 99, Loss: 1.1688915491104126, Accuracy: 0.6025390625\n",
      "Batch: 100, Loss: 1.0944929122924805, Accuracy: 0.630859375\n",
      "Batch: 101, Loss: 1.0537254810333252, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 1.1892448663711548, Accuracy: 0.630859375\n",
      "Batch: 103, Loss: 1.1431009769439697, Accuracy: 0.611328125\n",
      "Batch: 104, Loss: 1.184295892715454, Accuracy: 0.6142578125\n",
      "Batch: 105, Loss: 1.2610297203063965, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.2088308334350586, Accuracy: 0.6162109375\n",
      "Batch: 107, Loss: 1.2528705596923828, Accuracy: 0.5830078125\n",
      "Batch: 108, Loss: 1.2431869506835938, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.1622682809829712, Accuracy: 0.61328125\n",
      "Batch: 110, Loss: 1.1452240943908691, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.1500751972198486, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 1.1137654781341553, Accuracy: 0.6220703125\n",
      "Batch: 113, Loss: 1.1601859331130981, Accuracy: 0.607421875\n",
      "Batch: 114, Loss: 1.1294515132904053, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.2408572435379028, Accuracy: 0.5859375\n",
      "Batch: 116, Loss: 1.2346380949020386, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.2044726610183716, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.2026859521865845, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.2773680686950684, Accuracy: 0.5859375\n",
      "Batch: 120, Loss: 1.3105744123458862, Accuracy: 0.5869140625\n",
      "Batch: 121, Loss: 1.2215282917022705, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.2053782939910889, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.18019700050354, Accuracy: 0.6162109375\n",
      "Batch: 124, Loss: 1.2572317123413086, Accuracy: 0.587890625\n",
      "Batch: 125, Loss: 1.1912174224853516, Accuracy: 0.619140625\n",
      "Batch: 126, Loss: 1.2374171018600464, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.2405476570129395, Accuracy: 0.6015625\n",
      "Batch: 128, Loss: 1.1670432090759277, Accuracy: 0.6357421875\n",
      "Batch: 129, Loss: 1.2362679243087769, Accuracy: 0.599609375\n",
      "Batch: 130, Loss: 1.1402690410614014, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.2044963836669922, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.1191074848175049, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.206878662109375, Accuracy: 0.59765625\n",
      "Batch: 134, Loss: 1.1704318523406982, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.0561208724975586, Accuracy: 0.6689453125\n",
      "Batch: 136, Loss: 1.1070866584777832, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1376899480819702, Accuracy: 0.6357421875\n",
      "Batch: 138, Loss: 1.231405258178711, Accuracy: 0.6005859375\n",
      "Batch: 139, Loss: 1.1397708654403687, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.2659687995910645, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.1724090576171875, Accuracy: 0.6259765625\n",
      "Batch: 142, Loss: 1.2122867107391357, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.2555549144744873, Accuracy: 0.59765625\n",
      "Batch: 144, Loss: 1.2583725452423096, Accuracy: 0.5888671875\n",
      "Batch: 145, Loss: 1.267425537109375, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.2392957210540771, Accuracy: 0.583984375\n",
      "Batch: 147, Loss: 1.2269388437271118, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.1953558921813965, Accuracy: 0.609375\n",
      "Batch: 149, Loss: 1.1709562540054321, Accuracy: 0.6220703125\n",
      "Batch: 150, Loss: 1.1813397407531738, Accuracy: 0.61328125\n",
      "Batch: 151, Loss: 1.1473792791366577, Accuracy: 0.6298828125\n",
      "Batch: 152, Loss: 1.1951897144317627, Accuracy: 0.603515625\n",
      "Batch: 153, Loss: 1.1899030208587646, Accuracy: 0.625\n",
      "Batch: 154, Loss: 1.1085143089294434, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.130814552307129, Accuracy: 0.6201171875\n",
      "Epoch 466/200\n",
      "Batch: 1, Loss: 1.2303187847137451, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 1.133192777633667, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 1.06955885887146, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.141135334968567, Accuracy: 0.615234375\n",
      "Batch: 5, Loss: 1.0439789295196533, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.0815497636795044, Accuracy: 0.6396484375\n",
      "Batch: 7, Loss: 1.0710501670837402, Accuracy: 0.6376953125\n",
      "Batch: 8, Loss: 1.0063365697860718, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 1.0116653442382812, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 1.0153377056121826, Accuracy: 0.67578125\n",
      "Batch: 11, Loss: 1.030827522277832, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 1.085254192352295, Accuracy: 0.634765625\n",
      "Batch: 13, Loss: 1.0794336795806885, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 1.021986484527588, Accuracy: 0.65625\n",
      "Batch: 15, Loss: 0.9774144887924194, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0248082876205444, Accuracy: 0.67578125\n",
      "Batch: 17, Loss: 1.0408473014831543, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.131908893585205, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2149748802185059, Accuracy: 0.6005859375\n",
      "Batch: 20, Loss: 1.1650605201721191, Accuracy: 0.6396484375\n",
      "Batch: 21, Loss: 1.0906754732131958, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.2304326295852661, Accuracy: 0.6103515625\n",
      "Batch: 23, Loss: 1.245638132095337, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.1850786209106445, Accuracy: 0.6240234375\n",
      "Batch: 25, Loss: 1.1540626287460327, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.1800212860107422, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.1545705795288086, Accuracy: 0.623046875\n",
      "Batch: 28, Loss: 1.09706449508667, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.1020066738128662, Accuracy: 0.6376953125\n",
      "Batch: 30, Loss: 1.155471682548523, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.2364726066589355, Accuracy: 0.599609375\n",
      "Batch: 32, Loss: 1.1086962223052979, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 1.055106520652771, Accuracy: 0.65625\n",
      "Batch: 34, Loss: 1.1007128953933716, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1496440172195435, Accuracy: 0.6337890625\n",
      "Batch: 36, Loss: 1.2529165744781494, Accuracy: 0.6103515625\n",
      "Batch: 37, Loss: 1.2525346279144287, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.2406651973724365, Accuracy: 0.5927734375\n",
      "Batch: 39, Loss: 1.1398013830184937, Accuracy: 0.640625\n",
      "Batch: 40, Loss: 1.1539334058761597, Accuracy: 0.6162109375\n",
      "Batch: 41, Loss: 1.1724462509155273, Accuracy: 0.625\n",
      "Batch: 42, Loss: 1.075380802154541, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 1.0847196578979492, Accuracy: 0.6318359375\n",
      "Batch: 44, Loss: 1.0579519271850586, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.098365306854248, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.1605846881866455, Accuracy: 0.6162109375\n",
      "Batch: 47, Loss: 1.134267807006836, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.1483397483825684, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.2086982727050781, Accuracy: 0.599609375\n",
      "Batch: 50, Loss: 1.1614633798599243, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1492979526519775, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.2636871337890625, Accuracy: 0.57421875\n",
      "Batch: 53, Loss: 1.2017631530761719, Accuracy: 0.59765625\n",
      "Batch: 54, Loss: 1.2577623128890991, Accuracy: 0.607421875\n",
      "Batch: 55, Loss: 1.1467859745025635, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.1418135166168213, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1342179775238037, Accuracy: 0.6259765625\n",
      "Batch: 58, Loss: 1.1066102981567383, Accuracy: 0.634765625\n",
      "Batch: 59, Loss: 1.0684088468551636, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.3292940855026245, Accuracy: 0.5810546875\n",
      "Batch: 61, Loss: 1.1484653949737549, Accuracy: 0.6279296875\n",
      "Batch: 62, Loss: 1.2213225364685059, Accuracy: 0.5986328125\n",
      "Batch: 63, Loss: 1.215557336807251, Accuracy: 0.5908203125\n",
      "Batch: 64, Loss: 1.2665126323699951, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.1811869144439697, Accuracy: 0.6171875\n",
      "Batch: 66, Loss: 1.1459622383117676, Accuracy: 0.6123046875\n",
      "Batch: 67, Loss: 1.145552635192871, Accuracy: 0.634765625\n",
      "Batch: 68, Loss: 1.0953902006149292, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.1802833080291748, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1546064615249634, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.1315534114837646, Accuracy: 0.6298828125\n",
      "Batch: 72, Loss: 1.2148094177246094, Accuracy: 0.619140625\n",
      "Batch: 73, Loss: 1.210634469985962, Accuracy: 0.59375\n",
      "Batch: 74, Loss: 1.1290420293807983, Accuracy: 0.62890625\n",
      "Batch: 75, Loss: 1.1488200426101685, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.0996887683868408, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.0567089319229126, Accuracy: 0.6630859375\n",
      "Batch: 78, Loss: 1.1262809038162231, Accuracy: 0.6220703125\n",
      "Batch: 79, Loss: 1.1407500505447388, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.1284387111663818, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.1355897188186646, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.1660499572753906, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.2166399955749512, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.137633204460144, Accuracy: 0.625\n",
      "Batch: 85, Loss: 1.1706156730651855, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.1841367483139038, Accuracy: 0.6171875\n",
      "Batch: 87, Loss: 1.200620174407959, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.1303131580352783, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.141916036605835, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.185633897781372, Accuracy: 0.6103515625\n",
      "Batch: 91, Loss: 1.1945574283599854, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.1283254623413086, Accuracy: 0.6572265625\n",
      "Batch: 93, Loss: 1.1323707103729248, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.153862714767456, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.1668851375579834, Accuracy: 0.630859375\n",
      "Batch: 96, Loss: 1.1814631223678589, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 97, Loss: 1.165244221687317, Accuracy: 0.619140625\n",
      "Batch: 98, Loss: 1.127927303314209, Accuracy: 0.6181640625\n",
      "Batch: 99, Loss: 1.1731266975402832, Accuracy: 0.6181640625\n",
      "Batch: 100, Loss: 1.0595941543579102, Accuracy: 0.66796875\n",
      "Batch: 101, Loss: 1.080798864364624, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1932742595672607, Accuracy: 0.6083984375\n",
      "Batch: 103, Loss: 1.1809566020965576, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.1986699104309082, Accuracy: 0.6083984375\n",
      "Batch: 105, Loss: 1.2582895755767822, Accuracy: 0.6044921875\n",
      "Batch: 106, Loss: 1.1996744871139526, Accuracy: 0.6162109375\n",
      "Batch: 107, Loss: 1.2662664651870728, Accuracy: 0.591796875\n",
      "Batch: 108, Loss: 1.2263015508651733, Accuracy: 0.580078125\n",
      "Batch: 109, Loss: 1.1628806591033936, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.11932373046875, Accuracy: 0.638671875\n",
      "Batch: 111, Loss: 1.1629040241241455, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.1191385984420776, Accuracy: 0.6318359375\n",
      "Batch: 113, Loss: 1.1759443283081055, Accuracy: 0.607421875\n",
      "Batch: 114, Loss: 1.1617062091827393, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.2047221660614014, Accuracy: 0.576171875\n",
      "Batch: 116, Loss: 1.209680438041687, Accuracy: 0.6005859375\n",
      "Batch: 117, Loss: 1.1837832927703857, Accuracy: 0.59765625\n",
      "Batch: 118, Loss: 1.1615490913391113, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.2509404420852661, Accuracy: 0.591796875\n",
      "Batch: 120, Loss: 1.3064814805984497, Accuracy: 0.5908203125\n",
      "Batch: 121, Loss: 1.2406911849975586, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.272019624710083, Accuracy: 0.6171875\n",
      "Batch: 123, Loss: 1.1662546396255493, Accuracy: 0.6298828125\n",
      "Batch: 124, Loss: 1.2288615703582764, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.1676831245422363, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.2325522899627686, Accuracy: 0.6318359375\n",
      "Batch: 127, Loss: 1.2799465656280518, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2213082313537598, Accuracy: 0.62109375\n",
      "Batch: 129, Loss: 1.188360333442688, Accuracy: 0.6044921875\n",
      "Batch: 130, Loss: 1.1771228313446045, Accuracy: 0.61328125\n",
      "Batch: 131, Loss: 1.1947864294052124, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.1087346076965332, Accuracy: 0.626953125\n",
      "Batch: 133, Loss: 1.1579973697662354, Accuracy: 0.626953125\n",
      "Batch: 134, Loss: 1.1299554109573364, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.1133285760879517, Accuracy: 0.65234375\n",
      "Batch: 136, Loss: 1.1205086708068848, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.1572668552398682, Accuracy: 0.6201171875\n",
      "Batch: 138, Loss: 1.2068780660629272, Accuracy: 0.5908203125\n",
      "Batch: 139, Loss: 1.1840543746948242, Accuracy: 0.6337890625\n",
      "Batch: 140, Loss: 1.27586829662323, Accuracy: 0.59375\n",
      "Batch: 141, Loss: 1.1973564624786377, Accuracy: 0.583984375\n",
      "Batch: 142, Loss: 1.2285254001617432, Accuracy: 0.6103515625\n",
      "Batch: 143, Loss: 1.2319772243499756, Accuracy: 0.603515625\n",
      "Batch: 144, Loss: 1.2525224685668945, Accuracy: 0.5927734375\n",
      "Batch: 145, Loss: 1.2918637990951538, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.192629098892212, Accuracy: 0.6220703125\n",
      "Batch: 147, Loss: 1.2351466417312622, Accuracy: 0.58203125\n",
      "Batch: 148, Loss: 1.2138572931289673, Accuracy: 0.6220703125\n",
      "Batch: 149, Loss: 1.1969307661056519, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.2196012735366821, Accuracy: 0.6015625\n",
      "Batch: 151, Loss: 1.160365343093872, Accuracy: 0.6171875\n",
      "Batch: 152, Loss: 1.1712387800216675, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.1831055879592896, Accuracy: 0.6083984375\n",
      "Batch: 154, Loss: 1.0880823135375977, Accuracy: 0.6494140625\n",
      "Batch: 155, Loss: 1.0858979225158691, Accuracy: 0.65234375\n",
      "Epoch 467/200\n",
      "Batch: 1, Loss: 1.1832780838012695, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.1049748659133911, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 1.01272451877594, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.1072819232940674, Accuracy: 0.6376953125\n",
      "Batch: 5, Loss: 1.0299005508422852, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.1371638774871826, Accuracy: 0.63671875\n",
      "Batch: 7, Loss: 1.0146424770355225, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9866806268692017, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 1.0172474384307861, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9578811526298523, Accuracy: 0.677734375\n",
      "Batch: 11, Loss: 1.0276219844818115, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 1.0260894298553467, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0284144878387451, Accuracy: 0.669921875\n",
      "Batch: 14, Loss: 1.0482611656188965, Accuracy: 0.666015625\n",
      "Batch: 15, Loss: 0.9233055710792542, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 1.0613720417022705, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.0705082416534424, Accuracy: 0.6494140625\n",
      "Batch: 18, Loss: 1.1342463493347168, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.2459601163864136, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.12464439868927, Accuracy: 0.6533203125\n",
      "Batch: 21, Loss: 1.0774855613708496, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.2624289989471436, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2379428148269653, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.118766188621521, Accuracy: 0.662109375\n",
      "Batch: 25, Loss: 1.1706955432891846, Accuracy: 0.625\n",
      "Batch: 26, Loss: 1.1992356777191162, Accuracy: 0.609375\n",
      "Batch: 27, Loss: 1.1123316287994385, Accuracy: 0.6201171875\n",
      "Batch: 28, Loss: 1.0917799472808838, Accuracy: 0.6298828125\n",
      "Batch: 29, Loss: 1.0833436250686646, Accuracy: 0.6328125\n",
      "Batch: 30, Loss: 1.2139155864715576, Accuracy: 0.6025390625\n",
      "Batch: 31, Loss: 1.2440836429595947, Accuracy: 0.5908203125\n",
      "Batch: 32, Loss: 1.01595938205719, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.0196056365966797, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.0984201431274414, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.121964454650879, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.1694142818450928, Accuracy: 0.6044921875\n",
      "Batch: 37, Loss: 1.2105686664581299, Accuracy: 0.5859375\n",
      "Batch: 38, Loss: 1.1159546375274658, Accuracy: 0.634765625\n",
      "Batch: 39, Loss: 1.141221284866333, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.1644004583358765, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1594449281692505, Accuracy: 0.62109375\n",
      "Batch: 42, Loss: 1.1089202165603638, Accuracy: 0.642578125\n",
      "Batch: 43, Loss: 0.9806046485900879, Accuracy: 0.6650390625\n",
      "Batch: 44, Loss: 1.1127159595489502, Accuracy: 0.626953125\n",
      "Batch: 45, Loss: 1.0914673805236816, Accuracy: 0.640625\n",
      "Batch: 46, Loss: 1.1820088624954224, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.1123757362365723, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.141692876815796, Accuracy: 0.6240234375\n",
      "Batch: 49, Loss: 1.1675465106964111, Accuracy: 0.6240234375\n",
      "Batch: 50, Loss: 1.1030768156051636, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1313635110855103, Accuracy: 0.6123046875\n",
      "Batch: 52, Loss: 1.239319920539856, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.1974434852600098, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.1781593561172485, Accuracy: 0.6015625\n",
      "Batch: 55, Loss: 1.1404368877410889, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.1249518394470215, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.1003096103668213, Accuracy: 0.6640625\n",
      "Batch: 58, Loss: 1.1549172401428223, Accuracy: 0.6357421875\n",
      "Batch: 59, Loss: 1.1028574705123901, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.2292823791503906, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.2006852626800537, Accuracy: 0.587890625\n",
      "Batch: 62, Loss: 1.1551475524902344, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.2300164699554443, Accuracy: 0.5986328125\n",
      "Batch: 64, Loss: 1.2243778705596924, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.2165961265563965, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1840076446533203, Accuracy: 0.6201171875\n",
      "Batch: 67, Loss: 1.154880404472351, Accuracy: 0.6298828125\n",
      "Batch: 68, Loss: 1.061814308166504, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.2109119892120361, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.2606121301651, Accuracy: 0.595703125\n",
      "Batch: 71, Loss: 1.1761672496795654, Accuracy: 0.6171875\n",
      "Batch: 72, Loss: 1.1873717308044434, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.20650053024292, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.1101011037826538, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.1571309566497803, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.1121273040771484, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.0747709274291992, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.0590476989746094, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.1217049360275269, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.126392126083374, Accuracy: 0.611328125\n",
      "Batch: 81, Loss: 1.0670862197875977, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 1.0920944213867188, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 1.2113927602767944, Accuracy: 0.583984375\n",
      "Batch: 84, Loss: 1.1636896133422852, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.2160310745239258, Accuracy: 0.615234375\n",
      "Batch: 86, Loss: 1.2241355180740356, Accuracy: 0.6083984375\n",
      "Batch: 87, Loss: 1.1618061065673828, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.182901382446289, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.1815438270568848, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 1.1505212783813477, Accuracy: 0.6162109375\n",
      "Batch: 91, Loss: 1.1131904125213623, Accuracy: 0.638671875\n",
      "Batch: 92, Loss: 1.1076685190200806, Accuracy: 0.646484375\n",
      "Batch: 93, Loss: 1.1747605800628662, Accuracy: 0.615234375\n",
      "Batch: 94, Loss: 1.1742377281188965, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.2414307594299316, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2391330003738403, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.1951773166656494, Accuracy: 0.5947265625\n",
      "Batch: 98, Loss: 1.1303608417510986, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.2003536224365234, Accuracy: 0.6123046875\n",
      "Batch: 100, Loss: 1.0790035724639893, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.140857458114624, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.1893454790115356, Accuracy: 0.6025390625\n",
      "Batch: 103, Loss: 1.2053470611572266, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.1496102809906006, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.2135865688323975, Accuracy: 0.595703125\n",
      "Batch: 106, Loss: 1.1768906116485596, Accuracy: 0.615234375\n",
      "Batch: 107, Loss: 1.2832304239273071, Accuracy: 0.556640625\n",
      "Batch: 108, Loss: 1.1975866556167603, Accuracy: 0.5888671875\n",
      "Batch: 109, Loss: 1.2359075546264648, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.1487526893615723, Accuracy: 0.634765625\n",
      "Batch: 111, Loss: 1.1909410953521729, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.0785324573516846, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.2307994365692139, Accuracy: 0.595703125\n",
      "Batch: 114, Loss: 1.1789450645446777, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.1452865600585938, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.2183232307434082, Accuracy: 0.6015625\n",
      "Batch: 117, Loss: 1.1580313444137573, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 1.2518367767333984, Accuracy: 0.5830078125\n",
      "Batch: 119, Loss: 1.243019700050354, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.2991414070129395, Accuracy: 0.6005859375\n",
      "Batch: 121, Loss: 1.2543549537658691, Accuracy: 0.599609375\n",
      "Batch: 122, Loss: 1.2519311904907227, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.2220550775527954, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.1834959983825684, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.134683609008789, Accuracy: 0.650390625\n",
      "Batch: 126, Loss: 1.312530279159546, Accuracy: 0.583984375\n",
      "Batch: 127, Loss: 1.2019550800323486, Accuracy: 0.6181640625\n",
      "Batch: 128, Loss: 1.2324936389923096, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.1234219074249268, Accuracy: 0.6484375\n",
      "Batch: 130, Loss: 1.158935785293579, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.2654564380645752, Accuracy: 0.5859375\n",
      "Batch: 132, Loss: 1.1055625677108765, Accuracy: 0.6474609375\n",
      "Batch: 133, Loss: 1.2336894273757935, Accuracy: 0.5966796875\n",
      "Batch: 134, Loss: 1.1240925788879395, Accuracy: 0.6689453125\n",
      "Batch: 135, Loss: 1.0788623094558716, Accuracy: 0.638671875\n",
      "Batch: 136, Loss: 1.087039589881897, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.181128740310669, Accuracy: 0.6220703125\n",
      "Batch: 138, Loss: 1.307065725326538, Accuracy: 0.5751953125\n",
      "Batch: 139, Loss: 1.1845488548278809, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.2972007989883423, Accuracy: 0.5771484375\n",
      "Batch: 141, Loss: 1.1920312643051147, Accuracy: 0.61328125\n",
      "Batch: 142, Loss: 1.2326411008834839, Accuracy: 0.6142578125\n",
      "Batch: 143, Loss: 1.2360299825668335, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.2433969974517822, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.3059860467910767, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.2057945728302002, Accuracy: 0.6064453125\n",
      "Batch: 147, Loss: 1.2057479619979858, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.1416953802108765, Accuracy: 0.630859375\n",
      "Batch: 149, Loss: 1.17747962474823, Accuracy: 0.6142578125\n",
      "Batch: 150, Loss: 1.1811192035675049, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.1763046979904175, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.200629711151123, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.114930272102356, Accuracy: 0.638671875\n",
      "Batch: 154, Loss: 1.1641430854797363, Accuracy: 0.6298828125\n",
      "Batch: 155, Loss: 1.1510438919067383, Accuracy: 0.6171875\n",
      "Epoch 468/200\n",
      "Batch: 1, Loss: 1.2124826908111572, Accuracy: 0.62890625\n",
      "Batch: 2, Loss: 1.1157323122024536, Accuracy: 0.646484375\n",
      "Batch: 3, Loss: 1.019775629043579, Accuracy: 0.67578125\n",
      "Batch: 4, Loss: 1.0742683410644531, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0158607959747314, Accuracy: 0.6689453125\n",
      "Batch: 6, Loss: 1.0594067573547363, Accuracy: 0.6611328125\n",
      "Batch: 7, Loss: 1.0284138917922974, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 0.9960969090461731, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9843024015426636, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 1.0142583847045898, Accuracy: 0.671875\n",
      "Batch: 11, Loss: 1.03078031539917, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.0514439344406128, Accuracy: 0.6474609375\n",
      "Batch: 13, Loss: 1.0230863094329834, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9974144697189331, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.9067778587341309, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 1.0383992195129395, Accuracy: 0.662109375\n",
      "Batch: 17, Loss: 1.0697379112243652, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.1488723754882812, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.2418744564056396, Accuracy: 0.5966796875\n",
      "Batch: 20, Loss: 1.1441872119903564, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1057918071746826, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2673753499984741, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2485246658325195, Accuracy: 0.58984375\n",
      "Batch: 24, Loss: 1.1458563804626465, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1117135286331177, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.1599912643432617, Accuracy: 0.6083984375\n",
      "Batch: 27, Loss: 1.1572699546813965, Accuracy: 0.6142578125\n",
      "Batch: 28, Loss: 1.1143301725387573, Accuracy: 0.642578125\n",
      "Batch: 29, Loss: 1.0766854286193848, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.1788246631622314, Accuracy: 0.6103515625\n",
      "Batch: 31, Loss: 1.227515697479248, Accuracy: 0.5947265625\n",
      "Batch: 32, Loss: 1.038374662399292, Accuracy: 0.658203125\n",
      "Batch: 33, Loss: 1.0390214920043945, Accuracy: 0.642578125\n",
      "Batch: 34, Loss: 1.0678486824035645, Accuracy: 0.6865234375\n",
      "Batch: 35, Loss: 1.1678820848464966, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.2430452108383179, Accuracy: 0.591796875\n",
      "Batch: 37, Loss: 1.215993881225586, Accuracy: 0.583984375\n",
      "Batch: 38, Loss: 1.1452041864395142, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.0648859739303589, Accuracy: 0.63671875\n",
      "Batch: 40, Loss: 1.091780662536621, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1149914264678955, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0826371908187866, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.061532735824585, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.0650018453598022, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 1.0571436882019043, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.1327698230743408, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.131764531135559, Accuracy: 0.6640625\n",
      "Batch: 48, Loss: 1.1608150005340576, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.2130069732666016, Accuracy: 0.6103515625\n",
      "Batch: 50, Loss: 1.1109240055084229, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.2231237888336182, Accuracy: 0.576171875\n",
      "Batch: 52, Loss: 1.2797799110412598, Accuracy: 0.5771484375\n",
      "Batch: 53, Loss: 1.162210464477539, Accuracy: 0.615234375\n",
      "Batch: 54, Loss: 1.22359037399292, Accuracy: 0.59375\n",
      "Batch: 55, Loss: 1.0940852165222168, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.1194151639938354, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.1504135131835938, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.1224327087402344, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 1.1042221784591675, Accuracy: 0.654296875\n",
      "Batch: 60, Loss: 1.2355997562408447, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.1770731210708618, Accuracy: 0.603515625\n",
      "Batch: 62, Loss: 1.1161962747573853, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.1802418231964111, Accuracy: 0.6142578125\n",
      "Batch: 64, Loss: 1.225037932395935, Accuracy: 0.603515625\n",
      "Batch: 65, Loss: 1.2110531330108643, Accuracy: 0.59765625\n",
      "Batch: 66, Loss: 1.1549599170684814, Accuracy: 0.6240234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 67, Loss: 1.1957015991210938, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.0576961040496826, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.1637897491455078, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.2063300609588623, Accuracy: 0.6015625\n",
      "Batch: 71, Loss: 1.0954248905181885, Accuracy: 0.66015625\n",
      "Batch: 72, Loss: 1.2411611080169678, Accuracy: 0.599609375\n",
      "Batch: 73, Loss: 1.1663297414779663, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.1235668659210205, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.0784238576889038, Accuracy: 0.64453125\n",
      "Batch: 76, Loss: 1.0933754444122314, Accuracy: 0.6376953125\n",
      "Batch: 77, Loss: 1.053330898284912, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.0790157318115234, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.1792079210281372, Accuracy: 0.619140625\n",
      "Batch: 80, Loss: 1.1455059051513672, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.1471078395843506, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.1129118204116821, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 1.2660090923309326, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.1415448188781738, Accuracy: 0.623046875\n",
      "Batch: 85, Loss: 1.1385858058929443, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.190168857574463, Accuracy: 0.607421875\n",
      "Batch: 87, Loss: 1.1995203495025635, Accuracy: 0.623046875\n",
      "Batch: 88, Loss: 1.150094747543335, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.1316136121749878, Accuracy: 0.630859375\n",
      "Batch: 90, Loss: 1.1388643980026245, Accuracy: 0.62109375\n",
      "Batch: 91, Loss: 1.1611888408660889, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.1318256855010986, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.1409273147583008, Accuracy: 0.6298828125\n",
      "Batch: 94, Loss: 1.2347450256347656, Accuracy: 0.5947265625\n",
      "Batch: 95, Loss: 1.1964354515075684, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2301254272460938, Accuracy: 0.6142578125\n",
      "Batch: 97, Loss: 1.2464158535003662, Accuracy: 0.5751953125\n",
      "Batch: 98, Loss: 1.1085946559906006, Accuracy: 0.642578125\n",
      "Batch: 99, Loss: 1.1576039791107178, Accuracy: 0.6044921875\n",
      "Batch: 100, Loss: 1.051821231842041, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.086601734161377, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.1604669094085693, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.1965653896331787, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1719486713409424, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.288527488708496, Accuracy: 0.576171875\n",
      "Batch: 106, Loss: 1.1614482402801514, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.2362236976623535, Accuracy: 0.59765625\n",
      "Batch: 108, Loss: 1.162531852722168, Accuracy: 0.6044921875\n",
      "Batch: 109, Loss: 1.2319248914718628, Accuracy: 0.6044921875\n",
      "Batch: 110, Loss: 1.1538054943084717, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.08938467502594, Accuracy: 0.6484375\n",
      "Batch: 112, Loss: 1.1368703842163086, Accuracy: 0.6376953125\n",
      "Batch: 113, Loss: 1.1392054557800293, Accuracy: 0.619140625\n",
      "Batch: 114, Loss: 1.1918120384216309, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.1465706825256348, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1898183822631836, Accuracy: 0.603515625\n",
      "Batch: 117, Loss: 1.1792503595352173, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.211592435836792, Accuracy: 0.615234375\n",
      "Batch: 119, Loss: 1.2617764472961426, Accuracy: 0.59765625\n",
      "Batch: 120, Loss: 1.304189682006836, Accuracy: 0.5771484375\n",
      "Batch: 121, Loss: 1.198375940322876, Accuracy: 0.607421875\n",
      "Batch: 122, Loss: 1.2131458520889282, Accuracy: 0.6064453125\n",
      "Batch: 123, Loss: 1.1532269716262817, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.2211813926696777, Accuracy: 0.60546875\n",
      "Batch: 125, Loss: 1.122387409210205, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.2045845985412598, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.2540793418884277, Accuracy: 0.5791015625\n",
      "Batch: 128, Loss: 1.2016518115997314, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.2073793411254883, Accuracy: 0.6015625\n",
      "Batch: 130, Loss: 1.1355183124542236, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.2155362367630005, Accuracy: 0.599609375\n",
      "Batch: 132, Loss: 1.1114661693572998, Accuracy: 0.6376953125\n",
      "Batch: 133, Loss: 1.1528208255767822, Accuracy: 0.638671875\n",
      "Batch: 134, Loss: 1.1212506294250488, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.098881721496582, Accuracy: 0.640625\n",
      "Batch: 136, Loss: 1.1000890731811523, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.2134478092193604, Accuracy: 0.62109375\n",
      "Batch: 138, Loss: 1.2326064109802246, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.1923143863677979, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.2496098279953003, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.1783466339111328, Accuracy: 0.5966796875\n",
      "Batch: 142, Loss: 1.2393388748168945, Accuracy: 0.609375\n",
      "Batch: 143, Loss: 1.273547887802124, Accuracy: 0.591796875\n",
      "Batch: 144, Loss: 1.273360252380371, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.3201112747192383, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.229999303817749, Accuracy: 0.5986328125\n",
      "Batch: 147, Loss: 1.2100971937179565, Accuracy: 0.6103515625\n",
      "Batch: 148, Loss: 1.245033621788025, Accuracy: 0.5966796875\n",
      "Batch: 149, Loss: 1.2391676902770996, Accuracy: 0.587890625\n",
      "Batch: 150, Loss: 1.1472231149673462, Accuracy: 0.640625\n",
      "Batch: 151, Loss: 1.1085779666900635, Accuracy: 0.62890625\n",
      "Batch: 152, Loss: 1.2009029388427734, Accuracy: 0.6015625\n",
      "Batch: 153, Loss: 1.1772164106369019, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.1571886539459229, Accuracy: 0.6240234375\n",
      "Batch: 155, Loss: 1.0801578760147095, Accuracy: 0.642578125\n",
      "Epoch 469/200\n",
      "Batch: 1, Loss: 1.2196507453918457, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.0706806182861328, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 1.0653090476989746, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.1091582775115967, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.0127333402633667, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.0284806489944458, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 0.9907592535018921, Accuracy: 0.6748046875\n",
      "Batch: 8, Loss: 0.9669902324676514, Accuracy: 0.6943359375\n",
      "Batch: 9, Loss: 1.068704605102539, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 0.9602589011192322, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 0.9724827408790588, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 1.0500444173812866, Accuracy: 0.64453125\n",
      "Batch: 13, Loss: 1.033874750137329, Accuracy: 0.64453125\n",
      "Batch: 14, Loss: 1.049913763999939, Accuracy: 0.65234375\n",
      "Batch: 15, Loss: 0.9492048621177673, Accuracy: 0.69140625\n",
      "Batch: 16, Loss: 1.0706031322479248, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.0906083583831787, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1085336208343506, Accuracy: 0.654296875\n",
      "Batch: 19, Loss: 1.2518154382705688, Accuracy: 0.6044921875\n",
      "Batch: 20, Loss: 1.110772967338562, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.1415886878967285, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.2176405191421509, Accuracy: 0.619140625\n",
      "Batch: 23, Loss: 1.2738673686981201, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.1194453239440918, Accuracy: 0.6318359375\n",
      "Batch: 25, Loss: 1.1548949480056763, Accuracy: 0.634765625\n",
      "Batch: 26, Loss: 1.187408447265625, Accuracy: 0.5966796875\n",
      "Batch: 27, Loss: 1.1202722787857056, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.1031197309494019, Accuracy: 0.623046875\n",
      "Batch: 29, Loss: 1.0902013778686523, Accuracy: 0.6513671875\n",
      "Batch: 30, Loss: 1.1748082637786865, Accuracy: 0.6162109375\n",
      "Batch: 31, Loss: 1.2157316207885742, Accuracy: 0.6064453125\n",
      "Batch: 32, Loss: 1.1120028495788574, Accuracy: 0.6328125\n",
      "Batch: 33, Loss: 0.9943521022796631, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.16926908493042, Accuracy: 0.62890625\n",
      "Batch: 35, Loss: 1.1298153400421143, Accuracy: 0.6240234375\n",
      "Batch: 36, Loss: 1.1817984580993652, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.2125318050384521, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.191256046295166, Accuracy: 0.6015625\n",
      "Batch: 39, Loss: 1.1259441375732422, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.1191213130950928, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.15590238571167, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.1121087074279785, Accuracy: 0.6279296875\n",
      "Batch: 43, Loss: 1.1031205654144287, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.0420774221420288, Accuracy: 0.654296875\n",
      "Batch: 45, Loss: 1.1156935691833496, Accuracy: 0.626953125\n",
      "Batch: 46, Loss: 1.185051441192627, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.1264922618865967, Accuracy: 0.6435546875\n",
      "Batch: 48, Loss: 1.1111578941345215, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.2056183815002441, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.1648858785629272, Accuracy: 0.634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 51, Loss: 1.1106188297271729, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.2982138395309448, Accuracy: 0.583984375\n",
      "Batch: 53, Loss: 1.183919906616211, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.1895875930786133, Accuracy: 0.625\n",
      "Batch: 55, Loss: 1.1007945537567139, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.1123771667480469, Accuracy: 0.6455078125\n",
      "Batch: 57, Loss: 1.152408480644226, Accuracy: 0.6298828125\n",
      "Batch: 58, Loss: 1.077146291732788, Accuracy: 0.6484375\n",
      "Batch: 59, Loss: 1.1503454446792603, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2603988647460938, Accuracy: 0.59765625\n",
      "Batch: 61, Loss: 1.1496367454528809, Accuracy: 0.6201171875\n",
      "Batch: 62, Loss: 1.1243116855621338, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1938157081604004, Accuracy: 0.615234375\n",
      "Batch: 64, Loss: 1.2268965244293213, Accuracy: 0.595703125\n",
      "Batch: 65, Loss: 1.232606291770935, Accuracy: 0.59765625\n",
      "Batch: 66, Loss: 1.1671022176742554, Accuracy: 0.6181640625\n",
      "Batch: 67, Loss: 1.2255359888076782, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.0912377834320068, Accuracy: 0.6552734375\n",
      "Batch: 69, Loss: 1.1067490577697754, Accuracy: 0.6494140625\n",
      "Batch: 70, Loss: 1.1694716215133667, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.1042367219924927, Accuracy: 0.625\n",
      "Batch: 72, Loss: 1.212438941001892, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.2049483060836792, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1504952907562256, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.173590064048767, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.025720238685608, Accuracy: 0.66015625\n",
      "Batch: 77, Loss: 1.1203792095184326, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.0700438022613525, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.1048458814620972, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.2233695983886719, Accuracy: 0.611328125\n",
      "Batch: 81, Loss: 1.1257745027542114, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.1310398578643799, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.2535617351531982, Accuracy: 0.6142578125\n",
      "Batch: 84, Loss: 1.1606688499450684, Accuracy: 0.6171875\n",
      "Batch: 85, Loss: 1.1222591400146484, Accuracy: 0.63671875\n",
      "Batch: 86, Loss: 1.1769275665283203, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.1968332529067993, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.248891830444336, Accuracy: 0.595703125\n",
      "Batch: 89, Loss: 1.2161096334457397, Accuracy: 0.61328125\n",
      "Batch: 90, Loss: 1.2044219970703125, Accuracy: 0.6103515625\n",
      "Batch: 91, Loss: 1.1708519458770752, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1239007711410522, Accuracy: 0.650390625\n",
      "Batch: 93, Loss: 1.1585586071014404, Accuracy: 0.6259765625\n",
      "Batch: 94, Loss: 1.1944628953933716, Accuracy: 0.591796875\n",
      "Batch: 95, Loss: 1.2098493576049805, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.235149621963501, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.1849925518035889, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1666470766067505, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.116566777229309, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.0732285976409912, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.1276073455810547, Accuracy: 0.6328125\n",
      "Batch: 102, Loss: 1.224631428718567, Accuracy: 0.60546875\n",
      "Batch: 103, Loss: 1.1710538864135742, Accuracy: 0.61328125\n",
      "Batch: 104, Loss: 1.1412564516067505, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.2490369081497192, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.1810786724090576, Accuracy: 0.615234375\n",
      "Batch: 107, Loss: 1.254111409187317, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.2401232719421387, Accuracy: 0.587890625\n",
      "Batch: 109, Loss: 1.2154372930526733, Accuracy: 0.611328125\n",
      "Batch: 110, Loss: 1.1732368469238281, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.137791395187378, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.086414098739624, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.2087528705596924, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.208512306213379, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.205564022064209, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1905827522277832, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.1863515377044678, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.2237043380737305, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.2492632865905762, Accuracy: 0.6015625\n",
      "Batch: 120, Loss: 1.280846357345581, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.183206558227539, Accuracy: 0.62109375\n",
      "Batch: 122, Loss: 1.2519586086273193, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.180082082748413, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.2168447971343994, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.1652681827545166, Accuracy: 0.6494140625\n",
      "Batch: 126, Loss: 1.2785143852233887, Accuracy: 0.5888671875\n",
      "Batch: 127, Loss: 1.242717981338501, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.2398695945739746, Accuracy: 0.591796875\n",
      "Batch: 129, Loss: 1.199822187423706, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.2262213230133057, Accuracy: 0.6083984375\n",
      "Batch: 131, Loss: 1.2381459474563599, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.1126956939697266, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.168031930923462, Accuracy: 0.609375\n",
      "Batch: 134, Loss: 1.1090753078460693, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.046447515487671, Accuracy: 0.646484375\n",
      "Batch: 136, Loss: 1.1060744524002075, Accuracy: 0.6240234375\n",
      "Batch: 137, Loss: 1.147287368774414, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.1851160526275635, Accuracy: 0.6220703125\n",
      "Batch: 139, Loss: 1.2307918071746826, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.2376213073730469, Accuracy: 0.6259765625\n",
      "Batch: 141, Loss: 1.1862237453460693, Accuracy: 0.591796875\n",
      "Batch: 142, Loss: 1.1968969106674194, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.2473902702331543, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.2828857898712158, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.2960621118545532, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.2684299945831299, Accuracy: 0.5791015625\n",
      "Batch: 147, Loss: 1.2164216041564941, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.1961321830749512, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.180546522140503, Accuracy: 0.6044921875\n",
      "Batch: 150, Loss: 1.2220842838287354, Accuracy: 0.59375\n",
      "Batch: 151, Loss: 1.193988561630249, Accuracy: 0.6201171875\n",
      "Batch: 152, Loss: 1.155444622039795, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.1565454006195068, Accuracy: 0.6376953125\n",
      "Batch: 154, Loss: 1.147691011428833, Accuracy: 0.6162109375\n",
      "Batch: 155, Loss: 1.1170235872268677, Accuracy: 0.6318359375\n",
      "Epoch 470/200\n",
      "Batch: 1, Loss: 1.2165746688842773, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 1.0593023300170898, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.0444806814193726, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.095186471939087, Accuracy: 0.650390625\n",
      "Batch: 5, Loss: 1.0407249927520752, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.0659966468811035, Accuracy: 0.6474609375\n",
      "Batch: 7, Loss: 1.0132627487182617, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 1.0168981552124023, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 1.006568193435669, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9417018890380859, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 1.0040539503097534, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0087716579437256, Accuracy: 0.662109375\n",
      "Batch: 13, Loss: 0.989973247051239, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 0.9840710163116455, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.9541847109794617, Accuracy: 0.69140625\n",
      "Batch: 16, Loss: 1.0555949211120605, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.0998897552490234, Accuracy: 0.6279296875\n",
      "Batch: 18, Loss: 1.128488302230835, Accuracy: 0.6455078125\n",
      "Batch: 19, Loss: 1.2575279474258423, Accuracy: 0.5986328125\n",
      "Batch: 20, Loss: 1.0966334342956543, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.0747205018997192, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1827378273010254, Accuracy: 0.630859375\n",
      "Batch: 23, Loss: 1.2539007663726807, Accuracy: 0.5927734375\n",
      "Batch: 24, Loss: 1.1187641620635986, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.1868270635604858, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.1406002044677734, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.14606511592865, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.0676201581954956, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.1096813678741455, Accuracy: 0.638671875\n",
      "Batch: 30, Loss: 1.1382640600204468, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.192244529724121, Accuracy: 0.6044921875\n",
      "Batch: 32, Loss: 1.0602552890777588, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 0.9992501735687256, Accuracy: 0.6826171875\n",
      "Batch: 34, Loss: 1.1426007747650146, Accuracy: 0.640625\n",
      "Batch: 35, Loss: 1.179363489151001, Accuracy: 0.6162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 36, Loss: 1.278863787651062, Accuracy: 0.5869140625\n",
      "Batch: 37, Loss: 1.1554045677185059, Accuracy: 0.6123046875\n",
      "Batch: 38, Loss: 1.1630988121032715, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.097663164138794, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 1.1423451900482178, Accuracy: 0.6201171875\n",
      "Batch: 41, Loss: 1.1356871128082275, Accuracy: 0.626953125\n",
      "Batch: 42, Loss: 1.1089539527893066, Accuracy: 0.623046875\n",
      "Batch: 43, Loss: 1.1030573844909668, Accuracy: 0.630859375\n",
      "Batch: 44, Loss: 1.0838255882263184, Accuracy: 0.6328125\n",
      "Batch: 45, Loss: 1.0750114917755127, Accuracy: 0.63671875\n",
      "Batch: 46, Loss: 1.1394466161727905, Accuracy: 0.6171875\n",
      "Batch: 47, Loss: 1.0980098247528076, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.1453485488891602, Accuracy: 0.6357421875\n",
      "Batch: 49, Loss: 1.184464454650879, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.191056489944458, Accuracy: 0.6103515625\n",
      "Batch: 51, Loss: 1.1900222301483154, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.2189058065414429, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.1249321699142456, Accuracy: 0.6298828125\n",
      "Batch: 54, Loss: 1.2115073204040527, Accuracy: 0.6142578125\n",
      "Batch: 55, Loss: 1.1357522010803223, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.1330370903015137, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.1549372673034668, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.1056544780731201, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.1642465591430664, Accuracy: 0.62109375\n",
      "Batch: 60, Loss: 1.222493052482605, Accuracy: 0.6083984375\n",
      "Batch: 61, Loss: 1.0964595079421997, Accuracy: 0.63671875\n",
      "Batch: 62, Loss: 1.2364999055862427, Accuracy: 0.5859375\n",
      "Batch: 63, Loss: 1.1675045490264893, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.227181077003479, Accuracy: 0.603515625\n",
      "Batch: 65, Loss: 1.2145901918411255, Accuracy: 0.6171875\n",
      "Batch: 66, Loss: 1.158574104309082, Accuracy: 0.6142578125\n",
      "Batch: 67, Loss: 1.127319574356079, Accuracy: 0.6328125\n",
      "Batch: 68, Loss: 1.088979721069336, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.1921007633209229, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.2141597270965576, Accuracy: 0.61328125\n",
      "Batch: 71, Loss: 1.1355630159378052, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.2131417989730835, Accuracy: 0.5986328125\n",
      "Batch: 73, Loss: 1.1963436603546143, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.1469557285308838, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.1190917491912842, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.130295991897583, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.1057045459747314, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0980956554412842, Accuracy: 0.6337890625\n",
      "Batch: 79, Loss: 1.1945669651031494, Accuracy: 0.6162109375\n",
      "Batch: 80, Loss: 1.164829969406128, Accuracy: 0.6259765625\n",
      "Batch: 81, Loss: 1.1003742218017578, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.1731765270233154, Accuracy: 0.61328125\n",
      "Batch: 83, Loss: 1.215444803237915, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.1028491258621216, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.159522294998169, Accuracy: 0.61328125\n",
      "Batch: 86, Loss: 1.1548066139221191, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 1.1805537939071655, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.1712300777435303, Accuracy: 0.6142578125\n",
      "Batch: 89, Loss: 1.1543419361114502, Accuracy: 0.61328125\n",
      "Batch: 90, Loss: 1.1413453817367554, Accuracy: 0.6240234375\n",
      "Batch: 91, Loss: 1.1338038444519043, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.188967227935791, Accuracy: 0.6181640625\n",
      "Batch: 93, Loss: 1.173825740814209, Accuracy: 0.609375\n",
      "Batch: 94, Loss: 1.2335212230682373, Accuracy: 0.59765625\n",
      "Batch: 95, Loss: 1.246178150177002, Accuracy: 0.5927734375\n",
      "Batch: 96, Loss: 1.1977159976959229, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.150754690170288, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1021184921264648, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.173360824584961, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.1152657270431519, Accuracy: 0.640625\n",
      "Batch: 101, Loss: 1.156881332397461, Accuracy: 0.6201171875\n",
      "Batch: 102, Loss: 1.1241517066955566, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.159767985343933, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.13767671585083, Accuracy: 0.6484375\n",
      "Batch: 105, Loss: 1.2192890644073486, Accuracy: 0.619140625\n",
      "Batch: 106, Loss: 1.1937055587768555, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.2145353555679321, Accuracy: 0.6162109375\n",
      "Batch: 108, Loss: 1.2221845388412476, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.2500360012054443, Accuracy: 0.591796875\n",
      "Batch: 110, Loss: 1.167997121810913, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.1556396484375, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.151487112045288, Accuracy: 0.6337890625\n",
      "Batch: 113, Loss: 1.2000436782836914, Accuracy: 0.626953125\n",
      "Batch: 114, Loss: 1.1936943531036377, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.1934928894042969, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.2421749830245972, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.1905550956726074, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 1.2155307531356812, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.2729604244232178, Accuracy: 0.5869140625\n",
      "Batch: 120, Loss: 1.2723299264907837, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.2260870933532715, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.247633457183838, Accuracy: 0.587890625\n",
      "Batch: 123, Loss: 1.1807796955108643, Accuracy: 0.61328125\n",
      "Batch: 124, Loss: 1.2537668943405151, Accuracy: 0.607421875\n",
      "Batch: 125, Loss: 1.2486839294433594, Accuracy: 0.5927734375\n",
      "Batch: 126, Loss: 1.2969027757644653, Accuracy: 0.5966796875\n",
      "Batch: 127, Loss: 1.2693140506744385, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.2127695083618164, Accuracy: 0.6201171875\n",
      "Batch: 129, Loss: 1.1844968795776367, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.160156488418579, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.2600547075271606, Accuracy: 0.5751953125\n",
      "Batch: 132, Loss: 1.1230288743972778, Accuracy: 0.63671875\n",
      "Batch: 133, Loss: 1.1337449550628662, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.128533959388733, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.0274200439453125, Accuracy: 0.666015625\n",
      "Batch: 136, Loss: 1.0761405229568481, Accuracy: 0.6416015625\n",
      "Batch: 137, Loss: 1.1510365009307861, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.2390539646148682, Accuracy: 0.5888671875\n",
      "Batch: 139, Loss: 1.2091890573501587, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.2717764377593994, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.2032033205032349, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2390891313552856, Accuracy: 0.59375\n",
      "Batch: 143, Loss: 1.209272027015686, Accuracy: 0.6103515625\n",
      "Batch: 144, Loss: 1.307922124862671, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.2769198417663574, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.2224555015563965, Accuracy: 0.58984375\n",
      "Batch: 147, Loss: 1.2687625885009766, Accuracy: 0.59375\n",
      "Batch: 148, Loss: 1.219952940940857, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.1703623533248901, Accuracy: 0.6181640625\n",
      "Batch: 150, Loss: 1.1832703351974487, Accuracy: 0.6142578125\n",
      "Batch: 151, Loss: 1.1313115358352661, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.1633015871047974, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.1519811153411865, Accuracy: 0.6181640625\n",
      "Batch: 154, Loss: 1.0803070068359375, Accuracy: 0.6396484375\n",
      "Batch: 155, Loss: 1.1222407817840576, Accuracy: 0.6328125\n",
      "Saved Weights at epoch 470 to file Weights_470.h5\n",
      "Epoch 471/200\n",
      "Batch: 1, Loss: 1.2654956579208374, Accuracy: 0.6220703125\n",
      "Batch: 2, Loss: 1.0944440364837646, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 1.07830810546875, Accuracy: 0.634765625\n",
      "Batch: 4, Loss: 1.158679723739624, Accuracy: 0.6181640625\n",
      "Batch: 5, Loss: 1.0497584342956543, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.0876322984695435, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.0004338026046753, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 1.0135998725891113, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 1.0219717025756836, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 1.0098276138305664, Accuracy: 0.6708984375\n",
      "Batch: 11, Loss: 1.0313444137573242, Accuracy: 0.658203125\n",
      "Batch: 12, Loss: 1.0552120208740234, Accuracy: 0.666015625\n",
      "Batch: 13, Loss: 1.0545735359191895, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9957864284515381, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.9270207285881042, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 1.0140666961669922, Accuracy: 0.6669921875\n",
      "Batch: 17, Loss: 1.0628814697265625, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.1948795318603516, Accuracy: 0.6181640625\n",
      "Batch: 19, Loss: 1.2334046363830566, Accuracy: 0.587890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 1.1211695671081543, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.1274430751800537, Accuracy: 0.625\n",
      "Batch: 22, Loss: 1.2209124565124512, Accuracy: 0.6015625\n",
      "Batch: 23, Loss: 1.2898828983306885, Accuracy: 0.580078125\n",
      "Batch: 24, Loss: 1.095217227935791, Accuracy: 0.642578125\n",
      "Batch: 25, Loss: 1.172156572341919, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.189232349395752, Accuracy: 0.603515625\n",
      "Batch: 27, Loss: 1.15162992477417, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.0502827167510986, Accuracy: 0.6640625\n",
      "Batch: 29, Loss: 1.0553090572357178, Accuracy: 0.65625\n",
      "Batch: 30, Loss: 1.2053134441375732, Accuracy: 0.6162109375\n",
      "Batch: 31, Loss: 1.1992125511169434, Accuracy: 0.5859375\n",
      "Batch: 32, Loss: 1.0800130367279053, Accuracy: 0.638671875\n",
      "Batch: 33, Loss: 1.0267783403396606, Accuracy: 0.666015625\n",
      "Batch: 34, Loss: 1.1221692562103271, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.085328221321106, Accuracy: 0.650390625\n",
      "Batch: 36, Loss: 1.183976173400879, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.270107626914978, Accuracy: 0.5791015625\n",
      "Batch: 38, Loss: 1.1733722686767578, Accuracy: 0.6025390625\n",
      "Batch: 39, Loss: 1.0590931177139282, Accuracy: 0.646484375\n",
      "Batch: 40, Loss: 1.118030309677124, Accuracy: 0.6396484375\n",
      "Batch: 41, Loss: 1.1228790283203125, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.114667534828186, Accuracy: 0.625\n",
      "Batch: 43, Loss: 1.0192558765411377, Accuracy: 0.6552734375\n",
      "Batch: 44, Loss: 1.0536987781524658, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.1097478866577148, Accuracy: 0.6279296875\n",
      "Batch: 46, Loss: 1.1215932369232178, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.0662423372268677, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1568384170532227, Accuracy: 0.6240234375\n",
      "Batch: 49, Loss: 1.1884270906448364, Accuracy: 0.615234375\n",
      "Batch: 50, Loss: 1.171686053276062, Accuracy: 0.6083984375\n",
      "Batch: 51, Loss: 1.1826666593551636, Accuracy: 0.6064453125\n",
      "Batch: 52, Loss: 1.2492412328720093, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.205336570739746, Accuracy: 0.6044921875\n",
      "Batch: 54, Loss: 1.1699388027191162, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.1191766262054443, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.1278412342071533, Accuracy: 0.62109375\n",
      "Batch: 57, Loss: 1.1317672729492188, Accuracy: 0.6494140625\n",
      "Batch: 58, Loss: 1.1182430982589722, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.162909984588623, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.218924641609192, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.1532398462295532, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.2011396884918213, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.1631643772125244, Accuracy: 0.630859375\n",
      "Batch: 64, Loss: 1.2641998529434204, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.1562823057174683, Accuracy: 0.6337890625\n",
      "Batch: 66, Loss: 1.1822843551635742, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.2047350406646729, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0675947666168213, Accuracy: 0.6572265625\n",
      "Batch: 69, Loss: 1.229264736175537, Accuracy: 0.5888671875\n",
      "Batch: 70, Loss: 1.1890389919281006, Accuracy: 0.5927734375\n",
      "Batch: 71, Loss: 1.1816874742507935, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.1644597053527832, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.2133960723876953, Accuracy: 0.607421875\n",
      "Batch: 74, Loss: 1.09743332862854, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.1313602924346924, Accuracy: 0.626953125\n",
      "Batch: 76, Loss: 1.0919322967529297, Accuracy: 0.62109375\n",
      "Batch: 77, Loss: 1.0762245655059814, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.0227930545806885, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.1335361003875732, Accuracy: 0.6455078125\n",
      "Batch: 80, Loss: 1.1493762731552124, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.1700431108474731, Accuracy: 0.6220703125\n",
      "Batch: 82, Loss: 1.1382460594177246, Accuracy: 0.6376953125\n",
      "Batch: 83, Loss: 1.1956595182418823, Accuracy: 0.60546875\n",
      "Batch: 84, Loss: 1.146952748298645, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.1942105293273926, Accuracy: 0.6171875\n",
      "Batch: 86, Loss: 1.2147048711776733, Accuracy: 0.5986328125\n",
      "Batch: 87, Loss: 1.171884298324585, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.1995630264282227, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.1070492267608643, Accuracy: 0.634765625\n",
      "Batch: 90, Loss: 1.130577564239502, Accuracy: 0.63671875\n",
      "Batch: 91, Loss: 1.1196906566619873, Accuracy: 0.6337890625\n",
      "Batch: 92, Loss: 1.0583727359771729, Accuracy: 0.67578125\n",
      "Batch: 93, Loss: 1.156992793083191, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.2067317962646484, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.1684207916259766, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.2149429321289062, Accuracy: 0.6162109375\n",
      "Batch: 97, Loss: 1.1476130485534668, Accuracy: 0.6005859375\n",
      "Batch: 98, Loss: 1.150626301765442, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.1443886756896973, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.0949028730392456, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.1245986223220825, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.1775115728378296, Accuracy: 0.615234375\n",
      "Batch: 103, Loss: 1.1444742679595947, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1240298748016357, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.2709293365478516, Accuracy: 0.591796875\n",
      "Batch: 106, Loss: 1.1580499410629272, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.2409656047821045, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.1875555515289307, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.2172437906265259, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.1440867185592651, Accuracy: 0.6279296875\n",
      "Batch: 111, Loss: 1.1555967330932617, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.0955872535705566, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.1640214920043945, Accuracy: 0.6259765625\n",
      "Batch: 114, Loss: 1.1522681713104248, Accuracy: 0.595703125\n",
      "Batch: 115, Loss: 1.1564233303070068, Accuracy: 0.6328125\n",
      "Batch: 116, Loss: 1.2208261489868164, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.1417518854141235, Accuracy: 0.6337890625\n",
      "Batch: 118, Loss: 1.2185019254684448, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.2901208400726318, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.304932951927185, Accuracy: 0.5927734375\n",
      "Batch: 121, Loss: 1.179480791091919, Accuracy: 0.625\n",
      "Batch: 122, Loss: 1.207911729812622, Accuracy: 0.6171875\n",
      "Batch: 123, Loss: 1.2244360446929932, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.2349361181259155, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1992673873901367, Accuracy: 0.6083984375\n",
      "Batch: 126, Loss: 1.2907326221466064, Accuracy: 0.5830078125\n",
      "Batch: 127, Loss: 1.1872987747192383, Accuracy: 0.625\n",
      "Batch: 128, Loss: 1.1781113147735596, Accuracy: 0.625\n",
      "Batch: 129, Loss: 1.1896893978118896, Accuracy: 0.6162109375\n",
      "Batch: 130, Loss: 1.1625787019729614, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.2257814407348633, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.086946725845337, Accuracy: 0.6572265625\n",
      "Batch: 133, Loss: 1.1625783443450928, Accuracy: 0.638671875\n",
      "Batch: 134, Loss: 1.1561362743377686, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.07456374168396, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.109977126121521, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1817054748535156, Accuracy: 0.6083984375\n",
      "Batch: 138, Loss: 1.236877202987671, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.1772539615631104, Accuracy: 0.6259765625\n",
      "Batch: 140, Loss: 1.2699167728424072, Accuracy: 0.587890625\n",
      "Batch: 141, Loss: 1.1466196775436401, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 1.216036081314087, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.220367670059204, Accuracy: 0.59375\n",
      "Batch: 144, Loss: 1.3209245204925537, Accuracy: 0.5712890625\n",
      "Batch: 145, Loss: 1.3082594871520996, Accuracy: 0.5869140625\n",
      "Batch: 146, Loss: 1.163573980331421, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.291292667388916, Accuracy: 0.58984375\n",
      "Batch: 148, Loss: 1.1928895711898804, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.1874232292175293, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1697444915771484, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.180952548980713, Accuracy: 0.6259765625\n",
      "Batch: 152, Loss: 1.168102741241455, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.149812936782837, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1085898876190186, Accuracy: 0.640625\n",
      "Batch: 155, Loss: 1.1056427955627441, Accuracy: 0.640625\n",
      "Epoch 472/200\n",
      "Batch: 1, Loss: 1.2430644035339355, Accuracy: 0.6123046875\n",
      "Batch: 2, Loss: 1.0653291940689087, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.045377492904663, Accuracy: 0.6376953125\n",
      "Batch: 4, Loss: 1.1096999645233154, Accuracy: 0.642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5, Loss: 1.0517055988311768, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.098708987236023, Accuracy: 0.63671875\n",
      "Batch: 7, Loss: 0.9958512783050537, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 1.0053186416625977, Accuracy: 0.66796875\n",
      "Batch: 9, Loss: 0.9803768396377563, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 0.9784332513809204, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 0.9701181054115295, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.0104385614395142, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 1.0473462343215942, Accuracy: 0.6416015625\n",
      "Batch: 14, Loss: 0.9883284568786621, Accuracy: 0.681640625\n",
      "Batch: 15, Loss: 0.9424452185630798, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0391569137573242, Accuracy: 0.6591796875\n",
      "Batch: 17, Loss: 1.0950618982315063, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.144887089729309, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.1900242567062378, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0788806676864624, Accuracy: 0.6591796875\n",
      "Batch: 21, Loss: 1.0726094245910645, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.2842319011688232, Accuracy: 0.587890625\n",
      "Batch: 23, Loss: 1.2355480194091797, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.1290398836135864, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.1326813697814941, Accuracy: 0.6240234375\n",
      "Batch: 26, Loss: 1.2142938375473022, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.1470576524734497, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.0639562606811523, Accuracy: 0.646484375\n",
      "Batch: 29, Loss: 1.0506925582885742, Accuracy: 0.6484375\n",
      "Batch: 30, Loss: 1.1346956491470337, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.230698585510254, Accuracy: 0.5869140625\n",
      "Batch: 32, Loss: 1.0603924989700317, Accuracy: 0.65625\n",
      "Batch: 33, Loss: 1.001753330230713, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.0807511806488037, Accuracy: 0.6474609375\n",
      "Batch: 35, Loss: 1.1534250974655151, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.2230889797210693, Accuracy: 0.5771484375\n",
      "Batch: 37, Loss: 1.2363290786743164, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.15288245677948, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.091744303703308, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.1207634210586548, Accuracy: 0.6318359375\n",
      "Batch: 41, Loss: 1.1241765022277832, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 1.0184639692306519, Accuracy: 0.6591796875\n",
      "Batch: 43, Loss: 1.0524625778198242, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0494643449783325, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.0582858324050903, Accuracy: 0.6455078125\n",
      "Batch: 46, Loss: 1.1843541860580444, Accuracy: 0.587890625\n",
      "Batch: 47, Loss: 1.0630755424499512, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.066559076309204, Accuracy: 0.65625\n",
      "Batch: 49, Loss: 1.1993544101715088, Accuracy: 0.623046875\n",
      "Batch: 50, Loss: 1.143244981765747, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.120309591293335, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.3090614080429077, Accuracy: 0.578125\n",
      "Batch: 53, Loss: 1.1694786548614502, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.180850625038147, Accuracy: 0.62109375\n",
      "Batch: 55, Loss: 1.1706478595733643, Accuracy: 0.6162109375\n",
      "Batch: 56, Loss: 1.1028074026107788, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.1641113758087158, Accuracy: 0.623046875\n",
      "Batch: 58, Loss: 1.1556199789047241, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.124200701713562, Accuracy: 0.62890625\n",
      "Batch: 60, Loss: 1.2540788650512695, Accuracy: 0.6025390625\n",
      "Batch: 61, Loss: 1.1730695962905884, Accuracy: 0.6025390625\n",
      "Batch: 62, Loss: 1.1667264699935913, Accuracy: 0.6064453125\n",
      "Batch: 63, Loss: 1.1897902488708496, Accuracy: 0.611328125\n",
      "Batch: 64, Loss: 1.2211737632751465, Accuracy: 0.6005859375\n",
      "Batch: 65, Loss: 1.2450587749481201, Accuracy: 0.6015625\n",
      "Batch: 66, Loss: 1.154312252998352, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1473231315612793, Accuracy: 0.62890625\n",
      "Batch: 68, Loss: 1.1021900177001953, Accuracy: 0.6513671875\n",
      "Batch: 69, Loss: 1.1471556425094604, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.193256139755249, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.1227749586105347, Accuracy: 0.640625\n",
      "Batch: 72, Loss: 1.2049243450164795, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.2027226686477661, Accuracy: 0.611328125\n",
      "Batch: 74, Loss: 1.1324208974838257, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.130286693572998, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.0180662870407104, Accuracy: 0.6669921875\n",
      "Batch: 77, Loss: 1.0677716732025146, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 1.0916723012924194, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.1211847066879272, Accuracy: 0.6337890625\n",
      "Batch: 80, Loss: 1.1290723085403442, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.1076397895812988, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 1.1241893768310547, Accuracy: 0.6240234375\n",
      "Batch: 83, Loss: 1.1957756280899048, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.1644420623779297, Accuracy: 0.6162109375\n",
      "Batch: 85, Loss: 1.1982090473175049, Accuracy: 0.60546875\n",
      "Batch: 86, Loss: 1.1698297262191772, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.1671117544174194, Accuracy: 0.6298828125\n",
      "Batch: 88, Loss: 1.1738042831420898, Accuracy: 0.615234375\n",
      "Batch: 89, Loss: 1.1478558778762817, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.1268117427825928, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.1496319770812988, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1387279033660889, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.1778204441070557, Accuracy: 0.6162109375\n",
      "Batch: 94, Loss: 1.2111625671386719, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.1968932151794434, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.193267822265625, Accuracy: 0.6318359375\n",
      "Batch: 97, Loss: 1.2146495580673218, Accuracy: 0.6005859375\n",
      "Batch: 98, Loss: 1.0917140245437622, Accuracy: 0.64453125\n",
      "Batch: 99, Loss: 1.1628835201263428, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.0555864572525024, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0772629976272583, Accuracy: 0.642578125\n",
      "Batch: 102, Loss: 1.1700191497802734, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.1939804553985596, Accuracy: 0.634765625\n",
      "Batch: 104, Loss: 1.114598035812378, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.2158443927764893, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.1859664916992188, Accuracy: 0.6123046875\n",
      "Batch: 107, Loss: 1.2886381149291992, Accuracy: 0.5771484375\n",
      "Batch: 108, Loss: 1.1586064100265503, Accuracy: 0.611328125\n",
      "Batch: 109, Loss: 1.2043519020080566, Accuracy: 0.60546875\n",
      "Batch: 110, Loss: 1.1528209447860718, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.1173088550567627, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.1502923965454102, Accuracy: 0.6220703125\n",
      "Batch: 113, Loss: 1.1595852375030518, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.1910319328308105, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.2068305015563965, Accuracy: 0.6123046875\n",
      "Batch: 116, Loss: 1.194387435913086, Accuracy: 0.6171875\n",
      "Batch: 117, Loss: 1.2006458044052124, Accuracy: 0.60546875\n",
      "Batch: 118, Loss: 1.2414919137954712, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.2778273820877075, Accuracy: 0.58203125\n",
      "Batch: 120, Loss: 1.2691962718963623, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.2079880237579346, Accuracy: 0.62109375\n",
      "Batch: 122, Loss: 1.1929821968078613, Accuracy: 0.60546875\n",
      "Batch: 123, Loss: 1.164848804473877, Accuracy: 0.6162109375\n",
      "Batch: 124, Loss: 1.2349696159362793, Accuracy: 0.591796875\n",
      "Batch: 125, Loss: 1.197070598602295, Accuracy: 0.6142578125\n",
      "Batch: 126, Loss: 1.246628999710083, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2714362144470215, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2420397996902466, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.2175936698913574, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.101633906364441, Accuracy: 0.6328125\n",
      "Batch: 131, Loss: 1.1992883682250977, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.1178451776504517, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.2041959762573242, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1947486400604248, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.0462687015533447, Accuracy: 0.65234375\n",
      "Batch: 136, Loss: 1.1526281833648682, Accuracy: 0.6376953125\n",
      "Batch: 137, Loss: 1.1656408309936523, Accuracy: 0.623046875\n",
      "Batch: 138, Loss: 1.244143009185791, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.1993364095687866, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.264211654663086, Accuracy: 0.59375\n",
      "Batch: 141, Loss: 1.1722381114959717, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1842516660690308, Accuracy: 0.63671875\n",
      "Batch: 143, Loss: 1.215252161026001, Accuracy: 0.609375\n",
      "Batch: 144, Loss: 1.231355905532837, Accuracy: 0.59765625\n",
      "Batch: 145, Loss: 1.3010815382003784, Accuracy: 0.572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 146, Loss: 1.1982250213623047, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.2212066650390625, Accuracy: 0.5986328125\n",
      "Batch: 148, Loss: 1.2431854009628296, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.1444683074951172, Accuracy: 0.6396484375\n",
      "Batch: 150, Loss: 1.1592718362808228, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.2095513343811035, Accuracy: 0.607421875\n",
      "Batch: 152, Loss: 1.1764600276947021, Accuracy: 0.59765625\n",
      "Batch: 153, Loss: 1.1548781394958496, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.144340991973877, Accuracy: 0.630859375\n",
      "Batch: 155, Loss: 1.1268020868301392, Accuracy: 0.650390625\n",
      "Epoch 473/200\n",
      "Batch: 1, Loss: 1.1833360195159912, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.0739588737487793, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 1.0387802124023438, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0932869911193848, Accuracy: 0.6455078125\n",
      "Batch: 5, Loss: 1.0050137042999268, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.0861127376556396, Accuracy: 0.6337890625\n",
      "Batch: 7, Loss: 1.0786463022232056, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 0.9748862981796265, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 1.03493332862854, Accuracy: 0.6650390625\n",
      "Batch: 10, Loss: 0.9871132373809814, Accuracy: 0.6748046875\n",
      "Batch: 11, Loss: 1.013514518737793, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 1.0421525239944458, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.0591226816177368, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 0.9946545362472534, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.9529224634170532, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 1.1138484477996826, Accuracy: 0.6455078125\n",
      "Batch: 17, Loss: 1.053563117980957, Accuracy: 0.650390625\n",
      "Batch: 18, Loss: 1.1049084663391113, Accuracy: 0.654296875\n",
      "Batch: 19, Loss: 1.258690595626831, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.0999722480773926, Accuracy: 0.6611328125\n",
      "Batch: 21, Loss: 1.1446871757507324, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.2693164348602295, Accuracy: 0.6171875\n",
      "Batch: 23, Loss: 1.249874234199524, Accuracy: 0.5859375\n",
      "Batch: 24, Loss: 1.0973490476608276, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.1385011672973633, Accuracy: 0.62109375\n",
      "Batch: 26, Loss: 1.1973440647125244, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.1278467178344727, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 1.0953478813171387, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 1.050668716430664, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 1.2040681838989258, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.248720407485962, Accuracy: 0.5869140625\n",
      "Batch: 32, Loss: 1.0522024631500244, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 1.0252870321273804, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.1357882022857666, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.1464821100234985, Accuracy: 0.611328125\n",
      "Batch: 36, Loss: 1.2342019081115723, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.24667489528656, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.1655737161636353, Accuracy: 0.6376953125\n",
      "Batch: 39, Loss: 1.0721690654754639, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0882329940795898, Accuracy: 0.65234375\n",
      "Batch: 41, Loss: 1.1284406185150146, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.0843183994293213, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.0088839530944824, Accuracy: 0.669921875\n",
      "Batch: 44, Loss: 1.0533357858657837, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 1.0716034173965454, Accuracy: 0.6337890625\n",
      "Batch: 46, Loss: 1.1584441661834717, Accuracy: 0.5888671875\n",
      "Batch: 47, Loss: 1.0584630966186523, Accuracy: 0.6572265625\n",
      "Batch: 48, Loss: 1.097219467163086, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.1939964294433594, Accuracy: 0.611328125\n",
      "Batch: 50, Loss: 1.1198959350585938, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1686224937438965, Accuracy: 0.6005859375\n",
      "Batch: 52, Loss: 1.2267937660217285, Accuracy: 0.5986328125\n",
      "Batch: 53, Loss: 1.187863826751709, Accuracy: 0.6279296875\n",
      "Batch: 54, Loss: 1.1847636699676514, Accuracy: 0.599609375\n",
      "Batch: 55, Loss: 1.1750788688659668, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.0924477577209473, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.0869667530059814, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.14110267162323, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.1436107158660889, Accuracy: 0.6318359375\n",
      "Batch: 60, Loss: 1.2276082038879395, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1855874061584473, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.1865956783294678, Accuracy: 0.6064453125\n",
      "Batch: 63, Loss: 1.1627283096313477, Accuracy: 0.6015625\n",
      "Batch: 64, Loss: 1.2422919273376465, Accuracy: 0.5693359375\n",
      "Batch: 65, Loss: 1.1837458610534668, Accuracy: 0.6123046875\n",
      "Batch: 66, Loss: 1.2333260774612427, Accuracy: 0.6123046875\n",
      "Batch: 67, Loss: 1.1891369819641113, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.1309462785720825, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.2282911539077759, Accuracy: 0.609375\n",
      "Batch: 70, Loss: 1.1512740850448608, Accuracy: 0.6416015625\n",
      "Batch: 71, Loss: 1.2019449472427368, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.1732988357543945, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.2191028594970703, Accuracy: 0.5966796875\n",
      "Batch: 74, Loss: 1.1119829416275024, Accuracy: 0.65234375\n",
      "Batch: 75, Loss: 1.1264150142669678, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.0681049823760986, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0687040090560913, Accuracy: 0.6455078125\n",
      "Batch: 78, Loss: 1.1056381464004517, Accuracy: 0.6171875\n",
      "Batch: 79, Loss: 1.1584241390228271, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.130281686782837, Accuracy: 0.607421875\n",
      "Batch: 81, Loss: 1.1281232833862305, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.1143474578857422, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.2374792098999023, Accuracy: 0.607421875\n",
      "Batch: 84, Loss: 1.1702055931091309, Accuracy: 0.6318359375\n",
      "Batch: 85, Loss: 1.158881425857544, Accuracy: 0.607421875\n",
      "Batch: 86, Loss: 1.1883323192596436, Accuracy: 0.634765625\n",
      "Batch: 87, Loss: 1.1774966716766357, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.2144372463226318, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1530479192733765, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.1479880809783936, Accuracy: 0.6171875\n",
      "Batch: 91, Loss: 1.1626741886138916, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.15630042552948, Accuracy: 0.6298828125\n",
      "Batch: 93, Loss: 1.1561634540557861, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.171929121017456, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1943278312683105, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2173770666122437, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.1388471126556396, Accuracy: 0.6435546875\n",
      "Batch: 98, Loss: 1.135099172592163, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.1514098644256592, Accuracy: 0.611328125\n",
      "Batch: 100, Loss: 1.077529788017273, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.1299470663070679, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.2481598854064941, Accuracy: 0.5986328125\n",
      "Batch: 103, Loss: 1.1652233600616455, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1556556224822998, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.1974384784698486, Accuracy: 0.6376953125\n",
      "Batch: 106, Loss: 1.1531562805175781, Accuracy: 0.6328125\n",
      "Batch: 107, Loss: 1.3051190376281738, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.2288106679916382, Accuracy: 0.5791015625\n",
      "Batch: 109, Loss: 1.1767371892929077, Accuracy: 0.609375\n",
      "Batch: 110, Loss: 1.2015527486801147, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.1359658241271973, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.1278948783874512, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.1446455717086792, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.1832222938537598, Accuracy: 0.6044921875\n",
      "Batch: 115, Loss: 1.1731752157211304, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.2206108570098877, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1223704814910889, Accuracy: 0.6259765625\n",
      "Batch: 118, Loss: 1.2567462921142578, Accuracy: 0.6005859375\n",
      "Batch: 119, Loss: 1.2305326461791992, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.2971951961517334, Accuracy: 0.587890625\n",
      "Batch: 121, Loss: 1.2367019653320312, Accuracy: 0.591796875\n",
      "Batch: 122, Loss: 1.1734057664871216, Accuracy: 0.626953125\n",
      "Batch: 123, Loss: 1.1582856178283691, Accuracy: 0.6279296875\n",
      "Batch: 124, Loss: 1.2011911869049072, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.2464005947113037, Accuracy: 0.6103515625\n",
      "Batch: 126, Loss: 1.2615845203399658, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.233552098274231, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.214633584022522, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.2357828617095947, Accuracy: 0.6123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 1.1530437469482422, Accuracy: 0.62109375\n",
      "Batch: 131, Loss: 1.2362158298492432, Accuracy: 0.5927734375\n",
      "Batch: 132, Loss: 1.1179875135421753, Accuracy: 0.6279296875\n",
      "Batch: 133, Loss: 1.203476905822754, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1111661195755005, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.064729928970337, Accuracy: 0.654296875\n",
      "Batch: 136, Loss: 1.0805115699768066, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.1876118183135986, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.2779228687286377, Accuracy: 0.5791015625\n",
      "Batch: 139, Loss: 1.2043371200561523, Accuracy: 0.6162109375\n",
      "Batch: 140, Loss: 1.246717929840088, Accuracy: 0.59765625\n",
      "Batch: 141, Loss: 1.1314771175384521, Accuracy: 0.625\n",
      "Batch: 142, Loss: 1.2048285007476807, Accuracy: 0.623046875\n",
      "Batch: 143, Loss: 1.1993035078048706, Accuracy: 0.62109375\n",
      "Batch: 144, Loss: 1.2427783012390137, Accuracy: 0.5966796875\n",
      "Batch: 145, Loss: 1.273274540901184, Accuracy: 0.6044921875\n",
      "Batch: 146, Loss: 1.2814204692840576, Accuracy: 0.576171875\n",
      "Batch: 147, Loss: 1.2593237161636353, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.2669322490692139, Accuracy: 0.6171875\n",
      "Batch: 149, Loss: 1.133399248123169, Accuracy: 0.6455078125\n",
      "Batch: 150, Loss: 1.1536941528320312, Accuracy: 0.6171875\n",
      "Batch: 151, Loss: 1.140858769416809, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.1971895694732666, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.1733099222183228, Accuracy: 0.6201171875\n",
      "Batch: 154, Loss: 1.168996810913086, Accuracy: 0.623046875\n",
      "Batch: 155, Loss: 1.1143051385879517, Accuracy: 0.6298828125\n",
      "Epoch 474/200\n",
      "Batch: 1, Loss: 1.2328393459320068, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.1401891708374023, Accuracy: 0.6240234375\n",
      "Batch: 3, Loss: 1.0937495231628418, Accuracy: 0.6455078125\n",
      "Batch: 4, Loss: 1.0911693572998047, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.065544605255127, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.0419955253601074, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0558427572250366, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9991275072097778, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 1.0444211959838867, Accuracy: 0.658203125\n",
      "Batch: 10, Loss: 0.9685260653495789, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 0.972927987575531, Accuracy: 0.6962890625\n",
      "Batch: 12, Loss: 1.0145127773284912, Accuracy: 0.6689453125\n",
      "Batch: 13, Loss: 1.0269875526428223, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 0.9974364042282104, Accuracy: 0.681640625\n",
      "Batch: 15, Loss: 0.9623161554336548, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0400707721710205, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.039079189300537, Accuracy: 0.6767578125\n",
      "Batch: 18, Loss: 1.1693763732910156, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2387206554412842, Accuracy: 0.5986328125\n",
      "Batch: 20, Loss: 1.084624171257019, Accuracy: 0.66796875\n",
      "Batch: 21, Loss: 1.0908595323562622, Accuracy: 0.6435546875\n",
      "Batch: 22, Loss: 1.21990966796875, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.2148637771606445, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.1370820999145508, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1779685020446777, Accuracy: 0.61328125\n",
      "Batch: 26, Loss: 1.198745608329773, Accuracy: 0.591796875\n",
      "Batch: 27, Loss: 1.107547640800476, Accuracy: 0.6240234375\n",
      "Batch: 28, Loss: 1.0939366817474365, Accuracy: 0.619140625\n",
      "Batch: 29, Loss: 1.1103349924087524, Accuracy: 0.6201171875\n",
      "Batch: 30, Loss: 1.1387338638305664, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.2655894756317139, Accuracy: 0.5751953125\n",
      "Batch: 32, Loss: 1.0082741975784302, Accuracy: 0.6748046875\n",
      "Batch: 33, Loss: 0.9981313943862915, Accuracy: 0.658203125\n",
      "Batch: 34, Loss: 1.0860060453414917, Accuracy: 0.6552734375\n",
      "Batch: 35, Loss: 1.1400338411331177, Accuracy: 0.6494140625\n",
      "Batch: 36, Loss: 1.1661450862884521, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.2608368396759033, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.1909013986587524, Accuracy: 0.6171875\n",
      "Batch: 39, Loss: 1.063539981842041, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.1240158081054688, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.180184245109558, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0658997297286987, Accuracy: 0.6630859375\n",
      "Batch: 43, Loss: 1.092055082321167, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0479657649993896, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 0.9996625185012817, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.1218739748001099, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.075240969657898, Accuracy: 0.6689453125\n",
      "Batch: 48, Loss: 1.1767457723617554, Accuracy: 0.623046875\n",
      "Batch: 49, Loss: 1.1857514381408691, Accuracy: 0.6220703125\n",
      "Batch: 50, Loss: 1.1820614337921143, Accuracy: 0.59765625\n",
      "Batch: 51, Loss: 1.1809453964233398, Accuracy: 0.6103515625\n",
      "Batch: 52, Loss: 1.2296156883239746, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.1429859399795532, Accuracy: 0.634765625\n",
      "Batch: 54, Loss: 1.171971082687378, Accuracy: 0.6171875\n",
      "Batch: 55, Loss: 1.0745067596435547, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.124579668045044, Accuracy: 0.6318359375\n",
      "Batch: 57, Loss: 1.1712541580200195, Accuracy: 0.6298828125\n",
      "Batch: 58, Loss: 1.1754484176635742, Accuracy: 0.611328125\n",
      "Batch: 59, Loss: 1.1334879398345947, Accuracy: 0.623046875\n",
      "Batch: 60, Loss: 1.23875892162323, Accuracy: 0.6142578125\n",
      "Batch: 61, Loss: 1.1857261657714844, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.1515634059906006, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.1286530494689941, Accuracy: 0.6357421875\n",
      "Batch: 64, Loss: 1.2221064567565918, Accuracy: 0.5986328125\n",
      "Batch: 65, Loss: 1.1873056888580322, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.1230676174163818, Accuracy: 0.638671875\n",
      "Batch: 67, Loss: 1.1497164964675903, Accuracy: 0.6416015625\n",
      "Batch: 68, Loss: 1.1279933452606201, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1299511194229126, Accuracy: 0.6455078125\n",
      "Batch: 70, Loss: 1.2197035551071167, Accuracy: 0.603515625\n",
      "Batch: 71, Loss: 1.1505532264709473, Accuracy: 0.6298828125\n",
      "Batch: 72, Loss: 1.2143114805221558, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.2689392566680908, Accuracy: 0.580078125\n",
      "Batch: 74, Loss: 1.0952755212783813, Accuracy: 0.634765625\n",
      "Batch: 75, Loss: 1.1135571002960205, Accuracy: 0.650390625\n",
      "Batch: 76, Loss: 1.0659949779510498, Accuracy: 0.658203125\n",
      "Batch: 77, Loss: 1.0280485153198242, Accuracy: 0.677734375\n",
      "Batch: 78, Loss: 1.0875324010849, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1905843019485474, Accuracy: 0.60546875\n",
      "Batch: 80, Loss: 1.1792620420455933, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1087058782577515, Accuracy: 0.6279296875\n",
      "Batch: 82, Loss: 1.1361796855926514, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 1.2498705387115479, Accuracy: 0.607421875\n",
      "Batch: 84, Loss: 1.1615614891052246, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.2259578704833984, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.16598379611969, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.2046858072280884, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.179551362991333, Accuracy: 0.603515625\n",
      "Batch: 89, Loss: 1.1231098175048828, Accuracy: 0.6435546875\n",
      "Batch: 90, Loss: 1.1023776531219482, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.2377471923828125, Accuracy: 0.5888671875\n",
      "Batch: 92, Loss: 1.1240195035934448, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.1450968980789185, Accuracy: 0.6279296875\n",
      "Batch: 94, Loss: 1.1981923580169678, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.2382969856262207, Accuracy: 0.6171875\n",
      "Batch: 96, Loss: 1.226771354675293, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.1886651515960693, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.0891915559768677, Accuracy: 0.6533203125\n",
      "Batch: 99, Loss: 1.1736502647399902, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0825728178024292, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.0920939445495605, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.1729347705841064, Accuracy: 0.6455078125\n",
      "Batch: 103, Loss: 1.2075400352478027, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.1629998683929443, Accuracy: 0.6201171875\n",
      "Batch: 105, Loss: 1.2545980215072632, Accuracy: 0.60546875\n",
      "Batch: 106, Loss: 1.2185698747634888, Accuracy: 0.6083984375\n",
      "Batch: 107, Loss: 1.2239656448364258, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.1758102178573608, Accuracy: 0.59765625\n",
      "Batch: 109, Loss: 1.2408154010772705, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.2292205095291138, Accuracy: 0.6005859375\n",
      "Batch: 111, Loss: 1.1280486583709717, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.1179049015045166, Accuracy: 0.634765625\n",
      "Batch: 113, Loss: 1.1405967473983765, Accuracy: 0.6318359375\n",
      "Batch: 114, Loss: 1.1973373889923096, Accuracy: 0.6162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 115, Loss: 1.1976487636566162, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1972849369049072, Accuracy: 0.591796875\n",
      "Batch: 117, Loss: 1.2000312805175781, Accuracy: 0.6005859375\n",
      "Batch: 118, Loss: 1.251097559928894, Accuracy: 0.5986328125\n",
      "Batch: 119, Loss: 1.2398273944854736, Accuracy: 0.595703125\n",
      "Batch: 120, Loss: 1.3181203603744507, Accuracy: 0.6044921875\n",
      "Batch: 121, Loss: 1.1958662271499634, Accuracy: 0.6083984375\n",
      "Batch: 122, Loss: 1.2683789730072021, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.193122148513794, Accuracy: 0.6044921875\n",
      "Batch: 124, Loss: 1.2616114616394043, Accuracy: 0.6123046875\n",
      "Batch: 125, Loss: 1.1558430194854736, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.28559410572052, Accuracy: 0.6064453125\n",
      "Batch: 127, Loss: 1.2696506977081299, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.2097420692443848, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.2370399236679077, Accuracy: 0.5791015625\n",
      "Batch: 130, Loss: 1.1673178672790527, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.1938822269439697, Accuracy: 0.6171875\n",
      "Batch: 132, Loss: 1.1330186128616333, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.189989686012268, Accuracy: 0.619140625\n",
      "Batch: 134, Loss: 1.1438262462615967, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.068946123123169, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.1272468566894531, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.153564691543579, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.2432258129119873, Accuracy: 0.6064453125\n",
      "Batch: 139, Loss: 1.190740942955017, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.2425477504730225, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.208956241607666, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.1822580099105835, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.2121732234954834, Accuracy: 0.6181640625\n",
      "Batch: 144, Loss: 1.267091989517212, Accuracy: 0.5859375\n",
      "Batch: 145, Loss: 1.3165836334228516, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.2306067943572998, Accuracy: 0.595703125\n",
      "Batch: 147, Loss: 1.2386105060577393, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.197690486907959, Accuracy: 0.6044921875\n",
      "Batch: 149, Loss: 1.1769341230392456, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1314730644226074, Accuracy: 0.626953125\n",
      "Batch: 151, Loss: 1.180787444114685, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.1541091203689575, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1020708084106445, Accuracy: 0.62890625\n",
      "Batch: 154, Loss: 1.1573503017425537, Accuracy: 0.615234375\n",
      "Batch: 155, Loss: 1.1271594762802124, Accuracy: 0.6240234375\n",
      "Epoch 475/200\n",
      "Batch: 1, Loss: 1.2580761909484863, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 1.0721514225006104, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 1.0230051279067993, Accuracy: 0.6728515625\n",
      "Batch: 4, Loss: 1.101346731185913, Accuracy: 0.640625\n",
      "Batch: 5, Loss: 1.0099822282791138, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.0742924213409424, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.0368350744247437, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 0.9867583513259888, Accuracy: 0.6845703125\n",
      "Batch: 9, Loss: 1.0249186754226685, Accuracy: 0.6591796875\n",
      "Batch: 10, Loss: 0.956366777420044, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9743177890777588, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 1.0508697032928467, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 1.0249080657958984, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 1.0221604108810425, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 0.9947250485420227, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.015264868736267, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.08018159866333, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1138076782226562, Accuracy: 0.6298828125\n",
      "Batch: 19, Loss: 1.1453239917755127, Accuracy: 0.62890625\n",
      "Batch: 20, Loss: 1.0758036375045776, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.099656581878662, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2854580879211426, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.268073558807373, Accuracy: 0.6015625\n",
      "Batch: 24, Loss: 1.1066689491271973, Accuracy: 0.642578125\n",
      "Batch: 25, Loss: 1.2082545757293701, Accuracy: 0.5966796875\n",
      "Batch: 26, Loss: 1.2554755210876465, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.145864486694336, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.0605502128601074, Accuracy: 0.6396484375\n",
      "Batch: 29, Loss: 1.0849307775497437, Accuracy: 0.6513671875\n",
      "Batch: 30, Loss: 1.1827692985534668, Accuracy: 0.6142578125\n",
      "Batch: 31, Loss: 1.2394204139709473, Accuracy: 0.572265625\n",
      "Batch: 32, Loss: 1.0540858507156372, Accuracy: 0.66796875\n",
      "Batch: 33, Loss: 0.9957583546638489, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.153320074081421, Accuracy: 0.626953125\n",
      "Batch: 35, Loss: 1.138384461402893, Accuracy: 0.6123046875\n",
      "Batch: 36, Loss: 1.1911234855651855, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.2694990634918213, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.1775165796279907, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.0882434844970703, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.0736521482467651, Accuracy: 0.650390625\n",
      "Batch: 41, Loss: 1.1254223585128784, Accuracy: 0.626953125\n",
      "Batch: 42, Loss: 1.093686819076538, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0545696020126343, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.106332540512085, Accuracy: 0.6181640625\n",
      "Batch: 45, Loss: 1.0947778224945068, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.19953191280365, Accuracy: 0.6181640625\n",
      "Batch: 47, Loss: 1.115686058998108, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.1645455360412598, Accuracy: 0.6142578125\n",
      "Batch: 49, Loss: 1.1648366451263428, Accuracy: 0.6201171875\n",
      "Batch: 50, Loss: 1.1049325466156006, Accuracy: 0.65234375\n",
      "Batch: 51, Loss: 1.190366268157959, Accuracy: 0.6015625\n",
      "Batch: 52, Loss: 1.2745471000671387, Accuracy: 0.5869140625\n",
      "Batch: 53, Loss: 1.164829134941101, Accuracy: 0.62890625\n",
      "Batch: 54, Loss: 1.1740719079971313, Accuracy: 0.59765625\n",
      "Batch: 55, Loss: 1.118099331855774, Accuracy: 0.625\n",
      "Batch: 56, Loss: 1.0800585746765137, Accuracy: 0.634765625\n",
      "Batch: 57, Loss: 1.1071497201919556, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.201946496963501, Accuracy: 0.61328125\n",
      "Batch: 59, Loss: 1.1468758583068848, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2925270795822144, Accuracy: 0.5830078125\n",
      "Batch: 61, Loss: 1.2005318403244019, Accuracy: 0.599609375\n",
      "Batch: 62, Loss: 1.1044690608978271, Accuracy: 0.6572265625\n",
      "Batch: 63, Loss: 1.1876778602600098, Accuracy: 0.5986328125\n",
      "Batch: 64, Loss: 1.2048028707504272, Accuracy: 0.603515625\n",
      "Batch: 65, Loss: 1.2230401039123535, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.1346867084503174, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.2120447158813477, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.1015520095825195, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.1972556114196777, Accuracy: 0.62890625\n",
      "Batch: 70, Loss: 1.1813368797302246, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.233271837234497, Accuracy: 0.6044921875\n",
      "Batch: 72, Loss: 1.1917375326156616, Accuracy: 0.6005859375\n",
      "Batch: 73, Loss: 1.2218255996704102, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.118714690208435, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.128445029258728, Accuracy: 0.6083984375\n",
      "Batch: 76, Loss: 1.1496516466140747, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.0617399215698242, Accuracy: 0.646484375\n",
      "Batch: 78, Loss: 1.0959917306900024, Accuracy: 0.6337890625\n",
      "Batch: 79, Loss: 1.1884442567825317, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.2210838794708252, Accuracy: 0.6123046875\n",
      "Batch: 81, Loss: 1.1142613887786865, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.0902584791183472, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.2245333194732666, Accuracy: 0.595703125\n",
      "Batch: 84, Loss: 1.172573447227478, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.1996592283248901, Accuracy: 0.603515625\n",
      "Batch: 86, Loss: 1.20072603225708, Accuracy: 0.599609375\n",
      "Batch: 87, Loss: 1.191542387008667, Accuracy: 0.607421875\n",
      "Batch: 88, Loss: 1.2388108968734741, Accuracy: 0.61328125\n",
      "Batch: 89, Loss: 1.1790518760681152, Accuracy: 0.6064453125\n",
      "Batch: 90, Loss: 1.1100132465362549, Accuracy: 0.619140625\n",
      "Batch: 91, Loss: 1.1298909187316895, Accuracy: 0.640625\n",
      "Batch: 92, Loss: 1.2047559022903442, Accuracy: 0.60546875\n",
      "Batch: 93, Loss: 1.1540570259094238, Accuracy: 0.6181640625\n",
      "Batch: 94, Loss: 1.2014862298965454, Accuracy: 0.5908203125\n",
      "Batch: 95, Loss: 1.2123456001281738, Accuracy: 0.6240234375\n",
      "Batch: 96, Loss: 1.1817631721496582, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.1754779815673828, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1302200555801392, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.193894863128662, Accuracy: 0.6162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 1.0697391033172607, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.1466987133026123, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.2055115699768066, Accuracy: 0.6142578125\n",
      "Batch: 103, Loss: 1.2024505138397217, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.212472677230835, Accuracy: 0.6005859375\n",
      "Batch: 105, Loss: 1.2052758932113647, Accuracy: 0.6240234375\n",
      "Batch: 106, Loss: 1.2311084270477295, Accuracy: 0.59765625\n",
      "Batch: 107, Loss: 1.2966654300689697, Accuracy: 0.5830078125\n",
      "Batch: 108, Loss: 1.2306020259857178, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.170283317565918, Accuracy: 0.630859375\n",
      "Batch: 110, Loss: 1.179548978805542, Accuracy: 0.61328125\n",
      "Batch: 111, Loss: 1.1325181722640991, Accuracy: 0.619140625\n",
      "Batch: 112, Loss: 1.0967059135437012, Accuracy: 0.6376953125\n",
      "Batch: 113, Loss: 1.2179458141326904, Accuracy: 0.59765625\n",
      "Batch: 114, Loss: 1.144244909286499, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.2566128969192505, Accuracy: 0.5830078125\n",
      "Batch: 116, Loss: 1.160281777381897, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.15907621383667, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.2498842477798462, Accuracy: 0.587890625\n",
      "Batch: 119, Loss: 1.2536308765411377, Accuracy: 0.5908203125\n",
      "Batch: 120, Loss: 1.2361352443695068, Accuracy: 0.6064453125\n",
      "Batch: 121, Loss: 1.1937142610549927, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.2289832830429077, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.1509244441986084, Accuracy: 0.6416015625\n",
      "Batch: 124, Loss: 1.275989055633545, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.1764453649520874, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.242680311203003, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.2297677993774414, Accuracy: 0.60546875\n",
      "Batch: 128, Loss: 1.2375774383544922, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.2426915168762207, Accuracy: 0.6240234375\n",
      "Batch: 130, Loss: 1.2492458820343018, Accuracy: 0.5654296875\n",
      "Batch: 131, Loss: 1.1983275413513184, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.0706812143325806, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.1752631664276123, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.1478204727172852, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.0552623271942139, Accuracy: 0.666015625\n",
      "Batch: 136, Loss: 1.1487362384796143, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.172337532043457, Accuracy: 0.650390625\n",
      "Batch: 138, Loss: 1.259608507156372, Accuracy: 0.5947265625\n",
      "Batch: 139, Loss: 1.1798362731933594, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.2354607582092285, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.1910229921340942, Accuracy: 0.6162109375\n",
      "Batch: 142, Loss: 1.1889019012451172, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2440135478973389, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.2954916954040527, Accuracy: 0.576171875\n",
      "Batch: 145, Loss: 1.260323166847229, Accuracy: 0.6044921875\n",
      "Batch: 146, Loss: 1.2476511001586914, Accuracy: 0.5908203125\n",
      "Batch: 147, Loss: 1.207153558731079, Accuracy: 0.6015625\n",
      "Batch: 148, Loss: 1.2468039989471436, Accuracy: 0.5927734375\n",
      "Batch: 149, Loss: 1.1978192329406738, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.1834924221038818, Accuracy: 0.623046875\n",
      "Batch: 151, Loss: 1.2041099071502686, Accuracy: 0.61328125\n",
      "Batch: 152, Loss: 1.1819313764572144, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.1494410037994385, Accuracy: 0.6455078125\n",
      "Batch: 154, Loss: 1.1375622749328613, Accuracy: 0.6220703125\n",
      "Batch: 155, Loss: 1.0862290859222412, Accuracy: 0.6640625\n",
      "Epoch 476/200\n",
      "Batch: 1, Loss: 1.1981751918792725, Accuracy: 0.6474609375\n",
      "Batch: 2, Loss: 1.1643569469451904, Accuracy: 0.623046875\n",
      "Batch: 3, Loss: 1.0663089752197266, Accuracy: 0.634765625\n",
      "Batch: 4, Loss: 1.0502574443817139, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0394115447998047, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 1.0826972723007202, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.0235477685928345, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 1.0314594507217407, Accuracy: 0.671875\n",
      "Batch: 9, Loss: 0.9957143068313599, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9959157705307007, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9985989928245544, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 1.0261871814727783, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 1.0272340774536133, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 1.0100065469741821, Accuracy: 0.6748046875\n",
      "Batch: 15, Loss: 0.959141731262207, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0751218795776367, Accuracy: 0.6513671875\n",
      "Batch: 17, Loss: 1.0551080703735352, Accuracy: 0.65625\n",
      "Batch: 18, Loss: 1.1198062896728516, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.215664267539978, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.109694480895996, Accuracy: 0.646484375\n",
      "Batch: 21, Loss: 1.0171087980270386, Accuracy: 0.671875\n",
      "Batch: 22, Loss: 1.2176166772842407, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.2718828916549683, Accuracy: 0.576171875\n",
      "Batch: 24, Loss: 1.1380943059921265, Accuracy: 0.6357421875\n",
      "Batch: 25, Loss: 1.139601230621338, Accuracy: 0.630859375\n",
      "Batch: 26, Loss: 1.1902337074279785, Accuracy: 0.599609375\n",
      "Batch: 27, Loss: 1.1951611042022705, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.0802297592163086, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0809590816497803, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.1738814115524292, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2468459606170654, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0583341121673584, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 1.0115346908569336, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0751879215240479, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 1.079872727394104, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.1605409383773804, Accuracy: 0.615234375\n",
      "Batch: 37, Loss: 1.2849349975585938, Accuracy: 0.587890625\n",
      "Batch: 38, Loss: 1.1948871612548828, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.1219059228897095, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0796277523040771, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.1069681644439697, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.0828522443771362, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.0400938987731934, Accuracy: 0.666015625\n",
      "Batch: 44, Loss: 1.0146206617355347, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 1.0614166259765625, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.097145438194275, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.1191344261169434, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.0987721681594849, Accuracy: 0.6416015625\n",
      "Batch: 49, Loss: 1.191129446029663, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.1786797046661377, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.1688898801803589, Accuracy: 0.619140625\n",
      "Batch: 52, Loss: 1.2259410619735718, Accuracy: 0.615234375\n",
      "Batch: 53, Loss: 1.1498119831085205, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.1904394626617432, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.1333472728729248, Accuracy: 0.630859375\n",
      "Batch: 56, Loss: 1.1215028762817383, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.156321406364441, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.135603904724121, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.1852209568023682, Accuracy: 0.609375\n",
      "Batch: 60, Loss: 1.2258427143096924, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1244895458221436, Accuracy: 0.6123046875\n",
      "Batch: 62, Loss: 1.1627439260482788, Accuracy: 0.6201171875\n",
      "Batch: 63, Loss: 1.1626323461532593, Accuracy: 0.61328125\n",
      "Batch: 64, Loss: 1.2145493030548096, Accuracy: 0.607421875\n",
      "Batch: 65, Loss: 1.2150105237960815, Accuracy: 0.6279296875\n",
      "Batch: 66, Loss: 1.1372032165527344, Accuracy: 0.6337890625\n",
      "Batch: 67, Loss: 1.1931767463684082, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0805294513702393, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.21311354637146, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.1282308101654053, Accuracy: 0.63671875\n",
      "Batch: 71, Loss: 1.1359729766845703, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.2266830205917358, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.2016105651855469, Accuracy: 0.6064453125\n",
      "Batch: 74, Loss: 1.1371440887451172, Accuracy: 0.6142578125\n",
      "Batch: 75, Loss: 1.0983026027679443, Accuracy: 0.6240234375\n",
      "Batch: 76, Loss: 1.1178686618804932, Accuracy: 0.6337890625\n",
      "Batch: 77, Loss: 1.0891287326812744, Accuracy: 0.6337890625\n",
      "Batch: 78, Loss: 1.0675745010375977, Accuracy: 0.6328125\n",
      "Batch: 79, Loss: 1.1426095962524414, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.133280634880066, Accuracy: 0.6318359375\n",
      "Batch: 81, Loss: 1.1267874240875244, Accuracy: 0.62109375\n",
      "Batch: 82, Loss: 1.1198539733886719, Accuracy: 0.6240234375\n",
      "Batch: 83, Loss: 1.193049430847168, Accuracy: 0.599609375\n",
      "Batch: 84, Loss: 1.1673872470855713, Accuracy: 0.626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 1.1606205701828003, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.179558277130127, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.1557210683822632, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.2707431316375732, Accuracy: 0.5888671875\n",
      "Batch: 89, Loss: 1.193719506263733, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.0969271659851074, Accuracy: 0.6455078125\n",
      "Batch: 91, Loss: 1.1030070781707764, Accuracy: 0.6484375\n",
      "Batch: 92, Loss: 1.129083514213562, Accuracy: 0.6455078125\n",
      "Batch: 93, Loss: 1.1967867612838745, Accuracy: 0.6005859375\n",
      "Batch: 94, Loss: 1.22174072265625, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.1933822631835938, Accuracy: 0.607421875\n",
      "Batch: 96, Loss: 1.1415846347808838, Accuracy: 0.6552734375\n",
      "Batch: 97, Loss: 1.2081557512283325, Accuracy: 0.6015625\n",
      "Batch: 98, Loss: 1.12550950050354, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.145707607269287, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.151685357093811, Accuracy: 0.634765625\n",
      "Batch: 101, Loss: 1.0854620933532715, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.204317569732666, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.2103583812713623, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.168921709060669, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.227139949798584, Accuracy: 0.59765625\n",
      "Batch: 106, Loss: 1.1779755353927612, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.2553174495697021, Accuracy: 0.591796875\n",
      "Batch: 108, Loss: 1.2269878387451172, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.1615023612976074, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.120877981185913, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.1186667680740356, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.1063175201416016, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.1867451667785645, Accuracy: 0.6083984375\n",
      "Batch: 114, Loss: 1.1299107074737549, Accuracy: 0.62890625\n",
      "Batch: 115, Loss: 1.158170223236084, Accuracy: 0.623046875\n",
      "Batch: 116, Loss: 1.2597486972808838, Accuracy: 0.5791015625\n",
      "Batch: 117, Loss: 1.1452293395996094, Accuracy: 0.6474609375\n",
      "Batch: 118, Loss: 1.2244348526000977, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.2308510541915894, Accuracy: 0.5986328125\n",
      "Batch: 120, Loss: 1.2565889358520508, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.1951661109924316, Accuracy: 0.634765625\n",
      "Batch: 122, Loss: 1.1806867122650146, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.1851413249969482, Accuracy: 0.6396484375\n",
      "Batch: 124, Loss: 1.2290856838226318, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.1986987590789795, Accuracy: 0.6123046875\n",
      "Batch: 126, Loss: 1.2460824251174927, Accuracy: 0.615234375\n",
      "Batch: 127, Loss: 1.2717338800430298, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.228837490081787, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.2046432495117188, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.1838634014129639, Accuracy: 0.6171875\n",
      "Batch: 131, Loss: 1.2743637561798096, Accuracy: 0.5888671875\n",
      "Batch: 132, Loss: 1.0880529880523682, Accuracy: 0.630859375\n",
      "Batch: 133, Loss: 1.1812546253204346, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.1502728462219238, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 1.024993658065796, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.085605263710022, Accuracy: 0.6416015625\n",
      "Batch: 137, Loss: 1.1332051753997803, Accuracy: 0.6591796875\n",
      "Batch: 138, Loss: 1.206252932548523, Accuracy: 0.59765625\n",
      "Batch: 139, Loss: 1.2181886434555054, Accuracy: 0.5986328125\n",
      "Batch: 140, Loss: 1.2802870273590088, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.1610066890716553, Accuracy: 0.63671875\n",
      "Batch: 142, Loss: 1.1858125925064087, Accuracy: 0.6357421875\n",
      "Batch: 143, Loss: 1.2072057723999023, Accuracy: 0.6044921875\n",
      "Batch: 144, Loss: 1.2814116477966309, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.208885908126831, Accuracy: 0.623046875\n",
      "Batch: 146, Loss: 1.2450814247131348, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.1965818405151367, Accuracy: 0.619140625\n",
      "Batch: 148, Loss: 1.243052363395691, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.1980538368225098, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1734699010849, Accuracy: 0.625\n",
      "Batch: 151, Loss: 1.2520115375518799, Accuracy: 0.59765625\n",
      "Batch: 152, Loss: 1.1597075462341309, Accuracy: 0.6044921875\n",
      "Batch: 153, Loss: 1.1400973796844482, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1563243865966797, Accuracy: 0.6494140625\n",
      "Batch: 155, Loss: 1.073325753211975, Accuracy: 0.6484375\n",
      "Epoch 477/200\n",
      "Batch: 1, Loss: 1.2168991565704346, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 1.0740900039672852, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 1.080920696258545, Accuracy: 0.6396484375\n",
      "Batch: 4, Loss: 1.146803855895996, Accuracy: 0.619140625\n",
      "Batch: 5, Loss: 1.040143609046936, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.0504454374313354, Accuracy: 0.6650390625\n",
      "Batch: 7, Loss: 1.0013905763626099, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 1.0054007768630981, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 1.048500895500183, Accuracy: 0.64453125\n",
      "Batch: 10, Loss: 0.9911321997642517, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 0.9873751401901245, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.0535812377929688, Accuracy: 0.650390625\n",
      "Batch: 13, Loss: 1.0433433055877686, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9625544548034668, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.9098899364471436, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 1.0310803651809692, Accuracy: 0.654296875\n",
      "Batch: 17, Loss: 1.0896856784820557, Accuracy: 0.6455078125\n",
      "Batch: 18, Loss: 1.1257152557373047, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.2534794807434082, Accuracy: 0.6044921875\n",
      "Batch: 20, Loss: 1.094297170639038, Accuracy: 0.6435546875\n",
      "Batch: 21, Loss: 1.1097934246063232, Accuracy: 0.6171875\n",
      "Batch: 22, Loss: 1.206188440322876, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.1802421808242798, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.1786940097808838, Accuracy: 0.6142578125\n",
      "Batch: 25, Loss: 1.1156268119812012, Accuracy: 0.64453125\n",
      "Batch: 26, Loss: 1.1615207195281982, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.181106686592102, Accuracy: 0.5859375\n",
      "Batch: 28, Loss: 1.0985305309295654, Accuracy: 0.6181640625\n",
      "Batch: 29, Loss: 1.061420202255249, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.151835560798645, Accuracy: 0.6328125\n",
      "Batch: 31, Loss: 1.2028710842132568, Accuracy: 0.6103515625\n",
      "Batch: 32, Loss: 1.0939059257507324, Accuracy: 0.638671875\n",
      "Batch: 33, Loss: 1.0274690389633179, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.0846120119094849, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.1660709381103516, Accuracy: 0.6220703125\n",
      "Batch: 36, Loss: 1.1488147974014282, Accuracy: 0.615234375\n",
      "Batch: 37, Loss: 1.222329020500183, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.2169671058654785, Accuracy: 0.5927734375\n",
      "Batch: 39, Loss: 1.0856873989105225, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.1166611909866333, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.1411141157150269, Accuracy: 0.62890625\n",
      "Batch: 42, Loss: 1.116886854171753, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.0174754858016968, Accuracy: 0.666015625\n",
      "Batch: 44, Loss: 1.0490387678146362, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.069371223449707, Accuracy: 0.63671875\n",
      "Batch: 46, Loss: 1.127565622329712, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.1016082763671875, Accuracy: 0.646484375\n",
      "Batch: 48, Loss: 1.2210627794265747, Accuracy: 0.5888671875\n",
      "Batch: 49, Loss: 1.2239255905151367, Accuracy: 0.6044921875\n",
      "Batch: 50, Loss: 1.1551032066345215, Accuracy: 0.6298828125\n",
      "Batch: 51, Loss: 1.1720402240753174, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.2406264543533325, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.235181450843811, Accuracy: 0.59375\n",
      "Batch: 54, Loss: 1.1554675102233887, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.133605718612671, Accuracy: 0.6328125\n",
      "Batch: 56, Loss: 1.114759087562561, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.151569128036499, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.1085515022277832, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1682400703430176, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.235851764678955, Accuracy: 0.591796875\n",
      "Batch: 61, Loss: 1.1704094409942627, Accuracy: 0.60546875\n",
      "Batch: 62, Loss: 1.1670129299163818, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.207329273223877, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.159827470779419, Accuracy: 0.607421875\n",
      "Batch: 65, Loss: 1.18355131149292, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1852731704711914, Accuracy: 0.6103515625\n",
      "Batch: 67, Loss: 1.1020451784133911, Accuracy: 0.6376953125\n",
      "Batch: 68, Loss: 1.102963924407959, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1745078563690186, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.1900298595428467, Accuracy: 0.6298828125\n",
      "Batch: 71, Loss: 1.1444377899169922, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.197096347808838, Accuracy: 0.619140625\n",
      "Batch: 73, Loss: 1.195042610168457, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.0980637073516846, Accuracy: 0.65234375\n",
      "Batch: 75, Loss: 1.1482056379318237, Accuracy: 0.630859375\n",
      "Batch: 76, Loss: 1.043259620666504, Accuracy: 0.65234375\n",
      "Batch: 77, Loss: 1.1103636026382446, Accuracy: 0.6513671875\n",
      "Batch: 78, Loss: 1.0730173587799072, Accuracy: 0.6630859375\n",
      "Batch: 79, Loss: 1.132504940032959, Accuracy: 0.638671875\n",
      "Batch: 80, Loss: 1.1363213062286377, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.1504539251327515, Accuracy: 0.6171875\n",
      "Batch: 82, Loss: 1.1643931865692139, Accuracy: 0.6337890625\n",
      "Batch: 83, Loss: 1.198829174041748, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.1339185237884521, Accuracy: 0.638671875\n",
      "Batch: 85, Loss: 1.1734857559204102, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.2085744142532349, Accuracy: 0.6123046875\n",
      "Batch: 87, Loss: 1.2110389471054077, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1627275943756104, Accuracy: 0.6240234375\n",
      "Batch: 89, Loss: 1.1366353034973145, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.11678147315979, Accuracy: 0.6328125\n",
      "Batch: 91, Loss: 1.1751993894577026, Accuracy: 0.6220703125\n",
      "Batch: 92, Loss: 1.178066372871399, Accuracy: 0.6259765625\n",
      "Batch: 93, Loss: 1.1604814529418945, Accuracy: 0.62890625\n",
      "Batch: 94, Loss: 1.2126331329345703, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.1847693920135498, Accuracy: 0.6162109375\n",
      "Batch: 96, Loss: 1.211112141609192, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.194820523262024, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1083362102508545, Accuracy: 0.6171875\n",
      "Batch: 99, Loss: 1.2309072017669678, Accuracy: 0.6123046875\n",
      "Batch: 100, Loss: 1.1345469951629639, Accuracy: 0.6337890625\n",
      "Batch: 101, Loss: 1.086979627609253, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.2515056133270264, Accuracy: 0.6083984375\n",
      "Batch: 103, Loss: 1.2408297061920166, Accuracy: 0.61328125\n",
      "Batch: 104, Loss: 1.144289493560791, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.2023870944976807, Accuracy: 0.6083984375\n",
      "Batch: 106, Loss: 1.1482493877410889, Accuracy: 0.6279296875\n",
      "Batch: 107, Loss: 1.2236988544464111, Accuracy: 0.6083984375\n",
      "Batch: 108, Loss: 1.189808964729309, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.218610405921936, Accuracy: 0.59375\n",
      "Batch: 110, Loss: 1.178378939628601, Accuracy: 0.6240234375\n",
      "Batch: 111, Loss: 1.1108250617980957, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.1422474384307861, Accuracy: 0.6171875\n",
      "Batch: 113, Loss: 1.1793208122253418, Accuracy: 0.6162109375\n",
      "Batch: 114, Loss: 1.2007794380187988, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.216843605041504, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.2105956077575684, Accuracy: 0.6044921875\n",
      "Batch: 117, Loss: 1.219271183013916, Accuracy: 0.60546875\n",
      "Batch: 118, Loss: 1.2000774145126343, Accuracy: 0.5908203125\n",
      "Batch: 119, Loss: 1.249236822128296, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.2683134078979492, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.2050836086273193, Accuracy: 0.6103515625\n",
      "Batch: 122, Loss: 1.2462565898895264, Accuracy: 0.623046875\n",
      "Batch: 123, Loss: 1.1400847434997559, Accuracy: 0.6376953125\n",
      "Batch: 124, Loss: 1.2849743366241455, Accuracy: 0.591796875\n",
      "Batch: 125, Loss: 1.154050588607788, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.2301335334777832, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.2787432670593262, Accuracy: 0.6005859375\n",
      "Batch: 128, Loss: 1.2045683860778809, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.1988329887390137, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.0847725868225098, Accuracy: 0.658203125\n",
      "Batch: 131, Loss: 1.2292245626449585, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.1276469230651855, Accuracy: 0.623046875\n",
      "Batch: 133, Loss: 1.177987813949585, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1403677463531494, Accuracy: 0.64453125\n",
      "Batch: 135, Loss: 1.0431091785430908, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.07578444480896, Accuracy: 0.630859375\n",
      "Batch: 137, Loss: 1.1715762615203857, Accuracy: 0.6181640625\n",
      "Batch: 138, Loss: 1.2823346853256226, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.216580867767334, Accuracy: 0.6162109375\n",
      "Batch: 140, Loss: 1.2486263513565063, Accuracy: 0.619140625\n",
      "Batch: 141, Loss: 1.164804220199585, Accuracy: 0.6162109375\n",
      "Batch: 142, Loss: 1.1620434522628784, Accuracy: 0.6328125\n",
      "Batch: 143, Loss: 1.2215465307235718, Accuracy: 0.6064453125\n",
      "Batch: 144, Loss: 1.2423818111419678, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.2685623168945312, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.1546381711959839, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.1848942041397095, Accuracy: 0.6103515625\n",
      "Batch: 148, Loss: 1.2455635070800781, Accuracy: 0.58984375\n",
      "Batch: 149, Loss: 1.189446210861206, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.1663192510604858, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.2055622339248657, Accuracy: 0.609375\n",
      "Batch: 152, Loss: 1.1659505367279053, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.1463415622711182, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.1722946166992188, Accuracy: 0.6240234375\n",
      "Batch: 155, Loss: 1.107492446899414, Accuracy: 0.63671875\n",
      "Epoch 478/200\n",
      "Batch: 1, Loss: 1.1859707832336426, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 1.1315892934799194, Accuracy: 0.62109375\n",
      "Batch: 3, Loss: 1.053339958190918, Accuracy: 0.6396484375\n",
      "Batch: 4, Loss: 1.0697145462036133, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 1.0066907405853271, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0565061569213867, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.0728363990783691, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 1.0001637935638428, Accuracy: 0.6572265625\n",
      "Batch: 9, Loss: 0.9790624976158142, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9534770846366882, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.9918529987335205, Accuracy: 0.66796875\n",
      "Batch: 12, Loss: 1.0339572429656982, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0100739002227783, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.9745128750801086, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.9610647559165955, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 0.9883407950401306, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 1.093422293663025, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1179122924804688, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.2100543975830078, Accuracy: 0.5986328125\n",
      "Batch: 20, Loss: 1.1079521179199219, Accuracy: 0.6611328125\n",
      "Batch: 21, Loss: 1.1207029819488525, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2439943552017212, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.2342751026153564, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.1126550436019897, Accuracy: 0.626953125\n",
      "Batch: 25, Loss: 1.1624670028686523, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.238732099533081, Accuracy: 0.5908203125\n",
      "Batch: 27, Loss: 1.1372367143630981, Accuracy: 0.638671875\n",
      "Batch: 28, Loss: 1.0243644714355469, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.059723138809204, Accuracy: 0.6494140625\n",
      "Batch: 30, Loss: 1.1792070865631104, Accuracy: 0.6201171875\n",
      "Batch: 31, Loss: 1.2346444129943848, Accuracy: 0.5947265625\n",
      "Batch: 32, Loss: 1.0401908159255981, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 0.9944295287132263, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.1158843040466309, Accuracy: 0.62890625\n",
      "Batch: 35, Loss: 1.1256773471832275, Accuracy: 0.6279296875\n",
      "Batch: 36, Loss: 1.2007076740264893, Accuracy: 0.609375\n",
      "Batch: 37, Loss: 1.20013427734375, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.1634283065795898, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.0638957023620605, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.094640851020813, Accuracy: 0.6455078125\n",
      "Batch: 41, Loss: 1.115729570388794, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.111815333366394, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0718584060668945, Accuracy: 0.658203125\n",
      "Batch: 44, Loss: 1.07523775100708, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.0478284358978271, Accuracy: 0.6455078125\n",
      "Batch: 46, Loss: 1.1279239654541016, Accuracy: 0.6025390625\n",
      "Batch: 47, Loss: 1.0463404655456543, Accuracy: 0.6748046875\n",
      "Batch: 48, Loss: 1.1243062019348145, Accuracy: 0.6181640625\n",
      "Batch: 49, Loss: 1.1460905075073242, Accuracy: 0.625\n",
      "Batch: 50, Loss: 1.1520549058914185, Accuracy: 0.62109375\n",
      "Batch: 51, Loss: 1.1556395292282104, Accuracy: 0.6259765625\n",
      "Batch: 52, Loss: 1.3023797273635864, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.1857810020446777, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.198199987411499, Accuracy: 0.6103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 1.0721242427825928, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.075087070465088, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.1262147426605225, Accuracy: 0.626953125\n",
      "Batch: 58, Loss: 1.1221415996551514, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.1346558332443237, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2642555236816406, Accuracy: 0.5947265625\n",
      "Batch: 61, Loss: 1.1568858623504639, Accuracy: 0.6298828125\n",
      "Batch: 62, Loss: 1.1939753293991089, Accuracy: 0.61328125\n",
      "Batch: 63, Loss: 1.1539005041122437, Accuracy: 0.6337890625\n",
      "Batch: 64, Loss: 1.1802659034729004, Accuracy: 0.615234375\n",
      "Batch: 65, Loss: 1.1713542938232422, Accuracy: 0.634765625\n",
      "Batch: 66, Loss: 1.172340989112854, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1622004508972168, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.0987176895141602, Accuracy: 0.62890625\n",
      "Batch: 69, Loss: 1.2013927698135376, Accuracy: 0.6015625\n",
      "Batch: 70, Loss: 1.2131235599517822, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.1440731287002563, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.1956520080566406, Accuracy: 0.619140625\n",
      "Batch: 73, Loss: 1.1564867496490479, Accuracy: 0.6298828125\n",
      "Batch: 74, Loss: 1.161588191986084, Accuracy: 0.6162109375\n",
      "Batch: 75, Loss: 1.1260154247283936, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0890142917633057, Accuracy: 0.6455078125\n",
      "Batch: 77, Loss: 1.079258918762207, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.057037353515625, Accuracy: 0.6611328125\n",
      "Batch: 79, Loss: 1.1019392013549805, Accuracy: 0.654296875\n",
      "Batch: 80, Loss: 1.2019037008285522, Accuracy: 0.5966796875\n",
      "Batch: 81, Loss: 1.1584960222244263, Accuracy: 0.6064453125\n",
      "Batch: 82, Loss: 1.1712408065795898, Accuracy: 0.615234375\n",
      "Batch: 83, Loss: 1.2235900163650513, Accuracy: 0.591796875\n",
      "Batch: 84, Loss: 1.1842641830444336, Accuracy: 0.6103515625\n",
      "Batch: 85, Loss: 1.1437824964523315, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.2164332866668701, Accuracy: 0.609375\n",
      "Batch: 87, Loss: 1.2133492231369019, Accuracy: 0.59375\n",
      "Batch: 88, Loss: 1.1441595554351807, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.1441476345062256, Accuracy: 0.6435546875\n",
      "Batch: 90, Loss: 1.1440367698669434, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.1280170679092407, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1704230308532715, Accuracy: 0.6201171875\n",
      "Batch: 93, Loss: 1.181070327758789, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.1660336256027222, Accuracy: 0.6279296875\n",
      "Batch: 95, Loss: 1.1926007270812988, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.2101328372955322, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.2069096565246582, Accuracy: 0.6015625\n",
      "Batch: 98, Loss: 1.140897274017334, Accuracy: 0.6142578125\n",
      "Batch: 99, Loss: 1.1571464538574219, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.0413601398468018, Accuracy: 0.6591796875\n",
      "Batch: 101, Loss: 1.0913190841674805, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.2411220073699951, Accuracy: 0.5986328125\n",
      "Batch: 103, Loss: 1.1940131187438965, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.1619248390197754, Accuracy: 0.6494140625\n",
      "Batch: 105, Loss: 1.1939117908477783, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.2018992900848389, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.279344916343689, Accuracy: 0.5830078125\n",
      "Batch: 108, Loss: 1.2311644554138184, Accuracy: 0.61328125\n",
      "Batch: 109, Loss: 1.2235145568847656, Accuracy: 0.6005859375\n",
      "Batch: 110, Loss: 1.1684544086456299, Accuracy: 0.6376953125\n",
      "Batch: 111, Loss: 1.1532567739486694, Accuracy: 0.6328125\n",
      "Batch: 112, Loss: 1.1631404161453247, Accuracy: 0.6181640625\n",
      "Batch: 113, Loss: 1.1559770107269287, Accuracy: 0.6259765625\n",
      "Batch: 114, Loss: 1.1472985744476318, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.2014122009277344, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.1584408283233643, Accuracy: 0.6259765625\n",
      "Batch: 117, Loss: 1.1687052249908447, Accuracy: 0.623046875\n",
      "Batch: 118, Loss: 1.2096633911132812, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2665174007415771, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.3289674520492554, Accuracy: 0.5849609375\n",
      "Batch: 121, Loss: 1.1453129053115845, Accuracy: 0.6357421875\n",
      "Batch: 122, Loss: 1.2181212902069092, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.185206413269043, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.2555384635925293, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.1864075660705566, Accuracy: 0.6201171875\n",
      "Batch: 126, Loss: 1.2357665300369263, Accuracy: 0.623046875\n",
      "Batch: 127, Loss: 1.2197668552398682, Accuracy: 0.62890625\n",
      "Batch: 128, Loss: 1.2090344429016113, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.219724178314209, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.1407201290130615, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.2021104097366333, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.1224570274353027, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.1661348342895508, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1043224334716797, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 1.0205175876617432, Accuracy: 0.6650390625\n",
      "Batch: 136, Loss: 1.0891826152801514, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.1820204257965088, Accuracy: 0.6279296875\n",
      "Batch: 138, Loss: 1.280087947845459, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.21553635597229, Accuracy: 0.6142578125\n",
      "Batch: 140, Loss: 1.2927052974700928, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.1404917240142822, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.220268726348877, Accuracy: 0.60546875\n",
      "Batch: 143, Loss: 1.2010202407836914, Accuracy: 0.6201171875\n",
      "Batch: 144, Loss: 1.1883952617645264, Accuracy: 0.615234375\n",
      "Batch: 145, Loss: 1.1824312210083008, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.2177461385726929, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.1579968929290771, Accuracy: 0.6298828125\n",
      "Batch: 148, Loss: 1.2271085977554321, Accuracy: 0.6044921875\n",
      "Batch: 149, Loss: 1.17924165725708, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.1553863286972046, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.155702829360962, Accuracy: 0.615234375\n",
      "Batch: 152, Loss: 1.1845489740371704, Accuracy: 0.6044921875\n",
      "Batch: 153, Loss: 1.1931326389312744, Accuracy: 0.6162109375\n",
      "Batch: 154, Loss: 1.0923839807510376, Accuracy: 0.658203125\n",
      "Batch: 155, Loss: 1.0769753456115723, Accuracy: 0.6591796875\n",
      "Epoch 479/200\n",
      "Batch: 1, Loss: 1.233064889907837, Accuracy: 0.61328125\n",
      "Batch: 2, Loss: 1.1016786098480225, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.0034347772598267, Accuracy: 0.6767578125\n",
      "Batch: 4, Loss: 1.0737063884735107, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.0533250570297241, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0330986976623535, Accuracy: 0.6591796875\n",
      "Batch: 7, Loss: 1.0734220743179321, Accuracy: 0.6435546875\n",
      "Batch: 8, Loss: 1.052885890007019, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 0.9855169057846069, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9939574003219604, Accuracy: 0.658203125\n",
      "Batch: 11, Loss: 0.9696952104568481, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 1.0063329935073853, Accuracy: 0.6767578125\n",
      "Batch: 13, Loss: 1.006972074508667, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.9679455757141113, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.9222450852394104, Accuracy: 0.6865234375\n",
      "Batch: 16, Loss: 1.0112967491149902, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.0208063125610352, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1320768594741821, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.246808648109436, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.1308035850524902, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.083249807357788, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.2738630771636963, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.2342053651809692, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.1309924125671387, Accuracy: 0.6474609375\n",
      "Batch: 25, Loss: 1.1926544904708862, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.2147873640060425, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.1566779613494873, Accuracy: 0.634765625\n",
      "Batch: 28, Loss: 1.1035771369934082, Accuracy: 0.6298828125\n",
      "Batch: 29, Loss: 1.090295433998108, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.2017923593521118, Accuracy: 0.595703125\n",
      "Batch: 31, Loss: 1.2664936780929565, Accuracy: 0.5751953125\n",
      "Batch: 32, Loss: 1.0914452075958252, Accuracy: 0.6591796875\n",
      "Batch: 33, Loss: 1.0547975301742554, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.1351697444915771, Accuracy: 0.6298828125\n",
      "Batch: 35, Loss: 1.1929831504821777, Accuracy: 0.60546875\n",
      "Batch: 36, Loss: 1.228527307510376, Accuracy: 0.5908203125\n",
      "Batch: 37, Loss: 1.1861048936843872, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 38, Loss: 1.1444263458251953, Accuracy: 0.630859375\n",
      "Batch: 39, Loss: 1.068986415863037, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.1014742851257324, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.149091362953186, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.0707685947418213, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.0225672721862793, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0313111543655396, Accuracy: 0.6669921875\n",
      "Batch: 45, Loss: 1.0800257921218872, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1376696825027466, Accuracy: 0.6083984375\n",
      "Batch: 47, Loss: 1.1601436138153076, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.10849928855896, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.182337999343872, Accuracy: 0.6474609375\n",
      "Batch: 50, Loss: 1.1226398944854736, Accuracy: 0.640625\n",
      "Batch: 51, Loss: 1.1229968070983887, Accuracy: 0.640625\n",
      "Batch: 52, Loss: 1.2390656471252441, Accuracy: 0.591796875\n",
      "Batch: 53, Loss: 1.2040154933929443, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.233817458152771, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.1773134469985962, Accuracy: 0.5986328125\n",
      "Batch: 56, Loss: 1.139338731765747, Accuracy: 0.6279296875\n",
      "Batch: 57, Loss: 1.2080857753753662, Accuracy: 0.630859375\n",
      "Batch: 58, Loss: 1.09559965133667, Accuracy: 0.6640625\n",
      "Batch: 59, Loss: 1.1402924060821533, Accuracy: 0.634765625\n",
      "Batch: 60, Loss: 1.2356677055358887, Accuracy: 0.5947265625\n",
      "Batch: 61, Loss: 1.1485249996185303, Accuracy: 0.60546875\n",
      "Batch: 62, Loss: 1.1597025394439697, Accuracy: 0.609375\n",
      "Batch: 63, Loss: 1.1555781364440918, Accuracy: 0.61328125\n",
      "Batch: 64, Loss: 1.2105491161346436, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1841810941696167, Accuracy: 0.6337890625\n",
      "Batch: 66, Loss: 1.163257360458374, Accuracy: 0.6240234375\n",
      "Batch: 67, Loss: 1.1530566215515137, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0838563442230225, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1686118841171265, Accuracy: 0.6484375\n",
      "Batch: 70, Loss: 1.2141022682189941, Accuracy: 0.6025390625\n",
      "Batch: 71, Loss: 1.128793478012085, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.1449137926101685, Accuracy: 0.6337890625\n",
      "Batch: 73, Loss: 1.1879558563232422, Accuracy: 0.6357421875\n",
      "Batch: 74, Loss: 1.1271963119506836, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.0880028009414673, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.0870130062103271, Accuracy: 0.65625\n",
      "Batch: 77, Loss: 1.1027041673660278, Accuracy: 0.6337890625\n",
      "Batch: 78, Loss: 1.1479196548461914, Accuracy: 0.619140625\n",
      "Batch: 79, Loss: 1.2081997394561768, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.247749924659729, Accuracy: 0.5888671875\n",
      "Batch: 81, Loss: 1.0973153114318848, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.1259291172027588, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.1790902614593506, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.1277461051940918, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.2051912546157837, Accuracy: 0.61328125\n",
      "Batch: 86, Loss: 1.2001620531082153, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.218186378479004, Accuracy: 0.609375\n",
      "Batch: 88, Loss: 1.1512730121612549, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.1606957912445068, Accuracy: 0.6328125\n",
      "Batch: 90, Loss: 1.1321145296096802, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.182831883430481, Accuracy: 0.611328125\n",
      "Batch: 92, Loss: 1.162412166595459, Accuracy: 0.6298828125\n",
      "Batch: 93, Loss: 1.131737470626831, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.2201244831085205, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.2558822631835938, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.2359750270843506, Accuracy: 0.6005859375\n",
      "Batch: 97, Loss: 1.1623551845550537, Accuracy: 0.625\n",
      "Batch: 98, Loss: 1.142941951751709, Accuracy: 0.623046875\n",
      "Batch: 99, Loss: 1.1563076972961426, Accuracy: 0.6376953125\n",
      "Batch: 100, Loss: 1.0414156913757324, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.1071357727050781, Accuracy: 0.63671875\n",
      "Batch: 102, Loss: 1.1532248258590698, Accuracy: 0.642578125\n",
      "Batch: 103, Loss: 1.2104079723358154, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.1460973024368286, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.2352755069732666, Accuracy: 0.62890625\n",
      "Batch: 106, Loss: 1.1831445693969727, Accuracy: 0.6298828125\n",
      "Batch: 107, Loss: 1.2168614864349365, Accuracy: 0.59375\n",
      "Batch: 108, Loss: 1.174905776977539, Accuracy: 0.6142578125\n",
      "Batch: 109, Loss: 1.1999306678771973, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.1278860569000244, Accuracy: 0.654296875\n",
      "Batch: 111, Loss: 1.1768027544021606, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.0897271633148193, Accuracy: 0.6416015625\n",
      "Batch: 113, Loss: 1.175689697265625, Accuracy: 0.625\n",
      "Batch: 114, Loss: 1.1915788650512695, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.2003445625305176, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1913106441497803, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1670904159545898, Accuracy: 0.609375\n",
      "Batch: 118, Loss: 1.2178363800048828, Accuracy: 0.58984375\n",
      "Batch: 119, Loss: 1.2818305492401123, Accuracy: 0.58203125\n",
      "Batch: 120, Loss: 1.2430965900421143, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.1918492317199707, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.1888411045074463, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.195156216621399, Accuracy: 0.6240234375\n",
      "Batch: 124, Loss: 1.1989312171936035, Accuracy: 0.6162109375\n",
      "Batch: 125, Loss: 1.1978281736373901, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.240769863128662, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2496546506881714, Accuracy: 0.60546875\n",
      "Batch: 128, Loss: 1.2581169605255127, Accuracy: 0.5888671875\n",
      "Batch: 129, Loss: 1.2216780185699463, Accuracy: 0.6005859375\n",
      "Batch: 130, Loss: 1.190633773803711, Accuracy: 0.6201171875\n",
      "Batch: 131, Loss: 1.2458834648132324, Accuracy: 0.5966796875\n",
      "Batch: 132, Loss: 1.1310533285140991, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.1967138051986694, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1298916339874268, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 1.0559898614883423, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.0777391195297241, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1743292808532715, Accuracy: 0.6181640625\n",
      "Batch: 138, Loss: 1.2731082439422607, Accuracy: 0.5888671875\n",
      "Batch: 139, Loss: 1.18607497215271, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.3086202144622803, Accuracy: 0.564453125\n",
      "Batch: 141, Loss: 1.160784125328064, Accuracy: 0.6318359375\n",
      "Batch: 142, Loss: 1.210373878479004, Accuracy: 0.6083984375\n",
      "Batch: 143, Loss: 1.2361233234405518, Accuracy: 0.6064453125\n",
      "Batch: 144, Loss: 1.2643568515777588, Accuracy: 0.5966796875\n",
      "Batch: 145, Loss: 1.2596776485443115, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.2758944034576416, Accuracy: 0.5859375\n",
      "Batch: 147, Loss: 1.2110145092010498, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.1929314136505127, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 1.1854519844055176, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.1727981567382812, Accuracy: 0.6044921875\n",
      "Batch: 151, Loss: 1.1381741762161255, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.2172048091888428, Accuracy: 0.6064453125\n",
      "Batch: 153, Loss: 1.1343015432357788, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.1294479370117188, Accuracy: 0.634765625\n",
      "Batch: 155, Loss: 1.09794020652771, Accuracy: 0.63671875\n",
      "Epoch 480/200\n",
      "Batch: 1, Loss: 1.2572906017303467, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.1127914190292358, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.0350483655929565, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0732630491256714, Accuracy: 0.626953125\n",
      "Batch: 5, Loss: 1.0525188446044922, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.0718183517456055, Accuracy: 0.662109375\n",
      "Batch: 7, Loss: 1.0339174270629883, Accuracy: 0.6533203125\n",
      "Batch: 8, Loss: 1.0143353939056396, Accuracy: 0.666015625\n",
      "Batch: 9, Loss: 1.0198055505752563, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.993631899356842, Accuracy: 0.66796875\n",
      "Batch: 11, Loss: 0.9975435733795166, Accuracy: 0.685546875\n",
      "Batch: 12, Loss: 1.0142297744750977, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 1.0276422500610352, Accuracy: 0.65234375\n",
      "Batch: 14, Loss: 1.030102252960205, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9773657917976379, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0518755912780762, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.067718744277954, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.1330584287643433, Accuracy: 0.619140625\n",
      "Batch: 19, Loss: 1.2081584930419922, Accuracy: 0.5966796875\n",
      "Batch: 20, Loss: 1.0926995277404785, Accuracy: 0.642578125\n",
      "Batch: 21, Loss: 1.1338071823120117, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.3201887607574463, Accuracy: 0.5693359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23, Loss: 1.1924066543579102, Accuracy: 0.615234375\n",
      "Batch: 24, Loss: 1.125477910041809, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.1883537769317627, Accuracy: 0.630859375\n",
      "Batch: 26, Loss: 1.2579272985458374, Accuracy: 0.587890625\n",
      "Batch: 27, Loss: 1.1112380027770996, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.1211535930633545, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.128504753112793, Accuracy: 0.6259765625\n",
      "Batch: 30, Loss: 1.1971465349197388, Accuracy: 0.60546875\n",
      "Batch: 31, Loss: 1.2175763845443726, Accuracy: 0.6103515625\n",
      "Batch: 32, Loss: 1.0669690370559692, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.0192296504974365, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.12040114402771, Accuracy: 0.6298828125\n",
      "Batch: 35, Loss: 1.1216063499450684, Accuracy: 0.6328125\n",
      "Batch: 36, Loss: 1.2125084400177002, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.178296446800232, Accuracy: 0.6162109375\n",
      "Batch: 38, Loss: 1.2089431285858154, Accuracy: 0.6005859375\n",
      "Batch: 39, Loss: 1.1161248683929443, Accuracy: 0.6337890625\n",
      "Batch: 40, Loss: 1.1224868297576904, Accuracy: 0.6259765625\n",
      "Batch: 41, Loss: 1.1346919536590576, Accuracy: 0.6435546875\n",
      "Batch: 42, Loss: 1.1026278734207153, Accuracy: 0.6396484375\n",
      "Batch: 43, Loss: 0.9982360601425171, Accuracy: 0.6552734375\n",
      "Batch: 44, Loss: 1.0587142705917358, Accuracy: 0.634765625\n",
      "Batch: 45, Loss: 1.0582304000854492, Accuracy: 0.646484375\n",
      "Batch: 46, Loss: 1.1557503938674927, Accuracy: 0.6142578125\n",
      "Batch: 47, Loss: 1.1276466846466064, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.1393768787384033, Accuracy: 0.625\n",
      "Batch: 49, Loss: 1.2184033393859863, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.1602694988250732, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.176831841468811, Accuracy: 0.6025390625\n",
      "Batch: 52, Loss: 1.2383149862289429, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.1731656789779663, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.2298519611358643, Accuracy: 0.61328125\n",
      "Batch: 55, Loss: 1.1203194856643677, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.086045742034912, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.1313493251800537, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.1494674682617188, Accuracy: 0.638671875\n",
      "Batch: 59, Loss: 1.1144747734069824, Accuracy: 0.623046875\n",
      "Batch: 60, Loss: 1.197696566581726, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1854631900787354, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1619744300842285, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.1410006284713745, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.202244758605957, Accuracy: 0.5966796875\n",
      "Batch: 65, Loss: 1.2692795991897583, Accuracy: 0.58984375\n",
      "Batch: 66, Loss: 1.1308910846710205, Accuracy: 0.634765625\n",
      "Batch: 67, Loss: 1.1285040378570557, Accuracy: 0.6484375\n",
      "Batch: 68, Loss: 1.148383378982544, Accuracy: 0.6416015625\n",
      "Batch: 69, Loss: 1.1641433238983154, Accuracy: 0.6064453125\n",
      "Batch: 70, Loss: 1.2177367210388184, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1845817565917969, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.2140324115753174, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.18812894821167, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.1191644668579102, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.134163737297058, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.1041346788406372, Accuracy: 0.646484375\n",
      "Batch: 77, Loss: 1.134211778640747, Accuracy: 0.6298828125\n",
      "Batch: 78, Loss: 1.0847423076629639, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.134376883506775, Accuracy: 0.6337890625\n",
      "Batch: 80, Loss: 1.1564018726348877, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.1219582557678223, Accuracy: 0.625\n",
      "Batch: 82, Loss: 1.0929584503173828, Accuracy: 0.6396484375\n",
      "Batch: 83, Loss: 1.2009711265563965, Accuracy: 0.6220703125\n",
      "Batch: 84, Loss: 1.1454358100891113, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.1646010875701904, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.2673064470291138, Accuracy: 0.595703125\n",
      "Batch: 87, Loss: 1.2269093990325928, Accuracy: 0.6083984375\n",
      "Batch: 88, Loss: 1.208733081817627, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.1570638418197632, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.111475944519043, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.185105562210083, Accuracy: 0.61328125\n",
      "Batch: 92, Loss: 1.1609233617782593, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.1266008615493774, Accuracy: 0.6513671875\n",
      "Batch: 94, Loss: 1.1727432012557983, Accuracy: 0.6337890625\n",
      "Batch: 95, Loss: 1.1627154350280762, Accuracy: 0.6240234375\n",
      "Batch: 96, Loss: 1.2178682088851929, Accuracy: 0.6064453125\n",
      "Batch: 97, Loss: 1.1496586799621582, Accuracy: 0.619140625\n",
      "Batch: 98, Loss: 1.0994648933410645, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.1139572858810425, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.0292452573776245, Accuracy: 0.66796875\n",
      "Batch: 101, Loss: 1.113204002380371, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.189611792564392, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.2067837715148926, Accuracy: 0.609375\n",
      "Batch: 104, Loss: 1.1127877235412598, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.2233197689056396, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.156813383102417, Accuracy: 0.6181640625\n",
      "Batch: 107, Loss: 1.274329423904419, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.1965407133102417, Accuracy: 0.609375\n",
      "Batch: 109, Loss: 1.2452435493469238, Accuracy: 0.599609375\n",
      "Batch: 110, Loss: 1.1428425312042236, Accuracy: 0.630859375\n",
      "Batch: 111, Loss: 1.1380456686019897, Accuracy: 0.6298828125\n",
      "Batch: 112, Loss: 1.0641781091690063, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.1202120780944824, Accuracy: 0.626953125\n",
      "Batch: 114, Loss: 1.2293827533721924, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.157968521118164, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.186255693435669, Accuracy: 0.6171875\n",
      "Batch: 117, Loss: 1.180863857269287, Accuracy: 0.6171875\n",
      "Batch: 118, Loss: 1.1266400814056396, Accuracy: 0.6357421875\n",
      "Batch: 119, Loss: 1.250688076019287, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.299833059310913, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.2013635635375977, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.19535493850708, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.1948914527893066, Accuracy: 0.64453125\n",
      "Batch: 124, Loss: 1.1792967319488525, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.1862891912460327, Accuracy: 0.61328125\n",
      "Batch: 126, Loss: 1.2324968576431274, Accuracy: 0.6064453125\n",
      "Batch: 127, Loss: 1.2721061706542969, Accuracy: 0.5986328125\n",
      "Batch: 128, Loss: 1.2163398265838623, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.1860060691833496, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.0895028114318848, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 1.2091937065124512, Accuracy: 0.630859375\n",
      "Batch: 132, Loss: 1.0877898931503296, Accuracy: 0.64453125\n",
      "Batch: 133, Loss: 1.1733423471450806, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1141479015350342, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 1.0466279983520508, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.0932483673095703, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.1685290336608887, Accuracy: 0.6318359375\n",
      "Batch: 138, Loss: 1.2233673334121704, Accuracy: 0.6181640625\n",
      "Batch: 139, Loss: 1.2289708852767944, Accuracy: 0.59375\n",
      "Batch: 140, Loss: 1.2732336521148682, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.1832160949707031, Accuracy: 0.619140625\n",
      "Batch: 142, Loss: 1.174569845199585, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.1691139936447144, Accuracy: 0.623046875\n",
      "Batch: 144, Loss: 1.2690107822418213, Accuracy: 0.5830078125\n",
      "Batch: 145, Loss: 1.263307809829712, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.1491469144821167, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.2628886699676514, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.1942720413208008, Accuracy: 0.6171875\n",
      "Batch: 149, Loss: 1.152459740638733, Accuracy: 0.6220703125\n",
      "Batch: 150, Loss: 1.176705002784729, Accuracy: 0.609375\n",
      "Batch: 151, Loss: 1.1791658401489258, Accuracy: 0.63671875\n",
      "Batch: 152, Loss: 1.1863306760787964, Accuracy: 0.6005859375\n",
      "Batch: 153, Loss: 1.1358823776245117, Accuracy: 0.6416015625\n",
      "Batch: 154, Loss: 1.1184546947479248, Accuracy: 0.634765625\n",
      "Batch: 155, Loss: 1.1291632652282715, Accuracy: 0.6279296875\n",
      "Saved Weights at epoch 480 to file Weights_480.h5\n",
      "Epoch 481/200\n",
      "Batch: 1, Loss: 1.2305169105529785, Accuracy: 0.6552734375\n",
      "Batch: 2, Loss: 1.0722488164901733, Accuracy: 0.6513671875\n",
      "Batch: 3, Loss: 0.9924200773239136, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 1.1188623905181885, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.055267333984375, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6, Loss: 1.030778408050537, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.036512851715088, Accuracy: 0.673828125\n",
      "Batch: 8, Loss: 1.0071576833724976, Accuracy: 0.6796875\n",
      "Batch: 9, Loss: 1.0024276971817017, Accuracy: 0.6826171875\n",
      "Batch: 10, Loss: 0.987735390663147, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 1.0067756175994873, Accuracy: 0.658203125\n",
      "Batch: 12, Loss: 1.0464246273040771, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.048872709274292, Accuracy: 0.658203125\n",
      "Batch: 14, Loss: 1.028426170349121, Accuracy: 0.6640625\n",
      "Batch: 15, Loss: 0.9391529560089111, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 1.0844192504882812, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.0449943542480469, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1451588869094849, Accuracy: 0.6328125\n",
      "Batch: 19, Loss: 1.2094625234603882, Accuracy: 0.6162109375\n",
      "Batch: 20, Loss: 1.1046135425567627, Accuracy: 0.6533203125\n",
      "Batch: 21, Loss: 1.095691442489624, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.2930002212524414, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.2214627265930176, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.1242735385894775, Accuracy: 0.6416015625\n",
      "Batch: 25, Loss: 1.1845488548278809, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.2337455749511719, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.1751569509506226, Accuracy: 0.6083984375\n",
      "Batch: 28, Loss: 1.0691680908203125, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.1040046215057373, Accuracy: 0.63671875\n",
      "Batch: 30, Loss: 1.1635878086090088, Accuracy: 0.6201171875\n",
      "Batch: 31, Loss: 1.262073278427124, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.0558922290802002, Accuracy: 0.65234375\n",
      "Batch: 33, Loss: 0.9959743022918701, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1101601123809814, Accuracy: 0.6474609375\n",
      "Batch: 35, Loss: 1.144780158996582, Accuracy: 0.6298828125\n",
      "Batch: 36, Loss: 1.1607367992401123, Accuracy: 0.6376953125\n",
      "Batch: 37, Loss: 1.2081642150878906, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.1940228939056396, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.1198136806488037, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.099912166595459, Accuracy: 0.6416015625\n",
      "Batch: 41, Loss: 1.1248586177825928, Accuracy: 0.6357421875\n",
      "Batch: 42, Loss: 1.0660862922668457, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 1.0554835796356201, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.005424976348877, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 1.061617374420166, Accuracy: 0.630859375\n",
      "Batch: 46, Loss: 1.1279339790344238, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.1222467422485352, Accuracy: 0.6396484375\n",
      "Batch: 48, Loss: 1.0886319875717163, Accuracy: 0.6455078125\n",
      "Batch: 49, Loss: 1.213316559791565, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.1724083423614502, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.1558136940002441, Accuracy: 0.6171875\n",
      "Batch: 52, Loss: 1.2792940139770508, Accuracy: 0.5712890625\n",
      "Batch: 53, Loss: 1.1645455360412598, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.1932331323623657, Accuracy: 0.6064453125\n",
      "Batch: 55, Loss: 1.1260995864868164, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.1177724599838257, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.1546170711517334, Accuracy: 0.6162109375\n",
      "Batch: 58, Loss: 1.1889839172363281, Accuracy: 0.6044921875\n",
      "Batch: 59, Loss: 1.111986517906189, Accuracy: 0.6240234375\n",
      "Batch: 60, Loss: 1.2545723915100098, Accuracy: 0.591796875\n",
      "Batch: 61, Loss: 1.1335899829864502, Accuracy: 0.6328125\n",
      "Batch: 62, Loss: 1.251011610031128, Accuracy: 0.595703125\n",
      "Batch: 63, Loss: 1.174626111984253, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.2180328369140625, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.182584285736084, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.137705683708191, Accuracy: 0.6337890625\n",
      "Batch: 67, Loss: 1.187422275543213, Accuracy: 0.6103515625\n",
      "Batch: 68, Loss: 1.1005346775054932, Accuracy: 0.64453125\n",
      "Batch: 69, Loss: 1.2178542613983154, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.2197774648666382, Accuracy: 0.603515625\n",
      "Batch: 71, Loss: 1.1396565437316895, Accuracy: 0.6416015625\n",
      "Batch: 72, Loss: 1.164190649986267, Accuracy: 0.6123046875\n",
      "Batch: 73, Loss: 1.1815450191497803, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.1163253784179688, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.1261048316955566, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.0793663263320923, Accuracy: 0.662109375\n",
      "Batch: 77, Loss: 1.0882437229156494, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0808959007263184, Accuracy: 0.6513671875\n",
      "Batch: 79, Loss: 1.1810946464538574, Accuracy: 0.609375\n",
      "Batch: 80, Loss: 1.199220895767212, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1594653129577637, Accuracy: 0.619140625\n",
      "Batch: 82, Loss: 1.1837167739868164, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 1.289908528327942, Accuracy: 0.5830078125\n",
      "Batch: 84, Loss: 1.1671069860458374, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.218165397644043, Accuracy: 0.607421875\n",
      "Batch: 86, Loss: 1.1564141511917114, Accuracy: 0.6142578125\n",
      "Batch: 87, Loss: 1.2103725671768188, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.2065119743347168, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1940032243728638, Accuracy: 0.6015625\n",
      "Batch: 90, Loss: 1.1479334831237793, Accuracy: 0.6328125\n",
      "Batch: 91, Loss: 1.1486198902130127, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1263453960418701, Accuracy: 0.640625\n",
      "Batch: 93, Loss: 1.173724889755249, Accuracy: 0.6220703125\n",
      "Batch: 94, Loss: 1.2447762489318848, Accuracy: 0.5986328125\n",
      "Batch: 95, Loss: 1.181791067123413, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.168151617050171, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.179779291152954, Accuracy: 0.59375\n",
      "Batch: 98, Loss: 1.153794527053833, Accuracy: 0.625\n",
      "Batch: 99, Loss: 1.1126948595046997, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.0939269065856934, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.061885118484497, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.1932921409606934, Accuracy: 0.6123046875\n",
      "Batch: 103, Loss: 1.1985538005828857, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.1193023920059204, Accuracy: 0.646484375\n",
      "Batch: 105, Loss: 1.2210538387298584, Accuracy: 0.60546875\n",
      "Batch: 106, Loss: 1.1301982402801514, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.2562077045440674, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.1797735691070557, Accuracy: 0.59375\n",
      "Batch: 109, Loss: 1.212416648864746, Accuracy: 0.5966796875\n",
      "Batch: 110, Loss: 1.163228154182434, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.1708136796951294, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.0864856243133545, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.1839344501495361, Accuracy: 0.6162109375\n",
      "Batch: 114, Loss: 1.2259135246276855, Accuracy: 0.60546875\n",
      "Batch: 115, Loss: 1.2374939918518066, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1901229619979858, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.1036951541900635, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 1.2210192680358887, Accuracy: 0.6123046875\n",
      "Batch: 119, Loss: 1.2397773265838623, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.3191494941711426, Accuracy: 0.5986328125\n",
      "Batch: 121, Loss: 1.2440662384033203, Accuracy: 0.619140625\n",
      "Batch: 122, Loss: 1.222419261932373, Accuracy: 0.6083984375\n",
      "Batch: 123, Loss: 1.1879427433013916, Accuracy: 0.6513671875\n",
      "Batch: 124, Loss: 1.275721549987793, Accuracy: 0.5859375\n",
      "Batch: 125, Loss: 1.1843980550765991, Accuracy: 0.6142578125\n",
      "Batch: 126, Loss: 1.2930822372436523, Accuracy: 0.5849609375\n",
      "Batch: 127, Loss: 1.2674431800842285, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.2364273071289062, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.218737244606018, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.1672097444534302, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.268256425857544, Accuracy: 0.5849609375\n",
      "Batch: 132, Loss: 1.0758477449417114, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 1.164330005645752, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.0824227333068848, Accuracy: 0.66015625\n",
      "Batch: 135, Loss: 1.0769851207733154, Accuracy: 0.6357421875\n",
      "Batch: 136, Loss: 1.0948947668075562, Accuracy: 0.6376953125\n",
      "Batch: 137, Loss: 1.1220165491104126, Accuracy: 0.6259765625\n",
      "Batch: 138, Loss: 1.1994707584381104, Accuracy: 0.6103515625\n",
      "Batch: 139, Loss: 1.205296516418457, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.2681326866149902, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.2466790676116943, Accuracy: 0.603515625\n",
      "Batch: 142, Loss: 1.1728585958480835, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.2042964696884155, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.3179152011871338, Accuracy: 0.5986328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 145, Loss: 1.2925257682800293, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.2275950908660889, Accuracy: 0.59765625\n",
      "Batch: 147, Loss: 1.2053475379943848, Accuracy: 0.6103515625\n",
      "Batch: 148, Loss: 1.2241406440734863, Accuracy: 0.59765625\n",
      "Batch: 149, Loss: 1.1186702251434326, Accuracy: 0.62109375\n",
      "Batch: 150, Loss: 1.1629830598831177, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.209745168685913, Accuracy: 0.5986328125\n",
      "Batch: 152, Loss: 1.1454042196273804, Accuracy: 0.63671875\n",
      "Batch: 153, Loss: 1.1686125993728638, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.1486883163452148, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.0952260494232178, Accuracy: 0.6474609375\n",
      "Epoch 482/200\n",
      "Batch: 1, Loss: 1.2473444938659668, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.132925271987915, Accuracy: 0.623046875\n",
      "Batch: 3, Loss: 1.0455385446548462, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.1006455421447754, Accuracy: 0.626953125\n",
      "Batch: 5, Loss: 1.0614492893218994, Accuracy: 0.6357421875\n",
      "Batch: 6, Loss: 1.0197911262512207, Accuracy: 0.666015625\n",
      "Batch: 7, Loss: 1.0636985301971436, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 1.0010342597961426, Accuracy: 0.6689453125\n",
      "Batch: 9, Loss: 1.0493847131729126, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 0.9513893127441406, Accuracy: 0.689453125\n",
      "Batch: 11, Loss: 0.9917075634002686, Accuracy: 0.66015625\n",
      "Batch: 12, Loss: 1.0460110902786255, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 1.0301276445388794, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 1.012830138206482, Accuracy: 0.6572265625\n",
      "Batch: 15, Loss: 0.9470269680023193, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0461536645889282, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.0764820575714111, Accuracy: 0.6455078125\n",
      "Batch: 18, Loss: 1.130295991897583, Accuracy: 0.6328125\n",
      "Batch: 19, Loss: 1.1676863431930542, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 1.037494421005249, Accuracy: 0.6630859375\n",
      "Batch: 21, Loss: 1.1289634704589844, Accuracy: 0.6259765625\n",
      "Batch: 22, Loss: 1.2777955532073975, Accuracy: 0.591796875\n",
      "Batch: 23, Loss: 1.2487473487854004, Accuracy: 0.607421875\n",
      "Batch: 24, Loss: 1.1268947124481201, Accuracy: 0.634765625\n",
      "Batch: 25, Loss: 1.227102518081665, Accuracy: 0.599609375\n",
      "Batch: 26, Loss: 1.237977385520935, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.1223623752593994, Accuracy: 0.634765625\n",
      "Batch: 28, Loss: 1.0046629905700684, Accuracy: 0.6748046875\n",
      "Batch: 29, Loss: 1.1209967136383057, Accuracy: 0.63671875\n",
      "Batch: 30, Loss: 1.1255627870559692, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.150736689567566, Accuracy: 0.6103515625\n",
      "Batch: 32, Loss: 1.0598149299621582, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.0650027990341187, Accuracy: 0.63671875\n",
      "Batch: 34, Loss: 1.1612803936004639, Accuracy: 0.61328125\n",
      "Batch: 35, Loss: 1.1780035495758057, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.226380705833435, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.2262296676635742, Accuracy: 0.591796875\n",
      "Batch: 38, Loss: 1.2277328968048096, Accuracy: 0.6123046875\n",
      "Batch: 39, Loss: 1.034271001815796, Accuracy: 0.6689453125\n",
      "Batch: 40, Loss: 1.1269497871398926, Accuracy: 0.6513671875\n",
      "Batch: 41, Loss: 1.1531023979187012, Accuracy: 0.6220703125\n",
      "Batch: 42, Loss: 1.112743616104126, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.107684850692749, Accuracy: 0.64453125\n",
      "Batch: 44, Loss: 1.0613832473754883, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.1181764602661133, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.126287817955017, Accuracy: 0.6396484375\n",
      "Batch: 47, Loss: 1.1378268003463745, Accuracy: 0.6572265625\n",
      "Batch: 48, Loss: 1.136494755744934, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.1742475032806396, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.114880084991455, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1452512741088867, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.2146689891815186, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.177042841911316, Accuracy: 0.5986328125\n",
      "Batch: 54, Loss: 1.1760603189468384, Accuracy: 0.6171875\n",
      "Batch: 55, Loss: 1.1009385585784912, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.0744234323501587, Accuracy: 0.662109375\n",
      "Batch: 57, Loss: 1.1432008743286133, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.1266030073165894, Accuracy: 0.6357421875\n",
      "Batch: 59, Loss: 1.1163318157196045, Accuracy: 0.638671875\n",
      "Batch: 60, Loss: 1.249349594116211, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1755942106246948, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.1603403091430664, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.170967936515808, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.2191226482391357, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.1834571361541748, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1671253442764282, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.1750279664993286, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.0557790994644165, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.2309198379516602, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.1619336605072021, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1605651378631592, Accuracy: 0.615234375\n",
      "Batch: 72, Loss: 1.234228491783142, Accuracy: 0.5849609375\n",
      "Batch: 73, Loss: 1.2210062742233276, Accuracy: 0.6015625\n",
      "Batch: 74, Loss: 1.137920618057251, Accuracy: 0.6240234375\n",
      "Batch: 75, Loss: 1.113661527633667, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.1215391159057617, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 1.052739143371582, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0755672454833984, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1788533926010132, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.1729457378387451, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.1581425666809082, Accuracy: 0.6142578125\n",
      "Batch: 82, Loss: 1.1244981288909912, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 1.183500051498413, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.15805983543396, Accuracy: 0.6142578125\n",
      "Batch: 85, Loss: 1.1685036420822144, Accuracy: 0.625\n",
      "Batch: 86, Loss: 1.1751890182495117, Accuracy: 0.6103515625\n",
      "Batch: 87, Loss: 1.1789898872375488, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.1786103248596191, Accuracy: 0.6083984375\n",
      "Batch: 89, Loss: 1.1524838209152222, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.1696383953094482, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.1657569408416748, Accuracy: 0.64453125\n",
      "Batch: 92, Loss: 1.1398305892944336, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.1619555950164795, Accuracy: 0.6298828125\n",
      "Batch: 94, Loss: 1.232753872871399, Accuracy: 0.59375\n",
      "Batch: 95, Loss: 1.1808350086212158, Accuracy: 0.6181640625\n",
      "Batch: 96, Loss: 1.2059324979782104, Accuracy: 0.6279296875\n",
      "Batch: 97, Loss: 1.2169893980026245, Accuracy: 0.591796875\n",
      "Batch: 98, Loss: 1.1089591979980469, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.148414969444275, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0820212364196777, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.1077765226364136, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.191184401512146, Accuracy: 0.6171875\n",
      "Batch: 103, Loss: 1.1784083843231201, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1494356393814087, Accuracy: 0.6220703125\n",
      "Batch: 105, Loss: 1.248993158340454, Accuracy: 0.59765625\n",
      "Batch: 106, Loss: 1.1573822498321533, Accuracy: 0.640625\n",
      "Batch: 107, Loss: 1.2159650325775146, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.2037020921707153, Accuracy: 0.60546875\n",
      "Batch: 109, Loss: 1.2127013206481934, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 1.1945806741714478, Accuracy: 0.60546875\n",
      "Batch: 111, Loss: 1.1287740468978882, Accuracy: 0.6484375\n",
      "Batch: 112, Loss: 1.1054751873016357, Accuracy: 0.6337890625\n",
      "Batch: 113, Loss: 1.1150556802749634, Accuracy: 0.634765625\n",
      "Batch: 114, Loss: 1.1649644374847412, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.2374612092971802, Accuracy: 0.59765625\n",
      "Batch: 116, Loss: 1.1960362195968628, Accuracy: 0.6064453125\n",
      "Batch: 117, Loss: 1.1672369241714478, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.229567050933838, Accuracy: 0.5908203125\n",
      "Batch: 119, Loss: 1.2432780265808105, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.2692456245422363, Accuracy: 0.6044921875\n",
      "Batch: 121, Loss: 1.2406766414642334, Accuracy: 0.59765625\n",
      "Batch: 122, Loss: 1.1610636711120605, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1666914224624634, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.1992446184158325, Accuracy: 0.6298828125\n",
      "Batch: 125, Loss: 1.2249672412872314, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.2055723667144775, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.2923814058303833, Accuracy: 0.5712890625\n",
      "Batch: 128, Loss: 1.235408902168274, Accuracy: 0.5830078125\n",
      "Batch: 129, Loss: 1.1705621480941772, Accuracy: 0.626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 1.1003669500350952, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.2061339616775513, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.0712428092956543, Accuracy: 0.6630859375\n",
      "Batch: 133, Loss: 1.1337287425994873, Accuracy: 0.6259765625\n",
      "Batch: 134, Loss: 1.1588683128356934, Accuracy: 0.6376953125\n",
      "Batch: 135, Loss: 1.059345006942749, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.1143088340759277, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.1454894542694092, Accuracy: 0.6328125\n",
      "Batch: 138, Loss: 1.314441204071045, Accuracy: 0.572265625\n",
      "Batch: 139, Loss: 1.1867661476135254, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.2477437257766724, Accuracy: 0.6181640625\n",
      "Batch: 141, Loss: 1.1599901914596558, Accuracy: 0.6142578125\n",
      "Batch: 142, Loss: 1.179976463317871, Accuracy: 0.6025390625\n",
      "Batch: 143, Loss: 1.225142002105713, Accuracy: 0.6005859375\n",
      "Batch: 144, Loss: 1.2652300596237183, Accuracy: 0.5830078125\n",
      "Batch: 145, Loss: 1.293109655380249, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.185117483139038, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.2024133205413818, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.2439448833465576, Accuracy: 0.58984375\n",
      "Batch: 149, Loss: 1.1643403768539429, Accuracy: 0.5869140625\n",
      "Batch: 150, Loss: 1.1667203903198242, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.1447930335998535, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.1848771572113037, Accuracy: 0.609375\n",
      "Batch: 153, Loss: 1.1304385662078857, Accuracy: 0.64453125\n",
      "Batch: 154, Loss: 1.1141865253448486, Accuracy: 0.638671875\n",
      "Batch: 155, Loss: 1.0980675220489502, Accuracy: 0.64453125\n",
      "Epoch 483/200\n",
      "Batch: 1, Loss: 1.203831434249878, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.0886321067810059, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 1.0723986625671387, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.1033896207809448, Accuracy: 0.623046875\n",
      "Batch: 5, Loss: 1.062511920928955, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.0613828897476196, Accuracy: 0.6611328125\n",
      "Batch: 7, Loss: 1.0420573949813843, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 1.0583351850509644, Accuracy: 0.6455078125\n",
      "Batch: 9, Loss: 1.0064579248428345, Accuracy: 0.6796875\n",
      "Batch: 10, Loss: 0.9595588445663452, Accuracy: 0.6923828125\n",
      "Batch: 11, Loss: 1.0128928422927856, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 1.0015677213668823, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 1.0321300029754639, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 1.0086569786071777, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.9815782308578491, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0132765769958496, Accuracy: 0.69140625\n",
      "Batch: 17, Loss: 1.0036894083023071, Accuracy: 0.6728515625\n",
      "Batch: 18, Loss: 1.1285480260849, Accuracy: 0.607421875\n",
      "Batch: 19, Loss: 1.2387075424194336, Accuracy: 0.609375\n",
      "Batch: 20, Loss: 1.098546028137207, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.099526047706604, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.2065343856811523, Accuracy: 0.6181640625\n",
      "Batch: 23, Loss: 1.2438987493515015, Accuracy: 0.5791015625\n",
      "Batch: 24, Loss: 1.1309070587158203, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.1367216110229492, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.1839019060134888, Accuracy: 0.6005859375\n",
      "Batch: 27, Loss: 1.11171293258667, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.099058985710144, Accuracy: 0.63671875\n",
      "Batch: 29, Loss: 1.1035542488098145, Accuracy: 0.62890625\n",
      "Batch: 30, Loss: 1.18446683883667, Accuracy: 0.6015625\n",
      "Batch: 31, Loss: 1.1630992889404297, Accuracy: 0.6171875\n",
      "Batch: 32, Loss: 1.061124563217163, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.014288306236267, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.142453908920288, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.1424860954284668, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.2016390562057495, Accuracy: 0.591796875\n",
      "Batch: 37, Loss: 1.2779237031936646, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.1850619316101074, Accuracy: 0.6005859375\n",
      "Batch: 39, Loss: 1.118341088294983, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.1248066425323486, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.1165494918823242, Accuracy: 0.6357421875\n",
      "Batch: 42, Loss: 1.0310959815979004, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.0984246730804443, Accuracy: 0.6201171875\n",
      "Batch: 44, Loss: 1.0438063144683838, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.029677152633667, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.1565243005752563, Accuracy: 0.6142578125\n",
      "Batch: 47, Loss: 1.1322760581970215, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.1244091987609863, Accuracy: 0.61328125\n",
      "Batch: 49, Loss: 1.1625804901123047, Accuracy: 0.609375\n",
      "Batch: 50, Loss: 1.1228229999542236, Accuracy: 0.6455078125\n",
      "Batch: 51, Loss: 1.138375163078308, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.2400429248809814, Accuracy: 0.603515625\n",
      "Batch: 53, Loss: 1.2138729095458984, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.2233768701553345, Accuracy: 0.6015625\n",
      "Batch: 55, Loss: 1.1596473455429077, Accuracy: 0.6201171875\n",
      "Batch: 56, Loss: 1.1318259239196777, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.072824478149414, Accuracy: 0.658203125\n",
      "Batch: 58, Loss: 1.1449869871139526, Accuracy: 0.6162109375\n",
      "Batch: 59, Loss: 1.121851921081543, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2001160383224487, Accuracy: 0.595703125\n",
      "Batch: 61, Loss: 1.1872191429138184, Accuracy: 0.6201171875\n",
      "Batch: 62, Loss: 1.1331565380096436, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1928975582122803, Accuracy: 0.599609375\n",
      "Batch: 64, Loss: 1.2539938688278198, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.2351596355438232, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.2051494121551514, Accuracy: 0.6015625\n",
      "Batch: 67, Loss: 1.1351521015167236, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.141265630722046, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.2114061117172241, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.1081945896148682, Accuracy: 0.6357421875\n",
      "Batch: 71, Loss: 1.1124106645584106, Accuracy: 0.6357421875\n",
      "Batch: 72, Loss: 1.2348554134368896, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.1841013431549072, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.1342389583587646, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.112912654876709, Accuracy: 0.6337890625\n",
      "Batch: 76, Loss: 1.108402967453003, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.061615228652954, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.0735077857971191, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.1402809619903564, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1743199825286865, Accuracy: 0.61328125\n",
      "Batch: 81, Loss: 1.1256670951843262, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.132932424545288, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.2251734733581543, Accuracy: 0.6015625\n",
      "Batch: 84, Loss: 1.1576021909713745, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.1688131093978882, Accuracy: 0.607421875\n",
      "Batch: 86, Loss: 1.1875526905059814, Accuracy: 0.609375\n",
      "Batch: 87, Loss: 1.1818475723266602, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.1840753555297852, Accuracy: 0.62890625\n",
      "Batch: 89, Loss: 1.159475564956665, Accuracy: 0.61328125\n",
      "Batch: 90, Loss: 1.1543185710906982, Accuracy: 0.63671875\n",
      "Batch: 91, Loss: 1.1208593845367432, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1483200788497925, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.1499128341674805, Accuracy: 0.62109375\n",
      "Batch: 94, Loss: 1.2135589122772217, Accuracy: 0.6201171875\n",
      "Batch: 95, Loss: 1.1620945930480957, Accuracy: 0.62890625\n",
      "Batch: 96, Loss: 1.2546255588531494, Accuracy: 0.62890625\n",
      "Batch: 97, Loss: 1.1293104887008667, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.0832240581512451, Accuracy: 0.6435546875\n",
      "Batch: 99, Loss: 1.1048433780670166, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.0907652378082275, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.066150426864624, Accuracy: 0.666015625\n",
      "Batch: 102, Loss: 1.1909892559051514, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.1878397464752197, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.126568078994751, Accuracy: 0.6337890625\n",
      "Batch: 105, Loss: 1.2544269561767578, Accuracy: 0.6015625\n",
      "Batch: 106, Loss: 1.1798326969146729, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.2285845279693604, Accuracy: 0.6064453125\n",
      "Batch: 108, Loss: 1.1500179767608643, Accuracy: 0.6328125\n",
      "Batch: 109, Loss: 1.2009365558624268, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.1556477546691895, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.1734915971755981, Accuracy: 0.6435546875\n",
      "Batch: 112, Loss: 1.1054836511611938, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.1681911945343018, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.219951868057251, Accuracy: 0.6015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 115, Loss: 1.1886284351348877, Accuracy: 0.607421875\n",
      "Batch: 116, Loss: 1.1951886415481567, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1790310144424438, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 1.2403149604797363, Accuracy: 0.5830078125\n",
      "Batch: 119, Loss: 1.217220425605774, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.2746949195861816, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.2660170793533325, Accuracy: 0.595703125\n",
      "Batch: 122, Loss: 1.2486424446105957, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.1484475135803223, Accuracy: 0.6435546875\n",
      "Batch: 124, Loss: 1.254676342010498, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.1268634796142578, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.1915295124053955, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.2344167232513428, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2920669317245483, Accuracy: 0.5810546875\n",
      "Batch: 129, Loss: 1.1734766960144043, Accuracy: 0.6337890625\n",
      "Batch: 130, Loss: 1.1531709432601929, Accuracy: 0.63671875\n",
      "Batch: 131, Loss: 1.2275822162628174, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.0900533199310303, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.208693265914917, Accuracy: 0.615234375\n",
      "Batch: 134, Loss: 1.1030540466308594, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 1.032411813735962, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.137749433517456, Accuracy: 0.634765625\n",
      "Batch: 137, Loss: 1.183020830154419, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 1.219500184059143, Accuracy: 0.6181640625\n",
      "Batch: 139, Loss: 1.1702673435211182, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.2625988721847534, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.195715308189392, Accuracy: 0.61328125\n",
      "Batch: 142, Loss: 1.1456785202026367, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.191631555557251, Accuracy: 0.6044921875\n",
      "Batch: 144, Loss: 1.2490476369857788, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.2156989574432373, Accuracy: 0.615234375\n",
      "Batch: 146, Loss: 1.170466661453247, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.237932801246643, Accuracy: 0.609375\n",
      "Batch: 148, Loss: 1.2111287117004395, Accuracy: 0.5986328125\n",
      "Batch: 149, Loss: 1.1589704751968384, Accuracy: 0.6298828125\n",
      "Batch: 150, Loss: 1.1813956499099731, Accuracy: 0.609375\n",
      "Batch: 151, Loss: 1.2090590000152588, Accuracy: 0.6103515625\n",
      "Batch: 152, Loss: 1.1596496105194092, Accuracy: 0.6220703125\n",
      "Batch: 153, Loss: 1.1890692710876465, Accuracy: 0.6123046875\n",
      "Batch: 154, Loss: 1.1597702503204346, Accuracy: 0.611328125\n",
      "Batch: 155, Loss: 1.1298906803131104, Accuracy: 0.642578125\n",
      "Epoch 484/200\n",
      "Batch: 1, Loss: 1.230780005455017, Accuracy: 0.650390625\n",
      "Batch: 2, Loss: 1.1287363767623901, Accuracy: 0.6240234375\n",
      "Batch: 3, Loss: 1.0439270734786987, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 1.0747549533843994, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.0408650636672974, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.0180864334106445, Accuracy: 0.6650390625\n",
      "Batch: 7, Loss: 1.0742895603179932, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9926403760910034, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 1.0084609985351562, Accuracy: 0.6689453125\n",
      "Batch: 10, Loss: 0.9670323133468628, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 0.9631381630897522, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 1.0186940431594849, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.0858521461486816, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 0.9793506860733032, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.9457666873931885, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.0079354047775269, Accuracy: 0.6689453125\n",
      "Batch: 17, Loss: 1.0524779558181763, Accuracy: 0.6728515625\n",
      "Batch: 18, Loss: 1.132543683052063, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2311272621154785, Accuracy: 0.6181640625\n",
      "Batch: 20, Loss: 1.1230998039245605, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.092538595199585, Accuracy: 0.65234375\n",
      "Batch: 22, Loss: 1.2923128604888916, Accuracy: 0.5849609375\n",
      "Batch: 23, Loss: 1.2486308813095093, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.1520441770553589, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.1845898628234863, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.1909122467041016, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.1025786399841309, Accuracy: 0.6435546875\n",
      "Batch: 28, Loss: 1.1205291748046875, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.100022315979004, Accuracy: 0.642578125\n",
      "Batch: 30, Loss: 1.1540554761886597, Accuracy: 0.6162109375\n",
      "Batch: 31, Loss: 1.2386330366134644, Accuracy: 0.611328125\n",
      "Batch: 32, Loss: 1.0555665493011475, Accuracy: 0.658203125\n",
      "Batch: 33, Loss: 0.968288779258728, Accuracy: 0.677734375\n",
      "Batch: 34, Loss: 1.0572428703308105, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.0813500881195068, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.177121877670288, Accuracy: 0.623046875\n",
      "Batch: 37, Loss: 1.1876540184020996, Accuracy: 0.6103515625\n",
      "Batch: 38, Loss: 1.1413843631744385, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.114797592163086, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0778721570968628, Accuracy: 0.6201171875\n",
      "Batch: 41, Loss: 1.1350898742675781, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.065571665763855, Accuracy: 0.6416015625\n",
      "Batch: 43, Loss: 1.0472180843353271, Accuracy: 0.658203125\n",
      "Batch: 44, Loss: 1.0867340564727783, Accuracy: 0.6318359375\n",
      "Batch: 45, Loss: 1.0657076835632324, Accuracy: 0.6416015625\n",
      "Batch: 46, Loss: 1.1730618476867676, Accuracy: 0.6337890625\n",
      "Batch: 47, Loss: 1.1437504291534424, Accuracy: 0.6298828125\n",
      "Batch: 48, Loss: 1.1486504077911377, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.2070188522338867, Accuracy: 0.619140625\n",
      "Batch: 50, Loss: 1.1139838695526123, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.126432180404663, Accuracy: 0.6064453125\n",
      "Batch: 52, Loss: 1.2143902778625488, Accuracy: 0.6025390625\n",
      "Batch: 53, Loss: 1.1727817058563232, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.1824381351470947, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.1074607372283936, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.0590898990631104, Accuracy: 0.6630859375\n",
      "Batch: 57, Loss: 1.1333308219909668, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.1295926570892334, Accuracy: 0.6455078125\n",
      "Batch: 59, Loss: 1.1014244556427002, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.1918647289276123, Accuracy: 0.60546875\n",
      "Batch: 61, Loss: 1.1469664573669434, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.1752758026123047, Accuracy: 0.611328125\n",
      "Batch: 63, Loss: 1.2274270057678223, Accuracy: 0.60546875\n",
      "Batch: 64, Loss: 1.1944382190704346, Accuracy: 0.6142578125\n",
      "Batch: 65, Loss: 1.188795566558838, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.1827185153961182, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.1745057106018066, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0946037769317627, Accuracy: 0.62890625\n",
      "Batch: 69, Loss: 1.200616717338562, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.106073260307312, Accuracy: 0.638671875\n",
      "Batch: 71, Loss: 1.1655774116516113, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.1752281188964844, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.1980277299880981, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.1442548036575317, Accuracy: 0.626953125\n",
      "Batch: 75, Loss: 1.1555228233337402, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.081268310546875, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 1.032828688621521, Accuracy: 0.66796875\n",
      "Batch: 78, Loss: 1.064180850982666, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.137551188468933, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.1462790966033936, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.1248841285705566, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 1.099001169204712, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.2044202089309692, Accuracy: 0.6240234375\n",
      "Batch: 84, Loss: 1.1324995756149292, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.232452392578125, Accuracy: 0.6044921875\n",
      "Batch: 86, Loss: 1.153880000114441, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.1624853610992432, Accuracy: 0.6220703125\n",
      "Batch: 88, Loss: 1.1086686849594116, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.1862096786499023, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.1103501319885254, Accuracy: 0.6357421875\n",
      "Batch: 91, Loss: 1.1921981573104858, Accuracy: 0.6005859375\n",
      "Batch: 92, Loss: 1.109320878982544, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.1037557125091553, Accuracy: 0.642578125\n",
      "Batch: 94, Loss: 1.1990532875061035, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1807119846343994, Accuracy: 0.6171875\n",
      "Batch: 96, Loss: 1.1754906177520752, Accuracy: 0.646484375\n",
      "Batch: 97, Loss: 1.1610877513885498, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.116688847541809, Accuracy: 0.6435546875\n",
      "Batch: 99, Loss: 1.1650590896606445, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 1.027388572692871, Accuracy: 0.671875\n",
      "Batch: 101, Loss: 1.0896589756011963, Accuracy: 0.642578125\n",
      "Batch: 102, Loss: 1.1942994594573975, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.1668869256973267, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1858768463134766, Accuracy: 0.6171875\n",
      "Batch: 105, Loss: 1.2364773750305176, Accuracy: 0.6044921875\n",
      "Batch: 106, Loss: 1.1453406810760498, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2734386920928955, Accuracy: 0.5771484375\n",
      "Batch: 108, Loss: 1.1316888332366943, Accuracy: 0.6201171875\n",
      "Batch: 109, Loss: 1.1649630069732666, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 1.1339149475097656, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1658546924591064, Accuracy: 0.619140625\n",
      "Batch: 112, Loss: 1.0737254619598389, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.1388670206069946, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.165924072265625, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.1962369680404663, Accuracy: 0.62109375\n",
      "Batch: 116, Loss: 1.1997809410095215, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.183213472366333, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.2242271900177002, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.2543344497680664, Accuracy: 0.5908203125\n",
      "Batch: 120, Loss: 1.309705376625061, Accuracy: 0.5791015625\n",
      "Batch: 121, Loss: 1.1681159734725952, Accuracy: 0.62890625\n",
      "Batch: 122, Loss: 1.1686465740203857, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.1668392419815063, Accuracy: 0.6044921875\n",
      "Batch: 124, Loss: 1.1739717721939087, Accuracy: 0.642578125\n",
      "Batch: 125, Loss: 1.158246397972107, Accuracy: 0.6416015625\n",
      "Batch: 126, Loss: 1.2822859287261963, Accuracy: 0.5888671875\n",
      "Batch: 127, Loss: 1.265135407447815, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.187178611755371, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.1412652730941772, Accuracy: 0.6376953125\n",
      "Batch: 130, Loss: 1.1685757637023926, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.222369909286499, Accuracy: 0.611328125\n",
      "Batch: 132, Loss: 1.1100428104400635, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.2014600038528442, Accuracy: 0.6123046875\n",
      "Batch: 134, Loss: 1.0978598594665527, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.01873779296875, Accuracy: 0.66796875\n",
      "Batch: 136, Loss: 1.0803967714309692, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.221142292022705, Accuracy: 0.60546875\n",
      "Batch: 138, Loss: 1.2226096391677856, Accuracy: 0.5771484375\n",
      "Batch: 139, Loss: 1.1526830196380615, Accuracy: 0.6220703125\n",
      "Batch: 140, Loss: 1.2160754203796387, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.1445534229278564, Accuracy: 0.6240234375\n",
      "Batch: 142, Loss: 1.1829301118850708, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.2376511096954346, Accuracy: 0.6083984375\n",
      "Batch: 144, Loss: 1.2258327007293701, Accuracy: 0.580078125\n",
      "Batch: 145, Loss: 1.2320929765701294, Accuracy: 0.615234375\n",
      "Batch: 146, Loss: 1.2127090692520142, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.1875108480453491, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.2296442985534668, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.196582555770874, Accuracy: 0.6015625\n",
      "Batch: 150, Loss: 1.1555664539337158, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.1910663843154907, Accuracy: 0.62109375\n",
      "Batch: 152, Loss: 1.2135218381881714, Accuracy: 0.6025390625\n",
      "Batch: 153, Loss: 1.1428792476654053, Accuracy: 0.62890625\n",
      "Batch: 154, Loss: 1.130811095237732, Accuracy: 0.6318359375\n",
      "Batch: 155, Loss: 1.0766133069992065, Accuracy: 0.6474609375\n",
      "Epoch 485/200\n",
      "Batch: 1, Loss: 1.2527239322662354, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.0323145389556885, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0587568283081055, Accuracy: 0.6591796875\n",
      "Batch: 4, Loss: 1.1403703689575195, Accuracy: 0.63671875\n",
      "Batch: 5, Loss: 1.0124366283416748, Accuracy: 0.662109375\n",
      "Batch: 6, Loss: 1.0603055953979492, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 1.0072381496429443, Accuracy: 0.6708984375\n",
      "Batch: 8, Loss: 0.9944089651107788, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 1.0126690864562988, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 0.9167934060096741, Accuracy: 0.6962890625\n",
      "Batch: 11, Loss: 0.955075740814209, Accuracy: 0.6796875\n",
      "Batch: 12, Loss: 1.0174320936203003, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 1.036266803741455, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 1.0040161609649658, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.9848282337188721, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0182693004608154, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.042757272720337, Accuracy: 0.658203125\n",
      "Batch: 18, Loss: 1.123176097869873, Accuracy: 0.6279296875\n",
      "Batch: 19, Loss: 1.217942237854004, Accuracy: 0.615234375\n",
      "Batch: 20, Loss: 1.0777904987335205, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.0571479797363281, Accuracy: 0.6806640625\n",
      "Batch: 22, Loss: 1.2526886463165283, Accuracy: 0.6005859375\n",
      "Batch: 23, Loss: 1.2023481130599976, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.0774403810501099, Accuracy: 0.6669921875\n",
      "Batch: 25, Loss: 1.1730709075927734, Accuracy: 0.6171875\n",
      "Batch: 26, Loss: 1.2091412544250488, Accuracy: 0.6025390625\n",
      "Batch: 27, Loss: 1.1369439363479614, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.119438648223877, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.090896725654602, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.145202398300171, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.2363359928131104, Accuracy: 0.5986328125\n",
      "Batch: 32, Loss: 1.0544075965881348, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 0.996096134185791, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.1086230278015137, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.1079195737838745, Accuracy: 0.6123046875\n",
      "Batch: 36, Loss: 1.24857497215271, Accuracy: 0.5888671875\n",
      "Batch: 37, Loss: 1.222658634185791, Accuracy: 0.6005859375\n",
      "Batch: 38, Loss: 1.2069627046585083, Accuracy: 0.58984375\n",
      "Batch: 39, Loss: 1.043311595916748, Accuracy: 0.67578125\n",
      "Batch: 40, Loss: 1.1077234745025635, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.1120318174362183, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.1136500835418701, Accuracy: 0.6220703125\n",
      "Batch: 43, Loss: 1.0692747831344604, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0410072803497314, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 1.0408819913864136, Accuracy: 0.65625\n",
      "Batch: 46, Loss: 1.1535645723342896, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.1272027492523193, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.1549749374389648, Accuracy: 0.626953125\n",
      "Batch: 49, Loss: 1.144993782043457, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.1481842994689941, Accuracy: 0.6279296875\n",
      "Batch: 51, Loss: 1.112752914428711, Accuracy: 0.6259765625\n",
      "Batch: 52, Loss: 1.223012924194336, Accuracy: 0.609375\n",
      "Batch: 53, Loss: 1.163755178451538, Accuracy: 0.6181640625\n",
      "Batch: 54, Loss: 1.182847261428833, Accuracy: 0.60546875\n",
      "Batch: 55, Loss: 1.1017873287200928, Accuracy: 0.650390625\n",
      "Batch: 56, Loss: 1.1200168132781982, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.1237730979919434, Accuracy: 0.64453125\n",
      "Batch: 58, Loss: 1.1553664207458496, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.0743095874786377, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.2217767238616943, Accuracy: 0.6201171875\n",
      "Batch: 61, Loss: 1.1976444721221924, Accuracy: 0.5859375\n",
      "Batch: 62, Loss: 1.1837763786315918, Accuracy: 0.611328125\n",
      "Batch: 63, Loss: 1.232696294784546, Accuracy: 0.5869140625\n",
      "Batch: 64, Loss: 1.206998348236084, Accuracy: 0.6064453125\n",
      "Batch: 65, Loss: 1.1391549110412598, Accuracy: 0.642578125\n",
      "Batch: 66, Loss: 1.123895287513733, Accuracy: 0.6416015625\n",
      "Batch: 67, Loss: 1.1567776203155518, Accuracy: 0.611328125\n",
      "Batch: 68, Loss: 1.1610305309295654, Accuracy: 0.623046875\n",
      "Batch: 69, Loss: 1.1927752494812012, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1725714206695557, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.1744384765625, Accuracy: 0.609375\n",
      "Batch: 72, Loss: 1.2044398784637451, Accuracy: 0.6328125\n",
      "Batch: 73, Loss: 1.198843002319336, Accuracy: 0.615234375\n",
      "Batch: 74, Loss: 1.1119928359985352, Accuracy: 0.611328125\n",
      "Batch: 75, Loss: 1.095080852508545, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.0924427509307861, Accuracy: 0.640625\n",
      "Batch: 77, Loss: 1.0916000604629517, Accuracy: 0.64453125\n",
      "Batch: 78, Loss: 1.0573490858078003, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.1178762912750244, Accuracy: 0.6396484375\n",
      "Batch: 80, Loss: 1.1808888912200928, Accuracy: 0.6064453125\n",
      "Batch: 81, Loss: 1.1562139987945557, Accuracy: 0.6171875\n",
      "Batch: 82, Loss: 1.1925984621047974, Accuracy: 0.6083984375\n",
      "Batch: 83, Loss: 1.2400343418121338, Accuracy: 0.6005859375\n",
      "Batch: 84, Loss: 1.1123273372650146, Accuracy: 0.638671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 1.1851403713226318, Accuracy: 0.603515625\n",
      "Batch: 86, Loss: 1.2566049098968506, Accuracy: 0.583984375\n",
      "Batch: 87, Loss: 1.2643071413040161, Accuracy: 0.6103515625\n",
      "Batch: 88, Loss: 1.1620410680770874, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1553971767425537, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.1197729110717773, Accuracy: 0.640625\n",
      "Batch: 91, Loss: 1.1878809928894043, Accuracy: 0.5966796875\n",
      "Batch: 92, Loss: 1.1462446451187134, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.1032418012619019, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.169316053390503, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.203389286994934, Accuracy: 0.62109375\n",
      "Batch: 96, Loss: 1.2491638660430908, Accuracy: 0.6123046875\n",
      "Batch: 97, Loss: 1.2315795421600342, Accuracy: 0.6005859375\n",
      "Batch: 98, Loss: 1.1168122291564941, Accuracy: 0.6474609375\n",
      "Batch: 99, Loss: 1.106764316558838, Accuracy: 0.6435546875\n",
      "Batch: 100, Loss: 1.0660357475280762, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.0832083225250244, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.1846596002578735, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.1258774995803833, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.1298174858093262, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.196347951889038, Accuracy: 0.6201171875\n",
      "Batch: 106, Loss: 1.2549564838409424, Accuracy: 0.595703125\n",
      "Batch: 107, Loss: 1.2542909383773804, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.2191903591156006, Accuracy: 0.603515625\n",
      "Batch: 109, Loss: 1.1965612173080444, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1552343368530273, Accuracy: 0.62109375\n",
      "Batch: 111, Loss: 1.0966577529907227, Accuracy: 0.658203125\n",
      "Batch: 112, Loss: 1.1127923727035522, Accuracy: 0.6318359375\n",
      "Batch: 113, Loss: 1.2249433994293213, Accuracy: 0.599609375\n",
      "Batch: 114, Loss: 1.1732144355773926, Accuracy: 0.595703125\n",
      "Batch: 115, Loss: 1.1862297058105469, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.175705075263977, Accuracy: 0.5888671875\n",
      "Batch: 117, Loss: 1.170384407043457, Accuracy: 0.6171875\n",
      "Batch: 118, Loss: 1.2549442052841187, Accuracy: 0.5859375\n",
      "Batch: 119, Loss: 1.1964495182037354, Accuracy: 0.6279296875\n",
      "Batch: 120, Loss: 1.3055305480957031, Accuracy: 0.607421875\n",
      "Batch: 121, Loss: 1.2427271604537964, Accuracy: 0.60546875\n",
      "Batch: 122, Loss: 1.2027359008789062, Accuracy: 0.615234375\n",
      "Batch: 123, Loss: 1.1673436164855957, Accuracy: 0.6201171875\n",
      "Batch: 124, Loss: 1.2193907499313354, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.2131264209747314, Accuracy: 0.6142578125\n",
      "Batch: 126, Loss: 1.220369577407837, Accuracy: 0.6162109375\n",
      "Batch: 127, Loss: 1.29941725730896, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.1899869441986084, Accuracy: 0.619140625\n",
      "Batch: 129, Loss: 1.172607421875, Accuracy: 0.626953125\n",
      "Batch: 130, Loss: 1.1257646083831787, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.2041229009628296, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.1048424243927002, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.1256756782531738, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1162467002868652, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 1.0356976985931396, Accuracy: 0.685546875\n",
      "Batch: 136, Loss: 1.098456859588623, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.1870460510253906, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.2558457851409912, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.2418396472930908, Accuracy: 0.607421875\n",
      "Batch: 140, Loss: 1.2360844612121582, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.16146719455719, Accuracy: 0.625\n",
      "Batch: 142, Loss: 1.17379629611969, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2407900094985962, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.2369768619537354, Accuracy: 0.5986328125\n",
      "Batch: 145, Loss: 1.2966833114624023, Accuracy: 0.5859375\n",
      "Batch: 146, Loss: 1.1973192691802979, Accuracy: 0.6064453125\n",
      "Batch: 147, Loss: 1.2186951637268066, Accuracy: 0.5859375\n",
      "Batch: 148, Loss: 1.277701497077942, Accuracy: 0.6044921875\n",
      "Batch: 149, Loss: 1.2589728832244873, Accuracy: 0.591796875\n",
      "Batch: 150, Loss: 1.14031183719635, Accuracy: 0.615234375\n",
      "Batch: 151, Loss: 1.1419999599456787, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.1437207460403442, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.1469027996063232, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.1175131797790527, Accuracy: 0.646484375\n",
      "Batch: 155, Loss: 1.0935732126235962, Accuracy: 0.6640625\n",
      "Epoch 486/200\n",
      "Batch: 1, Loss: 1.1942105293273926, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.133929967880249, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 1.0570878982543945, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 1.067521333694458, Accuracy: 0.6298828125\n",
      "Batch: 5, Loss: 1.0596752166748047, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.1148383617401123, Accuracy: 0.6318359375\n",
      "Batch: 7, Loss: 1.033469796180725, Accuracy: 0.6640625\n",
      "Batch: 8, Loss: 0.9979391098022461, Accuracy: 0.6865234375\n",
      "Batch: 9, Loss: 1.0342228412628174, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 1.0011241436004639, Accuracy: 0.6708984375\n",
      "Batch: 11, Loss: 1.0139024257659912, Accuracy: 0.666015625\n",
      "Batch: 12, Loss: 1.0201103687286377, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 1.0088601112365723, Accuracy: 0.6650390625\n",
      "Batch: 14, Loss: 1.0538524389266968, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 0.9709235429763794, Accuracy: 0.6845703125\n",
      "Batch: 16, Loss: 1.0311890840530396, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.0797961950302124, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.1494524478912354, Accuracy: 0.62890625\n",
      "Batch: 19, Loss: 1.204185962677002, Accuracy: 0.6083984375\n",
      "Batch: 20, Loss: 1.1181917190551758, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.0986194610595703, Accuracy: 0.6484375\n",
      "Batch: 22, Loss: 1.268147587776184, Accuracy: 0.578125\n",
      "Batch: 23, Loss: 1.186328411102295, Accuracy: 0.623046875\n",
      "Batch: 24, Loss: 1.1166815757751465, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.1331920623779297, Accuracy: 0.638671875\n",
      "Batch: 26, Loss: 1.182521104812622, Accuracy: 0.611328125\n",
      "Batch: 27, Loss: 1.1899158954620361, Accuracy: 0.6103515625\n",
      "Batch: 28, Loss: 1.0541784763336182, Accuracy: 0.66015625\n",
      "Batch: 29, Loss: 1.0827834606170654, Accuracy: 0.6484375\n",
      "Batch: 30, Loss: 1.1691455841064453, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.1817545890808105, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 1.04597806930542, Accuracy: 0.6494140625\n",
      "Batch: 33, Loss: 1.0055263042449951, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0666062831878662, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 1.1632462739944458, Accuracy: 0.615234375\n",
      "Batch: 36, Loss: 1.1643661260604858, Accuracy: 0.6240234375\n",
      "Batch: 37, Loss: 1.2494158744812012, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.0951366424560547, Accuracy: 0.642578125\n",
      "Batch: 39, Loss: 1.1144068241119385, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.0837725400924683, Accuracy: 0.6416015625\n",
      "Batch: 41, Loss: 1.1269469261169434, Accuracy: 0.62109375\n",
      "Batch: 42, Loss: 1.1050283908843994, Accuracy: 0.6337890625\n",
      "Batch: 43, Loss: 1.044448971748352, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0960432291030884, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 1.0972095727920532, Accuracy: 0.630859375\n",
      "Batch: 46, Loss: 1.1647422313690186, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1061792373657227, Accuracy: 0.6396484375\n",
      "Batch: 48, Loss: 1.1428840160369873, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.2141518592834473, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.1177210807800293, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.1459496021270752, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.2313361167907715, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.2357782125473022, Accuracy: 0.5859375\n",
      "Batch: 54, Loss: 1.135979175567627, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.1210013628005981, Accuracy: 0.62890625\n",
      "Batch: 56, Loss: 1.0968284606933594, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.1196861267089844, Accuracy: 0.634765625\n",
      "Batch: 58, Loss: 1.0880247354507446, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.1219125986099243, Accuracy: 0.623046875\n",
      "Batch: 60, Loss: 1.2328497171401978, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.178425669670105, Accuracy: 0.591796875\n",
      "Batch: 62, Loss: 1.168651819229126, Accuracy: 0.6181640625\n",
      "Batch: 63, Loss: 1.134437918663025, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.259843349456787, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.1838041543960571, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.1629514694213867, Accuracy: 0.615234375\n",
      "Batch: 67, Loss: 1.1426358222961426, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0886080265045166, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.2172366380691528, Accuracy: 0.611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.213491439819336, Accuracy: 0.6103515625\n",
      "Batch: 71, Loss: 1.1017398834228516, Accuracy: 0.626953125\n",
      "Batch: 72, Loss: 1.2124309539794922, Accuracy: 0.6005859375\n",
      "Batch: 73, Loss: 1.2351069450378418, Accuracy: 0.609375\n",
      "Batch: 74, Loss: 1.120354413986206, Accuracy: 0.6435546875\n",
      "Batch: 75, Loss: 1.165239930152893, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0935531854629517, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0889666080474854, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.0845203399658203, Accuracy: 0.646484375\n",
      "Batch: 79, Loss: 1.1420321464538574, Accuracy: 0.6357421875\n",
      "Batch: 80, Loss: 1.163952112197876, Accuracy: 0.634765625\n",
      "Batch: 81, Loss: 1.1592941284179688, Accuracy: 0.6259765625\n",
      "Batch: 82, Loss: 1.120168685913086, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.223705768585205, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1702136993408203, Accuracy: 0.626953125\n",
      "Batch: 85, Loss: 1.1740995645523071, Accuracy: 0.6279296875\n",
      "Batch: 86, Loss: 1.1148196458816528, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 1.1625819206237793, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.1635546684265137, Accuracy: 0.619140625\n",
      "Batch: 89, Loss: 1.1482982635498047, Accuracy: 0.646484375\n",
      "Batch: 90, Loss: 1.1092616319656372, Accuracy: 0.63671875\n",
      "Batch: 91, Loss: 1.1817758083343506, Accuracy: 0.6142578125\n",
      "Batch: 92, Loss: 1.1085532903671265, Accuracy: 0.6455078125\n",
      "Batch: 93, Loss: 1.128959059715271, Accuracy: 0.6298828125\n",
      "Batch: 94, Loss: 1.209089756011963, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.1831666231155396, Accuracy: 0.6123046875\n",
      "Batch: 96, Loss: 1.214341163635254, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.1445976495742798, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.1478056907653809, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.138980507850647, Accuracy: 0.63671875\n",
      "Batch: 100, Loss: 1.0600481033325195, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0624065399169922, Accuracy: 0.6708984375\n",
      "Batch: 102, Loss: 1.200545310974121, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.1585099697113037, Accuracy: 0.6357421875\n",
      "Batch: 104, Loss: 1.1639862060546875, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.2167184352874756, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.212784767150879, Accuracy: 0.5986328125\n",
      "Batch: 107, Loss: 1.3031227588653564, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.1662395000457764, Accuracy: 0.623046875\n",
      "Batch: 109, Loss: 1.2132065296173096, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 1.1136019229888916, Accuracy: 0.638671875\n",
      "Batch: 111, Loss: 1.136098861694336, Accuracy: 0.630859375\n",
      "Batch: 112, Loss: 1.0924718379974365, Accuracy: 0.6318359375\n",
      "Batch: 113, Loss: 1.1473870277404785, Accuracy: 0.634765625\n",
      "Batch: 114, Loss: 1.1738133430480957, Accuracy: 0.6103515625\n",
      "Batch: 115, Loss: 1.1878833770751953, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.1824792623519897, Accuracy: 0.6318359375\n",
      "Batch: 117, Loss: 1.176131248474121, Accuracy: 0.609375\n",
      "Batch: 118, Loss: 1.2107503414154053, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.2439227104187012, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.241603136062622, Accuracy: 0.6123046875\n",
      "Batch: 121, Loss: 1.22348952293396, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.220971941947937, Accuracy: 0.6083984375\n",
      "Batch: 123, Loss: 1.185934066772461, Accuracy: 0.611328125\n",
      "Batch: 124, Loss: 1.2548319101333618, Accuracy: 0.5859375\n",
      "Batch: 125, Loss: 1.1853747367858887, Accuracy: 0.619140625\n",
      "Batch: 126, Loss: 1.228971004486084, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.2294728755950928, Accuracy: 0.5947265625\n",
      "Batch: 128, Loss: 1.2225556373596191, Accuracy: 0.591796875\n",
      "Batch: 129, Loss: 1.2098851203918457, Accuracy: 0.607421875\n",
      "Batch: 130, Loss: 1.1382184028625488, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.1620166301727295, Accuracy: 0.6220703125\n",
      "Batch: 132, Loss: 1.1582777500152588, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.1653470993041992, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.1215753555297852, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 1.0661170482635498, Accuracy: 0.6650390625\n",
      "Batch: 136, Loss: 1.0752108097076416, Accuracy: 0.6630859375\n",
      "Batch: 137, Loss: 1.132619857788086, Accuracy: 0.6298828125\n",
      "Batch: 138, Loss: 1.2258169651031494, Accuracy: 0.6083984375\n",
      "Batch: 139, Loss: 1.2055718898773193, Accuracy: 0.61328125\n",
      "Batch: 140, Loss: 1.2580211162567139, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.2142544984817505, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2192964553833008, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.2482173442840576, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.2660704851150513, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.1810225248336792, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.2346930503845215, Accuracy: 0.60546875\n",
      "Batch: 147, Loss: 1.2064446210861206, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.1970548629760742, Accuracy: 0.625\n",
      "Batch: 149, Loss: 1.2043395042419434, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.1167919635772705, Accuracy: 0.6337890625\n",
      "Batch: 151, Loss: 1.188884973526001, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.191622257232666, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.131534218788147, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1237834692001343, Accuracy: 0.6337890625\n",
      "Batch: 155, Loss: 1.0705757141113281, Accuracy: 0.6494140625\n",
      "Epoch 487/200\n",
      "Batch: 1, Loss: 1.1973063945770264, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 1.1208804845809937, Accuracy: 0.646484375\n",
      "Batch: 3, Loss: 1.0608869791030884, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.1063544750213623, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 1.0688221454620361, Accuracy: 0.6455078125\n",
      "Batch: 6, Loss: 1.0579217672348022, Accuracy: 0.642578125\n",
      "Batch: 7, Loss: 0.9911826252937317, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 1.0228074789047241, Accuracy: 0.6611328125\n",
      "Batch: 9, Loss: 0.9749224185943604, Accuracy: 0.6728515625\n",
      "Batch: 10, Loss: 1.0001851320266724, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 0.9874378442764282, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 1.0327807664871216, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 1.0474650859832764, Accuracy: 0.658203125\n",
      "Batch: 14, Loss: 0.9706287980079651, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.954196572303772, Accuracy: 0.6962890625\n",
      "Batch: 16, Loss: 0.9723676443099976, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.0658810138702393, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1268185377120972, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.2419328689575195, Accuracy: 0.58984375\n",
      "Batch: 20, Loss: 1.1108044385910034, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.0764323472976685, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.2256219387054443, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.154494285583496, Accuracy: 0.62109375\n",
      "Batch: 24, Loss: 1.1422951221466064, Accuracy: 0.626953125\n",
      "Batch: 25, Loss: 1.195071816444397, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.201486349105835, Accuracy: 0.609375\n",
      "Batch: 27, Loss: 1.1326284408569336, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 1.0962443351745605, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0560498237609863, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.1666529178619385, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.2118051052093506, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 1.108372449874878, Accuracy: 0.6240234375\n",
      "Batch: 33, Loss: 1.0392974615097046, Accuracy: 0.6494140625\n",
      "Batch: 34, Loss: 1.1165766716003418, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.1399637460708618, Accuracy: 0.611328125\n",
      "Batch: 36, Loss: 1.1796517372131348, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.1838289499282837, Accuracy: 0.6103515625\n",
      "Batch: 38, Loss: 1.1722588539123535, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.1086359024047852, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0899537801742554, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.1374492645263672, Accuracy: 0.6259765625\n",
      "Batch: 42, Loss: 1.0703240633010864, Accuracy: 0.642578125\n",
      "Batch: 43, Loss: 1.0763860940933228, Accuracy: 0.640625\n",
      "Batch: 44, Loss: 1.0288190841674805, Accuracy: 0.6708984375\n",
      "Batch: 45, Loss: 1.0682827234268188, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.135694980621338, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.1337422132492065, Accuracy: 0.6318359375\n",
      "Batch: 48, Loss: 1.1380277872085571, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.1891319751739502, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.111860752105713, Accuracy: 0.642578125\n",
      "Batch: 51, Loss: 1.2087821960449219, Accuracy: 0.587890625\n",
      "Batch: 52, Loss: 1.2818394899368286, Accuracy: 0.6015625\n",
      "Batch: 53, Loss: 1.1990865468978882, Accuracy: 0.6015625\n",
      "Batch: 54, Loss: 1.2146985530853271, Accuracy: 0.6279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 1.1440658569335938, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.161620020866394, Accuracy: 0.625\n",
      "Batch: 57, Loss: 1.1443214416503906, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.127624750137329, Accuracy: 0.6357421875\n",
      "Batch: 59, Loss: 1.1264408826828003, Accuracy: 0.64453125\n",
      "Batch: 60, Loss: 1.2163641452789307, Accuracy: 0.6279296875\n",
      "Batch: 61, Loss: 1.1484246253967285, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1746522188186646, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.1421011686325073, Accuracy: 0.63671875\n",
      "Batch: 64, Loss: 1.2041230201721191, Accuracy: 0.6142578125\n",
      "Batch: 65, Loss: 1.1813431978225708, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.145383596420288, Accuracy: 0.6318359375\n",
      "Batch: 67, Loss: 1.1702404022216797, Accuracy: 0.62890625\n",
      "Batch: 68, Loss: 1.0855860710144043, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.209486484527588, Accuracy: 0.5947265625\n",
      "Batch: 70, Loss: 1.1835447549819946, Accuracy: 0.630859375\n",
      "Batch: 71, Loss: 1.1518268585205078, Accuracy: 0.625\n",
      "Batch: 72, Loss: 1.2102148532867432, Accuracy: 0.619140625\n",
      "Batch: 73, Loss: 1.1801457405090332, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.1168484687805176, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.138487696647644, Accuracy: 0.642578125\n",
      "Batch: 76, Loss: 1.0766301155090332, Accuracy: 0.646484375\n",
      "Batch: 77, Loss: 1.0752848386764526, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.0713274478912354, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.208212971687317, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.202451467514038, Accuracy: 0.61328125\n",
      "Batch: 81, Loss: 1.1535941362380981, Accuracy: 0.626953125\n",
      "Batch: 82, Loss: 1.0918083190917969, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 1.1936311721801758, Accuracy: 0.61328125\n",
      "Batch: 84, Loss: 1.1677632331848145, Accuracy: 0.6240234375\n",
      "Batch: 85, Loss: 1.1364271640777588, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.181044340133667, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.174145221710205, Accuracy: 0.587890625\n",
      "Batch: 88, Loss: 1.1744139194488525, Accuracy: 0.642578125\n",
      "Batch: 89, Loss: 1.1572444438934326, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.1392810344696045, Accuracy: 0.6123046875\n",
      "Batch: 91, Loss: 1.1955585479736328, Accuracy: 0.59765625\n",
      "Batch: 92, Loss: 1.1371991634368896, Accuracy: 0.64453125\n",
      "Batch: 93, Loss: 1.148571491241455, Accuracy: 0.6064453125\n",
      "Batch: 94, Loss: 1.2074580192565918, Accuracy: 0.6044921875\n",
      "Batch: 95, Loss: 1.2025105953216553, Accuracy: 0.623046875\n",
      "Batch: 96, Loss: 1.2430403232574463, Accuracy: 0.6162109375\n",
      "Batch: 97, Loss: 1.2115733623504639, Accuracy: 0.6064453125\n",
      "Batch: 98, Loss: 1.151442527770996, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.141974687576294, Accuracy: 0.6279296875\n",
      "Batch: 100, Loss: 1.0210906267166138, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.1354914903640747, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.1767343282699585, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.236437201499939, Accuracy: 0.609375\n",
      "Batch: 104, Loss: 1.149282455444336, Accuracy: 0.625\n",
      "Batch: 105, Loss: 1.2177014350891113, Accuracy: 0.6171875\n",
      "Batch: 106, Loss: 1.1427663564682007, Accuracy: 0.6376953125\n",
      "Batch: 107, Loss: 1.2482469081878662, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.1589516401290894, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.1920900344848633, Accuracy: 0.619140625\n",
      "Batch: 110, Loss: 1.2086843252182007, Accuracy: 0.615234375\n",
      "Batch: 111, Loss: 1.11711585521698, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.123896598815918, Accuracy: 0.6494140625\n",
      "Batch: 113, Loss: 1.1600406169891357, Accuracy: 0.6181640625\n",
      "Batch: 114, Loss: 1.1781654357910156, Accuracy: 0.626953125\n",
      "Batch: 115, Loss: 1.2567112445831299, Accuracy: 0.5947265625\n",
      "Batch: 116, Loss: 1.2011818885803223, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.1883385181427002, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.248956322669983, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.2328603267669678, Accuracy: 0.611328125\n",
      "Batch: 120, Loss: 1.2334825992584229, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.2669305801391602, Accuracy: 0.5947265625\n",
      "Batch: 122, Loss: 1.311424970626831, Accuracy: 0.599609375\n",
      "Batch: 123, Loss: 1.1415438652038574, Accuracy: 0.6279296875\n",
      "Batch: 124, Loss: 1.2100024223327637, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.134450912475586, Accuracy: 0.634765625\n",
      "Batch: 126, Loss: 1.2662498950958252, Accuracy: 0.607421875\n",
      "Batch: 127, Loss: 1.2125667333602905, Accuracy: 0.615234375\n",
      "Batch: 128, Loss: 1.2094895839691162, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1778779029846191, Accuracy: 0.6220703125\n",
      "Batch: 130, Loss: 1.1613588333129883, Accuracy: 0.634765625\n",
      "Batch: 131, Loss: 1.231022596359253, Accuracy: 0.59375\n",
      "Batch: 132, Loss: 1.0534956455230713, Accuracy: 0.666015625\n",
      "Batch: 133, Loss: 1.1442275047302246, Accuracy: 0.6484375\n",
      "Batch: 134, Loss: 1.1629174947738647, Accuracy: 0.64453125\n",
      "Batch: 135, Loss: 1.0546878576278687, Accuracy: 0.6572265625\n",
      "Batch: 136, Loss: 1.096987247467041, Accuracy: 0.6435546875\n",
      "Batch: 137, Loss: 1.1601002216339111, Accuracy: 0.64453125\n",
      "Batch: 138, Loss: 1.2246136665344238, Accuracy: 0.5947265625\n",
      "Batch: 139, Loss: 1.204641580581665, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.2635715007781982, Accuracy: 0.60546875\n",
      "Batch: 141, Loss: 1.1354725360870361, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.2410587072372437, Accuracy: 0.5771484375\n",
      "Batch: 143, Loss: 1.2248421907424927, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.3001232147216797, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.2245869636535645, Accuracy: 0.59375\n",
      "Batch: 146, Loss: 1.1696536540985107, Accuracy: 0.6220703125\n",
      "Batch: 147, Loss: 1.226599097251892, Accuracy: 0.5869140625\n",
      "Batch: 148, Loss: 1.2126585245132446, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.1690659523010254, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.15018892288208, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.141181230545044, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.145883560180664, Accuracy: 0.625\n",
      "Batch: 153, Loss: 1.1363844871520996, Accuracy: 0.62890625\n",
      "Batch: 154, Loss: 1.133708119392395, Accuracy: 0.619140625\n",
      "Batch: 155, Loss: 1.1010172367095947, Accuracy: 0.650390625\n",
      "Epoch 488/200\n",
      "Batch: 1, Loss: 1.2048070430755615, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.0530468225479126, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.0672004222869873, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.0642671585083008, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.0422978401184082, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0856173038482666, Accuracy: 0.6494140625\n",
      "Batch: 7, Loss: 1.0290775299072266, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 0.9934818148612976, Accuracy: 0.6796875\n",
      "Batch: 9, Loss: 1.0365465879440308, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9274696707725525, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 0.9521539211273193, Accuracy: 0.697265625\n",
      "Batch: 12, Loss: 0.9867655038833618, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.0082957744598389, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9694015979766846, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9506914615631104, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.0181535482406616, Accuracy: 0.6884765625\n",
      "Batch: 17, Loss: 1.0943787097930908, Accuracy: 0.640625\n",
      "Batch: 18, Loss: 1.1530911922454834, Accuracy: 0.6298828125\n",
      "Batch: 19, Loss: 1.2021880149841309, Accuracy: 0.6103515625\n",
      "Batch: 20, Loss: 1.079972505569458, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0559145212173462, Accuracy: 0.6474609375\n",
      "Batch: 22, Loss: 1.214789867401123, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.2348963022232056, Accuracy: 0.587890625\n",
      "Batch: 24, Loss: 1.095606803894043, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.166581392288208, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.1615180969238281, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.1689982414245605, Accuracy: 0.6123046875\n",
      "Batch: 28, Loss: 1.0576480627059937, Accuracy: 0.66796875\n",
      "Batch: 29, Loss: 1.1245834827423096, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.1736266613006592, Accuracy: 0.5947265625\n",
      "Batch: 31, Loss: 1.1999225616455078, Accuracy: 0.615234375\n",
      "Batch: 32, Loss: 1.0284206867218018, Accuracy: 0.6640625\n",
      "Batch: 33, Loss: 1.0438101291656494, Accuracy: 0.63671875\n",
      "Batch: 34, Loss: 1.1064890623092651, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1115602254867554, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.1880605220794678, Accuracy: 0.5927734375\n",
      "Batch: 37, Loss: 1.2208893299102783, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.193530797958374, Accuracy: 0.5810546875\n",
      "Batch: 39, Loss: 1.047294020652771, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 1.0765987634658813, Accuracy: 0.6396484375\n",
      "Batch: 41, Loss: 1.1229593753814697, Accuracy: 0.6171875\n",
      "Batch: 42, Loss: 1.014398455619812, Accuracy: 0.669921875\n",
      "Batch: 43, Loss: 1.0692980289459229, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.0553317070007324, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.0549653768539429, Accuracy: 0.6337890625\n",
      "Batch: 46, Loss: 1.154274582862854, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.09486985206604, Accuracy: 0.6552734375\n",
      "Batch: 48, Loss: 1.1682939529418945, Accuracy: 0.6015625\n",
      "Batch: 49, Loss: 1.168095350265503, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.1284987926483154, Accuracy: 0.6171875\n",
      "Batch: 51, Loss: 1.1394376754760742, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.2768040895462036, Accuracy: 0.578125\n",
      "Batch: 53, Loss: 1.1680123805999756, Accuracy: 0.6103515625\n",
      "Batch: 54, Loss: 1.1671743392944336, Accuracy: 0.6201171875\n",
      "Batch: 55, Loss: 1.0997157096862793, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.1086269617080688, Accuracy: 0.634765625\n",
      "Batch: 57, Loss: 1.1196086406707764, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.1072731018066406, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 1.1384249925613403, Accuracy: 0.6240234375\n",
      "Batch: 60, Loss: 1.2859714031219482, Accuracy: 0.5712890625\n",
      "Batch: 61, Loss: 1.125993251800537, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.152881145477295, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1506547927856445, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2068783044815063, Accuracy: 0.6142578125\n",
      "Batch: 65, Loss: 1.2160232067108154, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.117903470993042, Accuracy: 0.6318359375\n",
      "Batch: 67, Loss: 1.1394785642623901, Accuracy: 0.6044921875\n",
      "Batch: 68, Loss: 1.114699363708496, Accuracy: 0.634765625\n",
      "Batch: 69, Loss: 1.1624970436096191, Accuracy: 0.62109375\n",
      "Batch: 70, Loss: 1.167641043663025, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.1648151874542236, Accuracy: 0.6474609375\n",
      "Batch: 72, Loss: 1.1606173515319824, Accuracy: 0.630859375\n",
      "Batch: 73, Loss: 1.144024133682251, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1438019275665283, Accuracy: 0.6318359375\n",
      "Batch: 75, Loss: 1.1194826364517212, Accuracy: 0.62109375\n",
      "Batch: 76, Loss: 1.0434293746948242, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 1.0787804126739502, Accuracy: 0.662109375\n",
      "Batch: 78, Loss: 1.1151306629180908, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.1577632427215576, Accuracy: 0.6005859375\n",
      "Batch: 80, Loss: 1.151870608329773, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.1166499853134155, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.0927835702896118, Accuracy: 0.6494140625\n",
      "Batch: 83, Loss: 1.2280857563018799, Accuracy: 0.5927734375\n",
      "Batch: 84, Loss: 1.175065279006958, Accuracy: 0.6181640625\n",
      "Batch: 85, Loss: 1.232539415359497, Accuracy: 0.6123046875\n",
      "Batch: 86, Loss: 1.172234058380127, Accuracy: 0.619140625\n",
      "Batch: 87, Loss: 1.1694958209991455, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.2267316579818726, Accuracy: 0.5947265625\n",
      "Batch: 89, Loss: 1.1729695796966553, Accuracy: 0.60546875\n",
      "Batch: 90, Loss: 1.1114778518676758, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1360995769500732, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1608169078826904, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.1279672384262085, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.1692200899124146, Accuracy: 0.6044921875\n",
      "Batch: 95, Loss: 1.1912429332733154, Accuracy: 0.625\n",
      "Batch: 96, Loss: 1.176830768585205, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.212934970855713, Accuracy: 0.599609375\n",
      "Batch: 98, Loss: 1.1198742389678955, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.1234700679779053, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 1.0567384958267212, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0659174919128418, Accuracy: 0.6669921875\n",
      "Batch: 102, Loss: 1.1659927368164062, Accuracy: 0.6171875\n",
      "Batch: 103, Loss: 1.1539926528930664, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.1556355953216553, Accuracy: 0.6279296875\n",
      "Batch: 105, Loss: 1.2501273155212402, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.1692869663238525, Accuracy: 0.6279296875\n",
      "Batch: 107, Loss: 1.2509167194366455, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.1723346710205078, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.256455898284912, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1324031352996826, Accuracy: 0.630859375\n",
      "Batch: 111, Loss: 1.1420516967773438, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.1314951181411743, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.1635429859161377, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.1958274841308594, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.15810227394104, Accuracy: 0.623046875\n",
      "Batch: 116, Loss: 1.1982003450393677, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.1569486856460571, Accuracy: 0.6162109375\n",
      "Batch: 118, Loss: 1.239190936088562, Accuracy: 0.6044921875\n",
      "Batch: 119, Loss: 1.2441619634628296, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.3312722444534302, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.2069523334503174, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.2044670581817627, Accuracy: 0.626953125\n",
      "Batch: 123, Loss: 1.1682000160217285, Accuracy: 0.6318359375\n",
      "Batch: 124, Loss: 1.2057253122329712, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1567208766937256, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.2353546619415283, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.20573890209198, Accuracy: 0.62890625\n",
      "Batch: 128, Loss: 1.1968319416046143, Accuracy: 0.6181640625\n",
      "Batch: 129, Loss: 1.1902379989624023, Accuracy: 0.615234375\n",
      "Batch: 130, Loss: 1.1692924499511719, Accuracy: 0.607421875\n",
      "Batch: 131, Loss: 1.2109935283660889, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.0641520023345947, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 1.1338016986846924, Accuracy: 0.642578125\n",
      "Batch: 134, Loss: 1.1355891227722168, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 1.0303431749343872, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.0621706247329712, Accuracy: 0.6767578125\n",
      "Batch: 137, Loss: 1.1879615783691406, Accuracy: 0.6171875\n",
      "Batch: 138, Loss: 1.264243721961975, Accuracy: 0.576171875\n",
      "Batch: 139, Loss: 1.1698853969573975, Accuracy: 0.6220703125\n",
      "Batch: 140, Loss: 1.2295985221862793, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.1926467418670654, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.1557347774505615, Accuracy: 0.6484375\n",
      "Batch: 143, Loss: 1.2340549230575562, Accuracy: 0.6005859375\n",
      "Batch: 144, Loss: 1.2655084133148193, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.245802402496338, Accuracy: 0.583984375\n",
      "Batch: 146, Loss: 1.2029719352722168, Accuracy: 0.609375\n",
      "Batch: 147, Loss: 1.1968320608139038, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.270566463470459, Accuracy: 0.5908203125\n",
      "Batch: 149, Loss: 1.1556668281555176, Accuracy: 0.62109375\n",
      "Batch: 150, Loss: 1.1583466529846191, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.1909273862838745, Accuracy: 0.6181640625\n",
      "Batch: 152, Loss: 1.1822566986083984, Accuracy: 0.607421875\n",
      "Batch: 153, Loss: 1.115297555923462, Accuracy: 0.646484375\n",
      "Batch: 154, Loss: 1.1104174852371216, Accuracy: 0.638671875\n",
      "Batch: 155, Loss: 1.1087206602096558, Accuracy: 0.6396484375\n",
      "Epoch 489/200\n",
      "Batch: 1, Loss: 1.1860401630401611, Accuracy: 0.630859375\n",
      "Batch: 2, Loss: 1.0914791822433472, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 1.0915992259979248, Accuracy: 0.642578125\n",
      "Batch: 4, Loss: 1.0852348804473877, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.057476282119751, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0409960746765137, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.0532382726669312, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 1.012018084526062, Accuracy: 0.677734375\n",
      "Batch: 9, Loss: 1.026078224182129, Accuracy: 0.6689453125\n",
      "Batch: 10, Loss: 0.9999098181724548, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9960616827011108, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 1.0456528663635254, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 1.0230662822723389, Accuracy: 0.69140625\n",
      "Batch: 14, Loss: 0.999070942401886, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.975645899772644, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0564934015274048, Accuracy: 0.6484375\n",
      "Batch: 17, Loss: 1.078855037689209, Accuracy: 0.6181640625\n",
      "Batch: 18, Loss: 1.1441752910614014, Accuracy: 0.6201171875\n",
      "Batch: 19, Loss: 1.1918885707855225, Accuracy: 0.615234375\n",
      "Batch: 20, Loss: 1.0856777429580688, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.070273518562317, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.2180095911026, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.2328789234161377, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.1221007108688354, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 25, Loss: 1.1300595998764038, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.211860179901123, Accuracy: 0.6064453125\n",
      "Batch: 27, Loss: 1.1231188774108887, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.1059846878051758, Accuracy: 0.6328125\n",
      "Batch: 29, Loss: 1.0323055982589722, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1644957065582275, Accuracy: 0.6044921875\n",
      "Batch: 31, Loss: 1.2373781204223633, Accuracy: 0.587890625\n",
      "Batch: 32, Loss: 1.0517642498016357, Accuracy: 0.6435546875\n",
      "Batch: 33, Loss: 0.991882860660553, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.0664434432983398, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.1571283340454102, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.2114630937576294, Accuracy: 0.5966796875\n",
      "Batch: 37, Loss: 1.248227596282959, Accuracy: 0.5712890625\n",
      "Batch: 38, Loss: 1.1223955154418945, Accuracy: 0.6240234375\n",
      "Batch: 39, Loss: 1.1041069030761719, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.0975253582000732, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.1781284809112549, Accuracy: 0.615234375\n",
      "Batch: 42, Loss: 1.0522680282592773, Accuracy: 0.626953125\n",
      "Batch: 43, Loss: 1.0831573009490967, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.0411109924316406, Accuracy: 0.6689453125\n",
      "Batch: 45, Loss: 1.104541540145874, Accuracy: 0.62890625\n",
      "Batch: 46, Loss: 1.159187912940979, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.0805823802947998, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.1093451976776123, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.171050786972046, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.1469603776931763, Accuracy: 0.625\n",
      "Batch: 51, Loss: 1.129502296447754, Accuracy: 0.63671875\n",
      "Batch: 52, Loss: 1.237534523010254, Accuracy: 0.6015625\n",
      "Batch: 53, Loss: 1.1711022853851318, Accuracy: 0.62890625\n",
      "Batch: 54, Loss: 1.169508934020996, Accuracy: 0.61328125\n",
      "Batch: 55, Loss: 1.1476846933364868, Accuracy: 0.638671875\n",
      "Batch: 56, Loss: 1.2089778184890747, Accuracy: 0.61328125\n",
      "Batch: 57, Loss: 1.0947668552398682, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.1051616668701172, Accuracy: 0.638671875\n",
      "Batch: 59, Loss: 1.0957696437835693, Accuracy: 0.6416015625\n",
      "Batch: 60, Loss: 1.235356330871582, Accuracy: 0.6025390625\n",
      "Batch: 61, Loss: 1.1478607654571533, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.1666524410247803, Accuracy: 0.623046875\n",
      "Batch: 63, Loss: 1.1518094539642334, Accuracy: 0.61328125\n",
      "Batch: 64, Loss: 1.2359565496444702, Accuracy: 0.591796875\n",
      "Batch: 65, Loss: 1.1424763202667236, Accuracy: 0.6298828125\n",
      "Batch: 66, Loss: 1.139755129814148, Accuracy: 0.640625\n",
      "Batch: 67, Loss: 1.1510593891143799, Accuracy: 0.6298828125\n",
      "Batch: 68, Loss: 1.1256264448165894, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1515318155288696, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.2111839056015015, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1406230926513672, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.1791021823883057, Accuracy: 0.6337890625\n",
      "Batch: 73, Loss: 1.1826283931732178, Accuracy: 0.6142578125\n",
      "Batch: 74, Loss: 1.1099333763122559, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.1148676872253418, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.0849119424819946, Accuracy: 0.638671875\n",
      "Batch: 77, Loss: 1.0122997760772705, Accuracy: 0.662109375\n",
      "Batch: 78, Loss: 1.0989210605621338, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.0687553882598877, Accuracy: 0.66796875\n",
      "Batch: 80, Loss: 1.1206917762756348, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.121819257736206, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1120965480804443, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 1.205270528793335, Accuracy: 0.6142578125\n",
      "Batch: 84, Loss: 1.1426023244857788, Accuracy: 0.6240234375\n",
      "Batch: 85, Loss: 1.1460654735565186, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.1649855375289917, Accuracy: 0.6171875\n",
      "Batch: 87, Loss: 1.1881524324417114, Accuracy: 0.6083984375\n",
      "Batch: 88, Loss: 1.212106704711914, Accuracy: 0.607421875\n",
      "Batch: 89, Loss: 1.163461446762085, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.0990225076675415, Accuracy: 0.646484375\n",
      "Batch: 91, Loss: 1.1628386974334717, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.106674313545227, Accuracy: 0.6455078125\n",
      "Batch: 93, Loss: 1.138339638710022, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.1678186655044556, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.217717170715332, Accuracy: 0.625\n",
      "Batch: 96, Loss: 1.1828598976135254, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.1591880321502686, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.1455421447753906, Accuracy: 0.609375\n",
      "Batch: 99, Loss: 1.1940844058990479, Accuracy: 0.60546875\n",
      "Batch: 100, Loss: 1.0151110887527466, Accuracy: 0.66796875\n",
      "Batch: 101, Loss: 1.1135125160217285, Accuracy: 0.6474609375\n",
      "Batch: 102, Loss: 1.1760022640228271, Accuracy: 0.6103515625\n",
      "Batch: 103, Loss: 1.1463979482650757, Accuracy: 0.62890625\n",
      "Batch: 104, Loss: 1.1200942993164062, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.2031207084655762, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.1563146114349365, Accuracy: 0.640625\n",
      "Batch: 107, Loss: 1.2088112831115723, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.2344274520874023, Accuracy: 0.5859375\n",
      "Batch: 109, Loss: 1.2178220748901367, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.1768854856491089, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1330231428146362, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.130552053451538, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.114487648010254, Accuracy: 0.6484375\n",
      "Batch: 114, Loss: 1.1451923847198486, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.1744012832641602, Accuracy: 0.6181640625\n",
      "Batch: 116, Loss: 1.2009377479553223, Accuracy: 0.6142578125\n",
      "Batch: 117, Loss: 1.1836739778518677, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.22572660446167, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2532250881195068, Accuracy: 0.5966796875\n",
      "Batch: 120, Loss: 1.2425918579101562, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.2007176876068115, Accuracy: 0.611328125\n",
      "Batch: 122, Loss: 1.1895363330841064, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.17557954788208, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.205096960067749, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.2127230167388916, Accuracy: 0.615234375\n",
      "Batch: 126, Loss: 1.27666175365448, Accuracy: 0.5947265625\n",
      "Batch: 127, Loss: 1.2143549919128418, Accuracy: 0.619140625\n",
      "Batch: 128, Loss: 1.2432408332824707, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.1764675378799438, Accuracy: 0.623046875\n",
      "Batch: 130, Loss: 1.1746196746826172, Accuracy: 0.6181640625\n",
      "Batch: 131, Loss: 1.189561128616333, Accuracy: 0.611328125\n",
      "Batch: 132, Loss: 1.0156348943710327, Accuracy: 0.6826171875\n",
      "Batch: 133, Loss: 1.151129961013794, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.167388916015625, Accuracy: 0.646484375\n",
      "Batch: 135, Loss: 1.031214952468872, Accuracy: 0.6728515625\n",
      "Batch: 136, Loss: 1.118168592453003, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1380740404129028, Accuracy: 0.6396484375\n",
      "Batch: 138, Loss: 1.2464555501937866, Accuracy: 0.59375\n",
      "Batch: 139, Loss: 1.1741454601287842, Accuracy: 0.6318359375\n",
      "Batch: 140, Loss: 1.3287580013275146, Accuracy: 0.572265625\n",
      "Batch: 141, Loss: 1.1853444576263428, Accuracy: 0.609375\n",
      "Batch: 142, Loss: 1.213681936264038, Accuracy: 0.623046875\n",
      "Batch: 143, Loss: 1.2674938440322876, Accuracy: 0.587890625\n",
      "Batch: 144, Loss: 1.3077130317687988, Accuracy: 0.5625\n",
      "Batch: 145, Loss: 1.283278465270996, Accuracy: 0.583984375\n",
      "Batch: 146, Loss: 1.254509687423706, Accuracy: 0.5830078125\n",
      "Batch: 147, Loss: 1.2350646257400513, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.2698333263397217, Accuracy: 0.5888671875\n",
      "Batch: 149, Loss: 1.1798961162567139, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.213030219078064, Accuracy: 0.6064453125\n",
      "Batch: 151, Loss: 1.1320502758026123, Accuracy: 0.6474609375\n",
      "Batch: 152, Loss: 1.1701586246490479, Accuracy: 0.623046875\n",
      "Batch: 153, Loss: 1.201615810394287, Accuracy: 0.61328125\n",
      "Batch: 154, Loss: 1.1129558086395264, Accuracy: 0.6455078125\n",
      "Batch: 155, Loss: 1.1147301197052002, Accuracy: 0.6396484375\n",
      "Epoch 490/200\n",
      "Batch: 1, Loss: 1.2656581401824951, Accuracy: 0.6181640625\n",
      "Batch: 2, Loss: 1.0694630146026611, Accuracy: 0.6630859375\n",
      "Batch: 3, Loss: 1.0719969272613525, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.082802653312683, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.0912466049194336, Accuracy: 0.6337890625\n",
      "Batch: 6, Loss: 1.0834044218063354, Accuracy: 0.642578125\n",
      "Batch: 7, Loss: 1.087010383605957, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.0415862798690796, Accuracy: 0.646484375\n",
      "Batch: 9, Loss: 1.0535058975219727, Accuracy: 0.62890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 1.0133074522018433, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 1.0387840270996094, Accuracy: 0.65625\n",
      "Batch: 12, Loss: 1.0032150745391846, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 1.073296308517456, Accuracy: 0.6298828125\n",
      "Batch: 14, Loss: 1.017404556274414, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9951175451278687, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0721204280853271, Accuracy: 0.654296875\n",
      "Batch: 17, Loss: 1.0836412906646729, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.1379070281982422, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.212545394897461, Accuracy: 0.6044921875\n",
      "Batch: 20, Loss: 1.1022915840148926, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.078063726425171, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.234593152999878, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2782491445541382, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.1158795356750488, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.0947537422180176, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.2121403217315674, Accuracy: 0.6162109375\n",
      "Batch: 27, Loss: 1.1530683040618896, Accuracy: 0.6181640625\n",
      "Batch: 28, Loss: 1.1292126178741455, Accuracy: 0.63671875\n",
      "Batch: 29, Loss: 1.0368752479553223, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1869785785675049, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.2450544834136963, Accuracy: 0.5869140625\n",
      "Batch: 32, Loss: 1.03842031955719, Accuracy: 0.6728515625\n",
      "Batch: 33, Loss: 1.0169355869293213, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.1222467422485352, Accuracy: 0.6396484375\n",
      "Batch: 35, Loss: 1.1067173480987549, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.2486903667449951, Accuracy: 0.5927734375\n",
      "Batch: 37, Loss: 1.2539286613464355, Accuracy: 0.5859375\n",
      "Batch: 38, Loss: 1.183122158050537, Accuracy: 0.625\n",
      "Batch: 39, Loss: 1.072619915008545, Accuracy: 0.64453125\n",
      "Batch: 40, Loss: 1.1086652278900146, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.1395334005355835, Accuracy: 0.6220703125\n",
      "Batch: 42, Loss: 1.0870680809020996, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0801172256469727, Accuracy: 0.6318359375\n",
      "Batch: 44, Loss: 1.0781052112579346, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.0843925476074219, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1528935432434082, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.129011869430542, Accuracy: 0.634765625\n",
      "Batch: 48, Loss: 1.1214778423309326, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.1890232563018799, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.16407310962677, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.1895203590393066, Accuracy: 0.6005859375\n",
      "Batch: 52, Loss: 1.2488627433776855, Accuracy: 0.6005859375\n",
      "Batch: 53, Loss: 1.180703043937683, Accuracy: 0.60546875\n",
      "Batch: 54, Loss: 1.250344157218933, Accuracy: 0.599609375\n",
      "Batch: 55, Loss: 1.1678454875946045, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.166917324066162, Accuracy: 0.6162109375\n",
      "Batch: 57, Loss: 1.1283307075500488, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.171508550643921, Accuracy: 0.6240234375\n",
      "Batch: 59, Loss: 1.1975678205490112, Accuracy: 0.6025390625\n",
      "Batch: 60, Loss: 1.218625545501709, Accuracy: 0.5966796875\n",
      "Batch: 61, Loss: 1.2149689197540283, Accuracy: 0.60546875\n",
      "Batch: 62, Loss: 1.1758008003234863, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.2432852983474731, Accuracy: 0.591796875\n",
      "Batch: 64, Loss: 1.2479393482208252, Accuracy: 0.5791015625\n",
      "Batch: 65, Loss: 1.1826369762420654, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.1898107528686523, Accuracy: 0.63671875\n",
      "Batch: 67, Loss: 1.1463019847869873, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.0993366241455078, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.2000932693481445, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.188812017440796, Accuracy: 0.6142578125\n",
      "Batch: 71, Loss: 1.1381620168685913, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.1926404237747192, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.2216824293136597, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.0946943759918213, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.123445987701416, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.0749672651290894, Accuracy: 0.65234375\n",
      "Batch: 77, Loss: 1.0776703357696533, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.0725442171096802, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.118759274482727, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.146122694015503, Accuracy: 0.6240234375\n",
      "Batch: 81, Loss: 1.163102149963379, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 1.1494710445404053, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.2217414379119873, Accuracy: 0.599609375\n",
      "Batch: 84, Loss: 1.1445908546447754, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.2322436571121216, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.204138994216919, Accuracy: 0.5986328125\n",
      "Batch: 87, Loss: 1.1924464702606201, Accuracy: 0.6279296875\n",
      "Batch: 88, Loss: 1.2070815563201904, Accuracy: 0.609375\n",
      "Batch: 89, Loss: 1.0976483821868896, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.0981662273406982, Accuracy: 0.640625\n",
      "Batch: 91, Loss: 1.165669560432434, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.167388916015625, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.1777458190917969, Accuracy: 0.6298828125\n",
      "Batch: 94, Loss: 1.18551766872406, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.2191964387893677, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2634272575378418, Accuracy: 0.60546875\n",
      "Batch: 97, Loss: 1.1940624713897705, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.1510930061340332, Accuracy: 0.6240234375\n",
      "Batch: 99, Loss: 1.1475739479064941, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.0493290424346924, Accuracy: 0.6650390625\n",
      "Batch: 101, Loss: 1.1186647415161133, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.2071161270141602, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.1432154178619385, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.179867148399353, Accuracy: 0.6162109375\n",
      "Batch: 105, Loss: 1.245788335800171, Accuracy: 0.6083984375\n",
      "Batch: 106, Loss: 1.1589875221252441, Accuracy: 0.615234375\n",
      "Batch: 107, Loss: 1.241646409034729, Accuracy: 0.5888671875\n",
      "Batch: 108, Loss: 1.1439093351364136, Accuracy: 0.6240234375\n",
      "Batch: 109, Loss: 1.271467924118042, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.1611326932907104, Accuracy: 0.6201171875\n",
      "Batch: 111, Loss: 1.1248196363449097, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.12241530418396, Accuracy: 0.634765625\n",
      "Batch: 113, Loss: 1.1381769180297852, Accuracy: 0.61328125\n",
      "Batch: 114, Loss: 1.222791314125061, Accuracy: 0.5966796875\n",
      "Batch: 115, Loss: 1.1990134716033936, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1812664270401, Accuracy: 0.6240234375\n",
      "Batch: 117, Loss: 1.190555453300476, Accuracy: 0.6044921875\n",
      "Batch: 118, Loss: 1.2421826124191284, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.2671794891357422, Accuracy: 0.5986328125\n",
      "Batch: 120, Loss: 1.2551264762878418, Accuracy: 0.6044921875\n",
      "Batch: 121, Loss: 1.1984755992889404, Accuracy: 0.5966796875\n",
      "Batch: 122, Loss: 1.2412075996398926, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.16178297996521, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2007319927215576, Accuracy: 0.6142578125\n",
      "Batch: 125, Loss: 1.2028734683990479, Accuracy: 0.6064453125\n",
      "Batch: 126, Loss: 1.227342128753662, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.2559518814086914, Accuracy: 0.5927734375\n",
      "Batch: 128, Loss: 1.2618992328643799, Accuracy: 0.5966796875\n",
      "Batch: 129, Loss: 1.2009472846984863, Accuracy: 0.609375\n",
      "Batch: 130, Loss: 1.1273494958877563, Accuracy: 0.63671875\n",
      "Batch: 131, Loss: 1.270078420639038, Accuracy: 0.5712890625\n",
      "Batch: 132, Loss: 1.0787197351455688, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.1346265077590942, Accuracy: 0.626953125\n",
      "Batch: 134, Loss: 1.1288721561431885, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 1.0585988759994507, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.1020386219024658, Accuracy: 0.66015625\n",
      "Batch: 137, Loss: 1.147875189781189, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.2764424085617065, Accuracy: 0.56640625\n",
      "Batch: 139, Loss: 1.2469345331192017, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.234719157218933, Accuracy: 0.59765625\n",
      "Batch: 141, Loss: 1.2114918231964111, Accuracy: 0.619140625\n",
      "Batch: 142, Loss: 1.155800461769104, Accuracy: 0.619140625\n",
      "Batch: 143, Loss: 1.1597520112991333, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.2815310955047607, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.317240834236145, Accuracy: 0.5751953125\n",
      "Batch: 146, Loss: 1.1997179985046387, Accuracy: 0.6064453125\n",
      "Batch: 147, Loss: 1.2099943161010742, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.242753028869629, Accuracy: 0.6015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 1.1585321426391602, Accuracy: 0.6201171875\n",
      "Batch: 150, Loss: 1.1718393564224243, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.1302874088287354, Accuracy: 0.6435546875\n",
      "Batch: 152, Loss: 1.198938250541687, Accuracy: 0.59375\n",
      "Batch: 153, Loss: 1.1621394157409668, Accuracy: 0.6103515625\n",
      "Batch: 154, Loss: 1.069665789604187, Accuracy: 0.6484375\n",
      "Batch: 155, Loss: 1.0689696073532104, Accuracy: 0.6416015625\n",
      "Saved Weights at epoch 490 to file Weights_490.h5\n",
      "Epoch 491/200\n",
      "Batch: 1, Loss: 1.2214552164077759, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.048738718032837, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 1.0849103927612305, Accuracy: 0.625\n",
      "Batch: 4, Loss: 1.1305432319641113, Accuracy: 0.62109375\n",
      "Batch: 5, Loss: 1.048128604888916, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0717226266860962, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.035122036933899, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 0.9645547866821289, Accuracy: 0.6982421875\n",
      "Batch: 9, Loss: 1.0439739227294922, Accuracy: 0.65234375\n",
      "Batch: 10, Loss: 0.9731616973876953, Accuracy: 0.6796875\n",
      "Batch: 11, Loss: 0.9979783892631531, Accuracy: 0.65625\n",
      "Batch: 12, Loss: 1.0275418758392334, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 1.0438809394836426, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 1.0021077394485474, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.952252984046936, Accuracy: 0.6826171875\n",
      "Batch: 16, Loss: 1.0492663383483887, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0575611591339111, Accuracy: 0.6650390625\n",
      "Batch: 18, Loss: 1.155012607574463, Accuracy: 0.615234375\n",
      "Batch: 19, Loss: 1.174966812133789, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 1.0949913263320923, Accuracy: 0.6640625\n",
      "Batch: 21, Loss: 1.0426928997039795, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.238131046295166, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.2674500942230225, Accuracy: 0.57421875\n",
      "Batch: 24, Loss: 1.1415531635284424, Accuracy: 0.6240234375\n",
      "Batch: 25, Loss: 1.1574501991271973, Accuracy: 0.6259765625\n",
      "Batch: 26, Loss: 1.171898365020752, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.1347371339797974, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.0871143341064453, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.1167880296707153, Accuracy: 0.642578125\n",
      "Batch: 30, Loss: 1.2453736066818237, Accuracy: 0.6025390625\n",
      "Batch: 31, Loss: 1.2099778652191162, Accuracy: 0.595703125\n",
      "Batch: 32, Loss: 1.10966157913208, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 1.023992657661438, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.133392333984375, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.1217446327209473, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.1427677869796753, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.171602725982666, Accuracy: 0.619140625\n",
      "Batch: 38, Loss: 1.1798063516616821, Accuracy: 0.607421875\n",
      "Batch: 39, Loss: 1.1120383739471436, Accuracy: 0.65234375\n",
      "Batch: 40, Loss: 1.0955191850662231, Accuracy: 0.6318359375\n",
      "Batch: 41, Loss: 1.1099662780761719, Accuracy: 0.626953125\n",
      "Batch: 42, Loss: 1.062560796737671, Accuracy: 0.658203125\n",
      "Batch: 43, Loss: 1.048753261566162, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.0874825716018677, Accuracy: 0.6455078125\n",
      "Batch: 45, Loss: 1.0417606830596924, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.1264266967773438, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1147819757461548, Accuracy: 0.6591796875\n",
      "Batch: 48, Loss: 1.123636245727539, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.1858947277069092, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.1351606845855713, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.1788461208343506, Accuracy: 0.603515625\n",
      "Batch: 52, Loss: 1.1912270784378052, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.1574794054031372, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.1812528371810913, Accuracy: 0.603515625\n",
      "Batch: 55, Loss: 1.1221668720245361, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.155795931816101, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.1282007694244385, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.1199146509170532, Accuracy: 0.646484375\n",
      "Batch: 59, Loss: 1.0793942213058472, Accuracy: 0.6611328125\n",
      "Batch: 60, Loss: 1.2626539468765259, Accuracy: 0.61328125\n",
      "Batch: 61, Loss: 1.1832520961761475, Accuracy: 0.611328125\n",
      "Batch: 62, Loss: 1.160696029663086, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.207961082458496, Accuracy: 0.615234375\n",
      "Batch: 64, Loss: 1.2350047826766968, Accuracy: 0.607421875\n",
      "Batch: 65, Loss: 1.2122700214385986, Accuracy: 0.611328125\n",
      "Batch: 66, Loss: 1.18863046169281, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.1211631298065186, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.0809168815612793, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1265108585357666, Accuracy: 0.634765625\n",
      "Batch: 70, Loss: 1.1960526704788208, Accuracy: 0.6220703125\n",
      "Batch: 71, Loss: 1.1659165620803833, Accuracy: 0.6279296875\n",
      "Batch: 72, Loss: 1.2012795209884644, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.2125084400177002, Accuracy: 0.607421875\n",
      "Batch: 74, Loss: 1.1024161577224731, Accuracy: 0.6279296875\n",
      "Batch: 75, Loss: 1.1162638664245605, Accuracy: 0.6220703125\n",
      "Batch: 76, Loss: 1.0896679162979126, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.0788507461547852, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.0875604152679443, Accuracy: 0.6328125\n",
      "Batch: 79, Loss: 1.1087439060211182, Accuracy: 0.6435546875\n",
      "Batch: 80, Loss: 1.2054173946380615, Accuracy: 0.6103515625\n",
      "Batch: 81, Loss: 1.1343185901641846, Accuracy: 0.611328125\n",
      "Batch: 82, Loss: 1.1932158470153809, Accuracy: 0.609375\n",
      "Batch: 83, Loss: 1.1745350360870361, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.0984055995941162, Accuracy: 0.626953125\n",
      "Batch: 85, Loss: 1.149757742881775, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1788803339004517, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.2167425155639648, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1298184394836426, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.1195101737976074, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.1451542377471924, Accuracy: 0.6162109375\n",
      "Batch: 91, Loss: 1.1573712825775146, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.1305179595947266, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.1524766683578491, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.2062005996704102, Accuracy: 0.6005859375\n",
      "Batch: 95, Loss: 1.1343755722045898, Accuracy: 0.642578125\n",
      "Batch: 96, Loss: 1.1330974102020264, Accuracy: 0.6435546875\n",
      "Batch: 97, Loss: 1.18825364112854, Accuracy: 0.59765625\n",
      "Batch: 98, Loss: 1.100965976715088, Accuracy: 0.6494140625\n",
      "Batch: 99, Loss: 1.1666215658187866, Accuracy: 0.6279296875\n",
      "Batch: 100, Loss: 1.05692458152771, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.1454992294311523, Accuracy: 0.625\n",
      "Batch: 102, Loss: 1.2324761152267456, Accuracy: 0.6171875\n",
      "Batch: 103, Loss: 1.1729588508605957, Accuracy: 0.6435546875\n",
      "Batch: 104, Loss: 1.1466443538665771, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.1536601781845093, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1495000123977661, Accuracy: 0.62890625\n",
      "Batch: 107, Loss: 1.254716396331787, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.165330171585083, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.1748048067092896, Accuracy: 0.6181640625\n",
      "Batch: 110, Loss: 1.1315410137176514, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1165649890899658, Accuracy: 0.6259765625\n",
      "Batch: 112, Loss: 1.0621827840805054, Accuracy: 0.65234375\n",
      "Batch: 113, Loss: 1.1621110439300537, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.1544671058654785, Accuracy: 0.6064453125\n",
      "Batch: 115, Loss: 1.2030218839645386, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.2132594585418701, Accuracy: 0.6142578125\n",
      "Batch: 117, Loss: 1.1592516899108887, Accuracy: 0.6171875\n",
      "Batch: 118, Loss: 1.1964495182037354, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.2522609233856201, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.2803764343261719, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.2114002704620361, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.1895809173583984, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.2028387784957886, Accuracy: 0.6279296875\n",
      "Batch: 124, Loss: 1.1929214000701904, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.188043236732483, Accuracy: 0.62890625\n",
      "Batch: 126, Loss: 1.2460336685180664, Accuracy: 0.611328125\n",
      "Batch: 127, Loss: 1.2279149293899536, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.2340279817581177, Accuracy: 0.59765625\n",
      "Batch: 129, Loss: 1.1813278198242188, Accuracy: 0.625\n",
      "Batch: 130, Loss: 1.07742440700531, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.2196100950241089, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.056857705116272, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.1825017929077148, Accuracy: 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 134, Loss: 1.11764395236969, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.023817539215088, Accuracy: 0.6630859375\n",
      "Batch: 136, Loss: 1.0753364562988281, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.1610040664672852, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.2066001892089844, Accuracy: 0.5966796875\n",
      "Batch: 139, Loss: 1.1867328882217407, Accuracy: 0.62890625\n",
      "Batch: 140, Loss: 1.183361530303955, Accuracy: 0.6220703125\n",
      "Batch: 141, Loss: 1.177013635635376, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.1347241401672363, Accuracy: 0.6435546875\n",
      "Batch: 143, Loss: 1.261777639389038, Accuracy: 0.5869140625\n",
      "Batch: 144, Loss: 1.2461638450622559, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.2474675178527832, Accuracy: 0.564453125\n",
      "Batch: 146, Loss: 1.2374753952026367, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.2465240955352783, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.1422165632247925, Accuracy: 0.625\n",
      "Batch: 149, Loss: 1.1887414455413818, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.2120335102081299, Accuracy: 0.6083984375\n",
      "Batch: 151, Loss: 1.1319164037704468, Accuracy: 0.6474609375\n",
      "Batch: 152, Loss: 1.1643723249435425, Accuracy: 0.6259765625\n",
      "Batch: 153, Loss: 1.117188572883606, Accuracy: 0.6240234375\n",
      "Batch: 154, Loss: 1.1313108205795288, Accuracy: 0.64453125\n",
      "Batch: 155, Loss: 1.120301365852356, Accuracy: 0.6484375\n",
      "Epoch 492/200\n",
      "Batch: 1, Loss: 1.2037431001663208, Accuracy: 0.65625\n",
      "Batch: 2, Loss: 1.1300690174102783, Accuracy: 0.625\n",
      "Batch: 3, Loss: 1.01558256149292, Accuracy: 0.65234375\n",
      "Batch: 4, Loss: 1.1238559484481812, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.1026701927185059, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.0534908771514893, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.030198574066162, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0124127864837646, Accuracy: 0.6611328125\n",
      "Batch: 9, Loss: 1.0480620861053467, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 0.9714952111244202, Accuracy: 0.6826171875\n",
      "Batch: 11, Loss: 0.9503594040870667, Accuracy: 0.705078125\n",
      "Batch: 12, Loss: 0.9948210716247559, Accuracy: 0.66015625\n",
      "Batch: 13, Loss: 1.033068060874939, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 1.0043251514434814, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9053375720977783, Accuracy: 0.6826171875\n",
      "Batch: 16, Loss: 1.0503764152526855, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.0366151332855225, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1447957754135132, Accuracy: 0.6455078125\n",
      "Batch: 19, Loss: 1.1781572103500366, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 1.1126840114593506, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0710852146148682, Accuracy: 0.66796875\n",
      "Batch: 22, Loss: 1.2534990310668945, Accuracy: 0.587890625\n",
      "Batch: 23, Loss: 1.226616621017456, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.1268903017044067, Accuracy: 0.6044921875\n",
      "Batch: 25, Loss: 1.1410248279571533, Accuracy: 0.623046875\n",
      "Batch: 26, Loss: 1.2138524055480957, Accuracy: 0.62109375\n",
      "Batch: 27, Loss: 1.141526699066162, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.0959105491638184, Accuracy: 0.6396484375\n",
      "Batch: 29, Loss: 1.054089069366455, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.1566963195800781, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.1919257640838623, Accuracy: 0.6181640625\n",
      "Batch: 32, Loss: 1.0589005947113037, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.0282089710235596, Accuracy: 0.658203125\n",
      "Batch: 34, Loss: 1.106339931488037, Accuracy: 0.6572265625\n",
      "Batch: 35, Loss: 1.1255919933319092, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.1589891910552979, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.193212866783142, Accuracy: 0.6044921875\n",
      "Batch: 38, Loss: 1.1623010635375977, Accuracy: 0.6318359375\n",
      "Batch: 39, Loss: 1.055983304977417, Accuracy: 0.6640625\n",
      "Batch: 40, Loss: 1.0753247737884521, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.1477177143096924, Accuracy: 0.60546875\n",
      "Batch: 42, Loss: 1.03397798538208, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.0049238204956055, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 1.0639901161193848, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0495209693908691, Accuracy: 0.6630859375\n",
      "Batch: 46, Loss: 1.1789016723632812, Accuracy: 0.61328125\n",
      "Batch: 47, Loss: 1.197908639907837, Accuracy: 0.609375\n",
      "Batch: 48, Loss: 1.1163201332092285, Accuracy: 0.619140625\n",
      "Batch: 49, Loss: 1.1883941888809204, Accuracy: 0.6240234375\n",
      "Batch: 50, Loss: 1.1227824687957764, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.2097018957138062, Accuracy: 0.5810546875\n",
      "Batch: 52, Loss: 1.2075510025024414, Accuracy: 0.6181640625\n",
      "Batch: 53, Loss: 1.151041865348816, Accuracy: 0.6259765625\n",
      "Batch: 54, Loss: 1.1896212100982666, Accuracy: 0.607421875\n",
      "Batch: 55, Loss: 1.1368484497070312, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.1254825592041016, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.1068687438964844, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.0968656539916992, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.077015995979309, Accuracy: 0.669921875\n",
      "Batch: 60, Loss: 1.2320482730865479, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1266121864318848, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1806350946426392, Accuracy: 0.6103515625\n",
      "Batch: 63, Loss: 1.1531805992126465, Accuracy: 0.6240234375\n",
      "Batch: 64, Loss: 1.2250975370407104, Accuracy: 0.5927734375\n",
      "Batch: 65, Loss: 1.205641269683838, Accuracy: 0.611328125\n",
      "Batch: 66, Loss: 1.1725997924804688, Accuracy: 0.615234375\n",
      "Batch: 67, Loss: 1.1525323390960693, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.1022368669509888, Accuracy: 0.6357421875\n",
      "Batch: 69, Loss: 1.1289540529251099, Accuracy: 0.6357421875\n",
      "Batch: 70, Loss: 1.175311803817749, Accuracy: 0.6162109375\n",
      "Batch: 71, Loss: 1.1307649612426758, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.1756162643432617, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.1737275123596191, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.0945852994918823, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.1323933601379395, Accuracy: 0.623046875\n",
      "Batch: 76, Loss: 1.0911190509796143, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 1.042532205581665, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 1.05891752243042, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.14847993850708, Accuracy: 0.615234375\n",
      "Batch: 80, Loss: 1.1302196979522705, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.064637303352356, Accuracy: 0.658203125\n",
      "Batch: 82, Loss: 1.1361255645751953, Accuracy: 0.611328125\n",
      "Batch: 83, Loss: 1.168792963027954, Accuracy: 0.6220703125\n",
      "Batch: 84, Loss: 1.1673688888549805, Accuracy: 0.615234375\n",
      "Batch: 85, Loss: 1.138350248336792, Accuracy: 0.638671875\n",
      "Batch: 86, Loss: 1.1385270357131958, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 1.2148743867874146, Accuracy: 0.6181640625\n",
      "Batch: 88, Loss: 1.1716294288635254, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.103244662284851, Accuracy: 0.66015625\n",
      "Batch: 90, Loss: 1.1261848211288452, Accuracy: 0.6494140625\n",
      "Batch: 91, Loss: 1.1820387840270996, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1630090475082397, Accuracy: 0.64453125\n",
      "Batch: 93, Loss: 1.0855177640914917, Accuracy: 0.623046875\n",
      "Batch: 94, Loss: 1.2232681512832642, Accuracy: 0.61328125\n",
      "Batch: 95, Loss: 1.1261887550354004, Accuracy: 0.6474609375\n",
      "Batch: 96, Loss: 1.1905772686004639, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.170013189315796, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1484111547470093, Accuracy: 0.6240234375\n",
      "Batch: 99, Loss: 1.0949039459228516, Accuracy: 0.6396484375\n",
      "Batch: 100, Loss: 1.0848218202590942, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.0399105548858643, Accuracy: 0.6650390625\n",
      "Batch: 102, Loss: 1.2021799087524414, Accuracy: 0.623046875\n",
      "Batch: 103, Loss: 1.125013828277588, Accuracy: 0.646484375\n",
      "Batch: 104, Loss: 1.1247197389602661, Accuracy: 0.6337890625\n",
      "Batch: 105, Loss: 1.175366997718811, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.1796363592147827, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.2056224346160889, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.1215603351593018, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.2028865814208984, Accuracy: 0.609375\n",
      "Batch: 110, Loss: 1.1834025382995605, Accuracy: 0.623046875\n",
      "Batch: 111, Loss: 1.114867925643921, Accuracy: 0.6328125\n",
      "Batch: 112, Loss: 1.0692832469940186, Accuracy: 0.65234375\n",
      "Batch: 113, Loss: 1.182928204536438, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.1598256826400757, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.1711621284484863, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.1247453689575195, Accuracy: 0.64453125\n",
      "Batch: 117, Loss: 1.1491804122924805, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 1.2254973649978638, Accuracy: 0.5888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 119, Loss: 1.2099356651306152, Accuracy: 0.595703125\n",
      "Batch: 120, Loss: 1.2843561172485352, Accuracy: 0.572265625\n",
      "Batch: 121, Loss: 1.1905875205993652, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.2296741008758545, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.2139387130737305, Accuracy: 0.6044921875\n",
      "Batch: 124, Loss: 1.2456872463226318, Accuracy: 0.6142578125\n",
      "Batch: 125, Loss: 1.1876786947250366, Accuracy: 0.6103515625\n",
      "Batch: 126, Loss: 1.2536922693252563, Accuracy: 0.6181640625\n",
      "Batch: 127, Loss: 1.2425516843795776, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.2769670486450195, Accuracy: 0.58203125\n",
      "Batch: 129, Loss: 1.1800510883331299, Accuracy: 0.6279296875\n",
      "Batch: 130, Loss: 1.1052128076553345, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.2542566061019897, Accuracy: 0.58984375\n",
      "Batch: 132, Loss: 1.1082683801651, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.1777229309082031, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.1169440746307373, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.0932884216308594, Accuracy: 0.6298828125\n",
      "Batch: 136, Loss: 1.0663505792617798, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.133838176727295, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.2013130187988281, Accuracy: 0.62109375\n",
      "Batch: 139, Loss: 1.1579307317733765, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.2321953773498535, Accuracy: 0.6279296875\n",
      "Batch: 141, Loss: 1.1763118505477905, Accuracy: 0.6123046875\n",
      "Batch: 142, Loss: 1.2096930742263794, Accuracy: 0.6064453125\n",
      "Batch: 143, Loss: 1.18190336227417, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.192250370979309, Accuracy: 0.61328125\n",
      "Batch: 145, Loss: 1.2408742904663086, Accuracy: 0.5869140625\n",
      "Batch: 146, Loss: 1.1981596946716309, Accuracy: 0.6005859375\n",
      "Batch: 147, Loss: 1.187760591506958, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1726707220077515, Accuracy: 0.6181640625\n",
      "Batch: 149, Loss: 1.2012131214141846, Accuracy: 0.5966796875\n",
      "Batch: 150, Loss: 1.1850011348724365, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.1422468423843384, Accuracy: 0.6357421875\n",
      "Batch: 152, Loss: 1.1475151777267456, Accuracy: 0.603515625\n",
      "Batch: 153, Loss: 1.1192100048065186, Accuracy: 0.6416015625\n",
      "Batch: 154, Loss: 1.1316239833831787, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.1381726264953613, Accuracy: 0.6337890625\n",
      "Epoch 493/200\n",
      "Batch: 1, Loss: 1.1772339344024658, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 1.0981566905975342, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.0221807956695557, Accuracy: 0.64453125\n",
      "Batch: 4, Loss: 1.055084228515625, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 1.0379146337509155, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.0427892208099365, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.0289113521575928, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 1.031195878982544, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 0.9673208594322205, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9437081217765808, Accuracy: 0.697265625\n",
      "Batch: 11, Loss: 0.9751628637313843, Accuracy: 0.677734375\n",
      "Batch: 12, Loss: 1.0128898620605469, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 1.0348403453826904, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 1.0265058279037476, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 0.9408531785011292, Accuracy: 0.6826171875\n",
      "Batch: 16, Loss: 1.045238733291626, Accuracy: 0.6513671875\n",
      "Batch: 17, Loss: 1.1202571392059326, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1933948993682861, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2220524549484253, Accuracy: 0.6181640625\n",
      "Batch: 20, Loss: 1.108066439628601, Accuracy: 0.6630859375\n",
      "Batch: 21, Loss: 1.0955168008804321, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.2266595363616943, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.1715281009674072, Accuracy: 0.6123046875\n",
      "Batch: 24, Loss: 1.1481846570968628, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.152475357055664, Accuracy: 0.6201171875\n",
      "Batch: 26, Loss: 1.1961989402770996, Accuracy: 0.5966796875\n",
      "Batch: 27, Loss: 1.1012935638427734, Accuracy: 0.6259765625\n",
      "Batch: 28, Loss: 1.0800645351409912, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.0989620685577393, Accuracy: 0.6435546875\n",
      "Batch: 30, Loss: 1.1376978158950806, Accuracy: 0.6357421875\n",
      "Batch: 31, Loss: 1.163564920425415, Accuracy: 0.623046875\n",
      "Batch: 32, Loss: 1.0428876876831055, Accuracy: 0.65625\n",
      "Batch: 33, Loss: 1.0111128091812134, Accuracy: 0.6845703125\n",
      "Batch: 34, Loss: 1.0223686695098877, Accuracy: 0.6767578125\n",
      "Batch: 35, Loss: 1.1361091136932373, Accuracy: 0.6181640625\n",
      "Batch: 36, Loss: 1.2350819110870361, Accuracy: 0.5849609375\n",
      "Batch: 37, Loss: 1.2329273223876953, Accuracy: 0.6005859375\n",
      "Batch: 38, Loss: 1.1257637739181519, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.1012221574783325, Accuracy: 0.6455078125\n",
      "Batch: 40, Loss: 1.1070549488067627, Accuracy: 0.6513671875\n",
      "Batch: 41, Loss: 1.0765241384506226, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 1.042626142501831, Accuracy: 0.6630859375\n",
      "Batch: 43, Loss: 1.0579888820648193, Accuracy: 0.6484375\n",
      "Batch: 44, Loss: 1.0737940073013306, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 1.033552885055542, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.1386218070983887, Accuracy: 0.619140625\n",
      "Batch: 47, Loss: 1.1196691989898682, Accuracy: 0.625\n",
      "Batch: 48, Loss: 1.1231212615966797, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.185939073562622, Accuracy: 0.5927734375\n",
      "Batch: 50, Loss: 1.119419813156128, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1790354251861572, Accuracy: 0.6103515625\n",
      "Batch: 52, Loss: 1.1914856433868408, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.1790447235107422, Accuracy: 0.615234375\n",
      "Batch: 54, Loss: 1.178427815437317, Accuracy: 0.6259765625\n",
      "Batch: 55, Loss: 1.0924811363220215, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.1390161514282227, Accuracy: 0.6318359375\n",
      "Batch: 57, Loss: 1.0865861177444458, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.1174955368041992, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 1.1142398118972778, Accuracy: 0.6455078125\n",
      "Batch: 60, Loss: 1.2546875476837158, Accuracy: 0.615234375\n",
      "Batch: 61, Loss: 1.1490178108215332, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1285110712051392, Accuracy: 0.64453125\n",
      "Batch: 63, Loss: 1.111985206604004, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.2134896516799927, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.2715184688568115, Accuracy: 0.5908203125\n",
      "Batch: 66, Loss: 1.1511266231536865, Accuracy: 0.630859375\n",
      "Batch: 67, Loss: 1.1669166088104248, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.0919711589813232, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.2029788494110107, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.203817367553711, Accuracy: 0.6123046875\n",
      "Batch: 71, Loss: 1.1964970827102661, Accuracy: 0.603515625\n",
      "Batch: 72, Loss: 1.194154977798462, Accuracy: 0.609375\n",
      "Batch: 73, Loss: 1.1741981506347656, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.1258289813995361, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.1144287586212158, Accuracy: 0.640625\n",
      "Batch: 76, Loss: 1.0301661491394043, Accuracy: 0.67578125\n",
      "Batch: 77, Loss: 1.0978878736495972, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.0876128673553467, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.1729226112365723, Accuracy: 0.638671875\n",
      "Batch: 80, Loss: 1.2276923656463623, Accuracy: 0.58203125\n",
      "Batch: 81, Loss: 1.0658471584320068, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.1728856563568115, Accuracy: 0.623046875\n",
      "Batch: 83, Loss: 1.197305679321289, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.1615259647369385, Accuracy: 0.623046875\n",
      "Batch: 85, Loss: 1.1692378520965576, Accuracy: 0.61328125\n",
      "Batch: 86, Loss: 1.2163289785385132, Accuracy: 0.5966796875\n",
      "Batch: 87, Loss: 1.1654162406921387, Accuracy: 0.609375\n",
      "Batch: 88, Loss: 1.1555497646331787, Accuracy: 0.6357421875\n",
      "Batch: 89, Loss: 1.178067922592163, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.1034271717071533, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.1513075828552246, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1174938678741455, Accuracy: 0.634765625\n",
      "Batch: 93, Loss: 1.1267279386520386, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.1729161739349365, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.2294834852218628, Accuracy: 0.5947265625\n",
      "Batch: 96, Loss: 1.220881700515747, Accuracy: 0.625\n",
      "Batch: 97, Loss: 1.1444199085235596, Accuracy: 0.6103515625\n",
      "Batch: 98, Loss: 1.1160253286361694, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.1856412887573242, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0675702095031738, Accuracy: 0.638671875\n",
      "Batch: 101, Loss: 1.0904031991958618, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.1723473072052002, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.1350314617156982, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 1.0983004570007324, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.210644245147705, Accuracy: 0.619140625\n",
      "Batch: 106, Loss: 1.2384992837905884, Accuracy: 0.595703125\n",
      "Batch: 107, Loss: 1.2756444215774536, Accuracy: 0.587890625\n",
      "Batch: 108, Loss: 1.1780073642730713, Accuracy: 0.603515625\n",
      "Batch: 109, Loss: 1.2045459747314453, Accuracy: 0.6015625\n",
      "Batch: 110, Loss: 1.2202377319335938, Accuracy: 0.5908203125\n",
      "Batch: 111, Loss: 1.1620382070541382, Accuracy: 0.623046875\n",
      "Batch: 112, Loss: 1.0719094276428223, Accuracy: 0.646484375\n",
      "Batch: 113, Loss: 1.1769306659698486, Accuracy: 0.6123046875\n",
      "Batch: 114, Loss: 1.1868435144424438, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.220930814743042, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1969964504241943, Accuracy: 0.6220703125\n",
      "Batch: 117, Loss: 1.1729466915130615, Accuracy: 0.6240234375\n",
      "Batch: 118, Loss: 1.2145663499832153, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.217398762702942, Accuracy: 0.6103515625\n",
      "Batch: 120, Loss: 1.2658271789550781, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.1708122491836548, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.2020747661590576, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.1857367753982544, Accuracy: 0.6328125\n",
      "Batch: 124, Loss: 1.2382097244262695, Accuracy: 0.603515625\n",
      "Batch: 125, Loss: 1.1659631729125977, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.182706356048584, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.1985456943511963, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.2317874431610107, Accuracy: 0.603515625\n",
      "Batch: 129, Loss: 1.2028834819793701, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.1878395080566406, Accuracy: 0.59765625\n",
      "Batch: 131, Loss: 1.2196159362792969, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.0839052200317383, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 1.1426420211791992, Accuracy: 0.6240234375\n",
      "Batch: 134, Loss: 1.1061638593673706, Accuracy: 0.63671875\n",
      "Batch: 135, Loss: 1.0970757007598877, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.0748083591461182, Accuracy: 0.65234375\n",
      "Batch: 137, Loss: 1.1713861227035522, Accuracy: 0.6259765625\n",
      "Batch: 138, Loss: 1.2282679080963135, Accuracy: 0.58203125\n",
      "Batch: 139, Loss: 1.214247703552246, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.2065342664718628, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1657118797302246, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.1724343299865723, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.1837449073791504, Accuracy: 0.6201171875\n",
      "Batch: 144, Loss: 1.2286386489868164, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.2823132276535034, Accuracy: 0.5703125\n",
      "Batch: 146, Loss: 1.177137851715088, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1755788326263428, Accuracy: 0.6318359375\n",
      "Batch: 148, Loss: 1.1958011388778687, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.1607434749603271, Accuracy: 0.609375\n",
      "Batch: 150, Loss: 1.1892024278640747, Accuracy: 0.6015625\n",
      "Batch: 151, Loss: 1.146695613861084, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.1227396726608276, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1271036863327026, Accuracy: 0.6142578125\n",
      "Batch: 154, Loss: 1.1363415718078613, Accuracy: 0.61328125\n",
      "Batch: 155, Loss: 1.0963752269744873, Accuracy: 0.6474609375\n",
      "Epoch 494/200\n",
      "Batch: 1, Loss: 1.1830724477767944, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 1.0825703144073486, Accuracy: 0.6455078125\n",
      "Batch: 3, Loss: 1.0164124965667725, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0554717779159546, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 0.9815530776977539, Accuracy: 0.6806640625\n",
      "Batch: 6, Loss: 1.0474634170532227, Accuracy: 0.6396484375\n",
      "Batch: 7, Loss: 1.0274357795715332, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 0.9931994676589966, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 0.9945276379585266, Accuracy: 0.654296875\n",
      "Batch: 10, Loss: 1.0074717998504639, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 0.9472610950469971, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 0.9766614437103271, Accuracy: 0.66015625\n",
      "Batch: 13, Loss: 1.016671895980835, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9846937656402588, Accuracy: 0.6787109375\n",
      "Batch: 15, Loss: 0.9591048955917358, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0150151252746582, Accuracy: 0.6806640625\n",
      "Batch: 17, Loss: 1.0963077545166016, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1117841005325317, Accuracy: 0.625\n",
      "Batch: 19, Loss: 1.137028455734253, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 1.0486528873443604, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.1027666330337524, Accuracy: 0.6494140625\n",
      "Batch: 22, Loss: 1.190049171447754, Accuracy: 0.6181640625\n",
      "Batch: 23, Loss: 1.168541669845581, Accuracy: 0.625\n",
      "Batch: 24, Loss: 1.1030924320220947, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.12039315700531, Accuracy: 0.6337890625\n",
      "Batch: 26, Loss: 1.162761926651001, Accuracy: 0.609375\n",
      "Batch: 27, Loss: 1.13275146484375, Accuracy: 0.6083984375\n",
      "Batch: 28, Loss: 1.0964165925979614, Accuracy: 0.642578125\n",
      "Batch: 29, Loss: 1.0597327947616577, Accuracy: 0.650390625\n",
      "Batch: 30, Loss: 1.1102123260498047, Accuracy: 0.6279296875\n",
      "Batch: 31, Loss: 1.1771597862243652, Accuracy: 0.6103515625\n",
      "Batch: 32, Loss: 1.026231288909912, Accuracy: 0.669921875\n",
      "Batch: 33, Loss: 0.9796954989433289, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.0876095294952393, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.131155014038086, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.233275055885315, Accuracy: 0.5859375\n",
      "Batch: 37, Loss: 1.2182986736297607, Accuracy: 0.591796875\n",
      "Batch: 38, Loss: 1.1260128021240234, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.0476977825164795, Accuracy: 0.65234375\n",
      "Batch: 40, Loss: 1.0981409549713135, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.1184498071670532, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.1002206802368164, Accuracy: 0.625\n",
      "Batch: 43, Loss: 0.9731502532958984, Accuracy: 0.6796875\n",
      "Batch: 44, Loss: 1.0305255651474, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0451195240020752, Accuracy: 0.640625\n",
      "Batch: 46, Loss: 1.180361032485962, Accuracy: 0.5947265625\n",
      "Batch: 47, Loss: 1.080782175064087, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.1314895153045654, Accuracy: 0.625\n",
      "Batch: 49, Loss: 1.1654036045074463, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.1331663131713867, Accuracy: 0.6201171875\n",
      "Batch: 51, Loss: 1.1461894512176514, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.2201833724975586, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1369643211364746, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.1561007499694824, Accuracy: 0.6220703125\n",
      "Batch: 55, Loss: 1.1355550289154053, Accuracy: 0.658203125\n",
      "Batch: 56, Loss: 1.1053022146224976, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.0782954692840576, Accuracy: 0.66796875\n",
      "Batch: 58, Loss: 1.1076648235321045, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.1029813289642334, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2289396524429321, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.1594244241714478, Accuracy: 0.6123046875\n",
      "Batch: 62, Loss: 1.1637907028198242, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.194021463394165, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.219203233718872, Accuracy: 0.5751953125\n",
      "Batch: 65, Loss: 1.1889705657958984, Accuracy: 0.62109375\n",
      "Batch: 66, Loss: 1.213334560394287, Accuracy: 0.6015625\n",
      "Batch: 67, Loss: 1.1782867908477783, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.0792567729949951, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.189600944519043, Accuracy: 0.626953125\n",
      "Batch: 70, Loss: 1.1936466693878174, Accuracy: 0.599609375\n",
      "Batch: 71, Loss: 1.1239752769470215, Accuracy: 0.6357421875\n",
      "Batch: 72, Loss: 1.183605670928955, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.1481566429138184, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.0629581212997437, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.0807485580444336, Accuracy: 0.6240234375\n",
      "Batch: 76, Loss: 1.0681785345077515, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0239579677581787, Accuracy: 0.67578125\n",
      "Batch: 78, Loss: 1.0788127183914185, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.1372774839401245, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.147432804107666, Accuracy: 0.6376953125\n",
      "Batch: 81, Loss: 1.0790231227874756, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 1.1494104862213135, Accuracy: 0.6279296875\n",
      "Batch: 83, Loss: 1.1780750751495361, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.1472289562225342, Accuracy: 0.6142578125\n",
      "Batch: 85, Loss: 1.1362172365188599, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1542205810546875, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.175572156906128, Accuracy: 0.6435546875\n",
      "Batch: 88, Loss: 1.1560800075531006, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 1.1250032186508179, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.1247365474700928, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.1274529695510864, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.124393343925476, Accuracy: 0.6416015625\n",
      "Batch: 93, Loss: 1.1288747787475586, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.1746227741241455, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.2067067623138428, Accuracy: 0.607421875\n",
      "Batch: 96, Loss: 1.1928225755691528, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.172736406326294, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.1526920795440674, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.146446704864502, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.0962791442871094, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.0921943187713623, Accuracy: 0.6572265625\n",
      "Batch: 102, Loss: 1.182595133781433, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.1509058475494385, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1698329448699951, Accuracy: 0.6142578125\n",
      "Batch: 105, Loss: 1.2443995475769043, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.149989366531372, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.230250358581543, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.1466424465179443, Accuracy: 0.60546875\n",
      "Batch: 109, Loss: 1.2188239097595215, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.1468615531921387, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1290943622589111, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.0900993347167969, Accuracy: 0.6337890625\n",
      "Batch: 113, Loss: 1.1835920810699463, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.1404712200164795, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.1522541046142578, Accuracy: 0.6171875\n",
      "Batch: 116, Loss: 1.1658263206481934, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.1378438472747803, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 1.205317735671997, Accuracy: 0.6162109375\n",
      "Batch: 119, Loss: 1.248356580734253, Accuracy: 0.59765625\n",
      "Batch: 120, Loss: 1.1916987895965576, Accuracy: 0.6162109375\n",
      "Batch: 121, Loss: 1.1512421369552612, Accuracy: 0.619140625\n",
      "Batch: 122, Loss: 1.2016160488128662, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.1471471786499023, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.1975260972976685, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.1559338569641113, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.1958014965057373, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.216615915298462, Accuracy: 0.6064453125\n",
      "Batch: 128, Loss: 1.228236198425293, Accuracy: 0.5927734375\n",
      "Batch: 129, Loss: 1.1820671558380127, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.162219762802124, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.2023429870605469, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.082958459854126, Accuracy: 0.6416015625\n",
      "Batch: 133, Loss: 1.2291812896728516, Accuracy: 0.6064453125\n",
      "Batch: 134, Loss: 1.1586953401565552, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.0183517932891846, Accuracy: 0.6806640625\n",
      "Batch: 136, Loss: 1.0782114267349243, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1355550289154053, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 1.182105541229248, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.1775832176208496, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.2601754665374756, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.1500380039215088, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.1796306371688843, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.1439746618270874, Accuracy: 0.646484375\n",
      "Batch: 144, Loss: 1.2264189720153809, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.3113007545471191, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.2228491306304932, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.1515841484069824, Accuracy: 0.6396484375\n",
      "Batch: 148, Loss: 1.2239692211151123, Accuracy: 0.6005859375\n",
      "Batch: 149, Loss: 1.1335124969482422, Accuracy: 0.6357421875\n",
      "Batch: 150, Loss: 1.1386632919311523, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1920216083526611, Accuracy: 0.6259765625\n",
      "Batch: 152, Loss: 1.1510121822357178, Accuracy: 0.6162109375\n",
      "Batch: 153, Loss: 1.1020147800445557, Accuracy: 0.6357421875\n",
      "Batch: 154, Loss: 1.1171014308929443, Accuracy: 0.6337890625\n",
      "Batch: 155, Loss: 1.1042879819869995, Accuracy: 0.625\n",
      "Epoch 495/200\n",
      "Batch: 1, Loss: 1.1955976486206055, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 0.9965378046035767, Accuracy: 0.6962890625\n",
      "Batch: 3, Loss: 1.0269098281860352, Accuracy: 0.650390625\n",
      "Batch: 4, Loss: 1.0429496765136719, Accuracy: 0.6552734375\n",
      "Batch: 5, Loss: 1.0345141887664795, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0318799018859863, Accuracy: 0.6806640625\n",
      "Batch: 7, Loss: 1.069298267364502, Accuracy: 0.6357421875\n",
      "Batch: 8, Loss: 1.0140814781188965, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 0.9664695858955383, Accuracy: 0.6806640625\n",
      "Batch: 10, Loss: 1.0028272867202759, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 0.9916685819625854, Accuracy: 0.67578125\n",
      "Batch: 12, Loss: 1.0248615741729736, Accuracy: 0.6708984375\n",
      "Batch: 13, Loss: 1.0066004991531372, Accuracy: 0.6708984375\n",
      "Batch: 14, Loss: 0.9954169392585754, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.978092610836029, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.0101088285446167, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.0124956369400024, Accuracy: 0.6787109375\n",
      "Batch: 18, Loss: 1.157959222793579, Accuracy: 0.6259765625\n",
      "Batch: 19, Loss: 1.2592833042144775, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.1245554685592651, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.109615683555603, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.2409049272537231, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.1863129138946533, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.1343634128570557, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.1796166896820068, Accuracy: 0.60546875\n",
      "Batch: 26, Loss: 1.1789251565933228, Accuracy: 0.619140625\n",
      "Batch: 27, Loss: 1.1468172073364258, Accuracy: 0.6240234375\n",
      "Batch: 28, Loss: 1.0918010473251343, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.104984998703003, Accuracy: 0.64453125\n",
      "Batch: 30, Loss: 1.1424980163574219, Accuracy: 0.630859375\n",
      "Batch: 31, Loss: 1.182419776916504, Accuracy: 0.6279296875\n",
      "Batch: 32, Loss: 1.0512449741363525, Accuracy: 0.669921875\n",
      "Batch: 33, Loss: 0.9869598150253296, Accuracy: 0.6826171875\n",
      "Batch: 34, Loss: 1.1040432453155518, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.1006035804748535, Accuracy: 0.6337890625\n",
      "Batch: 36, Loss: 1.1525437831878662, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.1923948526382446, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.1871212720870972, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.0529284477233887, Accuracy: 0.66796875\n",
      "Batch: 40, Loss: 1.1081976890563965, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.166187047958374, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.0691713094711304, Accuracy: 0.6494140625\n",
      "Batch: 43, Loss: 1.078998327255249, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.0247714519500732, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.067861557006836, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 1.1593011617660522, Accuracy: 0.6181640625\n",
      "Batch: 47, Loss: 1.0887985229492188, Accuracy: 0.6435546875\n",
      "Batch: 48, Loss: 1.1519924402236938, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.133548617362976, Accuracy: 0.630859375\n",
      "Batch: 50, Loss: 1.142594814300537, Accuracy: 0.646484375\n",
      "Batch: 51, Loss: 1.1764684915542603, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2499034404754639, Accuracy: 0.5927734375\n",
      "Batch: 53, Loss: 1.1307718753814697, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.1714906692504883, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.1089718341827393, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.1270415782928467, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.126368522644043, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.1685441732406616, Accuracy: 0.619140625\n",
      "Batch: 59, Loss: 1.0582826137542725, Accuracy: 0.6435546875\n",
      "Batch: 60, Loss: 1.196307897567749, Accuracy: 0.6142578125\n",
      "Batch: 61, Loss: 1.1819766759872437, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.133710503578186, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1721960306167603, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.2133371829986572, Accuracy: 0.5908203125\n",
      "Batch: 65, Loss: 1.2123761177062988, Accuracy: 0.6005859375\n",
      "Batch: 66, Loss: 1.208158016204834, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.1691009998321533, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.1167540550231934, Accuracy: 0.6328125\n",
      "Batch: 69, Loss: 1.1941227912902832, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.2059345245361328, Accuracy: 0.6083984375\n",
      "Batch: 71, Loss: 1.1877481937408447, Accuracy: 0.6201171875\n",
      "Batch: 72, Loss: 1.2002795934677124, Accuracy: 0.6142578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73, Loss: 1.250548243522644, Accuracy: 0.583984375\n",
      "Batch: 74, Loss: 1.1317392587661743, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.1227649450302124, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.0729496479034424, Accuracy: 0.6474609375\n",
      "Batch: 77, Loss: 1.1324565410614014, Accuracy: 0.6416015625\n",
      "Batch: 78, Loss: 1.0671387910842896, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1427178382873535, Accuracy: 0.6337890625\n",
      "Batch: 80, Loss: 1.167294979095459, Accuracy: 0.615234375\n",
      "Batch: 81, Loss: 1.1008832454681396, Accuracy: 0.6455078125\n",
      "Batch: 82, Loss: 1.1586418151855469, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.1833984851837158, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.1685566902160645, Accuracy: 0.64453125\n",
      "Batch: 85, Loss: 1.234940528869629, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.1499253511428833, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.2048332691192627, Accuracy: 0.6240234375\n",
      "Batch: 88, Loss: 1.1111342906951904, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1943697929382324, Accuracy: 0.626953125\n",
      "Batch: 90, Loss: 1.1235103607177734, Accuracy: 0.6396484375\n",
      "Batch: 91, Loss: 1.1226894855499268, Accuracy: 0.6259765625\n",
      "Batch: 92, Loss: 1.0995121002197266, Accuracy: 0.6669921875\n",
      "Batch: 93, Loss: 1.2158031463623047, Accuracy: 0.6064453125\n",
      "Batch: 94, Loss: 1.1979634761810303, Accuracy: 0.6123046875\n",
      "Batch: 95, Loss: 1.1928071975708008, Accuracy: 0.625\n",
      "Batch: 96, Loss: 1.2271075248718262, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.180356740951538, Accuracy: 0.6142578125\n",
      "Batch: 98, Loss: 1.133967638015747, Accuracy: 0.6357421875\n",
      "Batch: 99, Loss: 1.1799341440200806, Accuracy: 0.607421875\n",
      "Batch: 100, Loss: 1.0641777515411377, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.1228909492492676, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.1775599718093872, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.1863911151885986, Accuracy: 0.6142578125\n",
      "Batch: 104, Loss: 1.1928777694702148, Accuracy: 0.6162109375\n",
      "Batch: 105, Loss: 1.1882777214050293, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.189422607421875, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.2450916767120361, Accuracy: 0.58984375\n",
      "Batch: 108, Loss: 1.1970031261444092, Accuracy: 0.6064453125\n",
      "Batch: 109, Loss: 1.1740226745605469, Accuracy: 0.609375\n",
      "Batch: 110, Loss: 1.1613445281982422, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.088106632232666, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.1280066967010498, Accuracy: 0.630859375\n",
      "Batch: 113, Loss: 1.1435656547546387, Accuracy: 0.625\n",
      "Batch: 114, Loss: 1.177125334739685, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.173421859741211, Accuracy: 0.6298828125\n",
      "Batch: 116, Loss: 1.1887375116348267, Accuracy: 0.6181640625\n",
      "Batch: 117, Loss: 1.12191641330719, Accuracy: 0.634765625\n",
      "Batch: 118, Loss: 1.209049105644226, Accuracy: 0.58984375\n",
      "Batch: 119, Loss: 1.237865924835205, Accuracy: 0.59375\n",
      "Batch: 120, Loss: 1.2578611373901367, Accuracy: 0.6005859375\n",
      "Batch: 121, Loss: 1.1813409328460693, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.2474381923675537, Accuracy: 0.6171875\n",
      "Batch: 123, Loss: 1.1491649150848389, Accuracy: 0.6484375\n",
      "Batch: 124, Loss: 1.1976635456085205, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.2020690441131592, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.2636542320251465, Accuracy: 0.591796875\n",
      "Batch: 127, Loss: 1.3308066129684448, Accuracy: 0.568359375\n",
      "Batch: 128, Loss: 1.147743821144104, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1730396747589111, Accuracy: 0.6279296875\n",
      "Batch: 130, Loss: 1.1280791759490967, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.2311232089996338, Accuracy: 0.595703125\n",
      "Batch: 132, Loss: 1.0963689088821411, Accuracy: 0.6337890625\n",
      "Batch: 133, Loss: 1.161912202835083, Accuracy: 0.6484375\n",
      "Batch: 134, Loss: 1.1731233596801758, Accuracy: 0.6123046875\n",
      "Batch: 135, Loss: 1.082160234451294, Accuracy: 0.654296875\n",
      "Batch: 136, Loss: 1.0793726444244385, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.1456294059753418, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.217270851135254, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.2451122999191284, Accuracy: 0.6162109375\n",
      "Batch: 140, Loss: 1.2590818405151367, Accuracy: 0.58984375\n",
      "Batch: 141, Loss: 1.1799018383026123, Accuracy: 0.6181640625\n",
      "Batch: 142, Loss: 1.201446533203125, Accuracy: 0.611328125\n",
      "Batch: 143, Loss: 1.1952931880950928, Accuracy: 0.6220703125\n",
      "Batch: 144, Loss: 1.2202303409576416, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.2681435346603394, Accuracy: 0.60546875\n",
      "Batch: 146, Loss: 1.220634937286377, Accuracy: 0.59765625\n",
      "Batch: 147, Loss: 1.199880599975586, Accuracy: 0.6064453125\n",
      "Batch: 148, Loss: 1.2443798780441284, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.2332763671875, Accuracy: 0.5908203125\n",
      "Batch: 150, Loss: 1.1565771102905273, Accuracy: 0.6162109375\n",
      "Batch: 151, Loss: 1.1407116651535034, Accuracy: 0.62890625\n",
      "Batch: 152, Loss: 1.168735384941101, Accuracy: 0.6171875\n",
      "Batch: 153, Loss: 1.1781247854232788, Accuracy: 0.619140625\n",
      "Batch: 154, Loss: 1.0688525438308716, Accuracy: 0.65234375\n",
      "Batch: 155, Loss: 1.1348493099212646, Accuracy: 0.6337890625\n",
      "Epoch 496/200\n",
      "Batch: 1, Loss: 1.2283039093017578, Accuracy: 0.6484375\n",
      "Batch: 2, Loss: 1.0498720407485962, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0096008777618408, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.0930836200714111, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 0.9699231386184692, Accuracy: 0.681640625\n",
      "Batch: 6, Loss: 1.0577257871627808, Accuracy: 0.646484375\n",
      "Batch: 7, Loss: 1.0395203828811646, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.953446626663208, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 1.0295079946517944, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.968011200428009, Accuracy: 0.689453125\n",
      "Batch: 11, Loss: 0.9760102033615112, Accuracy: 0.6728515625\n",
      "Batch: 12, Loss: 1.00457763671875, Accuracy: 0.6728515625\n",
      "Batch: 13, Loss: 1.0110094547271729, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 0.9783055782318115, Accuracy: 0.6689453125\n",
      "Batch: 15, Loss: 0.9074006080627441, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 1.0534894466400146, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.0852265357971191, Accuracy: 0.640625\n",
      "Batch: 18, Loss: 1.1154334545135498, Accuracy: 0.626953125\n",
      "Batch: 19, Loss: 1.2509772777557373, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.0950369834899902, Accuracy: 0.642578125\n",
      "Batch: 21, Loss: 1.1066603660583496, Accuracy: 0.630859375\n",
      "Batch: 22, Loss: 1.2092229127883911, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.224745750427246, Accuracy: 0.6171875\n",
      "Batch: 24, Loss: 1.0862727165222168, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.1035624742507935, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.1728086471557617, Accuracy: 0.61328125\n",
      "Batch: 27, Loss: 1.0809632539749146, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.0787259340286255, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.0705870389938354, Accuracy: 0.6494140625\n",
      "Batch: 30, Loss: 1.1865110397338867, Accuracy: 0.609375\n",
      "Batch: 31, Loss: 1.2663538455963135, Accuracy: 0.5771484375\n",
      "Batch: 32, Loss: 1.0403776168823242, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 0.9754039645195007, Accuracy: 0.6767578125\n",
      "Batch: 34, Loss: 1.1308062076568604, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 1.1477291584014893, Accuracy: 0.6162109375\n",
      "Batch: 36, Loss: 1.2205311059951782, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.2710037231445312, Accuracy: 0.583984375\n",
      "Batch: 38, Loss: 1.2208406925201416, Accuracy: 0.59765625\n",
      "Batch: 39, Loss: 1.0895253419876099, Accuracy: 0.6552734375\n",
      "Batch: 40, Loss: 1.0864653587341309, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.07810640335083, Accuracy: 0.6474609375\n",
      "Batch: 42, Loss: 1.0777101516723633, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.0434048175811768, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0544583797454834, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.0695244073867798, Accuracy: 0.65625\n",
      "Batch: 46, Loss: 1.1203696727752686, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.1186244487762451, Accuracy: 0.62890625\n",
      "Batch: 48, Loss: 1.1572822332382202, Accuracy: 0.642578125\n",
      "Batch: 49, Loss: 1.1792223453521729, Accuracy: 0.6220703125\n",
      "Batch: 50, Loss: 1.1286039352416992, Accuracy: 0.6416015625\n",
      "Batch: 51, Loss: 1.1418077945709229, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.2342569828033447, Accuracy: 0.59375\n",
      "Batch: 53, Loss: 1.1262898445129395, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.2046189308166504, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.1645747423171997, Accuracy: 0.6318359375\n",
      "Batch: 56, Loss: 1.0941588878631592, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.1344795227050781, Accuracy: 0.6376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.1049425601959229, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.0836693048477173, Accuracy: 0.662109375\n",
      "Batch: 60, Loss: 1.2592403888702393, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.229781985282898, Accuracy: 0.5908203125\n",
      "Batch: 62, Loss: 1.2248260974884033, Accuracy: 0.59375\n",
      "Batch: 63, Loss: 1.1583188772201538, Accuracy: 0.6142578125\n",
      "Batch: 64, Loss: 1.180976152420044, Accuracy: 0.630859375\n",
      "Batch: 65, Loss: 1.1758644580841064, Accuracy: 0.6123046875\n",
      "Batch: 66, Loss: 1.1638227701187134, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.1390206813812256, Accuracy: 0.6494140625\n",
      "Batch: 68, Loss: 1.1234138011932373, Accuracy: 0.630859375\n",
      "Batch: 69, Loss: 1.1839675903320312, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.1958768367767334, Accuracy: 0.61328125\n",
      "Batch: 71, Loss: 1.0804784297943115, Accuracy: 0.6513671875\n",
      "Batch: 72, Loss: 1.1942007541656494, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.19382905960083, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.092881441116333, Accuracy: 0.6318359375\n",
      "Batch: 75, Loss: 1.1097753047943115, Accuracy: 0.6318359375\n",
      "Batch: 76, Loss: 1.0423128604888916, Accuracy: 0.6494140625\n",
      "Batch: 77, Loss: 1.080114483833313, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0924358367919922, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1529567241668701, Accuracy: 0.6298828125\n",
      "Batch: 80, Loss: 1.163477897644043, Accuracy: 0.6201171875\n",
      "Batch: 81, Loss: 1.0901024341583252, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.1295044422149658, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.1976544857025146, Accuracy: 0.63671875\n",
      "Batch: 84, Loss: 1.1401989459991455, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.2391724586486816, Accuracy: 0.603515625\n",
      "Batch: 86, Loss: 1.216259241104126, Accuracy: 0.61328125\n",
      "Batch: 87, Loss: 1.1719461679458618, Accuracy: 0.615234375\n",
      "Batch: 88, Loss: 1.1776058673858643, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1792898178100586, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.1319682598114014, Accuracy: 0.61328125\n",
      "Batch: 91, Loss: 1.1255428791046143, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.173107385635376, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.1766581535339355, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.207840085029602, Accuracy: 0.6181640625\n",
      "Batch: 95, Loss: 1.146228551864624, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.199736475944519, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.2233445644378662, Accuracy: 0.5869140625\n",
      "Batch: 98, Loss: 1.1307400465011597, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.1681673526763916, Accuracy: 0.6220703125\n",
      "Batch: 100, Loss: 1.0826668739318848, Accuracy: 0.6650390625\n",
      "Batch: 101, Loss: 1.1109130382537842, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.2311058044433594, Accuracy: 0.5966796875\n",
      "Batch: 103, Loss: 1.2032256126403809, Accuracy: 0.634765625\n",
      "Batch: 104, Loss: 1.185655951499939, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.2826766967773438, Accuracy: 0.5888671875\n",
      "Batch: 106, Loss: 1.1700375080108643, Accuracy: 0.640625\n",
      "Batch: 107, Loss: 1.2558554410934448, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.168962836265564, Accuracy: 0.626953125\n",
      "Batch: 109, Loss: 1.1849439144134521, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 1.1461812257766724, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1421422958374023, Accuracy: 0.6240234375\n",
      "Batch: 112, Loss: 1.0988291501998901, Accuracy: 0.6572265625\n",
      "Batch: 113, Loss: 1.1955807209014893, Accuracy: 0.5966796875\n",
      "Batch: 114, Loss: 1.203345537185669, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.2091615200042725, Accuracy: 0.59375\n",
      "Batch: 116, Loss: 1.2423046827316284, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.205155611038208, Accuracy: 0.5986328125\n",
      "Batch: 118, Loss: 1.2276208400726318, Accuracy: 0.591796875\n",
      "Batch: 119, Loss: 1.2910404205322266, Accuracy: 0.5888671875\n",
      "Batch: 120, Loss: 1.2193174362182617, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.201341152191162, Accuracy: 0.6279296875\n",
      "Batch: 122, Loss: 1.2290602922439575, Accuracy: 0.6064453125\n",
      "Batch: 123, Loss: 1.189331293106079, Accuracy: 0.6005859375\n",
      "Batch: 124, Loss: 1.2229759693145752, Accuracy: 0.5966796875\n",
      "Batch: 125, Loss: 1.1550936698913574, Accuracy: 0.62890625\n",
      "Batch: 126, Loss: 1.242411732673645, Accuracy: 0.5888671875\n",
      "Batch: 127, Loss: 1.3097786903381348, Accuracy: 0.55078125\n",
      "Batch: 128, Loss: 1.2155932188034058, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.2404109239578247, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.1447954177856445, Accuracy: 0.623046875\n",
      "Batch: 131, Loss: 1.253716230392456, Accuracy: 0.5947265625\n",
      "Batch: 132, Loss: 1.0740830898284912, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.1134560108184814, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.0922234058380127, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 1.054461121559143, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.1109353303909302, Accuracy: 0.6240234375\n",
      "Batch: 137, Loss: 1.1359814405441284, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.270159125328064, Accuracy: 0.6025390625\n",
      "Batch: 139, Loss: 1.2061936855316162, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.229583978652954, Accuracy: 0.5947265625\n",
      "Batch: 141, Loss: 1.147714614868164, Accuracy: 0.64453125\n",
      "Batch: 142, Loss: 1.1890714168548584, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.209389090538025, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.2591662406921387, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.2672903537750244, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.13213050365448, Accuracy: 0.6474609375\n",
      "Batch: 147, Loss: 1.211291790008545, Accuracy: 0.619140625\n",
      "Batch: 148, Loss: 1.1880017518997192, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.1528310775756836, Accuracy: 0.634765625\n",
      "Batch: 150, Loss: 1.1815986633300781, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.1460559368133545, Accuracy: 0.6484375\n",
      "Batch: 152, Loss: 1.2023670673370361, Accuracy: 0.5986328125\n",
      "Batch: 153, Loss: 1.0906143188476562, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.1319799423217773, Accuracy: 0.6298828125\n",
      "Batch: 155, Loss: 1.1125354766845703, Accuracy: 0.6494140625\n",
      "Epoch 497/200\n",
      "Batch: 1, Loss: 1.2438019514083862, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 1.0951602458953857, Accuracy: 0.638671875\n",
      "Batch: 3, Loss: 0.9961593151092529, Accuracy: 0.669921875\n",
      "Batch: 4, Loss: 1.0919444561004639, Accuracy: 0.6416015625\n",
      "Batch: 5, Loss: 1.0513942241668701, Accuracy: 0.6650390625\n",
      "Batch: 6, Loss: 1.0666089057922363, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.0762708187103271, Accuracy: 0.6572265625\n",
      "Batch: 8, Loss: 1.0558569431304932, Accuracy: 0.650390625\n",
      "Batch: 9, Loss: 0.9853535294532776, Accuracy: 0.6904296875\n",
      "Batch: 10, Loss: 0.9716343879699707, Accuracy: 0.669921875\n",
      "Batch: 11, Loss: 0.9694446325302124, Accuracy: 0.6552734375\n",
      "Batch: 12, Loss: 1.0283312797546387, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.0149959325790405, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 0.9843417406082153, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.974689781665802, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 1.029611587524414, Accuracy: 0.65625\n",
      "Batch: 17, Loss: 1.071101427078247, Accuracy: 0.640625\n",
      "Batch: 18, Loss: 1.097704291343689, Accuracy: 0.6396484375\n",
      "Batch: 19, Loss: 1.2302519083023071, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0739240646362305, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.1256308555603027, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.2119323015213013, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.2404686212539673, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.1577914953231812, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1472792625427246, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.192512035369873, Accuracy: 0.6123046875\n",
      "Batch: 27, Loss: 1.1923964023590088, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.0745081901550293, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.0548932552337646, Accuracy: 0.62109375\n",
      "Batch: 30, Loss: 1.120398759841919, Accuracy: 0.62890625\n",
      "Batch: 31, Loss: 1.1789350509643555, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0630842447280884, Accuracy: 0.646484375\n",
      "Batch: 33, Loss: 1.0496859550476074, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.0699591636657715, Accuracy: 0.669921875\n",
      "Batch: 35, Loss: 1.0831588506698608, Accuracy: 0.654296875\n",
      "Batch: 36, Loss: 1.1860599517822266, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.1899957656860352, Accuracy: 0.611328125\n",
      "Batch: 38, Loss: 1.2107480764389038, Accuracy: 0.603515625\n",
      "Batch: 39, Loss: 1.1383302211761475, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.0997623205184937, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.1443843841552734, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 42, Loss: 1.0829973220825195, Accuracy: 0.640625\n",
      "Batch: 43, Loss: 1.0820081233978271, Accuracy: 0.64453125\n",
      "Batch: 44, Loss: 1.0505740642547607, Accuracy: 0.658203125\n",
      "Batch: 45, Loss: 1.0362913608551025, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.1622791290283203, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.1265100240707397, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.157600998878479, Accuracy: 0.5986328125\n",
      "Batch: 49, Loss: 1.1120882034301758, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.1147948503494263, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.2019739151000977, Accuracy: 0.583984375\n",
      "Batch: 52, Loss: 1.2572369575500488, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.151877522468567, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.2046167850494385, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.1147600412368774, Accuracy: 0.646484375\n",
      "Batch: 56, Loss: 1.166638970375061, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.126072645187378, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.158308982849121, Accuracy: 0.6240234375\n",
      "Batch: 59, Loss: 1.1472232341766357, Accuracy: 0.6259765625\n",
      "Batch: 60, Loss: 1.29150390625, Accuracy: 0.57421875\n",
      "Batch: 61, Loss: 1.1853790283203125, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.12575364112854, Accuracy: 0.650390625\n",
      "Batch: 63, Loss: 1.1843392848968506, Accuracy: 0.6171875\n",
      "Batch: 64, Loss: 1.264045000076294, Accuracy: 0.595703125\n",
      "Batch: 65, Loss: 1.2142589092254639, Accuracy: 0.6083984375\n",
      "Batch: 66, Loss: 1.1309869289398193, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.1559569835662842, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.1197863817214966, Accuracy: 0.6318359375\n",
      "Batch: 69, Loss: 1.1588568687438965, Accuracy: 0.6357421875\n",
      "Batch: 70, Loss: 1.1878622770309448, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.148890495300293, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.2282472848892212, Accuracy: 0.62109375\n",
      "Batch: 73, Loss: 1.2117750644683838, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.0724331140518188, Accuracy: 0.6787109375\n",
      "Batch: 75, Loss: 1.0931472778320312, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.0574207305908203, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.0799856185913086, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 1.0696545839309692, Accuracy: 0.6357421875\n",
      "Batch: 79, Loss: 1.1301157474517822, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.1685512065887451, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.1186332702636719, Accuracy: 0.626953125\n",
      "Batch: 82, Loss: 1.1516869068145752, Accuracy: 0.6220703125\n",
      "Batch: 83, Loss: 1.2466344833374023, Accuracy: 0.609375\n",
      "Batch: 84, Loss: 1.1373807191848755, Accuracy: 0.62109375\n",
      "Batch: 85, Loss: 1.1840518712997437, Accuracy: 0.60546875\n",
      "Batch: 86, Loss: 1.1958436965942383, Accuracy: 0.6025390625\n",
      "Batch: 87, Loss: 1.174851655960083, Accuracy: 0.63671875\n",
      "Batch: 88, Loss: 1.145707130432129, Accuracy: 0.6201171875\n",
      "Batch: 89, Loss: 1.1253812313079834, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.0911335945129395, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.148313045501709, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1438511610031128, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.1103912591934204, Accuracy: 0.638671875\n",
      "Batch: 94, Loss: 1.1992084980010986, Accuracy: 0.6171875\n",
      "Batch: 95, Loss: 1.1981416940689087, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.1467840671539307, Accuracy: 0.6533203125\n",
      "Batch: 97, Loss: 1.1919357776641846, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.123819351196289, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.1052191257476807, Accuracy: 0.64453125\n",
      "Batch: 100, Loss: 1.070708155632019, Accuracy: 0.6416015625\n",
      "Batch: 101, Loss: 1.081275224685669, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.1680400371551514, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.1647889614105225, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.1543101072311401, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.1888569593429565, Accuracy: 0.6162109375\n",
      "Batch: 106, Loss: 1.1834527254104614, Accuracy: 0.6376953125\n",
      "Batch: 107, Loss: 1.1903347969055176, Accuracy: 0.611328125\n",
      "Batch: 108, Loss: 1.1728618144989014, Accuracy: 0.6220703125\n",
      "Batch: 109, Loss: 1.231209397315979, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 1.0915285348892212, Accuracy: 0.6494140625\n",
      "Batch: 111, Loss: 1.1489505767822266, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.1458675861358643, Accuracy: 0.619140625\n",
      "Batch: 113, Loss: 1.1886898279190063, Accuracy: 0.61328125\n",
      "Batch: 114, Loss: 1.1802561283111572, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2158843278884888, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.1586415767669678, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1480913162231445, Accuracy: 0.638671875\n",
      "Batch: 118, Loss: 1.2384347915649414, Accuracy: 0.6064453125\n",
      "Batch: 119, Loss: 1.2493922710418701, Accuracy: 0.603515625\n",
      "Batch: 120, Loss: 1.2922065258026123, Accuracy: 0.5830078125\n",
      "Batch: 121, Loss: 1.2229297161102295, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.2731692790985107, Accuracy: 0.5927734375\n",
      "Batch: 123, Loss: 1.2043664455413818, Accuracy: 0.6201171875\n",
      "Batch: 124, Loss: 1.2034614086151123, Accuracy: 0.6025390625\n",
      "Batch: 125, Loss: 1.1697860956192017, Accuracy: 0.63671875\n",
      "Batch: 126, Loss: 1.2455006837844849, Accuracy: 0.6083984375\n",
      "Batch: 127, Loss: 1.2903763055801392, Accuracy: 0.5849609375\n",
      "Batch: 128, Loss: 1.2127716541290283, Accuracy: 0.609375\n",
      "Batch: 129, Loss: 1.162095308303833, Accuracy: 0.615234375\n",
      "Batch: 130, Loss: 1.1080199480056763, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.2354931831359863, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.0809087753295898, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.1566524505615234, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.1073634624481201, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 1.045182466506958, Accuracy: 0.658203125\n",
      "Batch: 136, Loss: 1.0865027904510498, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.176025390625, Accuracy: 0.638671875\n",
      "Batch: 138, Loss: 1.2288901805877686, Accuracy: 0.599609375\n",
      "Batch: 139, Loss: 1.2445569038391113, Accuracy: 0.6064453125\n",
      "Batch: 140, Loss: 1.238520622253418, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.1333394050598145, Accuracy: 0.6416015625\n",
      "Batch: 142, Loss: 1.1950857639312744, Accuracy: 0.62890625\n",
      "Batch: 143, Loss: 1.2207024097442627, Accuracy: 0.5908203125\n",
      "Batch: 144, Loss: 1.2821969985961914, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.2794082164764404, Accuracy: 0.583984375\n",
      "Batch: 146, Loss: 1.162797451019287, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.2397758960723877, Accuracy: 0.5986328125\n",
      "Batch: 148, Loss: 1.2469122409820557, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.2124056816101074, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1527135372161865, Accuracy: 0.625\n",
      "Batch: 151, Loss: 1.1712969541549683, Accuracy: 0.625\n",
      "Batch: 152, Loss: 1.1552560329437256, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1264712810516357, Accuracy: 0.662109375\n",
      "Batch: 154, Loss: 1.1043970584869385, Accuracy: 0.6455078125\n",
      "Batch: 155, Loss: 1.1094452142715454, Accuracy: 0.638671875\n",
      "Epoch 498/200\n",
      "Batch: 1, Loss: 1.2212755680084229, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.1175408363342285, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 1.0132715702056885, Accuracy: 0.68359375\n",
      "Batch: 4, Loss: 1.0520272254943848, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 0.9912036657333374, Accuracy: 0.662109375\n",
      "Batch: 6, Loss: 1.1090424060821533, Accuracy: 0.6396484375\n",
      "Batch: 7, Loss: 1.0291720628738403, Accuracy: 0.666015625\n",
      "Batch: 8, Loss: 1.045642614364624, Accuracy: 0.6650390625\n",
      "Batch: 9, Loss: 1.0189753770828247, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 0.943427324295044, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 0.9558804035186768, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 1.0250849723815918, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.0103214979171753, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 0.9871249198913574, Accuracy: 0.6953125\n",
      "Batch: 15, Loss: 0.953848123550415, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0499165058135986, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0646439790725708, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1236363649368286, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.1780002117156982, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0616484880447388, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.03706693649292, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.2082905769348145, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.2191903591156006, Accuracy: 0.6201171875\n",
      "Batch: 24, Loss: 1.1599822044372559, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.1298078298568726, Accuracy: 0.6474609375\n",
      "Batch: 26, Loss: 1.162917971611023, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 1.1210577487945557, Accuracy: 0.6181640625\n",
      "Batch: 28, Loss: 1.1071363687515259, Accuracy: 0.623046875\n",
      "Batch: 29, Loss: 1.079230546951294, Accuracy: 0.638671875\n",
      "Batch: 30, Loss: 1.161928653717041, Accuracy: 0.6142578125\n",
      "Batch: 31, Loss: 1.1477422714233398, Accuracy: 0.6181640625\n",
      "Batch: 32, Loss: 1.0114881992340088, Accuracy: 0.677734375\n",
      "Batch: 33, Loss: 0.9818699359893799, Accuracy: 0.6748046875\n",
      "Batch: 34, Loss: 1.0497767925262451, Accuracy: 0.6640625\n",
      "Batch: 35, Loss: 1.143243670463562, Accuracy: 0.60546875\n",
      "Batch: 36, Loss: 1.2262581586837769, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.192434549331665, Accuracy: 0.623046875\n",
      "Batch: 38, Loss: 1.1674466133117676, Accuracy: 0.61328125\n",
      "Batch: 39, Loss: 1.0578758716583252, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.1179673671722412, Accuracy: 0.640625\n",
      "Batch: 41, Loss: 1.1011688709259033, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 1.058701515197754, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.0613539218902588, Accuracy: 0.6357421875\n",
      "Batch: 44, Loss: 1.0886900424957275, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.0656061172485352, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.1162238121032715, Accuracy: 0.625\n",
      "Batch: 47, Loss: 1.0908656120300293, Accuracy: 0.6318359375\n",
      "Batch: 48, Loss: 1.1059484481811523, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1040117740631104, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.1297316551208496, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.12209153175354, Accuracy: 0.6123046875\n",
      "Batch: 52, Loss: 1.2420270442962646, Accuracy: 0.5927734375\n",
      "Batch: 53, Loss: 1.1425565481185913, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.207040786743164, Accuracy: 0.61328125\n",
      "Batch: 55, Loss: 1.1036430597305298, Accuracy: 0.6572265625\n",
      "Batch: 56, Loss: 1.0746257305145264, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.0987035036087036, Accuracy: 0.6337890625\n",
      "Batch: 58, Loss: 1.115006685256958, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.1095517873764038, Accuracy: 0.6396484375\n",
      "Batch: 60, Loss: 1.2638218402862549, Accuracy: 0.5849609375\n",
      "Batch: 61, Loss: 1.1268762350082397, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1956291198730469, Accuracy: 0.615234375\n",
      "Batch: 63, Loss: 1.1654689311981201, Accuracy: 0.62890625\n",
      "Batch: 64, Loss: 1.1820273399353027, Accuracy: 0.615234375\n",
      "Batch: 65, Loss: 1.193047285079956, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.125449538230896, Accuracy: 0.638671875\n",
      "Batch: 67, Loss: 1.1570231914520264, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.1186845302581787, Accuracy: 0.6435546875\n",
      "Batch: 69, Loss: 1.1919516324996948, Accuracy: 0.62890625\n",
      "Batch: 70, Loss: 1.15751314163208, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1389672756195068, Accuracy: 0.6298828125\n",
      "Batch: 72, Loss: 1.173065423965454, Accuracy: 0.6181640625\n",
      "Batch: 73, Loss: 1.1587369441986084, Accuracy: 0.6220703125\n",
      "Batch: 74, Loss: 1.1089534759521484, Accuracy: 0.6533203125\n",
      "Batch: 75, Loss: 1.137970209121704, Accuracy: 0.6376953125\n",
      "Batch: 76, Loss: 1.0697920322418213, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 0.9950920939445496, Accuracy: 0.6611328125\n",
      "Batch: 78, Loss: 1.1010515689849854, Accuracy: 0.6298828125\n",
      "Batch: 79, Loss: 1.1866588592529297, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.1277527809143066, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.1299703121185303, Accuracy: 0.623046875\n",
      "Batch: 82, Loss: 1.1646729707717896, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.1867420673370361, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.1364532709121704, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.123871922492981, Accuracy: 0.6298828125\n",
      "Batch: 86, Loss: 1.121382236480713, Accuracy: 0.640625\n",
      "Batch: 87, Loss: 1.1608165502548218, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.1962604522705078, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.148168683052063, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.0578333139419556, Accuracy: 0.6572265625\n",
      "Batch: 91, Loss: 1.0852817296981812, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.1255085468292236, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.1334083080291748, Accuracy: 0.638671875\n",
      "Batch: 94, Loss: 1.1923930644989014, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.2000095844268799, Accuracy: 0.5947265625\n",
      "Batch: 96, Loss: 1.1836895942687988, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.2070682048797607, Accuracy: 0.6064453125\n",
      "Batch: 98, Loss: 1.1099601984024048, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.1861302852630615, Accuracy: 0.62109375\n",
      "Batch: 100, Loss: 1.0708858966827393, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.1239008903503418, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.2096889019012451, Accuracy: 0.611328125\n",
      "Batch: 103, Loss: 1.1760270595550537, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.1162896156311035, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.1801906824111938, Accuracy: 0.607421875\n",
      "Batch: 106, Loss: 1.1015119552612305, Accuracy: 0.6337890625\n",
      "Batch: 107, Loss: 1.229716420173645, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.1524732112884521, Accuracy: 0.6123046875\n",
      "Batch: 109, Loss: 1.1587703227996826, Accuracy: 0.6435546875\n",
      "Batch: 110, Loss: 1.0911827087402344, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.091925024986267, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.1025009155273438, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.1512134075164795, Accuracy: 0.625\n",
      "Batch: 114, Loss: 1.148047924041748, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.1521596908569336, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1954690217971802, Accuracy: 0.607421875\n",
      "Batch: 117, Loss: 1.1870808601379395, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.2616469860076904, Accuracy: 0.591796875\n",
      "Batch: 119, Loss: 1.224318265914917, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.2504149675369263, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.166032314300537, Accuracy: 0.62890625\n",
      "Batch: 122, Loss: 1.1697723865509033, Accuracy: 0.62890625\n",
      "Batch: 123, Loss: 1.1953802108764648, Accuracy: 0.6064453125\n",
      "Batch: 124, Loss: 1.1940040588378906, Accuracy: 0.626953125\n",
      "Batch: 125, Loss: 1.184500813484192, Accuracy: 0.6015625\n",
      "Batch: 126, Loss: 1.2921583652496338, Accuracy: 0.5869140625\n",
      "Batch: 127, Loss: 1.2729501724243164, Accuracy: 0.59765625\n",
      "Batch: 128, Loss: 1.2211785316467285, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.1805238723754883, Accuracy: 0.6259765625\n",
      "Batch: 130, Loss: 1.1724853515625, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.2389073371887207, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.0750609636306763, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.112044334411621, Accuracy: 0.6591796875\n",
      "Batch: 134, Loss: 1.101275086402893, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 1.042532205581665, Accuracy: 0.6484375\n",
      "Batch: 136, Loss: 1.0484788417816162, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1725480556488037, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 1.22202730178833, Accuracy: 0.5966796875\n",
      "Batch: 139, Loss: 1.1865955591201782, Accuracy: 0.6103515625\n",
      "Batch: 140, Loss: 1.282989501953125, Accuracy: 0.6025390625\n",
      "Batch: 141, Loss: 1.2029762268066406, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.2084510326385498, Accuracy: 0.619140625\n",
      "Batch: 143, Loss: 1.1694661378860474, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.2889235019683838, Accuracy: 0.5830078125\n",
      "Batch: 145, Loss: 1.2415968179702759, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.2106056213378906, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.1657705307006836, Accuracy: 0.6357421875\n",
      "Batch: 148, Loss: 1.2317485809326172, Accuracy: 0.6015625\n",
      "Batch: 149, Loss: 1.1663120985031128, Accuracy: 0.619140625\n",
      "Batch: 150, Loss: 1.1341674327850342, Accuracy: 0.5947265625\n",
      "Batch: 151, Loss: 1.1570804119110107, Accuracy: 0.6181640625\n",
      "Batch: 152, Loss: 1.1385743618011475, Accuracy: 0.6298828125\n",
      "Batch: 153, Loss: 1.0994088649749756, Accuracy: 0.6533203125\n",
      "Batch: 154, Loss: 1.1457691192626953, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.1240599155426025, Accuracy: 0.6220703125\n",
      "Epoch 499/200\n",
      "Batch: 1, Loss: 1.2417316436767578, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.0835762023925781, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0473549365997314, Accuracy: 0.66796875\n",
      "Batch: 4, Loss: 1.0798125267028809, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.0805833339691162, Accuracy: 0.6376953125\n",
      "Batch: 6, Loss: 1.0384960174560547, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 1.0472939014434814, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 1.0279191732406616, Accuracy: 0.6650390625\n",
      "Batch: 9, Loss: 0.9432321786880493, Accuracy: 0.697265625\n",
      "Batch: 10, Loss: 0.95066237449646, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 0.9059046506881714, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12, Loss: 1.056404948234558, Accuracy: 0.6572265625\n",
      "Batch: 13, Loss: 1.00808584690094, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9666287302970886, Accuracy: 0.7060546875\n",
      "Batch: 15, Loss: 0.9657931923866272, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0140693187713623, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 1.025647521018982, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.083975076675415, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.2371225357055664, Accuracy: 0.5849609375\n",
      "Batch: 20, Loss: 1.0799508094787598, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.064690113067627, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.187622308731079, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.218029260635376, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.1243422031402588, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1159119606018066, Accuracy: 0.6357421875\n",
      "Batch: 26, Loss: 1.1756718158721924, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.1277601718902588, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.0548027753829956, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.0342010259628296, Accuracy: 0.66796875\n",
      "Batch: 30, Loss: 1.1786887645721436, Accuracy: 0.607421875\n",
      "Batch: 31, Loss: 1.18196702003479, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0303500890731812, Accuracy: 0.6494140625\n",
      "Batch: 33, Loss: 1.0068063735961914, Accuracy: 0.6767578125\n",
      "Batch: 34, Loss: 1.0920307636260986, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.1087143421173096, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.1604864597320557, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.1732571125030518, Accuracy: 0.630859375\n",
      "Batch: 38, Loss: 1.154523491859436, Accuracy: 0.6171875\n",
      "Batch: 39, Loss: 1.0562753677368164, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.0790653228759766, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.136499285697937, Accuracy: 0.6123046875\n",
      "Batch: 42, Loss: 1.0271270275115967, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.0461699962615967, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 1.0597302913665771, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 0.9975486993789673, Accuracy: 0.6748046875\n",
      "Batch: 46, Loss: 1.156299352645874, Accuracy: 0.603515625\n",
      "Batch: 47, Loss: 1.1190342903137207, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.0862244367599487, Accuracy: 0.6416015625\n",
      "Batch: 49, Loss: 1.175447940826416, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.1088649034500122, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1387097835540771, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.174222469329834, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.1674351692199707, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.1695873737335205, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.099395751953125, Accuracy: 0.642578125\n",
      "Batch: 56, Loss: 1.1319572925567627, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.1005284786224365, Accuracy: 0.6611328125\n",
      "Batch: 58, Loss: 1.1218183040618896, Accuracy: 0.6181640625\n",
      "Batch: 59, Loss: 1.1245696544647217, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.2599472999572754, Accuracy: 0.5966796875\n",
      "Batch: 61, Loss: 1.1641191244125366, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.0818707942962646, Accuracy: 0.6513671875\n",
      "Batch: 63, Loss: 1.1185396909713745, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.166250467300415, Accuracy: 0.630859375\n",
      "Batch: 65, Loss: 1.1719163656234741, Accuracy: 0.62890625\n",
      "Batch: 66, Loss: 1.1634435653686523, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.1397223472595215, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.1005102396011353, Accuracy: 0.6513671875\n",
      "Batch: 69, Loss: 1.192596197128296, Accuracy: 0.615234375\n",
      "Batch: 70, Loss: 1.2191193103790283, Accuracy: 0.6103515625\n",
      "Batch: 71, Loss: 1.1599833965301514, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.2175076007843018, Accuracy: 0.59375\n",
      "Batch: 73, Loss: 1.1412444114685059, Accuracy: 0.6357421875\n",
      "Batch: 74, Loss: 1.1288248300552368, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.1285836696624756, Accuracy: 0.626953125\n",
      "Batch: 76, Loss: 1.0941530466079712, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0650242567062378, Accuracy: 0.654296875\n",
      "Batch: 78, Loss: 1.080077052116394, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1577417850494385, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.1753168106079102, Accuracy: 0.6171875\n",
      "Batch: 81, Loss: 1.1030266284942627, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1022181510925293, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 1.1762698888778687, Accuracy: 0.6123046875\n",
      "Batch: 84, Loss: 1.1859899759292603, Accuracy: 0.623046875\n",
      "Batch: 85, Loss: 1.1361827850341797, Accuracy: 0.6474609375\n",
      "Batch: 86, Loss: 1.18377685546875, Accuracy: 0.609375\n",
      "Batch: 87, Loss: 1.1464579105377197, Accuracy: 0.6474609375\n",
      "Batch: 88, Loss: 1.1336541175842285, Accuracy: 0.6337890625\n",
      "Batch: 89, Loss: 1.1447380781173706, Accuracy: 0.6455078125\n",
      "Batch: 90, Loss: 1.0835561752319336, Accuracy: 0.654296875\n",
      "Batch: 91, Loss: 1.1439801454544067, Accuracy: 0.6298828125\n",
      "Batch: 92, Loss: 1.1824679374694824, Accuracy: 0.634765625\n",
      "Batch: 93, Loss: 1.147342324256897, Accuracy: 0.62109375\n",
      "Batch: 94, Loss: 1.1324164867401123, Accuracy: 0.63671875\n",
      "Batch: 95, Loss: 1.1283235549926758, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.1828922033309937, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.204616665840149, Accuracy: 0.5869140625\n",
      "Batch: 98, Loss: 1.113637924194336, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.1749948263168335, Accuracy: 0.6123046875\n",
      "Batch: 100, Loss: 1.1102263927459717, Accuracy: 0.6318359375\n",
      "Batch: 101, Loss: 1.0925116539001465, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.1716742515563965, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.1732999086380005, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.1339887380599976, Accuracy: 0.6279296875\n",
      "Batch: 105, Loss: 1.229353904724121, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.1607692241668701, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.1577744483947754, Accuracy: 0.619140625\n",
      "Batch: 108, Loss: 1.159730315208435, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.2285995483398438, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.1394000053405762, Accuracy: 0.6201171875\n",
      "Batch: 111, Loss: 1.11799955368042, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.083147406578064, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.113405704498291, Accuracy: 0.6328125\n",
      "Batch: 114, Loss: 1.1337202787399292, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.1772139072418213, Accuracy: 0.62109375\n",
      "Batch: 116, Loss: 1.1432609558105469, Accuracy: 0.64453125\n",
      "Batch: 117, Loss: 1.15708327293396, Accuracy: 0.6337890625\n",
      "Batch: 118, Loss: 1.2004338502883911, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.2327744960784912, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.2522943019866943, Accuracy: 0.6083984375\n",
      "Batch: 121, Loss: 1.1983071565628052, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.2099416255950928, Accuracy: 0.623046875\n",
      "Batch: 123, Loss: 1.164198875427246, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.2035737037658691, Accuracy: 0.626953125\n",
      "Batch: 125, Loss: 1.1601274013519287, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.206769585609436, Accuracy: 0.6220703125\n",
      "Batch: 127, Loss: 1.2202856540679932, Accuracy: 0.619140625\n",
      "Batch: 128, Loss: 1.2233233451843262, Accuracy: 0.6015625\n",
      "Batch: 129, Loss: 1.2171497344970703, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.1217005252838135, Accuracy: 0.62109375\n",
      "Batch: 131, Loss: 1.1903245449066162, Accuracy: 0.5908203125\n",
      "Batch: 132, Loss: 1.0601447820663452, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 1.1892669200897217, Accuracy: 0.6201171875\n",
      "Batch: 134, Loss: 1.1319944858551025, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.0340760946273804, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.124274492263794, Accuracy: 0.6318359375\n",
      "Batch: 137, Loss: 1.164231300354004, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.2263251543045044, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.194222092628479, Accuracy: 0.623046875\n",
      "Batch: 140, Loss: 1.2073118686676025, Accuracy: 0.6318359375\n",
      "Batch: 141, Loss: 1.186038613319397, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.1812784671783447, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.2117393016815186, Accuracy: 0.607421875\n",
      "Batch: 144, Loss: 1.2468844652175903, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.2329293489456177, Accuracy: 0.59765625\n",
      "Batch: 146, Loss: 1.2295677661895752, Accuracy: 0.5986328125\n",
      "Batch: 147, Loss: 1.1737879514694214, Accuracy: 0.6142578125\n",
      "Batch: 148, Loss: 1.1932538747787476, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.155322790145874, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.128357172012329, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1504271030426025, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 152, Loss: 1.1567432880401611, Accuracy: 0.6240234375\n",
      "Batch: 153, Loss: 1.1439743041992188, Accuracy: 0.6279296875\n",
      "Batch: 154, Loss: 1.1202342510223389, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.144991159439087, Accuracy: 0.6181640625\n",
      "Epoch 500/200\n",
      "Batch: 1, Loss: 1.1629184484481812, Accuracy: 0.6484375\n",
      "Batch: 2, Loss: 1.06684410572052, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.0036673545837402, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 1.0600296258926392, Accuracy: 0.65625\n",
      "Batch: 5, Loss: 1.0266461372375488, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.0050034523010254, Accuracy: 0.6884765625\n",
      "Batch: 7, Loss: 1.0386399030685425, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0218051671981812, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 0.9988645315170288, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9982542395591736, Accuracy: 0.6572265625\n",
      "Batch: 11, Loss: 0.9360312819480896, Accuracy: 0.6884765625\n",
      "Batch: 12, Loss: 1.0115878582000732, Accuracy: 0.671875\n",
      "Batch: 13, Loss: 1.0229949951171875, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.9438916444778442, Accuracy: 0.7001953125\n",
      "Batch: 15, Loss: 0.9258452653884888, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 0.9888911843299866, Accuracy: 0.685546875\n",
      "Batch: 17, Loss: 1.0424808263778687, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1591414213180542, Accuracy: 0.6259765625\n",
      "Batch: 19, Loss: 1.2088913917541504, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.1132786273956299, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.0835046768188477, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.233997106552124, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.1910637617111206, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.1552302837371826, Accuracy: 0.6259765625\n",
      "Batch: 25, Loss: 1.142258644104004, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.1752033233642578, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.1302859783172607, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0534461736679077, Accuracy: 0.6591796875\n",
      "Batch: 29, Loss: 1.0708444118499756, Accuracy: 0.6474609375\n",
      "Batch: 30, Loss: 1.150219440460205, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.1850401163101196, Accuracy: 0.6162109375\n",
      "Batch: 32, Loss: 1.035636305809021, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.0334662199020386, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.071995496749878, Accuracy: 0.6494140625\n",
      "Batch: 35, Loss: 1.177459716796875, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.1520949602127075, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.1905744075775146, Accuracy: 0.6103515625\n",
      "Batch: 38, Loss: 1.1935007572174072, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.0796892642974854, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0451725721359253, Accuracy: 0.6611328125\n",
      "Batch: 41, Loss: 1.139101505279541, Accuracy: 0.626953125\n",
      "Batch: 42, Loss: 1.0972732305526733, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.0202515125274658, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.0339977741241455, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.0531079769134521, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.17667555809021, Accuracy: 0.5966796875\n",
      "Batch: 47, Loss: 1.0970458984375, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.1450996398925781, Accuracy: 0.6103515625\n",
      "Batch: 49, Loss: 1.165481448173523, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.1016312837600708, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.1960381269454956, Accuracy: 0.6123046875\n",
      "Batch: 52, Loss: 1.2992538213729858, Accuracy: 0.5947265625\n",
      "Batch: 53, Loss: 1.1942238807678223, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.1885418891906738, Accuracy: 0.6318359375\n",
      "Batch: 55, Loss: 1.1058193445205688, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.0938541889190674, Accuracy: 0.646484375\n",
      "Batch: 57, Loss: 1.1328561305999756, Accuracy: 0.642578125\n",
      "Batch: 58, Loss: 1.1274075508117676, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.0704197883605957, Accuracy: 0.6552734375\n",
      "Batch: 60, Loss: 1.287214756011963, Accuracy: 0.5908203125\n",
      "Batch: 61, Loss: 1.1590099334716797, Accuracy: 0.6162109375\n",
      "Batch: 62, Loss: 1.2017822265625, Accuracy: 0.623046875\n",
      "Batch: 63, Loss: 1.1448638439178467, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.200499415397644, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.1665165424346924, Accuracy: 0.6083984375\n",
      "Batch: 66, Loss: 1.1595900058746338, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.106484293937683, Accuracy: 0.6474609375\n",
      "Batch: 68, Loss: 1.1025758981704712, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1561652421951294, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.1912033557891846, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.120140790939331, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.195628046989441, Accuracy: 0.611328125\n",
      "Batch: 73, Loss: 1.1906533241271973, Accuracy: 0.625\n",
      "Batch: 74, Loss: 1.138035535812378, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.0870529413223267, Accuracy: 0.6435546875\n",
      "Batch: 76, Loss: 1.052241325378418, Accuracy: 0.6640625\n",
      "Batch: 77, Loss: 1.093218445777893, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0502727031707764, Accuracy: 0.6630859375\n",
      "Batch: 79, Loss: 1.1230366230010986, Accuracy: 0.6484375\n",
      "Batch: 80, Loss: 1.1407935619354248, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.1290819644927979, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 1.0928140878677368, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 1.2200465202331543, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.1620286703109741, Accuracy: 0.625\n",
      "Batch: 85, Loss: 1.1554985046386719, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.1262952089309692, Accuracy: 0.650390625\n",
      "Batch: 87, Loss: 1.2035236358642578, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.1700358390808105, Accuracy: 0.615234375\n",
      "Batch: 89, Loss: 1.1274340152740479, Accuracy: 0.626953125\n",
      "Batch: 90, Loss: 1.0859901905059814, Accuracy: 0.6484375\n",
      "Batch: 91, Loss: 1.1537320613861084, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1157290935516357, Accuracy: 0.6435546875\n",
      "Batch: 93, Loss: 1.1485047340393066, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.1695102453231812, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1493793725967407, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.2445164918899536, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.203476905822754, Accuracy: 0.5947265625\n",
      "Batch: 98, Loss: 1.144722580909729, Accuracy: 0.625\n",
      "Batch: 99, Loss: 1.1561179161071777, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.0396077632904053, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.0715420246124268, Accuracy: 0.6552734375\n",
      "Batch: 102, Loss: 1.1924858093261719, Accuracy: 0.6162109375\n",
      "Batch: 103, Loss: 1.1720869541168213, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.1246241331100464, Accuracy: 0.6162109375\n",
      "Batch: 105, Loss: 1.2288391590118408, Accuracy: 0.6162109375\n",
      "Batch: 106, Loss: 1.146822214126587, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.1855318546295166, Accuracy: 0.6025390625\n",
      "Batch: 108, Loss: 1.1930675506591797, Accuracy: 0.6044921875\n",
      "Batch: 109, Loss: 1.1535459756851196, Accuracy: 0.6279296875\n",
      "Batch: 110, Loss: 1.19350266456604, Accuracy: 0.6005859375\n",
      "Batch: 111, Loss: 1.1049400568008423, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.090633749961853, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.0754127502441406, Accuracy: 0.6513671875\n",
      "Batch: 114, Loss: 1.1470404863357544, Accuracy: 0.6416015625\n",
      "Batch: 115, Loss: 1.1869428157806396, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1942036151885986, Accuracy: 0.61328125\n",
      "Batch: 117, Loss: 1.0786871910095215, Accuracy: 0.6328125\n",
      "Batch: 118, Loss: 1.1787760257720947, Accuracy: 0.6162109375\n",
      "Batch: 119, Loss: 1.2447898387908936, Accuracy: 0.6015625\n",
      "Batch: 120, Loss: 1.2990007400512695, Accuracy: 0.591796875\n",
      "Batch: 121, Loss: 1.1948273181915283, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.2152236700057983, Accuracy: 0.6123046875\n",
      "Batch: 123, Loss: 1.1097562313079834, Accuracy: 0.6396484375\n",
      "Batch: 124, Loss: 1.1975123882293701, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.195004940032959, Accuracy: 0.6025390625\n",
      "Batch: 126, Loss: 1.2276134490966797, Accuracy: 0.6064453125\n",
      "Batch: 127, Loss: 1.2158944606781006, Accuracy: 0.625\n",
      "Batch: 128, Loss: 1.2793447971343994, Accuracy: 0.6015625\n",
      "Batch: 129, Loss: 1.1959567070007324, Accuracy: 0.6162109375\n",
      "Batch: 130, Loss: 1.157099723815918, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.232602596282959, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.1039789915084839, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.146859884262085, Accuracy: 0.61328125\n",
      "Batch: 134, Loss: 1.1721283197402954, Accuracy: 0.6298828125\n",
      "Batch: 135, Loss: 1.0415902137756348, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.0784320831298828, Accuracy: 0.654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.1402063369750977, Accuracy: 0.6328125\n",
      "Batch: 138, Loss: 1.259116291999817, Accuracy: 0.595703125\n",
      "Batch: 139, Loss: 1.2102704048156738, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.207338571548462, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.1416081190109253, Accuracy: 0.638671875\n",
      "Batch: 142, Loss: 1.1476036310195923, Accuracy: 0.6357421875\n",
      "Batch: 143, Loss: 1.1862971782684326, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.2226817607879639, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.2435176372528076, Accuracy: 0.59765625\n",
      "Batch: 146, Loss: 1.1944410800933838, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.1932957172393799, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.222200870513916, Accuracy: 0.60546875\n",
      "Batch: 149, Loss: 1.1563501358032227, Accuracy: 0.5986328125\n",
      "Batch: 150, Loss: 1.1804665327072144, Accuracy: 0.6123046875\n",
      "Batch: 151, Loss: 1.1505241394042969, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.1905326843261719, Accuracy: 0.6220703125\n",
      "Batch: 153, Loss: 1.1241843700408936, Accuracy: 0.65234375\n",
      "Batch: 154, Loss: 1.099809169769287, Accuracy: 0.6337890625\n",
      "Batch: 155, Loss: 1.1527318954467773, Accuracy: 0.6201171875\n",
      "Saved Weights at epoch 500 to file Weights_500.h5\n",
      "Epoch 501/200\n",
      "Batch: 1, Loss: 1.2383885383605957, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.0696967840194702, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 0.9844530820846558, Accuracy: 0.68359375\n",
      "Batch: 4, Loss: 1.1062543392181396, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0247284173965454, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 0.9935356378555298, Accuracy: 0.6796875\n",
      "Batch: 7, Loss: 1.0070070028305054, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.9918009042739868, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 1.0097699165344238, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 0.9324186444282532, Accuracy: 0.701171875\n",
      "Batch: 11, Loss: 0.9925633668899536, Accuracy: 0.6474609375\n",
      "Batch: 12, Loss: 1.0502536296844482, Accuracy: 0.66015625\n",
      "Batch: 13, Loss: 1.0190445184707642, Accuracy: 0.6708984375\n",
      "Batch: 14, Loss: 1.0249011516571045, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.8993543386459351, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 1.0569292306900024, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.0478012561798096, Accuracy: 0.6474609375\n",
      "Batch: 18, Loss: 1.1251153945922852, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.2277076244354248, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.100754976272583, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.1064815521240234, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.1914328336715698, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.226775884628296, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.1249037981033325, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.1308629512786865, Accuracy: 0.6220703125\n",
      "Batch: 26, Loss: 1.1281487941741943, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.162348985671997, Accuracy: 0.6328125\n",
      "Batch: 28, Loss: 1.0864415168762207, Accuracy: 0.646484375\n",
      "Batch: 29, Loss: 1.0136938095092773, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.1324706077575684, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.183891773223877, Accuracy: 0.609375\n",
      "Batch: 32, Loss: 0.9998329281806946, Accuracy: 0.685546875\n",
      "Batch: 33, Loss: 1.0387747287750244, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.0940438508987427, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.1560564041137695, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.1738789081573486, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.2077698707580566, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.1258811950683594, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.0521984100341797, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.0602800846099854, Accuracy: 0.6513671875\n",
      "Batch: 41, Loss: 1.1733360290527344, Accuracy: 0.6005859375\n",
      "Batch: 42, Loss: 1.1205555200576782, Accuracy: 0.6337890625\n",
      "Batch: 43, Loss: 1.0712010860443115, Accuracy: 0.625\n",
      "Batch: 44, Loss: 1.0410412549972534, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 1.0660436153411865, Accuracy: 0.64453125\n",
      "Batch: 46, Loss: 1.1003226041793823, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.091688632965088, Accuracy: 0.666015625\n",
      "Batch: 48, Loss: 1.1037611961364746, Accuracy: 0.6533203125\n",
      "Batch: 49, Loss: 1.0919688940048218, Accuracy: 0.642578125\n",
      "Batch: 50, Loss: 1.1373907327651978, Accuracy: 0.634765625\n",
      "Batch: 51, Loss: 1.1647789478302002, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.2449404001235962, Accuracy: 0.6005859375\n",
      "Batch: 53, Loss: 1.185603380203247, Accuracy: 0.6005859375\n",
      "Batch: 54, Loss: 1.2134449481964111, Accuracy: 0.5947265625\n",
      "Batch: 55, Loss: 1.1136664152145386, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.143534779548645, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.1272823810577393, Accuracy: 0.62890625\n",
      "Batch: 58, Loss: 1.1435856819152832, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.0659199953079224, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.2031588554382324, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.155531644821167, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1537835597991943, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.1978843212127686, Accuracy: 0.611328125\n",
      "Batch: 64, Loss: 1.189407229423523, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1780046224594116, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.1450560092926025, Accuracy: 0.6201171875\n",
      "Batch: 67, Loss: 1.1023125648498535, Accuracy: 0.65625\n",
      "Batch: 68, Loss: 1.042473316192627, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 1.142579197883606, Accuracy: 0.6357421875\n",
      "Batch: 70, Loss: 1.1073930263519287, Accuracy: 0.642578125\n",
      "Batch: 71, Loss: 1.1088699102401733, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.1916749477386475, Accuracy: 0.6083984375\n",
      "Batch: 73, Loss: 1.1945996284484863, Accuracy: 0.5966796875\n",
      "Batch: 74, Loss: 1.0780059099197388, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.1153554916381836, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.0658422708511353, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.0364489555358887, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.0711677074432373, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1542794704437256, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.1716967821121216, Accuracy: 0.6298828125\n",
      "Batch: 81, Loss: 1.1124215126037598, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.126516580581665, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.1984858512878418, Accuracy: 0.6328125\n",
      "Batch: 84, Loss: 1.1423137187957764, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.133180856704712, Accuracy: 0.6220703125\n",
      "Batch: 86, Loss: 1.1552013158798218, Accuracy: 0.607421875\n",
      "Batch: 87, Loss: 1.1537381410598755, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.1637485027313232, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1043784618377686, Accuracy: 0.646484375\n",
      "Batch: 90, Loss: 1.0883479118347168, Accuracy: 0.6474609375\n",
      "Batch: 91, Loss: 1.1572834253311157, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1872713565826416, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.1021424531936646, Accuracy: 0.6455078125\n",
      "Batch: 94, Loss: 1.1848520040512085, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.2007534503936768, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.2070400714874268, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.151141881942749, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.1614713668823242, Accuracy: 0.6220703125\n",
      "Batch: 99, Loss: 1.190538763999939, Accuracy: 0.619140625\n",
      "Batch: 100, Loss: 1.0318198204040527, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.0925753116607666, Accuracy: 0.626953125\n",
      "Batch: 102, Loss: 1.20516836643219, Accuracy: 0.6044921875\n",
      "Batch: 103, Loss: 1.1452789306640625, Accuracy: 0.62109375\n",
      "Batch: 104, Loss: 1.1524341106414795, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.2253226041793823, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.1673399209976196, Accuracy: 0.6455078125\n",
      "Batch: 107, Loss: 1.200168490409851, Accuracy: 0.62109375\n",
      "Batch: 108, Loss: 1.2216095924377441, Accuracy: 0.5712890625\n",
      "Batch: 109, Loss: 1.2465431690216064, Accuracy: 0.5869140625\n",
      "Batch: 110, Loss: 1.1146624088287354, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.1618883609771729, Accuracy: 0.6279296875\n",
      "Batch: 112, Loss: 1.0731103420257568, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1556446552276611, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.1697213649749756, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.13974928855896, Accuracy: 0.638671875\n",
      "Batch: 116, Loss: 1.1800322532653809, Accuracy: 0.60546875\n",
      "Batch: 117, Loss: 1.1295318603515625, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 1.2225048542022705, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.2020673751831055, Accuracy: 0.623046875\n",
      "Batch: 120, Loss: 1.2681132555007935, Accuracy: 0.5888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 121, Loss: 1.1280395984649658, Accuracy: 0.634765625\n",
      "Batch: 122, Loss: 1.1796042919158936, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.1825222969055176, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.2501606941223145, Accuracy: 0.609375\n",
      "Batch: 125, Loss: 1.1572028398513794, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.2998864650726318, Accuracy: 0.5869140625\n",
      "Batch: 127, Loss: 1.2152509689331055, Accuracy: 0.6201171875\n",
      "Batch: 128, Loss: 1.2429966926574707, Accuracy: 0.59375\n",
      "Batch: 129, Loss: 1.1753662824630737, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.111249327659607, Accuracy: 0.640625\n",
      "Batch: 131, Loss: 1.1990196704864502, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 1.0840518474578857, Accuracy: 0.6494140625\n",
      "Batch: 133, Loss: 1.1493654251098633, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.1290647983551025, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 1.045816421508789, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.0451489686965942, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 1.1705132722854614, Accuracy: 0.611328125\n",
      "Batch: 138, Loss: 1.1269772052764893, Accuracy: 0.6396484375\n",
      "Batch: 139, Loss: 1.1626670360565186, Accuracy: 0.63671875\n",
      "Batch: 140, Loss: 1.3051445484161377, Accuracy: 0.5927734375\n",
      "Batch: 141, Loss: 1.197754144668579, Accuracy: 0.61328125\n",
      "Batch: 142, Loss: 1.1853595972061157, Accuracy: 0.630859375\n",
      "Batch: 143, Loss: 1.2243024110794067, Accuracy: 0.5986328125\n",
      "Batch: 144, Loss: 1.2661713361740112, Accuracy: 0.5830078125\n",
      "Batch: 145, Loss: 1.2668448686599731, Accuracy: 0.6025390625\n",
      "Batch: 146, Loss: 1.188410758972168, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.2259397506713867, Accuracy: 0.591796875\n",
      "Batch: 148, Loss: 1.2513251304626465, Accuracy: 0.58203125\n",
      "Batch: 149, Loss: 1.1577694416046143, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1790494918823242, Accuracy: 0.611328125\n",
      "Batch: 151, Loss: 1.1795878410339355, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.2155401706695557, Accuracy: 0.5859375\n",
      "Batch: 153, Loss: 1.14454984664917, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1471612453460693, Accuracy: 0.6201171875\n",
      "Batch: 155, Loss: 1.1299092769622803, Accuracy: 0.6240234375\n",
      "Epoch 502/200\n",
      "Batch: 1, Loss: 1.2249563932418823, Accuracy: 0.6376953125\n",
      "Batch: 2, Loss: 1.077060580253601, Accuracy: 0.6533203125\n",
      "Batch: 3, Loss: 1.06289541721344, Accuracy: 0.66015625\n",
      "Batch: 4, Loss: 1.06864595413208, Accuracy: 0.666015625\n",
      "Batch: 5, Loss: 1.0584688186645508, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.0214630365371704, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.0317659378051758, Accuracy: 0.6416015625\n",
      "Batch: 8, Loss: 0.9962893128395081, Accuracy: 0.6767578125\n",
      "Batch: 9, Loss: 0.9852502346038818, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 1.0437211990356445, Accuracy: 0.646484375\n",
      "Batch: 11, Loss: 0.9656191468238831, Accuracy: 0.6728515625\n",
      "Batch: 12, Loss: 1.009270429611206, Accuracy: 0.681640625\n",
      "Batch: 13, Loss: 0.9876700043678284, Accuracy: 0.6884765625\n",
      "Batch: 14, Loss: 0.9603800773620605, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.9252766966819763, Accuracy: 0.7060546875\n",
      "Batch: 16, Loss: 1.0691115856170654, Accuracy: 0.6494140625\n",
      "Batch: 17, Loss: 1.0936481952667236, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.0794910192489624, Accuracy: 0.6572265625\n",
      "Batch: 19, Loss: 1.2714009284973145, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.1443331241607666, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.1337478160858154, Accuracy: 0.625\n",
      "Batch: 22, Loss: 1.2550216913223267, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.2249830961227417, Accuracy: 0.6201171875\n",
      "Batch: 24, Loss: 1.0827968120574951, Accuracy: 0.6591796875\n",
      "Batch: 25, Loss: 1.0951478481292725, Accuracy: 0.6494140625\n",
      "Batch: 26, Loss: 1.1813607215881348, Accuracy: 0.607421875\n",
      "Batch: 27, Loss: 1.1325328350067139, Accuracy: 0.640625\n",
      "Batch: 28, Loss: 1.063206672668457, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.099111557006836, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1507378816604614, Accuracy: 0.6220703125\n",
      "Batch: 31, Loss: 1.1864955425262451, Accuracy: 0.615234375\n",
      "Batch: 32, Loss: 1.0797009468078613, Accuracy: 0.6494140625\n",
      "Batch: 33, Loss: 0.9572629928588867, Accuracy: 0.6904296875\n",
      "Batch: 34, Loss: 1.1049747467041016, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.184420108795166, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.1622470617294312, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.218658208847046, Accuracy: 0.5859375\n",
      "Batch: 38, Loss: 1.2216992378234863, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.084625005722046, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.1004137992858887, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.0934855937957764, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.0833826065063477, Accuracy: 0.6591796875\n",
      "Batch: 43, Loss: 1.0510224103927612, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0363290309906006, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0336158275604248, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.1308979988098145, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.1174030303955078, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.1299221515655518, Accuracy: 0.646484375\n",
      "Batch: 49, Loss: 1.1495321989059448, Accuracy: 0.63671875\n",
      "Batch: 50, Loss: 1.136137843132019, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.112388014793396, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2423069477081299, Accuracy: 0.6181640625\n",
      "Batch: 53, Loss: 1.177430510520935, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.192694902420044, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.1099724769592285, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.0610268115997314, Accuracy: 0.685546875\n",
      "Batch: 57, Loss: 1.1198127269744873, Accuracy: 0.62890625\n",
      "Batch: 58, Loss: 1.1279394626617432, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1598230600357056, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2316327095031738, Accuracy: 0.59765625\n",
      "Batch: 61, Loss: 1.1440520286560059, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.1812024116516113, Accuracy: 0.630859375\n",
      "Batch: 63, Loss: 1.1893858909606934, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2254369258880615, Accuracy: 0.5849609375\n",
      "Batch: 65, Loss: 1.1847505569458008, Accuracy: 0.62109375\n",
      "Batch: 66, Loss: 1.1590383052825928, Accuracy: 0.6162109375\n",
      "Batch: 67, Loss: 1.1692039966583252, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.1087849140167236, Accuracy: 0.6416015625\n",
      "Batch: 69, Loss: 1.218711018562317, Accuracy: 0.62109375\n",
      "Batch: 70, Loss: 1.158309817314148, Accuracy: 0.63671875\n",
      "Batch: 71, Loss: 1.1537907123565674, Accuracy: 0.615234375\n",
      "Batch: 72, Loss: 1.1913349628448486, Accuracy: 0.619140625\n",
      "Batch: 73, Loss: 1.1783671379089355, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.1211168766021729, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.157294511795044, Accuracy: 0.6162109375\n",
      "Batch: 76, Loss: 1.1016101837158203, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 1.0495030879974365, Accuracy: 0.65625\n",
      "Batch: 78, Loss: 1.040457010269165, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.117635726928711, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.184512734413147, Accuracy: 0.6171875\n",
      "Batch: 81, Loss: 1.0711231231689453, Accuracy: 0.6533203125\n",
      "Batch: 82, Loss: 1.137290596961975, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 1.2154186964035034, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.147620439529419, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.1945161819458008, Accuracy: 0.62109375\n",
      "Batch: 86, Loss: 1.1722056865692139, Accuracy: 0.61328125\n",
      "Batch: 87, Loss: 1.1497952938079834, Accuracy: 0.6318359375\n",
      "Batch: 88, Loss: 1.186326503753662, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1521509885787964, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.0935239791870117, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.1519088745117188, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.1920533180236816, Accuracy: 0.62890625\n",
      "Batch: 93, Loss: 1.17313551902771, Accuracy: 0.6220703125\n",
      "Batch: 94, Loss: 1.1666203737258911, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.1963770389556885, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.1978487968444824, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.1271085739135742, Accuracy: 0.6123046875\n",
      "Batch: 98, Loss: 1.1007822751998901, Accuracy: 0.6669921875\n",
      "Batch: 99, Loss: 1.148868441581726, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.0802193880081177, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.1163113117218018, Accuracy: 0.6474609375\n",
      "Batch: 102, Loss: 1.1534501314163208, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.1270474195480347, Accuracy: 0.658203125\n",
      "Batch: 104, Loss: 1.1390342712402344, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.210523009300232, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 1.1713449954986572, Accuracy: 0.6181640625\n",
      "Batch: 107, Loss: 1.2676386833190918, Accuracy: 0.59765625\n",
      "Batch: 108, Loss: 1.1425237655639648, Accuracy: 0.6279296875\n",
      "Batch: 109, Loss: 1.2044384479522705, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.1090424060821533, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.0781241655349731, Accuracy: 0.6572265625\n",
      "Batch: 112, Loss: 1.1587297916412354, Accuracy: 0.61328125\n",
      "Batch: 113, Loss: 1.1017357110977173, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.148433804512024, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.1961349248886108, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.2129034996032715, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1198818683624268, Accuracy: 0.638671875\n",
      "Batch: 118, Loss: 1.2697813510894775, Accuracy: 0.57421875\n",
      "Batch: 119, Loss: 1.1938238143920898, Accuracy: 0.603515625\n",
      "Batch: 120, Loss: 1.3051085472106934, Accuracy: 0.5966796875\n",
      "Batch: 121, Loss: 1.2237720489501953, Accuracy: 0.5927734375\n",
      "Batch: 122, Loss: 1.2213103771209717, Accuracy: 0.6005859375\n",
      "Batch: 123, Loss: 1.1704216003417969, Accuracy: 0.6162109375\n",
      "Batch: 124, Loss: 1.1946067810058594, Accuracy: 0.630859375\n",
      "Batch: 125, Loss: 1.2190144062042236, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.2441294193267822, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.2045997381210327, Accuracy: 0.615234375\n",
      "Batch: 128, Loss: 1.1551125049591064, Accuracy: 0.6484375\n",
      "Batch: 129, Loss: 1.1990642547607422, Accuracy: 0.603515625\n",
      "Batch: 130, Loss: 1.1132595539093018, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.216041088104248, Accuracy: 0.6083984375\n",
      "Batch: 132, Loss: 1.0596905946731567, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.1687357425689697, Accuracy: 0.5830078125\n",
      "Batch: 134, Loss: 1.118164300918579, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.015286922454834, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.0691896677017212, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.1302802562713623, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.234197735786438, Accuracy: 0.59765625\n",
      "Batch: 139, Loss: 1.1574128866195679, Accuracy: 0.62109375\n",
      "Batch: 140, Loss: 1.1849181652069092, Accuracy: 0.6396484375\n",
      "Batch: 141, Loss: 1.1737818717956543, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.2227872610092163, Accuracy: 0.6044921875\n",
      "Batch: 143, Loss: 1.204514503479004, Accuracy: 0.62109375\n",
      "Batch: 144, Loss: 1.2403051853179932, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.2385754585266113, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.2136162519454956, Accuracy: 0.595703125\n",
      "Batch: 147, Loss: 1.2334849834442139, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.2199851274490356, Accuracy: 0.611328125\n",
      "Batch: 149, Loss: 1.182023525238037, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.1094378232955933, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.1318254470825195, Accuracy: 0.6513671875\n",
      "Batch: 152, Loss: 1.1151530742645264, Accuracy: 0.6259765625\n",
      "Batch: 153, Loss: 1.1439698934555054, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.1305139064788818, Accuracy: 0.6240234375\n",
      "Batch: 155, Loss: 1.0773797035217285, Accuracy: 0.6259765625\n",
      "Epoch 503/200\n",
      "Batch: 1, Loss: 1.1621193885803223, Accuracy: 0.66015625\n",
      "Batch: 2, Loss: 1.0819567441940308, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 1.0735774040222168, Accuracy: 0.64453125\n",
      "Batch: 4, Loss: 1.0384187698364258, Accuracy: 0.662109375\n",
      "Batch: 5, Loss: 1.0328439474105835, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.1012730598449707, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.0026512145996094, Accuracy: 0.6787109375\n",
      "Batch: 8, Loss: 1.028228759765625, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 0.9955220818519592, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 0.9507503509521484, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9655790328979492, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 1.0074708461761475, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 1.0057241916656494, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 0.9749897718429565, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.9424630999565125, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0153942108154297, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.0118294954299927, Accuracy: 0.6650390625\n",
      "Batch: 18, Loss: 1.0979646444320679, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.2063888311386108, Accuracy: 0.6064453125\n",
      "Batch: 20, Loss: 1.139481782913208, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.0598738193511963, Accuracy: 0.6474609375\n",
      "Batch: 22, Loss: 1.2411826848983765, Accuracy: 0.5859375\n",
      "Batch: 23, Loss: 1.228674054145813, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.1150133609771729, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.1469298601150513, Accuracy: 0.62109375\n",
      "Batch: 26, Loss: 1.1859391927719116, Accuracy: 0.619140625\n",
      "Batch: 27, Loss: 1.1389216184616089, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.0587687492370605, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 1.068267822265625, Accuracy: 0.6298828125\n",
      "Batch: 30, Loss: 1.129522442817688, Accuracy: 0.6240234375\n",
      "Batch: 31, Loss: 1.1726428270339966, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.0579073429107666, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 0.9740930199623108, Accuracy: 0.6845703125\n",
      "Batch: 34, Loss: 1.0672502517700195, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.0956450700759888, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.2019970417022705, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.2354490756988525, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.1462700366973877, Accuracy: 0.6328125\n",
      "Batch: 39, Loss: 1.1331061124801636, Accuracy: 0.6142578125\n",
      "Batch: 40, Loss: 1.0892740488052368, Accuracy: 0.6376953125\n",
      "Batch: 41, Loss: 1.122289776802063, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0609257221221924, Accuracy: 0.66015625\n",
      "Batch: 43, Loss: 1.080256700515747, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.0147299766540527, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 1.0018465518951416, Accuracy: 0.6767578125\n",
      "Batch: 46, Loss: 1.1025609970092773, Accuracy: 0.615234375\n",
      "Batch: 47, Loss: 1.0767707824707031, Accuracy: 0.6552734375\n",
      "Batch: 48, Loss: 1.1020535230636597, Accuracy: 0.6533203125\n",
      "Batch: 49, Loss: 1.1485697031021118, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.1071820259094238, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.112389087677002, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.2567708492279053, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.1882438659667969, Accuracy: 0.6171875\n",
      "Batch: 54, Loss: 1.132045030593872, Accuracy: 0.626953125\n",
      "Batch: 55, Loss: 1.165555477142334, Accuracy: 0.630859375\n",
      "Batch: 56, Loss: 1.1056150197982788, Accuracy: 0.6513671875\n",
      "Batch: 57, Loss: 1.063330888748169, Accuracy: 0.6533203125\n",
      "Batch: 58, Loss: 1.1659133434295654, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 1.1222515106201172, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.2541017532348633, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.1363024711608887, Accuracy: 0.6201171875\n",
      "Batch: 62, Loss: 1.1286427974700928, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.1285980939865112, Accuracy: 0.6357421875\n",
      "Batch: 64, Loss: 1.1540781259536743, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.1631238460540771, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.2116563320159912, Accuracy: 0.6083984375\n",
      "Batch: 67, Loss: 1.1387628316879272, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.1236786842346191, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.1478524208068848, Accuracy: 0.6376953125\n",
      "Batch: 70, Loss: 1.1341564655303955, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.1355457305908203, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.2222208976745605, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.1695120334625244, Accuracy: 0.6220703125\n",
      "Batch: 74, Loss: 1.0685089826583862, Accuracy: 0.6669921875\n",
      "Batch: 75, Loss: 1.0897212028503418, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.0061825513839722, Accuracy: 0.6708984375\n",
      "Batch: 77, Loss: 1.0283746719360352, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.080061674118042, Accuracy: 0.658203125\n",
      "Batch: 79, Loss: 1.1406841278076172, Accuracy: 0.6123046875\n",
      "Batch: 80, Loss: 1.1253747940063477, Accuracy: 0.6220703125\n",
      "Batch: 81, Loss: 1.0832610130310059, Accuracy: 0.6640625\n",
      "Batch: 82, Loss: 1.1007118225097656, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 1.1951355934143066, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1821787357330322, Accuracy: 0.615234375\n",
      "Batch: 85, Loss: 1.149048089981079, Accuracy: 0.6416015625\n",
      "Batch: 86, Loss: 1.191653847694397, Accuracy: 0.615234375\n",
      "Batch: 87, Loss: 1.1769136190414429, Accuracy: 0.6201171875\n",
      "Batch: 88, Loss: 1.2119274139404297, Accuracy: 0.6064453125\n",
      "Batch: 89, Loss: 1.089768409729004, Accuracy: 0.654296875\n",
      "Batch: 90, Loss: 1.0462337732315063, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 91, Loss: 1.156494140625, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.095194935798645, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.1457809209823608, Accuracy: 0.6142578125\n",
      "Batch: 94, Loss: 1.167739987373352, Accuracy: 0.6162109375\n",
      "Batch: 95, Loss: 1.1723933219909668, Accuracy: 0.6337890625\n",
      "Batch: 96, Loss: 1.1876795291900635, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.154152750968933, Accuracy: 0.6103515625\n",
      "Batch: 98, Loss: 1.1193134784698486, Accuracy: 0.615234375\n",
      "Batch: 99, Loss: 1.1192227602005005, Accuracy: 0.63671875\n",
      "Batch: 100, Loss: 1.0971407890319824, Accuracy: 0.63671875\n",
      "Batch: 101, Loss: 1.1029787063598633, Accuracy: 0.6162109375\n",
      "Batch: 102, Loss: 1.1762033700942993, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.1120638847351074, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.1278728246688843, Accuracy: 0.654296875\n",
      "Batch: 105, Loss: 1.1955006122589111, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.1279338598251343, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.180517315864563, Accuracy: 0.6220703125\n",
      "Batch: 108, Loss: 1.1558533906936646, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.1648123264312744, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 1.1620045900344849, Accuracy: 0.6083984375\n",
      "Batch: 111, Loss: 1.1406821012496948, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.121016502380371, Accuracy: 0.6259765625\n",
      "Batch: 113, Loss: 1.1595295667648315, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.1496455669403076, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.1612269878387451, Accuracy: 0.6298828125\n",
      "Batch: 116, Loss: 1.164008617401123, Accuracy: 0.6005859375\n",
      "Batch: 117, Loss: 1.155278205871582, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.2733391523361206, Accuracy: 0.5908203125\n",
      "Batch: 119, Loss: 1.2293741703033447, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2761871814727783, Accuracy: 0.619140625\n",
      "Batch: 121, Loss: 1.173305630683899, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.213079810142517, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.1438894271850586, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.234736680984497, Accuracy: 0.5888671875\n",
      "Batch: 125, Loss: 1.1736831665039062, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.202440857887268, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.2935799360275269, Accuracy: 0.5888671875\n",
      "Batch: 128, Loss: 1.1672712564468384, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.2243900299072266, Accuracy: 0.5947265625\n",
      "Batch: 130, Loss: 1.1283483505249023, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.1948127746582031, Accuracy: 0.5986328125\n",
      "Batch: 132, Loss: 1.0931341648101807, Accuracy: 0.6396484375\n",
      "Batch: 133, Loss: 1.1379945278167725, Accuracy: 0.6279296875\n",
      "Batch: 134, Loss: 1.1451189517974854, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 1.003969669342041, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.1067938804626465, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.1451753377914429, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.2148886919021606, Accuracy: 0.6044921875\n",
      "Batch: 139, Loss: 1.1857680082321167, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.259386420249939, Accuracy: 0.595703125\n",
      "Batch: 141, Loss: 1.1427757740020752, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.128061056137085, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.2322956323623657, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.2431869506835938, Accuracy: 0.611328125\n",
      "Batch: 145, Loss: 1.245323657989502, Accuracy: 0.61328125\n",
      "Batch: 146, Loss: 1.2147144079208374, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.1749300956726074, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.2123560905456543, Accuracy: 0.6015625\n",
      "Batch: 149, Loss: 1.1267428398132324, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.1781797409057617, Accuracy: 0.6064453125\n",
      "Batch: 151, Loss: 1.1427971124649048, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.147900104522705, Accuracy: 0.62890625\n",
      "Batch: 153, Loss: 1.1508305072784424, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.0741593837738037, Accuracy: 0.6416015625\n",
      "Batch: 155, Loss: 1.0956568717956543, Accuracy: 0.65625\n",
      "Epoch 504/200\n",
      "Batch: 1, Loss: 1.2349388599395752, Accuracy: 0.6376953125\n",
      "Batch: 2, Loss: 1.0806174278259277, Accuracy: 0.62890625\n",
      "Batch: 3, Loss: 1.0388813018798828, Accuracy: 0.642578125\n",
      "Batch: 4, Loss: 1.079103946685791, Accuracy: 0.64453125\n",
      "Batch: 5, Loss: 1.0161302089691162, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 1.053269624710083, Accuracy: 0.65625\n",
      "Batch: 7, Loss: 1.0252690315246582, Accuracy: 0.65625\n",
      "Batch: 8, Loss: 0.9551497101783752, Accuracy: 0.6875\n",
      "Batch: 9, Loss: 1.0235505104064941, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 0.9282422661781311, Accuracy: 0.693359375\n",
      "Batch: 11, Loss: 0.93556809425354, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.015523910522461, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 1.0537691116333008, Accuracy: 0.681640625\n",
      "Batch: 14, Loss: 1.009549617767334, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.9248178601264954, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.05133056640625, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0175645351409912, Accuracy: 0.662109375\n",
      "Batch: 18, Loss: 1.110066533088684, Accuracy: 0.6328125\n",
      "Batch: 19, Loss: 1.239636778831482, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.090297818183899, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.0807206630706787, Accuracy: 0.669921875\n",
      "Batch: 22, Loss: 1.222651720046997, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.1806213855743408, Accuracy: 0.6396484375\n",
      "Batch: 24, Loss: 1.0910338163375854, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.1347873210906982, Accuracy: 0.63671875\n",
      "Batch: 26, Loss: 1.166121244430542, Accuracy: 0.62109375\n",
      "Batch: 27, Loss: 1.1081461906433105, Accuracy: 0.634765625\n",
      "Batch: 28, Loss: 1.160839319229126, Accuracy: 0.6357421875\n",
      "Batch: 29, Loss: 1.0652308464050293, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.1834216117858887, Accuracy: 0.5966796875\n",
      "Batch: 31, Loss: 1.1778137683868408, Accuracy: 0.62890625\n",
      "Batch: 32, Loss: 1.0738701820373535, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 1.0071524381637573, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.0997378826141357, Accuracy: 0.6396484375\n",
      "Batch: 35, Loss: 1.136528491973877, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.173460841178894, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.2736320495605469, Accuracy: 0.611328125\n",
      "Batch: 38, Loss: 1.1596953868865967, Accuracy: 0.6142578125\n",
      "Batch: 39, Loss: 1.090291976928711, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.078643560409546, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.1267248392105103, Accuracy: 0.625\n",
      "Batch: 42, Loss: 1.0870028734207153, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.080074429512024, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.0640316009521484, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.0595214366912842, Accuracy: 0.6279296875\n",
      "Batch: 46, Loss: 1.173139214515686, Accuracy: 0.6064453125\n",
      "Batch: 47, Loss: 1.110101580619812, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.1491504907608032, Accuracy: 0.607421875\n",
      "Batch: 49, Loss: 1.1585004329681396, Accuracy: 0.61328125\n",
      "Batch: 50, Loss: 1.124010682106018, Accuracy: 0.6162109375\n",
      "Batch: 51, Loss: 1.1270151138305664, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.2634413242340088, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.1407861709594727, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.1925249099731445, Accuracy: 0.646484375\n",
      "Batch: 55, Loss: 1.0949697494506836, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.142263650894165, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.063124179840088, Accuracy: 0.662109375\n",
      "Batch: 58, Loss: 1.0686843395233154, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 1.1121547222137451, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2674193382263184, Accuracy: 0.5859375\n",
      "Batch: 61, Loss: 1.2042824029922485, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.1158056259155273, Accuracy: 0.6435546875\n",
      "Batch: 63, Loss: 1.1939102411270142, Accuracy: 0.6103515625\n",
      "Batch: 64, Loss: 1.20387864112854, Accuracy: 0.59765625\n",
      "Batch: 65, Loss: 1.1928163766860962, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.108447790145874, Accuracy: 0.6484375\n",
      "Batch: 67, Loss: 1.1457300186157227, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.1109882593154907, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.1603116989135742, Accuracy: 0.634765625\n",
      "Batch: 70, Loss: 1.1325864791870117, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1435115337371826, Accuracy: 0.6181640625\n",
      "Batch: 72, Loss: 1.204491138458252, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.164652705192566, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1349828243255615, Accuracy: 0.625\n",
      "Batch: 75, Loss: 1.128032922744751, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 1.1087315082550049, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.1250720024108887, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.0976002216339111, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1554839611053467, Accuracy: 0.6201171875\n",
      "Batch: 80, Loss: 1.1578800678253174, Accuracy: 0.6123046875\n",
      "Batch: 81, Loss: 1.0872551202774048, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1186094284057617, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 1.1713238954544067, Accuracy: 0.6240234375\n",
      "Batch: 84, Loss: 1.1134636402130127, Accuracy: 0.6318359375\n",
      "Batch: 85, Loss: 1.1497570276260376, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.161083698272705, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 1.1395268440246582, Accuracy: 0.6318359375\n",
      "Batch: 88, Loss: 1.1295262575149536, Accuracy: 0.6474609375\n",
      "Batch: 89, Loss: 1.1246085166931152, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.1179747581481934, Accuracy: 0.6171875\n",
      "Batch: 91, Loss: 1.1117370128631592, Accuracy: 0.6240234375\n",
      "Batch: 92, Loss: 1.1374359130859375, Accuracy: 0.634765625\n",
      "Batch: 93, Loss: 1.1760237216949463, Accuracy: 0.6044921875\n",
      "Batch: 94, Loss: 1.180138349533081, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.1831977367401123, Accuracy: 0.6181640625\n",
      "Batch: 96, Loss: 1.1967651844024658, Accuracy: 0.6162109375\n",
      "Batch: 97, Loss: 1.1614315509796143, Accuracy: 0.6015625\n",
      "Batch: 98, Loss: 1.139614224433899, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.1680028438568115, Accuracy: 0.62109375\n",
      "Batch: 100, Loss: 1.0582913160324097, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.0878324508666992, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.1748484373092651, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.1525349617004395, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.2322709560394287, Accuracy: 0.61328125\n",
      "Batch: 105, Loss: 1.229597568511963, Accuracy: 0.6103515625\n",
      "Batch: 106, Loss: 1.1643781661987305, Accuracy: 0.6318359375\n",
      "Batch: 107, Loss: 1.2593498229980469, Accuracy: 0.59765625\n",
      "Batch: 108, Loss: 1.160084843635559, Accuracy: 0.6240234375\n",
      "Batch: 109, Loss: 1.1861445903778076, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.1653046607971191, Accuracy: 0.6083984375\n",
      "Batch: 111, Loss: 1.1183748245239258, Accuracy: 0.658203125\n",
      "Batch: 112, Loss: 1.1477394104003906, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.16078519821167, Accuracy: 0.62890625\n",
      "Batch: 114, Loss: 1.1475615501403809, Accuracy: 0.630859375\n",
      "Batch: 115, Loss: 1.160142183303833, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.2012803554534912, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.104612112045288, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.204268455505371, Accuracy: 0.595703125\n",
      "Batch: 119, Loss: 1.2334487438201904, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.265021800994873, Accuracy: 0.5986328125\n",
      "Batch: 121, Loss: 1.1777253150939941, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.2313683032989502, Accuracy: 0.595703125\n",
      "Batch: 123, Loss: 1.169809341430664, Accuracy: 0.6416015625\n",
      "Batch: 124, Loss: 1.2281025648117065, Accuracy: 0.607421875\n",
      "Batch: 125, Loss: 1.1501140594482422, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.2603774070739746, Accuracy: 0.6044921875\n",
      "Batch: 127, Loss: 1.289685845375061, Accuracy: 0.58203125\n",
      "Batch: 128, Loss: 1.193217158317566, Accuracy: 0.6337890625\n",
      "Batch: 129, Loss: 1.2512614727020264, Accuracy: 0.6162109375\n",
      "Batch: 130, Loss: 1.150397777557373, Accuracy: 0.6201171875\n",
      "Batch: 131, Loss: 1.2367939949035645, Accuracy: 0.5908203125\n",
      "Batch: 132, Loss: 1.0392705202102661, Accuracy: 0.6689453125\n",
      "Batch: 133, Loss: 1.1469051837921143, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.1496155261993408, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.0406959056854248, Accuracy: 0.669921875\n",
      "Batch: 136, Loss: 1.1105122566223145, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.1823335886001587, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.2251886129379272, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1456669569015503, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.3098828792572021, Accuracy: 0.5693359375\n",
      "Batch: 141, Loss: 1.1917146444320679, Accuracy: 0.6298828125\n",
      "Batch: 142, Loss: 1.183983564376831, Accuracy: 0.6220703125\n",
      "Batch: 143, Loss: 1.188009262084961, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.2259639501571655, Accuracy: 0.6201171875\n",
      "Batch: 145, Loss: 1.2902779579162598, Accuracy: 0.5751953125\n",
      "Batch: 146, Loss: 1.1908103227615356, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.1781262159347534, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.223372459411621, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.240264892578125, Accuracy: 0.587890625\n",
      "Batch: 150, Loss: 1.1356714963912964, Accuracy: 0.640625\n",
      "Batch: 151, Loss: 1.184488296508789, Accuracy: 0.63671875\n",
      "Batch: 152, Loss: 1.1926865577697754, Accuracy: 0.6044921875\n",
      "Batch: 153, Loss: 1.1331731081008911, Accuracy: 0.626953125\n",
      "Batch: 154, Loss: 1.1074233055114746, Accuracy: 0.646484375\n",
      "Batch: 155, Loss: 1.082134485244751, Accuracy: 0.6494140625\n",
      "Epoch 505/200\n",
      "Batch: 1, Loss: 1.2295904159545898, Accuracy: 0.630859375\n",
      "Batch: 2, Loss: 1.0720980167388916, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 1.017034888267517, Accuracy: 0.6689453125\n",
      "Batch: 4, Loss: 1.0790190696716309, Accuracy: 0.64453125\n",
      "Batch: 5, Loss: 1.0245635509490967, Accuracy: 0.6640625\n",
      "Batch: 6, Loss: 1.0953823328018188, Accuracy: 0.6376953125\n",
      "Batch: 7, Loss: 1.0258564949035645, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 0.9951305389404297, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0002015829086304, Accuracy: 0.671875\n",
      "Batch: 10, Loss: 0.9811922311782837, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 1.039380669593811, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 1.0064526796340942, Accuracy: 0.6728515625\n",
      "Batch: 13, Loss: 1.0423907041549683, Accuracy: 0.65234375\n",
      "Batch: 14, Loss: 1.0097873210906982, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.9716668128967285, Accuracy: 0.67578125\n",
      "Batch: 16, Loss: 1.0533435344696045, Accuracy: 0.6416015625\n",
      "Batch: 17, Loss: 1.0434985160827637, Accuracy: 0.6435546875\n",
      "Batch: 18, Loss: 1.1580209732055664, Accuracy: 0.6279296875\n",
      "Batch: 19, Loss: 1.2158416509628296, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.0815458297729492, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.0907974243164062, Accuracy: 0.6474609375\n",
      "Batch: 22, Loss: 1.2733559608459473, Accuracy: 0.5810546875\n",
      "Batch: 23, Loss: 1.220276951789856, Accuracy: 0.6064453125\n",
      "Batch: 24, Loss: 1.0692437887191772, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.1753201484680176, Accuracy: 0.6337890625\n",
      "Batch: 26, Loss: 1.1851961612701416, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.1183339357376099, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.1134690046310425, Accuracy: 0.6552734375\n",
      "Batch: 29, Loss: 1.0923008918762207, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.124700903892517, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.2404508590698242, Accuracy: 0.580078125\n",
      "Batch: 32, Loss: 1.0329408645629883, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.0186997652053833, Accuracy: 0.6474609375\n",
      "Batch: 34, Loss: 1.0524988174438477, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.1519619226455688, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.141036033630371, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.168304681777954, Accuracy: 0.625\n",
      "Batch: 38, Loss: 1.2353211641311646, Accuracy: 0.5810546875\n",
      "Batch: 39, Loss: 1.0426584482192993, Accuracy: 0.673828125\n",
      "Batch: 40, Loss: 1.1231746673583984, Accuracy: 0.62890625\n",
      "Batch: 41, Loss: 1.1591575145721436, Accuracy: 0.6142578125\n",
      "Batch: 42, Loss: 1.0884215831756592, Accuracy: 0.6279296875\n",
      "Batch: 43, Loss: 1.0812816619873047, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.0477657318115234, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 1.0351784229278564, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.1284687519073486, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.1191306114196777, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.120903730392456, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.151555061340332, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.1435670852661133, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.1053466796875, Accuracy: 0.6298828125\n",
      "Batch: 52, Loss: 1.2538747787475586, Accuracy: 0.603515625\n",
      "Batch: 53, Loss: 1.1465648412704468, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.1925828456878662, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.1112501621246338, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.1617000102996826, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1151732206344604, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.1255382299423218, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.1103384494781494, Accuracy: 0.638671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 1.209871530532837, Accuracy: 0.60546875\n",
      "Batch: 61, Loss: 1.2001352310180664, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.0775434970855713, Accuracy: 0.619140625\n",
      "Batch: 63, Loss: 1.2116773128509521, Accuracy: 0.6171875\n",
      "Batch: 64, Loss: 1.2513186931610107, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.2176337242126465, Accuracy: 0.5986328125\n",
      "Batch: 66, Loss: 1.167043685913086, Accuracy: 0.6083984375\n",
      "Batch: 67, Loss: 1.1684900522232056, Accuracy: 0.6015625\n",
      "Batch: 68, Loss: 1.0499699115753174, Accuracy: 0.6689453125\n",
      "Batch: 69, Loss: 1.166804313659668, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.2023818492889404, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.1379384994506836, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.253208875656128, Accuracy: 0.59765625\n",
      "Batch: 73, Loss: 1.1828281879425049, Accuracy: 0.5966796875\n",
      "Batch: 74, Loss: 1.0910813808441162, Accuracy: 0.65234375\n",
      "Batch: 75, Loss: 1.1196660995483398, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.0794644355773926, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.107541799545288, Accuracy: 0.63671875\n",
      "Batch: 78, Loss: 1.0466501712799072, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1224989891052246, Accuracy: 0.6455078125\n",
      "Batch: 80, Loss: 1.124176263809204, Accuracy: 0.6416015625\n",
      "Batch: 81, Loss: 1.13142728805542, Accuracy: 0.626953125\n",
      "Batch: 82, Loss: 1.101914882659912, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 1.1656471490859985, Accuracy: 0.62109375\n",
      "Batch: 84, Loss: 1.1225979328155518, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.1776072978973389, Accuracy: 0.611328125\n",
      "Batch: 86, Loss: 1.1468071937561035, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 1.1740553379058838, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1550745964050293, Accuracy: 0.619140625\n",
      "Batch: 89, Loss: 1.153164267539978, Accuracy: 0.6396484375\n",
      "Batch: 90, Loss: 1.080913782119751, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.1240233182907104, Accuracy: 0.6396484375\n",
      "Batch: 92, Loss: 1.1291570663452148, Accuracy: 0.64453125\n",
      "Batch: 93, Loss: 1.1036090850830078, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.1629085540771484, Accuracy: 0.638671875\n",
      "Batch: 95, Loss: 1.1304957866668701, Accuracy: 0.658203125\n",
      "Batch: 96, Loss: 1.2598786354064941, Accuracy: 0.599609375\n",
      "Batch: 97, Loss: 1.1367111206054688, Accuracy: 0.603515625\n",
      "Batch: 98, Loss: 1.1641364097595215, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.1490339040756226, Accuracy: 0.619140625\n",
      "Batch: 100, Loss: 1.059617042541504, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.143445611000061, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.1478915214538574, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.2063531875610352, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.132336139678955, Accuracy: 0.6474609375\n",
      "Batch: 105, Loss: 1.2375816106796265, Accuracy: 0.6044921875\n",
      "Batch: 106, Loss: 1.1626918315887451, Accuracy: 0.6279296875\n",
      "Batch: 107, Loss: 1.2266789674758911, Accuracy: 0.603515625\n",
      "Batch: 108, Loss: 1.152564287185669, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.2151390314102173, Accuracy: 0.6015625\n",
      "Batch: 110, Loss: 1.0863347053527832, Accuracy: 0.654296875\n",
      "Batch: 111, Loss: 1.1476902961730957, Accuracy: 0.64453125\n",
      "Batch: 112, Loss: 1.069422721862793, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.1515130996704102, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.2124634981155396, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.1078588962554932, Accuracy: 0.6171875\n",
      "Batch: 116, Loss: 1.1962871551513672, Accuracy: 0.607421875\n",
      "Batch: 117, Loss: 1.1882352828979492, Accuracy: 0.599609375\n",
      "Batch: 118, Loss: 1.2094695568084717, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.2437686920166016, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2237435579299927, Accuracy: 0.58984375\n",
      "Batch: 121, Loss: 1.163658618927002, Accuracy: 0.6181640625\n",
      "Batch: 122, Loss: 1.2079495191574097, Accuracy: 0.6064453125\n",
      "Batch: 123, Loss: 1.205223798751831, Accuracy: 0.6103515625\n",
      "Batch: 124, Loss: 1.1891770362854004, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.0798678398132324, Accuracy: 0.6630859375\n",
      "Batch: 126, Loss: 1.2456105947494507, Accuracy: 0.5986328125\n",
      "Batch: 127, Loss: 1.2237703800201416, Accuracy: 0.59375\n",
      "Batch: 128, Loss: 1.2191736698150635, Accuracy: 0.5888671875\n",
      "Batch: 129, Loss: 1.2201242446899414, Accuracy: 0.6044921875\n",
      "Batch: 130, Loss: 1.094961404800415, Accuracy: 0.646484375\n",
      "Batch: 131, Loss: 1.2253444194793701, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.071596622467041, Accuracy: 0.6474609375\n",
      "Batch: 133, Loss: 1.1602156162261963, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1170880794525146, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 1.0431451797485352, Accuracy: 0.650390625\n",
      "Batch: 136, Loss: 1.1192102432250977, Accuracy: 0.6435546875\n",
      "Batch: 137, Loss: 1.1351878643035889, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.2178497314453125, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.2096803188323975, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.268478274345398, Accuracy: 0.6025390625\n",
      "Batch: 141, Loss: 1.1715326309204102, Accuracy: 0.619140625\n",
      "Batch: 142, Loss: 1.1543678045272827, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.2006056308746338, Accuracy: 0.6171875\n",
      "Batch: 144, Loss: 1.236344575881958, Accuracy: 0.599609375\n",
      "Batch: 145, Loss: 1.3019170761108398, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.2025341987609863, Accuracy: 0.6123046875\n",
      "Batch: 147, Loss: 1.1408699750900269, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.1765958070755005, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 1.1785109043121338, Accuracy: 0.6171875\n",
      "Batch: 150, Loss: 1.1541502475738525, Accuracy: 0.6240234375\n",
      "Batch: 151, Loss: 1.1566336154937744, Accuracy: 0.6279296875\n",
      "Batch: 152, Loss: 1.1402709484100342, Accuracy: 0.6162109375\n",
      "Batch: 153, Loss: 1.0935992002487183, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.1168802976608276, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.152217984199524, Accuracy: 0.6279296875\n",
      "Epoch 506/200\n",
      "Batch: 1, Loss: 1.2005589008331299, Accuracy: 0.6533203125\n",
      "Batch: 2, Loss: 1.0522632598876953, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 1.0708497762680054, Accuracy: 0.6298828125\n",
      "Batch: 4, Loss: 1.0648961067199707, Accuracy: 0.634765625\n",
      "Batch: 5, Loss: 1.0263482332229614, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.01827073097229, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.0321755409240723, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 0.9678359031677246, Accuracy: 0.6865234375\n",
      "Batch: 9, Loss: 0.9796587228775024, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9673023819923401, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 0.9758486747741699, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.9793002009391785, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 0.9489356279373169, Accuracy: 0.6953125\n",
      "Batch: 14, Loss: 0.9562793970108032, Accuracy: 0.6787109375\n",
      "Batch: 15, Loss: 0.8976140022277832, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.0445504188537598, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.04947829246521, Accuracy: 0.6357421875\n",
      "Batch: 18, Loss: 1.1525088548660278, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.1589345932006836, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.0943028926849365, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.0583258867263794, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.1795934438705444, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.2307041883468628, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.1709882020950317, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1283955574035645, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.1686145067214966, Accuracy: 0.6083984375\n",
      "Batch: 27, Loss: 1.0883142948150635, Accuracy: 0.6513671875\n",
      "Batch: 28, Loss: 1.0717101097106934, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.0551217794418335, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.2238632440567017, Accuracy: 0.59375\n",
      "Batch: 31, Loss: 1.2147555351257324, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.0339553356170654, Accuracy: 0.634765625\n",
      "Batch: 33, Loss: 1.0002834796905518, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1146459579467773, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.1176466941833496, Accuracy: 0.6396484375\n",
      "Batch: 36, Loss: 1.1627447605133057, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.2523090839385986, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.1461833715438843, Accuracy: 0.6318359375\n",
      "Batch: 39, Loss: 1.0941483974456787, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.0850615501403809, Accuracy: 0.6513671875\n",
      "Batch: 41, Loss: 1.1039109230041504, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.0624562501907349, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.0688698291778564, Accuracy: 0.6552734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 1.031341791152954, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.0310649871826172, Accuracy: 0.662109375\n",
      "Batch: 46, Loss: 1.1631476879119873, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.0956931114196777, Accuracy: 0.6572265625\n",
      "Batch: 48, Loss: 1.136001467704773, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.1831855773925781, Accuracy: 0.619140625\n",
      "Batch: 50, Loss: 1.1543447971343994, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.1685478687286377, Accuracy: 0.59765625\n",
      "Batch: 52, Loss: 1.1977179050445557, Accuracy: 0.6015625\n",
      "Batch: 53, Loss: 1.1806379556655884, Accuracy: 0.60546875\n",
      "Batch: 54, Loss: 1.1776154041290283, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.1504855155944824, Accuracy: 0.6044921875\n",
      "Batch: 56, Loss: 1.0687956809997559, Accuracy: 0.6376953125\n",
      "Batch: 57, Loss: 1.0543384552001953, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.1296656131744385, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.10932457447052, Accuracy: 0.6416015625\n",
      "Batch: 60, Loss: 1.2168241739273071, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.2012746334075928, Accuracy: 0.6015625\n",
      "Batch: 62, Loss: 1.1537977457046509, Accuracy: 0.62890625\n",
      "Batch: 63, Loss: 1.1934802532196045, Accuracy: 0.6171875\n",
      "Batch: 64, Loss: 1.1801549196243286, Accuracy: 0.6142578125\n",
      "Batch: 65, Loss: 1.2035200595855713, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.1663565635681152, Accuracy: 0.611328125\n",
      "Batch: 67, Loss: 1.17374587059021, Accuracy: 0.63671875\n",
      "Batch: 68, Loss: 1.0763583183288574, Accuracy: 0.6572265625\n",
      "Batch: 69, Loss: 1.1932958364486694, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.169257402420044, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1177027225494385, Accuracy: 0.6123046875\n",
      "Batch: 72, Loss: 1.1658793687820435, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.2366032600402832, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.1154723167419434, Accuracy: 0.65234375\n",
      "Batch: 75, Loss: 1.172719955444336, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.0687854290008545, Accuracy: 0.6455078125\n",
      "Batch: 77, Loss: 1.1002556085586548, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.122753620147705, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.1669646501541138, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.1739985942840576, Accuracy: 0.638671875\n",
      "Batch: 81, Loss: 1.1397104263305664, Accuracy: 0.6181640625\n",
      "Batch: 82, Loss: 1.1257953643798828, Accuracy: 0.6103515625\n",
      "Batch: 83, Loss: 1.1426258087158203, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.1013031005859375, Accuracy: 0.650390625\n",
      "Batch: 85, Loss: 1.1683075428009033, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.2135608196258545, Accuracy: 0.611328125\n",
      "Batch: 87, Loss: 1.2225724458694458, Accuracy: 0.6044921875\n",
      "Batch: 88, Loss: 1.147221326828003, Accuracy: 0.6298828125\n",
      "Batch: 89, Loss: 1.1446752548217773, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.0553858280181885, Accuracy: 0.654296875\n",
      "Batch: 91, Loss: 1.1025166511535645, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.1134650707244873, Accuracy: 0.6572265625\n",
      "Batch: 93, Loss: 1.1806172132492065, Accuracy: 0.615234375\n",
      "Batch: 94, Loss: 1.2031093835830688, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1259732246398926, Accuracy: 0.6513671875\n",
      "Batch: 96, Loss: 1.1861704587936401, Accuracy: 0.62890625\n",
      "Batch: 97, Loss: 1.1811537742614746, Accuracy: 0.619140625\n",
      "Batch: 98, Loss: 1.150026559829712, Accuracy: 0.62890625\n",
      "Batch: 99, Loss: 1.182063341140747, Accuracy: 0.6181640625\n",
      "Batch: 100, Loss: 1.10069739818573, Accuracy: 0.6435546875\n",
      "Batch: 101, Loss: 1.0849080085754395, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 1.17841374874115, Accuracy: 0.615234375\n",
      "Batch: 103, Loss: 1.149175763130188, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.146798849105835, Accuracy: 0.625\n",
      "Batch: 105, Loss: 1.2413760423660278, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.1578741073608398, Accuracy: 0.630859375\n",
      "Batch: 107, Loss: 1.2986592054367065, Accuracy: 0.5595703125\n",
      "Batch: 108, Loss: 1.1209421157836914, Accuracy: 0.6240234375\n",
      "Batch: 109, Loss: 1.2479987144470215, Accuracy: 0.5947265625\n",
      "Batch: 110, Loss: 1.096503496170044, Accuracy: 0.6435546875\n",
      "Batch: 111, Loss: 1.1432592868804932, Accuracy: 0.6162109375\n",
      "Batch: 112, Loss: 1.0846211910247803, Accuracy: 0.6484375\n",
      "Batch: 113, Loss: 1.1467864513397217, Accuracy: 0.630859375\n",
      "Batch: 114, Loss: 1.1527676582336426, Accuracy: 0.6259765625\n",
      "Batch: 115, Loss: 1.192118525505066, Accuracy: 0.61328125\n",
      "Batch: 116, Loss: 1.2122750282287598, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1579431295394897, Accuracy: 0.6220703125\n",
      "Batch: 118, Loss: 1.2536370754241943, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.1934010982513428, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.259927749633789, Accuracy: 0.6240234375\n",
      "Batch: 121, Loss: 1.1486109495162964, Accuracy: 0.6318359375\n",
      "Batch: 122, Loss: 1.1735506057739258, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.2001543045043945, Accuracy: 0.595703125\n",
      "Batch: 124, Loss: 1.2594428062438965, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.2317535877227783, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.2510437965393066, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.2005369663238525, Accuracy: 0.60546875\n",
      "Batch: 128, Loss: 1.1891798973083496, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.1238582134246826, Accuracy: 0.63671875\n",
      "Batch: 130, Loss: 1.111441731452942, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.2114167213439941, Accuracy: 0.595703125\n",
      "Batch: 132, Loss: 1.0420631170272827, Accuracy: 0.6572265625\n",
      "Batch: 133, Loss: 1.156177043914795, Accuracy: 0.630859375\n",
      "Batch: 134, Loss: 1.1259636878967285, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.0132479667663574, Accuracy: 0.6767578125\n",
      "Batch: 136, Loss: 1.0756464004516602, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1274075508117676, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 1.2200900316238403, Accuracy: 0.615234375\n",
      "Batch: 139, Loss: 1.2162554264068604, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.2138272523880005, Accuracy: 0.6298828125\n",
      "Batch: 141, Loss: 1.1592564582824707, Accuracy: 0.623046875\n",
      "Batch: 142, Loss: 1.1765806674957275, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2221869230270386, Accuracy: 0.591796875\n",
      "Batch: 144, Loss: 1.2077662944793701, Accuracy: 0.623046875\n",
      "Batch: 145, Loss: 1.1492462158203125, Accuracy: 0.619140625\n",
      "Batch: 146, Loss: 1.234601616859436, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.2630058526992798, Accuracy: 0.5859375\n",
      "Batch: 148, Loss: 1.1753478050231934, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.2402652502059937, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.1394672393798828, Accuracy: 0.6240234375\n",
      "Batch: 151, Loss: 1.134765625, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1199930906295776, Accuracy: 0.6357421875\n",
      "Batch: 153, Loss: 1.1105945110321045, Accuracy: 0.6181640625\n",
      "Batch: 154, Loss: 1.1093344688415527, Accuracy: 0.640625\n",
      "Batch: 155, Loss: 1.1021740436553955, Accuracy: 0.6513671875\n",
      "Epoch 507/200\n",
      "Batch: 1, Loss: 1.2477028369903564, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.0435051918029785, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 0.9747885465621948, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 1.0618915557861328, Accuracy: 0.6455078125\n",
      "Batch: 5, Loss: 1.0376120805740356, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.0626463890075684, Accuracy: 0.6591796875\n",
      "Batch: 7, Loss: 0.989984393119812, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 1.018019437789917, Accuracy: 0.6552734375\n",
      "Batch: 9, Loss: 1.026930332183838, Accuracy: 0.6728515625\n",
      "Batch: 10, Loss: 0.9751643538475037, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 1.0113685131072998, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 0.9712806940078735, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 1.0264835357666016, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 0.9945031404495239, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.9754273891448975, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.0305540561676025, Accuracy: 0.6455078125\n",
      "Batch: 17, Loss: 1.0248949527740479, Accuracy: 0.654296875\n",
      "Batch: 18, Loss: 1.0961228609085083, Accuracy: 0.65625\n",
      "Batch: 19, Loss: 1.1970044374465942, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.1000521183013916, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.076209306716919, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.206465244293213, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.2113115787506104, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.1150709390640259, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.145230770111084, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.1857081651687622, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.100414752960205, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.0530074834823608, Accuracy: 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 1.1047415733337402, Accuracy: 0.623046875\n",
      "Batch: 30, Loss: 1.2060277462005615, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2083637714385986, Accuracy: 0.6142578125\n",
      "Batch: 32, Loss: 1.012481927871704, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 0.9852465987205505, Accuracy: 0.6591796875\n",
      "Batch: 34, Loss: 1.16459321975708, Accuracy: 0.6328125\n",
      "Batch: 35, Loss: 1.1200531721115112, Accuracy: 0.62890625\n",
      "Batch: 36, Loss: 1.1623504161834717, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.2494280338287354, Accuracy: 0.5830078125\n",
      "Batch: 38, Loss: 1.1090928316116333, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.0418951511383057, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.1113754510879517, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1185555458068848, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0598872900009155, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 0.9858217239379883, Accuracy: 0.689453125\n",
      "Batch: 44, Loss: 1.059455156326294, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.0278726816177368, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.1223602294921875, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.0381965637207031, Accuracy: 0.6728515625\n",
      "Batch: 48, Loss: 1.1261370182037354, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.1633793115615845, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.1005738973617554, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.1209534406661987, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.2398943901062012, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.1580374240875244, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1686279773712158, Accuracy: 0.6220703125\n",
      "Batch: 55, Loss: 1.144242286682129, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.0964314937591553, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.0759990215301514, Accuracy: 0.65234375\n",
      "Batch: 58, Loss: 1.137838363647461, Accuracy: 0.6337890625\n",
      "Batch: 59, Loss: 1.0424965620040894, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.2695786952972412, Accuracy: 0.5859375\n",
      "Batch: 61, Loss: 1.1627528667449951, Accuracy: 0.6328125\n",
      "Batch: 62, Loss: 1.1302217245101929, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.1257195472717285, Accuracy: 0.6181640625\n",
      "Batch: 64, Loss: 1.2295451164245605, Accuracy: 0.5908203125\n",
      "Batch: 65, Loss: 1.1862452030181885, Accuracy: 0.6123046875\n",
      "Batch: 66, Loss: 1.1460015773773193, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.0974129438400269, Accuracy: 0.65234375\n",
      "Batch: 68, Loss: 1.092003345489502, Accuracy: 0.6572265625\n",
      "Batch: 69, Loss: 1.1930150985717773, Accuracy: 0.630859375\n",
      "Batch: 70, Loss: 1.1331207752227783, Accuracy: 0.6298828125\n",
      "Batch: 71, Loss: 1.1358764171600342, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.2006587982177734, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.1661170721054077, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.126955509185791, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.0835827589035034, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.0295912027359009, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 1.0638599395751953, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.1213877201080322, Accuracy: 0.6201171875\n",
      "Batch: 79, Loss: 1.153233528137207, Accuracy: 0.6181640625\n",
      "Batch: 80, Loss: 1.1661522388458252, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.0877227783203125, Accuracy: 0.6474609375\n",
      "Batch: 82, Loss: 1.1235058307647705, Accuracy: 0.6337890625\n",
      "Batch: 83, Loss: 1.1354718208312988, Accuracy: 0.625\n",
      "Batch: 84, Loss: 1.1585692167282104, Accuracy: 0.611328125\n",
      "Batch: 85, Loss: 1.1984293460845947, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.1588528156280518, Accuracy: 0.6318359375\n",
      "Batch: 87, Loss: 1.17307448387146, Accuracy: 0.6162109375\n",
      "Batch: 88, Loss: 1.1526025533676147, Accuracy: 0.6259765625\n",
      "Batch: 89, Loss: 1.184836506843567, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.061536192893982, Accuracy: 0.64453125\n",
      "Batch: 91, Loss: 1.077549934387207, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.1631547212600708, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.1381890773773193, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.1420365571975708, Accuracy: 0.6396484375\n",
      "Batch: 95, Loss: 1.1663511991500854, Accuracy: 0.646484375\n",
      "Batch: 96, Loss: 1.1827480792999268, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.164123296737671, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.0994155406951904, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.1839849948883057, Accuracy: 0.61328125\n",
      "Batch: 100, Loss: 1.0492327213287354, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.1032118797302246, Accuracy: 0.662109375\n",
      "Batch: 102, Loss: 1.165381908416748, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.2184314727783203, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1566917896270752, Accuracy: 0.6259765625\n",
      "Batch: 105, Loss: 1.2285337448120117, Accuracy: 0.5927734375\n",
      "Batch: 106, Loss: 1.1332682371139526, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2509238719940186, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.1537823677062988, Accuracy: 0.6357421875\n",
      "Batch: 109, Loss: 1.2063089609146118, Accuracy: 0.6025390625\n",
      "Batch: 110, Loss: 1.1366231441497803, Accuracy: 0.638671875\n",
      "Batch: 111, Loss: 1.058626651763916, Accuracy: 0.662109375\n",
      "Batch: 112, Loss: 1.112945556640625, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1822795867919922, Accuracy: 0.6181640625\n",
      "Batch: 114, Loss: 1.1885309219360352, Accuracy: 0.595703125\n",
      "Batch: 115, Loss: 1.1817470788955688, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1799664497375488, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.2181291580200195, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.2554762363433838, Accuracy: 0.6044921875\n",
      "Batch: 119, Loss: 1.2392877340316772, Accuracy: 0.6220703125\n",
      "Batch: 120, Loss: 1.300786018371582, Accuracy: 0.603515625\n",
      "Batch: 121, Loss: 1.2145136594772339, Accuracy: 0.6259765625\n",
      "Batch: 122, Loss: 1.1964399814605713, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.1435284614562988, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.2082223892211914, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.143436312675476, Accuracy: 0.6318359375\n",
      "Batch: 126, Loss: 1.2533832788467407, Accuracy: 0.595703125\n",
      "Batch: 127, Loss: 1.2511578798294067, Accuracy: 0.587890625\n",
      "Batch: 128, Loss: 1.2574501037597656, Accuracy: 0.5966796875\n",
      "Batch: 129, Loss: 1.1816892623901367, Accuracy: 0.6337890625\n",
      "Batch: 130, Loss: 1.164130449295044, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.2276294231414795, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0589513778686523, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.1585144996643066, Accuracy: 0.6142578125\n",
      "Batch: 134, Loss: 1.1388921737670898, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.0545923709869385, Accuracy: 0.66015625\n",
      "Batch: 136, Loss: 1.0564497709274292, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.116554856300354, Accuracy: 0.6552734375\n",
      "Batch: 138, Loss: 1.2198681831359863, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.1307674646377563, Accuracy: 0.6337890625\n",
      "Batch: 140, Loss: 1.2091748714447021, Accuracy: 0.59765625\n",
      "Batch: 141, Loss: 1.1437525749206543, Accuracy: 0.623046875\n",
      "Batch: 142, Loss: 1.1795499324798584, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.2480186223983765, Accuracy: 0.6064453125\n",
      "Batch: 144, Loss: 1.2692461013793945, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.2568621635437012, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.2400617599487305, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.2102437019348145, Accuracy: 0.6083984375\n",
      "Batch: 148, Loss: 1.2093231678009033, Accuracy: 0.5908203125\n",
      "Batch: 149, Loss: 1.1848008632659912, Accuracy: 0.599609375\n",
      "Batch: 150, Loss: 1.1623800992965698, Accuracy: 0.6298828125\n",
      "Batch: 151, Loss: 1.1872836351394653, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.1930046081542969, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.0671582221984863, Accuracy: 0.66796875\n",
      "Batch: 154, Loss: 1.090957760810852, Accuracy: 0.654296875\n",
      "Batch: 155, Loss: 1.0795906782150269, Accuracy: 0.6474609375\n",
      "Epoch 508/200\n",
      "Batch: 1, Loss: 1.1913692951202393, Accuracy: 0.66015625\n",
      "Batch: 2, Loss: 1.0383317470550537, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 1.0171561241149902, Accuracy: 0.65234375\n",
      "Batch: 4, Loss: 1.046057939529419, Accuracy: 0.65625\n",
      "Batch: 5, Loss: 1.038362741470337, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.038771152496338, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.1013858318328857, Accuracy: 0.63671875\n",
      "Batch: 8, Loss: 1.0073294639587402, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 1.0537488460540771, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 1.0020726919174194, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 0.9865599274635315, Accuracy: 0.6611328125\n",
      "Batch: 12, Loss: 1.0028011798858643, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.9981029629707336, Accuracy: 0.6767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.9776116609573364, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9467703700065613, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0615119934082031, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.0115768909454346, Accuracy: 0.669921875\n",
      "Batch: 18, Loss: 1.150383710861206, Accuracy: 0.6162109375\n",
      "Batch: 19, Loss: 1.247253656387329, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.1567593812942505, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.0481034517288208, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.1911852359771729, Accuracy: 0.634765625\n",
      "Batch: 23, Loss: 1.1822092533111572, Accuracy: 0.6171875\n",
      "Batch: 24, Loss: 1.097315788269043, Accuracy: 0.638671875\n",
      "Batch: 25, Loss: 1.1470773220062256, Accuracy: 0.6123046875\n",
      "Batch: 26, Loss: 1.1628484725952148, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.1195894479751587, Accuracy: 0.6181640625\n",
      "Batch: 28, Loss: 1.0630230903625488, Accuracy: 0.6328125\n",
      "Batch: 29, Loss: 1.0444375276565552, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.183167815208435, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.1777067184448242, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.0195362567901611, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 0.9939709305763245, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0856057405471802, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.088403344154358, Accuracy: 0.642578125\n",
      "Batch: 36, Loss: 1.1790180206298828, Accuracy: 0.595703125\n",
      "Batch: 37, Loss: 1.208954095840454, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.1521809101104736, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.0748109817504883, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0823969841003418, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.0948104858398438, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 1.0347445011138916, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.04923415184021, Accuracy: 0.673828125\n",
      "Batch: 44, Loss: 1.053456425666809, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.0391876697540283, Accuracy: 0.67578125\n",
      "Batch: 46, Loss: 1.1468408107757568, Accuracy: 0.6298828125\n",
      "Batch: 47, Loss: 1.0754812955856323, Accuracy: 0.662109375\n",
      "Batch: 48, Loss: 1.1326407194137573, Accuracy: 0.619140625\n",
      "Batch: 49, Loss: 1.169954776763916, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.1183857917785645, Accuracy: 0.6396484375\n",
      "Batch: 51, Loss: 1.1270033121109009, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2226372957229614, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.2166121006011963, Accuracy: 0.58984375\n",
      "Batch: 54, Loss: 1.2007079124450684, Accuracy: 0.59375\n",
      "Batch: 55, Loss: 1.110320806503296, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0934709310531616, Accuracy: 0.65625\n",
      "Batch: 57, Loss: 1.05826997756958, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.0990458726882935, Accuracy: 0.658203125\n",
      "Batch: 59, Loss: 1.099013328552246, Accuracy: 0.6611328125\n",
      "Batch: 60, Loss: 1.2615342140197754, Accuracy: 0.58203125\n",
      "Batch: 61, Loss: 1.1210479736328125, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1532061100006104, Accuracy: 0.6201171875\n",
      "Batch: 63, Loss: 1.1616337299346924, Accuracy: 0.6337890625\n",
      "Batch: 64, Loss: 1.186750888824463, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1605145931243896, Accuracy: 0.615234375\n",
      "Batch: 66, Loss: 1.1495468616485596, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1228466033935547, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.1427569389343262, Accuracy: 0.6318359375\n",
      "Batch: 69, Loss: 1.1615657806396484, Accuracy: 0.6298828125\n",
      "Batch: 70, Loss: 1.1026102304458618, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.1143769025802612, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.13441801071167, Accuracy: 0.6328125\n",
      "Batch: 73, Loss: 1.2436320781707764, Accuracy: 0.5927734375\n",
      "Batch: 74, Loss: 1.107469081878662, Accuracy: 0.6259765625\n",
      "Batch: 75, Loss: 1.1148979663848877, Accuracy: 0.64453125\n",
      "Batch: 76, Loss: 1.0998971462249756, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 1.0828542709350586, Accuracy: 0.6552734375\n",
      "Batch: 78, Loss: 1.0532104969024658, Accuracy: 0.6767578125\n",
      "Batch: 79, Loss: 1.1287084817886353, Accuracy: 0.62109375\n",
      "Batch: 80, Loss: 1.127892255783081, Accuracy: 0.62890625\n",
      "Batch: 81, Loss: 1.1385358572006226, Accuracy: 0.640625\n",
      "Batch: 82, Loss: 1.101050853729248, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.148059606552124, Accuracy: 0.626953125\n",
      "Batch: 84, Loss: 1.1644551753997803, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.120887279510498, Accuracy: 0.6376953125\n",
      "Batch: 86, Loss: 1.1424710750579834, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.1362884044647217, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.1354261636734009, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.1029596328735352, Accuracy: 0.650390625\n",
      "Batch: 90, Loss: 1.1240456104278564, Accuracy: 0.61328125\n",
      "Batch: 91, Loss: 1.0960984230041504, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.1143838167190552, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.0990204811096191, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.18539559841156, Accuracy: 0.623046875\n",
      "Batch: 95, Loss: 1.1506874561309814, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.1534779071807861, Accuracy: 0.6552734375\n",
      "Batch: 97, Loss: 1.1741631031036377, Accuracy: 0.609375\n",
      "Batch: 98, Loss: 1.1492586135864258, Accuracy: 0.62109375\n",
      "Batch: 99, Loss: 1.0797488689422607, Accuracy: 0.65625\n",
      "Batch: 100, Loss: 1.073587417602539, Accuracy: 0.6611328125\n",
      "Batch: 101, Loss: 1.1306700706481934, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.0770624876022339, Accuracy: 0.65625\n",
      "Batch: 103, Loss: 1.1876202821731567, Accuracy: 0.62109375\n",
      "Batch: 104, Loss: 1.1125916242599487, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.210378646850586, Accuracy: 0.6083984375\n",
      "Batch: 106, Loss: 1.1595526933670044, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.264786720275879, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.1743073463439941, Accuracy: 0.6279296875\n",
      "Batch: 109, Loss: 1.2014670372009277, Accuracy: 0.59765625\n",
      "Batch: 110, Loss: 1.1537458896636963, Accuracy: 0.6279296875\n",
      "Batch: 111, Loss: 1.1569421291351318, Accuracy: 0.6103515625\n",
      "Batch: 112, Loss: 1.110998272895813, Accuracy: 0.6298828125\n",
      "Batch: 113, Loss: 1.1159697771072388, Accuracy: 0.6494140625\n",
      "Batch: 114, Loss: 1.1704280376434326, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.1567606925964355, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.2187440395355225, Accuracy: 0.5849609375\n",
      "Batch: 117, Loss: 1.1434730291366577, Accuracy: 0.6298828125\n",
      "Batch: 118, Loss: 1.1917188167572021, Accuracy: 0.6220703125\n",
      "Batch: 119, Loss: 1.239868402481079, Accuracy: 0.6123046875\n",
      "Batch: 120, Loss: 1.2615249156951904, Accuracy: 0.603515625\n",
      "Batch: 121, Loss: 1.1656969785690308, Accuracy: 0.61328125\n",
      "Batch: 122, Loss: 1.1591039896011353, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.1995497941970825, Accuracy: 0.6064453125\n",
      "Batch: 124, Loss: 1.2428966760635376, Accuracy: 0.62109375\n",
      "Batch: 125, Loss: 1.1655561923980713, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.2284150123596191, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.170815348625183, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.191511869430542, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.2143943309783936, Accuracy: 0.595703125\n",
      "Batch: 130, Loss: 1.1209745407104492, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.220322847366333, Accuracy: 0.59375\n",
      "Batch: 132, Loss: 1.0658878087997437, Accuracy: 0.6669921875\n",
      "Batch: 133, Loss: 1.177978515625, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.1432099342346191, Accuracy: 0.6357421875\n",
      "Batch: 135, Loss: 1.0655229091644287, Accuracy: 0.6337890625\n",
      "Batch: 136, Loss: 1.1354089975357056, Accuracy: 0.62109375\n",
      "Batch: 137, Loss: 1.1637191772460938, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.2103863954544067, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.184107780456543, Accuracy: 0.6318359375\n",
      "Batch: 140, Loss: 1.2452129125595093, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.1612924337387085, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1071797609329224, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.2274401187896729, Accuracy: 0.58984375\n",
      "Batch: 144, Loss: 1.2011386156082153, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.234548568725586, Accuracy: 0.6171875\n",
      "Batch: 146, Loss: 1.1574571132659912, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.2054930925369263, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1383217573165894, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.1595332622528076, Accuracy: 0.5966796875\n",
      "Batch: 150, Loss: 1.1483345031738281, Accuracy: 0.625\n",
      "Batch: 151, Loss: 1.134217381477356, Accuracy: 0.6357421875\n",
      "Batch: 152, Loss: 1.2208439111709595, Accuracy: 0.6064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 153, Loss: 1.0862880945205688, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.0899035930633545, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.0751861333847046, Accuracy: 0.6484375\n",
      "Epoch 509/200\n",
      "Batch: 1, Loss: 1.2329001426696777, Accuracy: 0.615234375\n",
      "Batch: 2, Loss: 1.066648244857788, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.0309163331985474, Accuracy: 0.6474609375\n",
      "Batch: 4, Loss: 1.0882450342178345, Accuracy: 0.6259765625\n",
      "Batch: 5, Loss: 1.0026028156280518, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.0335336923599243, Accuracy: 0.6611328125\n",
      "Batch: 7, Loss: 0.998085618019104, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9682588577270508, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 1.0076053142547607, Accuracy: 0.6748046875\n",
      "Batch: 10, Loss: 1.000413179397583, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9854069948196411, Accuracy: 0.666015625\n",
      "Batch: 12, Loss: 1.0270335674285889, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 1.0600651502609253, Accuracy: 0.642578125\n",
      "Batch: 14, Loss: 0.9706997871398926, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9560694694519043, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 1.0117771625518799, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 1.0962624549865723, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.0897557735443115, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1380749940872192, Accuracy: 0.63671875\n",
      "Batch: 20, Loss: 1.0805675983428955, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.055063009262085, Accuracy: 0.666015625\n",
      "Batch: 22, Loss: 1.2210261821746826, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.209280014038086, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.1010794639587402, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.194305419921875, Accuracy: 0.60546875\n",
      "Batch: 26, Loss: 1.1763863563537598, Accuracy: 0.6123046875\n",
      "Batch: 27, Loss: 1.108959674835205, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.0950727462768555, Accuracy: 0.642578125\n",
      "Batch: 29, Loss: 1.0711405277252197, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1118783950805664, Accuracy: 0.6298828125\n",
      "Batch: 31, Loss: 1.1905345916748047, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.0262268781661987, Accuracy: 0.6796875\n",
      "Batch: 33, Loss: 0.9915505647659302, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0547316074371338, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 1.1958413124084473, Accuracy: 0.6025390625\n",
      "Batch: 36, Loss: 1.2105157375335693, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.1903036832809448, Accuracy: 0.619140625\n",
      "Batch: 38, Loss: 1.1774044036865234, Accuracy: 0.6142578125\n",
      "Batch: 39, Loss: 1.045055866241455, Accuracy: 0.6611328125\n",
      "Batch: 40, Loss: 1.1059958934783936, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.1088733673095703, Accuracy: 0.6171875\n",
      "Batch: 42, Loss: 1.0665650367736816, Accuracy: 0.6416015625\n",
      "Batch: 43, Loss: 1.0441726446151733, Accuracy: 0.658203125\n",
      "Batch: 44, Loss: 1.0531026124954224, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 1.0089681148529053, Accuracy: 0.6669921875\n",
      "Batch: 46, Loss: 1.1308631896972656, Accuracy: 0.60546875\n",
      "Batch: 47, Loss: 1.0593830347061157, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.1129155158996582, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.1722233295440674, Accuracy: 0.6240234375\n",
      "Batch: 50, Loss: 1.114033579826355, Accuracy: 0.6396484375\n",
      "Batch: 51, Loss: 1.1576054096221924, Accuracy: 0.5966796875\n",
      "Batch: 52, Loss: 1.2209255695343018, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1522648334503174, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.122236728668213, Accuracy: 0.62890625\n",
      "Batch: 55, Loss: 1.120466709136963, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.1205352544784546, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.1426082849502563, Accuracy: 0.63671875\n",
      "Batch: 58, Loss: 1.1815447807312012, Accuracy: 0.6279296875\n",
      "Batch: 59, Loss: 1.129845142364502, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.2524019479751587, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1522455215454102, Accuracy: 0.634765625\n",
      "Batch: 62, Loss: 1.1100850105285645, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.1851979494094849, Accuracy: 0.6328125\n",
      "Batch: 64, Loss: 1.18564772605896, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.1655899286270142, Accuracy: 0.6181640625\n",
      "Batch: 66, Loss: 1.1260029077529907, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.142858862876892, Accuracy: 0.6376953125\n",
      "Batch: 68, Loss: 1.1009187698364258, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1849524974822998, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1190922260284424, Accuracy: 0.6396484375\n",
      "Batch: 71, Loss: 1.1460717916488647, Accuracy: 0.6279296875\n",
      "Batch: 72, Loss: 1.156894326210022, Accuracy: 0.62109375\n",
      "Batch: 73, Loss: 1.1775693893432617, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.0972005128860474, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.13101327419281, Accuracy: 0.626953125\n",
      "Batch: 76, Loss: 1.0427653789520264, Accuracy: 0.6650390625\n",
      "Batch: 77, Loss: 1.077512264251709, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.065229892730713, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.1152782440185547, Accuracy: 0.64453125\n",
      "Batch: 80, Loss: 1.1934601068496704, Accuracy: 0.6220703125\n",
      "Batch: 81, Loss: 1.123016595840454, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.114270567893982, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.1531524658203125, Accuracy: 0.638671875\n",
      "Batch: 84, Loss: 1.1664140224456787, Accuracy: 0.626953125\n",
      "Batch: 85, Loss: 1.1289689540863037, Accuracy: 0.6376953125\n",
      "Batch: 86, Loss: 1.1792632341384888, Accuracy: 0.6025390625\n",
      "Batch: 87, Loss: 1.2142019271850586, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.111114501953125, Accuracy: 0.64453125\n",
      "Batch: 89, Loss: 1.1598845720291138, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.0402235984802246, Accuracy: 0.6669921875\n",
      "Batch: 91, Loss: 1.138737440109253, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.1243135929107666, Accuracy: 0.6494140625\n",
      "Batch: 93, Loss: 1.141737461090088, Accuracy: 0.623046875\n",
      "Batch: 94, Loss: 1.1965460777282715, Accuracy: 0.6201171875\n",
      "Batch: 95, Loss: 1.2131640911102295, Accuracy: 0.609375\n",
      "Batch: 96, Loss: 1.1638264656066895, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.1667413711547852, Accuracy: 0.6181640625\n",
      "Batch: 98, Loss: 1.0935235023498535, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.139626145362854, Accuracy: 0.6259765625\n",
      "Batch: 100, Loss: 1.0436985492706299, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.0735743045806885, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.1380736827850342, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1516187191009521, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.1201417446136475, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.1826348304748535, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.164665699005127, Accuracy: 0.6181640625\n",
      "Batch: 107, Loss: 1.2492413520812988, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.1470668315887451, Accuracy: 0.630859375\n",
      "Batch: 109, Loss: 1.1882843971252441, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.1467912197113037, Accuracy: 0.62890625\n",
      "Batch: 111, Loss: 1.1578764915466309, Accuracy: 0.6279296875\n",
      "Batch: 112, Loss: 1.1538259983062744, Accuracy: 0.64453125\n",
      "Batch: 113, Loss: 1.1061694622039795, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.1446609497070312, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.2479387521743774, Accuracy: 0.5927734375\n",
      "Batch: 116, Loss: 1.1963382959365845, Accuracy: 0.595703125\n",
      "Batch: 117, Loss: 1.117504358291626, Accuracy: 0.6416015625\n",
      "Batch: 118, Loss: 1.1892204284667969, Accuracy: 0.6142578125\n",
      "Batch: 119, Loss: 1.2516003847122192, Accuracy: 0.5908203125\n",
      "Batch: 120, Loss: 1.256201982498169, Accuracy: 0.6044921875\n",
      "Batch: 121, Loss: 1.2007933855056763, Accuracy: 0.6103515625\n",
      "Batch: 122, Loss: 1.1958835124969482, Accuracy: 0.615234375\n",
      "Batch: 123, Loss: 1.1391791105270386, Accuracy: 0.6318359375\n",
      "Batch: 124, Loss: 1.1738375425338745, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.154465913772583, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.2202693223953247, Accuracy: 0.6201171875\n",
      "Batch: 127, Loss: 1.2277143001556396, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2166111469268799, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.2271316051483154, Accuracy: 0.6162109375\n",
      "Batch: 130, Loss: 1.1869995594024658, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.2280259132385254, Accuracy: 0.607421875\n",
      "Batch: 132, Loss: 1.059592604637146, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.164061427116394, Accuracy: 0.6103515625\n",
      "Batch: 134, Loss: 1.111817479133606, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.0474108457565308, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.0941684246063232, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.1498072147369385, Accuracy: 0.623046875\n",
      "Batch: 138, Loss: 1.2876583337783813, Accuracy: 0.57421875\n",
      "Batch: 139, Loss: 1.2011783123016357, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.2125139236450195, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.1765210628509521, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.156448483467102, Accuracy: 0.6220703125\n",
      "Batch: 143, Loss: 1.2143319845199585, Accuracy: 0.6220703125\n",
      "Batch: 144, Loss: 1.2376377582550049, Accuracy: 0.607421875\n",
      "Batch: 145, Loss: 1.242134928703308, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.1952688694000244, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.1902294158935547, Accuracy: 0.6064453125\n",
      "Batch: 148, Loss: 1.2352819442749023, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.149053931236267, Accuracy: 0.6328125\n",
      "Batch: 150, Loss: 1.143510341644287, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.124394178390503, Accuracy: 0.6533203125\n",
      "Batch: 152, Loss: 1.1694998741149902, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.1097147464752197, Accuracy: 0.6513671875\n",
      "Batch: 154, Loss: 1.1112357378005981, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.1129825115203857, Accuracy: 0.6572265625\n",
      "Epoch 510/200\n",
      "Batch: 1, Loss: 1.2162718772888184, Accuracy: 0.6455078125\n",
      "Batch: 2, Loss: 1.0491104125976562, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 1.042546033859253, Accuracy: 0.6591796875\n",
      "Batch: 4, Loss: 1.0578045845031738, Accuracy: 0.6630859375\n",
      "Batch: 5, Loss: 1.023828387260437, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.0922882556915283, Accuracy: 0.6494140625\n",
      "Batch: 7, Loss: 1.0791467428207397, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 0.9670482277870178, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 0.9791173934936523, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 0.9833508133888245, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 0.9255412220954895, Accuracy: 0.71875\n",
      "Batch: 12, Loss: 1.0306057929992676, Accuracy: 0.6826171875\n",
      "Batch: 13, Loss: 1.0253369808197021, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 0.9735289216041565, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9302619099617004, Accuracy: 0.69921875\n",
      "Batch: 16, Loss: 1.0142096281051636, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.1104313135147095, Accuracy: 0.6259765625\n",
      "Batch: 18, Loss: 1.1298398971557617, Accuracy: 0.6474609375\n",
      "Batch: 19, Loss: 1.1531071662902832, Accuracy: 0.62890625\n",
      "Batch: 20, Loss: 1.0690624713897705, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.0768266916275024, Accuracy: 0.6708984375\n",
      "Batch: 22, Loss: 1.2275296449661255, Accuracy: 0.5986328125\n",
      "Batch: 23, Loss: 1.1665152311325073, Accuracy: 0.6259765625\n",
      "Batch: 24, Loss: 1.0636790990829468, Accuracy: 0.6533203125\n",
      "Batch: 25, Loss: 1.1378324031829834, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.1836292743682861, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.1468534469604492, Accuracy: 0.603515625\n",
      "Batch: 28, Loss: 1.1091417074203491, Accuracy: 0.6337890625\n",
      "Batch: 29, Loss: 1.0593613386154175, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 1.1172990798950195, Accuracy: 0.6298828125\n",
      "Batch: 31, Loss: 1.2094744443893433, Accuracy: 0.5986328125\n",
      "Batch: 32, Loss: 1.0292987823486328, Accuracy: 0.650390625\n",
      "Batch: 33, Loss: 1.0020661354064941, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.0716073513031006, Accuracy: 0.65625\n",
      "Batch: 35, Loss: 1.0928128957748413, Accuracy: 0.6513671875\n",
      "Batch: 36, Loss: 1.2006645202636719, Accuracy: 0.5947265625\n",
      "Batch: 37, Loss: 1.2025606632232666, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.1918283700942993, Accuracy: 0.6181640625\n",
      "Batch: 39, Loss: 1.138871192932129, Accuracy: 0.625\n",
      "Batch: 40, Loss: 1.0902761220932007, Accuracy: 0.6455078125\n",
      "Batch: 41, Loss: 1.0947283506393433, Accuracy: 0.6435546875\n",
      "Batch: 42, Loss: 1.0963383913040161, Accuracy: 0.6142578125\n",
      "Batch: 43, Loss: 1.0499579906463623, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0220921039581299, Accuracy: 0.6748046875\n",
      "Batch: 45, Loss: 1.0341136455535889, Accuracy: 0.6494140625\n",
      "Batch: 46, Loss: 1.1404926776885986, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.140047311782837, Accuracy: 0.63671875\n",
      "Batch: 48, Loss: 1.0735043287277222, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.1725883483886719, Accuracy: 0.6123046875\n",
      "Batch: 50, Loss: 1.152683973312378, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.1473510265350342, Accuracy: 0.611328125\n",
      "Batch: 52, Loss: 1.2106837034225464, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.134527325630188, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.1725289821624756, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.1511356830596924, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.093342900276184, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.0834879875183105, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.075880527496338, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.107800006866455, Accuracy: 0.6376953125\n",
      "Batch: 60, Loss: 1.1807969808578491, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1789970397949219, Accuracy: 0.599609375\n",
      "Batch: 62, Loss: 1.10935640335083, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.179246187210083, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.1761436462402344, Accuracy: 0.615234375\n",
      "Batch: 65, Loss: 1.1824581623077393, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1410045623779297, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.1588749885559082, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.0623964071273804, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.1283900737762451, Accuracy: 0.6220703125\n",
      "Batch: 70, Loss: 1.1397459506988525, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1407772302627563, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.1825730800628662, Accuracy: 0.611328125\n",
      "Batch: 73, Loss: 1.123740315437317, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.0780689716339111, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.0363967418670654, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.0527427196502686, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0624771118164062, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0761492252349854, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.1364555358886719, Accuracy: 0.6416015625\n",
      "Batch: 80, Loss: 1.1754705905914307, Accuracy: 0.603515625\n",
      "Batch: 81, Loss: 1.1144615411758423, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.1052545309066772, Accuracy: 0.6494140625\n",
      "Batch: 83, Loss: 1.1653274297714233, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.0834988355636597, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.1639630794525146, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.2053256034851074, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.1527628898620605, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.12919020652771, Accuracy: 0.640625\n",
      "Batch: 89, Loss: 1.1475508213043213, Accuracy: 0.6337890625\n",
      "Batch: 90, Loss: 1.1118583679199219, Accuracy: 0.626953125\n",
      "Batch: 91, Loss: 1.1225090026855469, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.1744914054870605, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.180131196975708, Accuracy: 0.6142578125\n",
      "Batch: 94, Loss: 1.1753517389297485, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.1428977251052856, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.2026692628860474, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.102022647857666, Accuracy: 0.6240234375\n",
      "Batch: 98, Loss: 1.1383486986160278, Accuracy: 0.6240234375\n",
      "Batch: 99, Loss: 1.1259509325027466, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.0725798606872559, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.077526330947876, Accuracy: 0.654296875\n",
      "Batch: 102, Loss: 1.150613784790039, Accuracy: 0.634765625\n",
      "Batch: 103, Loss: 1.1424839496612549, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.1071614027023315, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.2012262344360352, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.1397652626037598, Accuracy: 0.6474609375\n",
      "Batch: 107, Loss: 1.2007358074188232, Accuracy: 0.6181640625\n",
      "Batch: 108, Loss: 1.1330162286758423, Accuracy: 0.6259765625\n",
      "Batch: 109, Loss: 1.220934271812439, Accuracy: 0.5927734375\n",
      "Batch: 110, Loss: 1.1496957540512085, Accuracy: 0.625\n",
      "Batch: 111, Loss: 1.1284023523330688, Accuracy: 0.65234375\n",
      "Batch: 112, Loss: 1.1349796056747437, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1073217391967773, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.1429193019866943, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.176037311553955, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.1909472942352295, Accuracy: 0.62890625\n",
      "Batch: 117, Loss: 1.1248302459716797, Accuracy: 0.6298828125\n",
      "Batch: 118, Loss: 1.22031831741333, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.2235335111618042, Accuracy: 0.6103515625\n",
      "Batch: 120, Loss: 1.2362170219421387, Accuracy: 0.6044921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 121, Loss: 1.2129664421081543, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.1935515403747559, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.2100896835327148, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.1691433191299438, Accuracy: 0.634765625\n",
      "Batch: 125, Loss: 1.135284423828125, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.1948721408843994, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2399944067001343, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.231879472732544, Accuracy: 0.6123046875\n",
      "Batch: 129, Loss: 1.1540045738220215, Accuracy: 0.6240234375\n",
      "Batch: 130, Loss: 1.1744272708892822, Accuracy: 0.607421875\n",
      "Batch: 131, Loss: 1.1969434022903442, Accuracy: 0.6279296875\n",
      "Batch: 132, Loss: 1.0908353328704834, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.1216737031936646, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1596996784210205, Accuracy: 0.623046875\n",
      "Batch: 135, Loss: 1.0166411399841309, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.0480279922485352, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.1613688468933105, Accuracy: 0.6298828125\n",
      "Batch: 138, Loss: 1.1903833150863647, Accuracy: 0.6064453125\n",
      "Batch: 139, Loss: 1.1441433429718018, Accuracy: 0.6337890625\n",
      "Batch: 140, Loss: 1.2467868328094482, Accuracy: 0.61328125\n",
      "Batch: 141, Loss: 1.1835886240005493, Accuracy: 0.6162109375\n",
      "Batch: 142, Loss: 1.2311463356018066, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.1675150394439697, Accuracy: 0.6328125\n",
      "Batch: 144, Loss: 1.222553014755249, Accuracy: 0.59765625\n",
      "Batch: 145, Loss: 1.2165658473968506, Accuracy: 0.615234375\n",
      "Batch: 146, Loss: 1.1852096319198608, Accuracy: 0.5986328125\n",
      "Batch: 147, Loss: 1.2233353853225708, Accuracy: 0.6064453125\n",
      "Batch: 148, Loss: 1.2014789581298828, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.112457036972046, Accuracy: 0.6455078125\n",
      "Batch: 150, Loss: 1.0894763469696045, Accuracy: 0.6513671875\n",
      "Batch: 151, Loss: 1.1120027303695679, Accuracy: 0.638671875\n",
      "Batch: 152, Loss: 1.1519474983215332, Accuracy: 0.6171875\n",
      "Batch: 153, Loss: 1.1133506298065186, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.1130272150039673, Accuracy: 0.6513671875\n",
      "Batch: 155, Loss: 1.1450104713439941, Accuracy: 0.6103515625\n",
      "Saved Weights at epoch 510 to file Weights_510.h5\n",
      "Epoch 511/200\n",
      "Batch: 1, Loss: 1.2659507989883423, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 1.0788161754608154, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 1.0463013648986816, Accuracy: 0.6650390625\n",
      "Batch: 4, Loss: 1.1078150272369385, Accuracy: 0.6357421875\n",
      "Batch: 5, Loss: 1.0373173952102661, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.0659337043762207, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0567017793655396, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 0.9979715347290039, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 1.0363467931747437, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9943782091140747, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 1.0088765621185303, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 1.001853346824646, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 0.9839971661567688, Accuracy: 0.6826171875\n",
      "Batch: 14, Loss: 0.9839216470718384, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.9671429991722107, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 1.0319788455963135, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.0504207611083984, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.1122281551361084, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.1664302349090576, Accuracy: 0.6376953125\n",
      "Batch: 20, Loss: 1.0399811267852783, Accuracy: 0.6865234375\n",
      "Batch: 21, Loss: 1.0909645557403564, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.283949375152588, Accuracy: 0.58203125\n",
      "Batch: 23, Loss: 1.2402329444885254, Accuracy: 0.6025390625\n",
      "Batch: 24, Loss: 1.0754421949386597, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 1.141553521156311, Accuracy: 0.6171875\n",
      "Batch: 26, Loss: 1.1564054489135742, Accuracy: 0.611328125\n",
      "Batch: 27, Loss: 1.1411666870117188, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.0468827486038208, Accuracy: 0.66015625\n",
      "Batch: 29, Loss: 1.0653233528137207, Accuracy: 0.6328125\n",
      "Batch: 30, Loss: 1.1632301807403564, Accuracy: 0.6240234375\n",
      "Batch: 31, Loss: 1.170303463935852, Accuracy: 0.6181640625\n",
      "Batch: 32, Loss: 1.0333694219589233, Accuracy: 0.67578125\n",
      "Batch: 33, Loss: 1.0029199123382568, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.0865559577941895, Accuracy: 0.6494140625\n",
      "Batch: 35, Loss: 1.1399736404418945, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.212825059890747, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.14963698387146, Accuracy: 0.6162109375\n",
      "Batch: 38, Loss: 1.2006802558898926, Accuracy: 0.603515625\n",
      "Batch: 39, Loss: 1.0148723125457764, Accuracy: 0.6669921875\n",
      "Batch: 40, Loss: 1.0668597221374512, Accuracy: 0.6513671875\n",
      "Batch: 41, Loss: 1.1518595218658447, Accuracy: 0.619140625\n",
      "Batch: 42, Loss: 1.0655614137649536, Accuracy: 0.658203125\n",
      "Batch: 43, Loss: 1.0233092308044434, Accuracy: 0.6630859375\n",
      "Batch: 44, Loss: 1.0700656175613403, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0065503120422363, Accuracy: 0.6640625\n",
      "Batch: 46, Loss: 1.1135011911392212, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.0965547561645508, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.136474847793579, Accuracy: 0.626953125\n",
      "Batch: 49, Loss: 1.1928765773773193, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.1809189319610596, Accuracy: 0.607421875\n",
      "Batch: 51, Loss: 1.1401197910308838, Accuracy: 0.619140625\n",
      "Batch: 52, Loss: 1.226757287979126, Accuracy: 0.6005859375\n",
      "Batch: 53, Loss: 1.1854950189590454, Accuracy: 0.615234375\n",
      "Batch: 54, Loss: 1.1767696142196655, Accuracy: 0.607421875\n",
      "Batch: 55, Loss: 1.1230772733688354, Accuracy: 0.646484375\n",
      "Batch: 56, Loss: 1.1569710969924927, Accuracy: 0.64453125\n",
      "Batch: 57, Loss: 1.0862492322921753, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.0853914022445679, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.131071925163269, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.2797887325286865, Accuracy: 0.5732421875\n",
      "Batch: 61, Loss: 1.1835193634033203, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.134485125541687, Accuracy: 0.62890625\n",
      "Batch: 63, Loss: 1.1994094848632812, Accuracy: 0.611328125\n",
      "Batch: 64, Loss: 1.2090303897857666, Accuracy: 0.603515625\n",
      "Batch: 65, Loss: 1.174269199371338, Accuracy: 0.6181640625\n",
      "Batch: 66, Loss: 1.112806797027588, Accuracy: 0.64453125\n",
      "Batch: 67, Loss: 1.1395238637924194, Accuracy: 0.6181640625\n",
      "Batch: 68, Loss: 1.1115310192108154, Accuracy: 0.6435546875\n",
      "Batch: 69, Loss: 1.1580817699432373, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.164503574371338, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.1073329448699951, Accuracy: 0.6484375\n",
      "Batch: 72, Loss: 1.0895674228668213, Accuracy: 0.646484375\n",
      "Batch: 73, Loss: 1.1830565929412842, Accuracy: 0.6201171875\n",
      "Batch: 74, Loss: 1.1333212852478027, Accuracy: 0.630859375\n",
      "Batch: 75, Loss: 1.0870039463043213, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.0368168354034424, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 1.0323727130889893, Accuracy: 0.6533203125\n",
      "Batch: 78, Loss: 1.0890238285064697, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.1673468351364136, Accuracy: 0.6259765625\n",
      "Batch: 80, Loss: 1.1068135499954224, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.1024202108383179, Accuracy: 0.6611328125\n",
      "Batch: 82, Loss: 1.1040483713150024, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.2123969793319702, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.1757521629333496, Accuracy: 0.6142578125\n",
      "Batch: 85, Loss: 1.1855506896972656, Accuracy: 0.609375\n",
      "Batch: 86, Loss: 1.2269554138183594, Accuracy: 0.5966796875\n",
      "Batch: 87, Loss: 1.1681125164031982, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1028988361358643, Accuracy: 0.642578125\n",
      "Batch: 89, Loss: 1.1307518482208252, Accuracy: 0.634765625\n",
      "Batch: 90, Loss: 1.129481554031372, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.1452302932739258, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1512725353240967, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.142106294631958, Accuracy: 0.623046875\n",
      "Batch: 94, Loss: 1.174309492111206, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.1866123676300049, Accuracy: 0.6240234375\n",
      "Batch: 96, Loss: 1.1654231548309326, Accuracy: 0.6279296875\n",
      "Batch: 97, Loss: 1.138704538345337, Accuracy: 0.625\n",
      "Batch: 98, Loss: 1.119201898574829, Accuracy: 0.623046875\n",
      "Batch: 99, Loss: 1.1163840293884277, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.082261562347412, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.1488020420074463, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.142141342163086, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.1639786958694458, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 1.1064536571502686, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.1700077056884766, Accuracy: 0.6337890625\n",
      "Batch: 106, Loss: 1.1591064929962158, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.2078778743743896, Accuracy: 0.625\n",
      "Batch: 108, Loss: 1.2210978269577026, Accuracy: 0.6064453125\n",
      "Batch: 109, Loss: 1.2013731002807617, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.0996476411819458, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.1216139793395996, Accuracy: 0.6494140625\n",
      "Batch: 112, Loss: 1.090883731842041, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.0764034986495972, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.1543645858764648, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.1922607421875, Accuracy: 0.60546875\n",
      "Batch: 116, Loss: 1.1977500915527344, Accuracy: 0.59375\n",
      "Batch: 117, Loss: 1.1215709447860718, Accuracy: 0.6279296875\n",
      "Batch: 118, Loss: 1.212022066116333, Accuracy: 0.60546875\n",
      "Batch: 119, Loss: 1.2644683122634888, Accuracy: 0.5859375\n",
      "Batch: 120, Loss: 1.2499706745147705, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.2023859024047852, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.204716444015503, Accuracy: 0.64453125\n",
      "Batch: 123, Loss: 1.1466974020004272, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.2393615245819092, Accuracy: 0.5859375\n",
      "Batch: 125, Loss: 1.1722428798675537, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.1833908557891846, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.2588565349578857, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.2154244184494019, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.157354474067688, Accuracy: 0.6357421875\n",
      "Batch: 130, Loss: 1.0844333171844482, Accuracy: 0.6484375\n",
      "Batch: 131, Loss: 1.1759130954742432, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.125179648399353, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.1226658821105957, Accuracy: 0.6240234375\n",
      "Batch: 134, Loss: 1.089719295501709, Accuracy: 0.6767578125\n",
      "Batch: 135, Loss: 1.090943455696106, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.0891327857971191, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.142822504043579, Accuracy: 0.6279296875\n",
      "Batch: 138, Loss: 1.2743384838104248, Accuracy: 0.595703125\n",
      "Batch: 139, Loss: 1.167189359664917, Accuracy: 0.611328125\n",
      "Batch: 140, Loss: 1.2268762588500977, Accuracy: 0.587890625\n",
      "Batch: 141, Loss: 1.1376559734344482, Accuracy: 0.625\n",
      "Batch: 142, Loss: 1.1479946374893188, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.218369960784912, Accuracy: 0.6083984375\n",
      "Batch: 144, Loss: 1.227318525314331, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.1866214275360107, Accuracy: 0.623046875\n",
      "Batch: 146, Loss: 1.147728681564331, Accuracy: 0.6298828125\n",
      "Batch: 147, Loss: 1.161348819732666, Accuracy: 0.59375\n",
      "Batch: 148, Loss: 1.2256155014038086, Accuracy: 0.5966796875\n",
      "Batch: 149, Loss: 1.1705492734909058, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.1768386363983154, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.1582045555114746, Accuracy: 0.6357421875\n",
      "Batch: 152, Loss: 1.1540637016296387, Accuracy: 0.623046875\n",
      "Batch: 153, Loss: 1.117870569229126, Accuracy: 0.6513671875\n",
      "Batch: 154, Loss: 1.1560633182525635, Accuracy: 0.625\n",
      "Batch: 155, Loss: 1.143160104751587, Accuracy: 0.6259765625\n",
      "Epoch 512/200\n",
      "Batch: 1, Loss: 1.2561957836151123, Accuracy: 0.62109375\n",
      "Batch: 2, Loss: 1.0791070461273193, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0293152332305908, Accuracy: 0.6650390625\n",
      "Batch: 4, Loss: 1.0401537418365479, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 0.9698399901390076, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.0453386306762695, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.0285842418670654, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 1.0020344257354736, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 0.967041552066803, Accuracy: 0.6953125\n",
      "Batch: 10, Loss: 0.9148745536804199, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 1.0031802654266357, Accuracy: 0.6787109375\n",
      "Batch: 12, Loss: 0.9863200187683105, Accuracy: 0.6826171875\n",
      "Batch: 13, Loss: 1.0384607315063477, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 0.9715418815612793, Accuracy: 0.6943359375\n",
      "Batch: 15, Loss: 0.9940201044082642, Accuracy: 0.669921875\n",
      "Batch: 16, Loss: 1.0209647417068481, Accuracy: 0.66796875\n",
      "Batch: 17, Loss: 1.0214158296585083, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.1443573236465454, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.2294955253601074, Accuracy: 0.5966796875\n",
      "Batch: 20, Loss: 1.084352731704712, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.101409912109375, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2201621532440186, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.2670180797576904, Accuracy: 0.6005859375\n",
      "Batch: 24, Loss: 1.1204320192337036, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.1752568483352661, Accuracy: 0.6103515625\n",
      "Batch: 26, Loss: 1.2076666355133057, Accuracy: 0.5947265625\n",
      "Batch: 27, Loss: 1.165870189666748, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.0695163011550903, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 1.0934756994247437, Accuracy: 0.6201171875\n",
      "Batch: 30, Loss: 1.1227667331695557, Accuracy: 0.6279296875\n",
      "Batch: 31, Loss: 1.213301658630371, Accuracy: 0.6015625\n",
      "Batch: 32, Loss: 1.0633188486099243, Accuracy: 0.6435546875\n",
      "Batch: 33, Loss: 1.0127875804901123, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.0745794773101807, Accuracy: 0.6474609375\n",
      "Batch: 35, Loss: 1.2120211124420166, Accuracy: 0.6005859375\n",
      "Batch: 36, Loss: 1.1594003438949585, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.236678123474121, Accuracy: 0.583984375\n",
      "Batch: 38, Loss: 1.1589628458023071, Accuracy: 0.6171875\n",
      "Batch: 39, Loss: 1.0527859926223755, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.0945825576782227, Accuracy: 0.638671875\n",
      "Batch: 41, Loss: 1.07572340965271, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.0892255306243896, Accuracy: 0.6259765625\n",
      "Batch: 43, Loss: 1.0687763690948486, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.025902271270752, Accuracy: 0.65234375\n",
      "Batch: 45, Loss: 1.0629643201828003, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.1488341093063354, Accuracy: 0.5908203125\n",
      "Batch: 47, Loss: 1.1071972846984863, Accuracy: 0.6376953125\n",
      "Batch: 48, Loss: 1.1086854934692383, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.1647298336029053, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.1573543548583984, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.1330960988998413, Accuracy: 0.611328125\n",
      "Batch: 52, Loss: 1.2577757835388184, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.131119728088379, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.2386231422424316, Accuracy: 0.59375\n",
      "Batch: 55, Loss: 1.1087217330932617, Accuracy: 0.6318359375\n",
      "Batch: 56, Loss: 1.094178318977356, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.1051135063171387, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.1272118091583252, Accuracy: 0.646484375\n",
      "Batch: 59, Loss: 1.103678584098816, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2103734016418457, Accuracy: 0.609375\n",
      "Batch: 61, Loss: 1.1219358444213867, Accuracy: 0.6201171875\n",
      "Batch: 62, Loss: 1.159493327140808, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.1655383110046387, Accuracy: 0.625\n",
      "Batch: 64, Loss: 1.224058747291565, Accuracy: 0.595703125\n",
      "Batch: 65, Loss: 1.217273235321045, Accuracy: 0.59765625\n",
      "Batch: 66, Loss: 1.1070955991744995, Accuracy: 0.6640625\n",
      "Batch: 67, Loss: 1.1426153182983398, Accuracy: 0.6298828125\n",
      "Batch: 68, Loss: 1.0437800884246826, Accuracy: 0.6767578125\n",
      "Batch: 69, Loss: 1.1719311475753784, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.1848645210266113, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1417226791381836, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.2281514406204224, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.1219196319580078, Accuracy: 0.6357421875\n",
      "Batch: 74, Loss: 1.0780441761016846, Accuracy: 0.66015625\n",
      "Batch: 75, Loss: 1.1153314113616943, Accuracy: 0.63671875\n",
      "Batch: 76, Loss: 1.0493348836898804, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 1.0245864391326904, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0586044788360596, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.163307785987854, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.1452231407165527, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1185160875320435, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.118822693824768, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 1.1936845779418945, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.1614207029342651, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.1514976024627686, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.1423907279968262, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.189105749130249, Accuracy: 0.6240234375\n",
      "Batch: 88, Loss: 1.1472773551940918, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.16315495967865, Accuracy: 0.619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 1.0761029720306396, Accuracy: 0.6494140625\n",
      "Batch: 91, Loss: 1.1025880575180054, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.1079845428466797, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.1456769704818726, Accuracy: 0.642578125\n",
      "Batch: 94, Loss: 1.1667680740356445, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.1467406749725342, Accuracy: 0.6435546875\n",
      "Batch: 96, Loss: 1.1985280513763428, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.1778430938720703, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.1536420583724976, Accuracy: 0.623046875\n",
      "Batch: 99, Loss: 1.1622352600097656, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.07704496383667, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.099823236465454, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.1902334690093994, Accuracy: 0.6240234375\n",
      "Batch: 103, Loss: 1.1259766817092896, Accuracy: 0.64453125\n",
      "Batch: 104, Loss: 1.1514087915420532, Accuracy: 0.6259765625\n",
      "Batch: 105, Loss: 1.1791677474975586, Accuracy: 0.6318359375\n",
      "Batch: 106, Loss: 1.1497248411178589, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.2177749872207642, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.2093368768692017, Accuracy: 0.5859375\n",
      "Batch: 109, Loss: 1.158994197845459, Accuracy: 0.625\n",
      "Batch: 110, Loss: 1.1578071117401123, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.1132628917694092, Accuracy: 0.6630859375\n",
      "Batch: 112, Loss: 1.0486323833465576, Accuracy: 0.6640625\n",
      "Batch: 113, Loss: 1.1682918071746826, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.1341888904571533, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.1538165807724, Accuracy: 0.6328125\n",
      "Batch: 116, Loss: 1.1838476657867432, Accuracy: 0.6220703125\n",
      "Batch: 117, Loss: 1.1110340356826782, Accuracy: 0.6513671875\n",
      "Batch: 118, Loss: 1.1917747259140015, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.1851638555526733, Accuracy: 0.6396484375\n",
      "Batch: 120, Loss: 1.2675747871398926, Accuracy: 0.6103515625\n",
      "Batch: 121, Loss: 1.2001683712005615, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.2225123643875122, Accuracy: 0.6123046875\n",
      "Batch: 123, Loss: 1.0946383476257324, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.131391167640686, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.1098082065582275, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.262840986251831, Accuracy: 0.609375\n",
      "Batch: 127, Loss: 1.2078626155853271, Accuracy: 0.6181640625\n",
      "Batch: 128, Loss: 1.1808350086212158, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.163482427597046, Accuracy: 0.625\n",
      "Batch: 130, Loss: 1.1633632183074951, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.167970061302185, Accuracy: 0.6171875\n",
      "Batch: 132, Loss: 1.041794776916504, Accuracy: 0.669921875\n",
      "Batch: 133, Loss: 1.1102240085601807, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1439765691757202, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.035078525543213, Accuracy: 0.658203125\n",
      "Batch: 136, Loss: 1.0587035417556763, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.1720867156982422, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 1.2723125219345093, Accuracy: 0.578125\n",
      "Batch: 139, Loss: 1.1624271869659424, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.2660648822784424, Accuracy: 0.5908203125\n",
      "Batch: 141, Loss: 1.2149882316589355, Accuracy: 0.5986328125\n",
      "Batch: 142, Loss: 1.1306830644607544, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.216491937637329, Accuracy: 0.6103515625\n",
      "Batch: 144, Loss: 1.2663652896881104, Accuracy: 0.5927734375\n",
      "Batch: 145, Loss: 1.2251873016357422, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.188583493232727, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.2316142320632935, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.222917079925537, Accuracy: 0.599609375\n",
      "Batch: 149, Loss: 1.1096268892288208, Accuracy: 0.6328125\n",
      "Batch: 150, Loss: 1.1599395275115967, Accuracy: 0.6162109375\n",
      "Batch: 151, Loss: 1.122267246246338, Accuracy: 0.6435546875\n",
      "Batch: 152, Loss: 1.1783013343811035, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.0780549049377441, Accuracy: 0.650390625\n",
      "Batch: 154, Loss: 1.0899828672409058, Accuracy: 0.6298828125\n",
      "Batch: 155, Loss: 1.106421947479248, Accuracy: 0.6474609375\n",
      "Epoch 513/200\n",
      "Batch: 1, Loss: 1.1624815464019775, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 1.0781325101852417, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.014699935913086, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.0462539196014404, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 0.9937760829925537, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0421807765960693, Accuracy: 0.6826171875\n",
      "Batch: 7, Loss: 1.0173990726470947, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 1.0215877294540405, Accuracy: 0.6640625\n",
      "Batch: 9, Loss: 1.0377881526947021, Accuracy: 0.650390625\n",
      "Batch: 10, Loss: 0.983153223991394, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 0.9140519499778748, Accuracy: 0.701171875\n",
      "Batch: 12, Loss: 1.0198276042938232, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 0.9954536557197571, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9879655838012695, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.8999632000923157, Accuracy: 0.6943359375\n",
      "Batch: 16, Loss: 1.02720046043396, Accuracy: 0.6484375\n",
      "Batch: 17, Loss: 1.1521793603897095, Accuracy: 0.611328125\n",
      "Batch: 18, Loss: 1.0833033323287964, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.2036417722702026, Accuracy: 0.62109375\n",
      "Batch: 20, Loss: 1.088025689125061, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.070559024810791, Accuracy: 0.6484375\n",
      "Batch: 22, Loss: 1.2102866172790527, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.1663392782211304, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.1294041872024536, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1853011846542358, Accuracy: 0.6240234375\n",
      "Batch: 26, Loss: 1.174572467803955, Accuracy: 0.625\n",
      "Batch: 27, Loss: 1.159972071647644, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0844850540161133, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.0563093423843384, Accuracy: 0.650390625\n",
      "Batch: 30, Loss: 1.1500756740570068, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.1477166414260864, Accuracy: 0.6240234375\n",
      "Batch: 32, Loss: 1.0475904941558838, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 1.0209187269210815, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.0580250024795532, Accuracy: 0.64453125\n",
      "Batch: 35, Loss: 1.1575254201889038, Accuracy: 0.609375\n",
      "Batch: 36, Loss: 1.1916133165359497, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.2391709089279175, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.1881895065307617, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.1366870403289795, Accuracy: 0.6162109375\n",
      "Batch: 40, Loss: 1.1214616298675537, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.0741876363754272, Accuracy: 0.6572265625\n",
      "Batch: 42, Loss: 1.0762842893600464, Accuracy: 0.6611328125\n",
      "Batch: 43, Loss: 1.0297496318817139, Accuracy: 0.6689453125\n",
      "Batch: 44, Loss: 1.0229312181472778, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.033377766609192, Accuracy: 0.6787109375\n",
      "Batch: 46, Loss: 1.1500270366668701, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.1010465621948242, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.1421763896942139, Accuracy: 0.6171875\n",
      "Batch: 49, Loss: 1.1583595275878906, Accuracy: 0.6416015625\n",
      "Batch: 50, Loss: 1.1180229187011719, Accuracy: 0.6533203125\n",
      "Batch: 51, Loss: 1.1714916229248047, Accuracy: 0.591796875\n",
      "Batch: 52, Loss: 1.1903948783874512, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.2017065286636353, Accuracy: 0.611328125\n",
      "Batch: 54, Loss: 1.1790218353271484, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.1207749843597412, Accuracy: 0.642578125\n",
      "Batch: 56, Loss: 1.093064785003662, Accuracy: 0.646484375\n",
      "Batch: 57, Loss: 1.0677478313446045, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.110154390335083, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1319997310638428, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.2105472087860107, Accuracy: 0.6259765625\n",
      "Batch: 61, Loss: 1.155413269996643, Accuracy: 0.6279296875\n",
      "Batch: 62, Loss: 1.1381969451904297, Accuracy: 0.609375\n",
      "Batch: 63, Loss: 1.1889914274215698, Accuracy: 0.6015625\n",
      "Batch: 64, Loss: 1.1912362575531006, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1590187549591064, Accuracy: 0.6162109375\n",
      "Batch: 66, Loss: 1.1675326824188232, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1488641500473022, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.0900331735610962, Accuracy: 0.6357421875\n",
      "Batch: 69, Loss: 1.129958152770996, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.1359291076660156, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.127800703048706, Accuracy: 0.6279296875\n",
      "Batch: 72, Loss: 1.2186022996902466, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.132590889930725, Accuracy: 0.6240234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 1.0633305311203003, Accuracy: 0.6435546875\n",
      "Batch: 75, Loss: 1.1183371543884277, Accuracy: 0.63671875\n",
      "Batch: 76, Loss: 1.0559985637664795, Accuracy: 0.65625\n",
      "Batch: 77, Loss: 1.098923921585083, Accuracy: 0.6455078125\n",
      "Batch: 78, Loss: 1.0818541049957275, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.1253422498703003, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.161081314086914, Accuracy: 0.6240234375\n",
      "Batch: 81, Loss: 1.1019797325134277, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.162473201751709, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.171616554260254, Accuracy: 0.630859375\n",
      "Batch: 84, Loss: 1.1127294301986694, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.1091980934143066, Accuracy: 0.6494140625\n",
      "Batch: 86, Loss: 1.1557644605636597, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.2258906364440918, Accuracy: 0.5947265625\n",
      "Batch: 88, Loss: 1.159965991973877, Accuracy: 0.6357421875\n",
      "Batch: 89, Loss: 1.177187204360962, Accuracy: 0.630859375\n",
      "Batch: 90, Loss: 1.108116626739502, Accuracy: 0.64453125\n",
      "Batch: 91, Loss: 1.1112275123596191, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1651084423065186, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.0999611616134644, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.2465763092041016, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.1767122745513916, Accuracy: 0.61328125\n",
      "Batch: 96, Loss: 1.2855732440948486, Accuracy: 0.5966796875\n",
      "Batch: 97, Loss: 1.1337687969207764, Accuracy: 0.60546875\n",
      "Batch: 98, Loss: 1.131059169769287, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.200756311416626, Accuracy: 0.6103515625\n",
      "Batch: 100, Loss: 1.046135663986206, Accuracy: 0.646484375\n",
      "Batch: 101, Loss: 1.0778357982635498, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.1450769901275635, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.1417368650436401, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.16391122341156, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.1998882293701172, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.111388087272644, Accuracy: 0.6435546875\n",
      "Batch: 107, Loss: 1.2602132558822632, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.2041265964508057, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.1701056957244873, Accuracy: 0.611328125\n",
      "Batch: 110, Loss: 1.120487093925476, Accuracy: 0.623046875\n",
      "Batch: 111, Loss: 1.1298789978027344, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.0656380653381348, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.1039063930511475, Accuracy: 0.65625\n",
      "Batch: 114, Loss: 1.1951061487197876, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.119757056236267, Accuracy: 0.63671875\n",
      "Batch: 116, Loss: 1.2218812704086304, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.179889440536499, Accuracy: 0.6220703125\n",
      "Batch: 118, Loss: 1.2426693439483643, Accuracy: 0.6015625\n",
      "Batch: 119, Loss: 1.215313196182251, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.3027976751327515, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.1649346351623535, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.220503330230713, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.1232469081878662, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.1701602935791016, Accuracy: 0.638671875\n",
      "Batch: 125, Loss: 1.1529541015625, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.2418057918548584, Accuracy: 0.60546875\n",
      "Batch: 127, Loss: 1.2668392658233643, Accuracy: 0.599609375\n",
      "Batch: 128, Loss: 1.1974220275878906, Accuracy: 0.6279296875\n",
      "Batch: 129, Loss: 1.1558573246002197, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.1036362648010254, Accuracy: 0.6513671875\n",
      "Batch: 131, Loss: 1.1730891466140747, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.047683835029602, Accuracy: 0.6689453125\n",
      "Batch: 133, Loss: 1.1623907089233398, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.0476086139678955, Accuracy: 0.6728515625\n",
      "Batch: 135, Loss: 1.0291709899902344, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.064997911453247, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1942527294158936, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 1.2434613704681396, Accuracy: 0.6220703125\n",
      "Batch: 139, Loss: 1.2262630462646484, Accuracy: 0.5927734375\n",
      "Batch: 140, Loss: 1.207043170928955, Accuracy: 0.6142578125\n",
      "Batch: 141, Loss: 1.1732338666915894, Accuracy: 0.60546875\n",
      "Batch: 142, Loss: 1.250566840171814, Accuracy: 0.6025390625\n",
      "Batch: 143, Loss: 1.1568408012390137, Accuracy: 0.603515625\n",
      "Batch: 144, Loss: 1.228458046913147, Accuracy: 0.6025390625\n",
      "Batch: 145, Loss: 1.2537531852722168, Accuracy: 0.60546875\n",
      "Batch: 146, Loss: 1.2182939052581787, Accuracy: 0.599609375\n",
      "Batch: 147, Loss: 1.186024785041809, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.1762056350708008, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.1407991647720337, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.1550300121307373, Accuracy: 0.6103515625\n",
      "Batch: 151, Loss: 1.178853988647461, Accuracy: 0.615234375\n",
      "Batch: 152, Loss: 1.1896599531173706, Accuracy: 0.59375\n",
      "Batch: 153, Loss: 1.0272958278656006, Accuracy: 0.6611328125\n",
      "Batch: 154, Loss: 1.05649995803833, Accuracy: 0.650390625\n",
      "Batch: 155, Loss: 1.1341097354888916, Accuracy: 0.6318359375\n",
      "Epoch 514/200\n",
      "Batch: 1, Loss: 1.2341736555099487, Accuracy: 0.62890625\n",
      "Batch: 2, Loss: 0.998666524887085, Accuracy: 0.6767578125\n",
      "Batch: 3, Loss: 0.9998551607131958, Accuracy: 0.68359375\n",
      "Batch: 4, Loss: 1.1061524152755737, Accuracy: 0.6328125\n",
      "Batch: 5, Loss: 1.0253783464431763, Accuracy: 0.6650390625\n",
      "Batch: 6, Loss: 1.0128902196884155, Accuracy: 0.66796875\n",
      "Batch: 7, Loss: 1.0265371799468994, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 1.0002222061157227, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 0.996215283870697, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 1.0158193111419678, Accuracy: 0.6572265625\n",
      "Batch: 11, Loss: 0.9359294176101685, Accuracy: 0.6943359375\n",
      "Batch: 12, Loss: 1.0107730627059937, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 1.0288883447647095, Accuracy: 0.6728515625\n",
      "Batch: 14, Loss: 0.9927142858505249, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.9578560590744019, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.007655143737793, Accuracy: 0.6845703125\n",
      "Batch: 17, Loss: 1.0455610752105713, Accuracy: 0.6435546875\n",
      "Batch: 18, Loss: 1.092115879058838, Accuracy: 0.63671875\n",
      "Batch: 19, Loss: 1.2258331775665283, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.0405032634735107, Accuracy: 0.6865234375\n",
      "Batch: 21, Loss: 1.0640020370483398, Accuracy: 0.6572265625\n",
      "Batch: 22, Loss: 1.2203128337860107, Accuracy: 0.595703125\n",
      "Batch: 23, Loss: 1.2897895574569702, Accuracy: 0.5615234375\n",
      "Batch: 24, Loss: 1.0864455699920654, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.1589395999908447, Accuracy: 0.61328125\n",
      "Batch: 26, Loss: 1.1508699655532837, Accuracy: 0.6162109375\n",
      "Batch: 27, Loss: 1.1102375984191895, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.066367506980896, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.0547597408294678, Accuracy: 0.662109375\n",
      "Batch: 30, Loss: 1.1235835552215576, Accuracy: 0.6416015625\n",
      "Batch: 31, Loss: 1.1718111038208008, Accuracy: 0.61328125\n",
      "Batch: 32, Loss: 0.9986736178398132, Accuracy: 0.6787109375\n",
      "Batch: 33, Loss: 1.0038126707077026, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.0950881242752075, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.1084749698638916, Accuracy: 0.6328125\n",
      "Batch: 36, Loss: 1.1770254373550415, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.1995326280593872, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.2228997945785522, Accuracy: 0.599609375\n",
      "Batch: 39, Loss: 1.0737231969833374, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.0932104587554932, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.126619577407837, Accuracy: 0.623046875\n",
      "Batch: 42, Loss: 1.0666851997375488, Accuracy: 0.6474609375\n",
      "Batch: 43, Loss: 1.0767360925674438, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.036194086074829, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 0.9841259717941284, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.1563388109207153, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.1424767971038818, Accuracy: 0.625\n",
      "Batch: 48, Loss: 1.1503229141235352, Accuracy: 0.6240234375\n",
      "Batch: 49, Loss: 1.1793222427368164, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.092873454093933, Accuracy: 0.6513671875\n",
      "Batch: 51, Loss: 1.1635831594467163, Accuracy: 0.599609375\n",
      "Batch: 52, Loss: 1.2857999801635742, Accuracy: 0.5908203125\n",
      "Batch: 53, Loss: 1.1667180061340332, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.1556322574615479, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.1582975387573242, Accuracy: 0.6337890625\n",
      "Batch: 56, Loss: 1.112126111984253, Accuracy: 0.6455078125\n",
      "Batch: 57, Loss: 1.1054412126541138, Accuracy: 0.6416015625\n",
      "Batch: 58, Loss: 1.1355082988739014, Accuracy: 0.6484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 1.1403034925460815, Accuracy: 0.619140625\n",
      "Batch: 60, Loss: 1.2607311010360718, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.1363471746444702, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1043764352798462, Accuracy: 0.6474609375\n",
      "Batch: 63, Loss: 1.1581363677978516, Accuracy: 0.625\n",
      "Batch: 64, Loss: 1.2161693572998047, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.1737401485443115, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.1486132144927979, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.154280424118042, Accuracy: 0.634765625\n",
      "Batch: 68, Loss: 1.0876041650772095, Accuracy: 0.6669921875\n",
      "Batch: 69, Loss: 1.1983296871185303, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.1483782529830933, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.09067702293396, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.187546730041504, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.1036522388458252, Accuracy: 0.6357421875\n",
      "Batch: 74, Loss: 1.1059365272521973, Accuracy: 0.6435546875\n",
      "Batch: 75, Loss: 1.1012465953826904, Accuracy: 0.6484375\n",
      "Batch: 76, Loss: 1.067089319229126, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 1.035212755203247, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.0861186981201172, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.147958517074585, Accuracy: 0.62890625\n",
      "Batch: 80, Loss: 1.1008267402648926, Accuracy: 0.6435546875\n",
      "Batch: 81, Loss: 1.1132649183273315, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.144385576248169, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.1976330280303955, Accuracy: 0.6005859375\n",
      "Batch: 84, Loss: 1.1055424213409424, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1857223510742188, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.1659955978393555, Accuracy: 0.6328125\n",
      "Batch: 87, Loss: 1.1857538223266602, Accuracy: 0.60546875\n",
      "Batch: 88, Loss: 1.1321920156478882, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.183293104171753, Accuracy: 0.6142578125\n",
      "Batch: 90, Loss: 1.0897037982940674, Accuracy: 0.6328125\n",
      "Batch: 91, Loss: 1.127071738243103, Accuracy: 0.609375\n",
      "Batch: 92, Loss: 1.1244609355926514, Accuracy: 0.6435546875\n",
      "Batch: 93, Loss: 1.1176751852035522, Accuracy: 0.65234375\n",
      "Batch: 94, Loss: 1.189319133758545, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.1337668895721436, Accuracy: 0.6376953125\n",
      "Batch: 96, Loss: 1.2295483350753784, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.1075451374053955, Accuracy: 0.62890625\n",
      "Batch: 98, Loss: 1.1142252683639526, Accuracy: 0.6357421875\n",
      "Batch: 99, Loss: 1.1382535696029663, Accuracy: 0.6455078125\n",
      "Batch: 100, Loss: 1.0466043949127197, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.0947952270507812, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.184767484664917, Accuracy: 0.619140625\n",
      "Batch: 103, Loss: 1.1644213199615479, Accuracy: 0.634765625\n",
      "Batch: 104, Loss: 1.0912680625915527, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.202968716621399, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.148939609527588, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.1794464588165283, Accuracy: 0.6142578125\n",
      "Batch: 108, Loss: 1.1525146961212158, Accuracy: 0.62890625\n",
      "Batch: 109, Loss: 1.214078664779663, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.131568193435669, Accuracy: 0.6318359375\n",
      "Batch: 111, Loss: 1.105952501296997, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.0466171503067017, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.132944941520691, Accuracy: 0.6435546875\n",
      "Batch: 114, Loss: 1.2241652011871338, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.1653468608856201, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.2124173641204834, Accuracy: 0.603515625\n",
      "Batch: 117, Loss: 1.1131179332733154, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 1.2184183597564697, Accuracy: 0.6103515625\n",
      "Batch: 119, Loss: 1.2199084758758545, Accuracy: 0.623046875\n",
      "Batch: 120, Loss: 1.2647905349731445, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.164459466934204, Accuracy: 0.638671875\n",
      "Batch: 122, Loss: 1.2130012512207031, Accuracy: 0.607421875\n",
      "Batch: 123, Loss: 1.1300005912780762, Accuracy: 0.650390625\n",
      "Batch: 124, Loss: 1.2448831796646118, Accuracy: 0.6044921875\n",
      "Batch: 125, Loss: 1.1388604640960693, Accuracy: 0.6396484375\n",
      "Batch: 126, Loss: 1.2067205905914307, Accuracy: 0.6044921875\n",
      "Batch: 127, Loss: 1.2478424310684204, Accuracy: 0.6025390625\n",
      "Batch: 128, Loss: 1.21561598777771, Accuracy: 0.58984375\n",
      "Batch: 129, Loss: 1.1822566986083984, Accuracy: 0.6044921875\n",
      "Batch: 130, Loss: 1.0957262516021729, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 1.1785612106323242, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.048064947128296, Accuracy: 0.6787109375\n",
      "Batch: 133, Loss: 1.170551061630249, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1410629749298096, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.0047458410263062, Accuracy: 0.677734375\n",
      "Batch: 136, Loss: 1.0606321096420288, Accuracy: 0.666015625\n",
      "Batch: 137, Loss: 1.172298789024353, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.235920786857605, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.1186299324035645, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.2444032430648804, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.1737860441207886, Accuracy: 0.6044921875\n",
      "Batch: 142, Loss: 1.1862133741378784, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2558252811431885, Accuracy: 0.58984375\n",
      "Batch: 144, Loss: 1.315026044845581, Accuracy: 0.5712890625\n",
      "Batch: 145, Loss: 1.2536158561706543, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.2170765399932861, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.1912771463394165, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.1665834188461304, Accuracy: 0.6396484375\n",
      "Batch: 149, Loss: 1.16267991065979, Accuracy: 0.5966796875\n",
      "Batch: 150, Loss: 1.191519021987915, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.1749475002288818, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.1772692203521729, Accuracy: 0.6328125\n",
      "Batch: 153, Loss: 1.0773998498916626, Accuracy: 0.6630859375\n",
      "Batch: 154, Loss: 1.11415696144104, Accuracy: 0.64453125\n",
      "Batch: 155, Loss: 1.0955679416656494, Accuracy: 0.640625\n",
      "Epoch 515/200\n",
      "Batch: 1, Loss: 1.2442909479141235, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 1.0579314231872559, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 1.007354736328125, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 1.1159732341766357, Accuracy: 0.63671875\n",
      "Batch: 5, Loss: 1.0208661556243896, Accuracy: 0.646484375\n",
      "Batch: 6, Loss: 1.0586525201797485, Accuracy: 0.6474609375\n",
      "Batch: 7, Loss: 1.0431432723999023, Accuracy: 0.642578125\n",
      "Batch: 8, Loss: 0.975159764289856, Accuracy: 0.6884765625\n",
      "Batch: 9, Loss: 1.0458216667175293, Accuracy: 0.6650390625\n",
      "Batch: 10, Loss: 0.9565305709838867, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 1.0305771827697754, Accuracy: 0.6533203125\n",
      "Batch: 12, Loss: 0.9800069332122803, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 1.0095750093460083, Accuracy: 0.6650390625\n",
      "Batch: 14, Loss: 1.0136809349060059, Accuracy: 0.662109375\n",
      "Batch: 15, Loss: 0.9611964821815491, Accuracy: 0.701171875\n",
      "Batch: 16, Loss: 1.0866531133651733, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.0006414651870728, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.1417502164840698, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.19212806224823, Accuracy: 0.5986328125\n",
      "Batch: 20, Loss: 1.06590735912323, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.0847970247268677, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.273650884628296, Accuracy: 0.5869140625\n",
      "Batch: 23, Loss: 1.2033958435058594, Accuracy: 0.5927734375\n",
      "Batch: 24, Loss: 1.1398861408233643, Accuracy: 0.642578125\n",
      "Batch: 25, Loss: 1.118988275527954, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.1646461486816406, Accuracy: 0.640625\n",
      "Batch: 27, Loss: 1.1314833164215088, Accuracy: 0.6279296875\n",
      "Batch: 28, Loss: 1.0949525833129883, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.1096725463867188, Accuracy: 0.6279296875\n",
      "Batch: 30, Loss: 1.131838083267212, Accuracy: 0.6298828125\n",
      "Batch: 31, Loss: 1.2039146423339844, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.0759637355804443, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 1.0200093984603882, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.0981807708740234, Accuracy: 0.6396484375\n",
      "Batch: 35, Loss: 1.1380327939987183, Accuracy: 0.6181640625\n",
      "Batch: 36, Loss: 1.2131834030151367, Accuracy: 0.5947265625\n",
      "Batch: 37, Loss: 1.169163703918457, Accuracy: 0.6298828125\n",
      "Batch: 38, Loss: 1.1594640016555786, Accuracy: 0.609375\n",
      "Batch: 39, Loss: 1.0683565139770508, Accuracy: 0.6650390625\n",
      "Batch: 40, Loss: 1.1086654663085938, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.1096320152282715, Accuracy: 0.6357421875\n",
      "Batch: 42, Loss: 1.0839498043060303, Accuracy: 0.6572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 43, Loss: 1.1368224620819092, Accuracy: 0.62890625\n",
      "Batch: 44, Loss: 1.1012699604034424, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 1.088491439819336, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.1551074981689453, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.117121696472168, Accuracy: 0.658203125\n",
      "Batch: 48, Loss: 1.1296231746673584, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.1551049947738647, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.070685625076294, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.1490581035614014, Accuracy: 0.611328125\n",
      "Batch: 52, Loss: 1.2379417419433594, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.1479554176330566, Accuracy: 0.6318359375\n",
      "Batch: 54, Loss: 1.2068666219711304, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.0704374313354492, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.1198959350585938, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.1513615846633911, Accuracy: 0.6416015625\n",
      "Batch: 58, Loss: 1.0823328495025635, Accuracy: 0.6572265625\n",
      "Batch: 59, Loss: 1.0748884677886963, Accuracy: 0.6357421875\n",
      "Batch: 60, Loss: 1.2112561464309692, Accuracy: 0.60546875\n",
      "Batch: 61, Loss: 1.1638680696487427, Accuracy: 0.611328125\n",
      "Batch: 62, Loss: 1.1483464241027832, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.1452853679656982, Accuracy: 0.6318359375\n",
      "Batch: 64, Loss: 1.2012782096862793, Accuracy: 0.5830078125\n",
      "Batch: 65, Loss: 1.190720796585083, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1153924465179443, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.1726269721984863, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.026479721069336, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.2024790048599243, Accuracy: 0.60546875\n",
      "Batch: 70, Loss: 1.2343300580978394, Accuracy: 0.5888671875\n",
      "Batch: 71, Loss: 1.1623321771621704, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.1857898235321045, Accuracy: 0.6103515625\n",
      "Batch: 73, Loss: 1.1959683895111084, Accuracy: 0.62890625\n",
      "Batch: 74, Loss: 1.066011667251587, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.1069321632385254, Accuracy: 0.6357421875\n",
      "Batch: 76, Loss: 1.1192666292190552, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.0518839359283447, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.04669189453125, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.1429306268692017, Accuracy: 0.61328125\n",
      "Batch: 80, Loss: 1.1505630016326904, Accuracy: 0.634765625\n",
      "Batch: 81, Loss: 1.0873310565948486, Accuracy: 0.6572265625\n",
      "Batch: 82, Loss: 1.1445679664611816, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 1.1935923099517822, Accuracy: 0.59375\n",
      "Batch: 84, Loss: 1.1115353107452393, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1716749668121338, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.171613335609436, Accuracy: 0.5966796875\n",
      "Batch: 87, Loss: 1.1509724855422974, Accuracy: 0.62109375\n",
      "Batch: 88, Loss: 1.1765077114105225, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.1362202167510986, Accuracy: 0.6611328125\n",
      "Batch: 90, Loss: 1.0618524551391602, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.1570284366607666, Accuracy: 0.6396484375\n",
      "Batch: 92, Loss: 1.180060625076294, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.1426281929016113, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.2116072177886963, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.1436351537704468, Accuracy: 0.63671875\n",
      "Batch: 96, Loss: 1.2425209283828735, Accuracy: 0.625\n",
      "Batch: 97, Loss: 1.1321182250976562, Accuracy: 0.6357421875\n",
      "Batch: 98, Loss: 1.0864238739013672, Accuracy: 0.65234375\n",
      "Batch: 99, Loss: 1.177983045578003, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 1.0478479862213135, Accuracy: 0.6689453125\n",
      "Batch: 101, Loss: 1.103608250617981, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.1785722970962524, Accuracy: 0.6162109375\n",
      "Batch: 103, Loss: 1.1405261754989624, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.1718087196350098, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.2190266847610474, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.081369400024414, Accuracy: 0.65234375\n",
      "Batch: 107, Loss: 1.2203830480575562, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.162603497505188, Accuracy: 0.61328125\n",
      "Batch: 109, Loss: 1.2100797891616821, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.1179182529449463, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.1366856098175049, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.1234666109085083, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.2074064016342163, Accuracy: 0.611328125\n",
      "Batch: 114, Loss: 1.2023463249206543, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.197008490562439, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.14744234085083, Accuracy: 0.62890625\n",
      "Batch: 117, Loss: 1.1569056510925293, Accuracy: 0.6328125\n",
      "Batch: 118, Loss: 1.2541884183883667, Accuracy: 0.5703125\n",
      "Batch: 119, Loss: 1.1849489212036133, Accuracy: 0.6103515625\n",
      "Batch: 120, Loss: 1.2462272644042969, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.2427682876586914, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.2032034397125244, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.1617896556854248, Accuracy: 0.6328125\n",
      "Batch: 124, Loss: 1.1864649057388306, Accuracy: 0.625\n",
      "Batch: 125, Loss: 1.1733062267303467, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.2452023029327393, Accuracy: 0.6162109375\n",
      "Batch: 127, Loss: 1.1880440711975098, Accuracy: 0.6162109375\n",
      "Batch: 128, Loss: 1.2514293193817139, Accuracy: 0.5947265625\n",
      "Batch: 129, Loss: 1.168243169784546, Accuracy: 0.626953125\n",
      "Batch: 130, Loss: 1.1062999963760376, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.1474318504333496, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 1.0997761487960815, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.1838159561157227, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1283646821975708, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 0.9810453653335571, Accuracy: 0.6630859375\n",
      "Batch: 136, Loss: 1.0995869636535645, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.1596074104309082, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.1972289085388184, Accuracy: 0.5966796875\n",
      "Batch: 139, Loss: 1.151466727256775, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.2056894302368164, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.1913526058197021, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.2163829803466797, Accuracy: 0.6015625\n",
      "Batch: 143, Loss: 1.2394073009490967, Accuracy: 0.5986328125\n",
      "Batch: 144, Loss: 1.2051239013671875, Accuracy: 0.6123046875\n",
      "Batch: 145, Loss: 1.2745115756988525, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.2151858806610107, Accuracy: 0.595703125\n",
      "Batch: 147, Loss: 1.1624000072479248, Accuracy: 0.6328125\n",
      "Batch: 148, Loss: 1.2288167476654053, Accuracy: 0.5810546875\n",
      "Batch: 149, Loss: 1.2036343812942505, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1695550680160522, Accuracy: 0.626953125\n",
      "Batch: 151, Loss: 1.1965502500534058, Accuracy: 0.60546875\n",
      "Batch: 152, Loss: 1.1455237865447998, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.120192289352417, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1358985900878906, Accuracy: 0.63671875\n",
      "Batch: 155, Loss: 1.1039658784866333, Accuracy: 0.640625\n",
      "Epoch 516/200\n",
      "Batch: 1, Loss: 1.2069356441497803, Accuracy: 0.6474609375\n",
      "Batch: 2, Loss: 1.1398570537567139, Accuracy: 0.626953125\n",
      "Batch: 3, Loss: 0.9979743361473083, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.0356550216674805, Accuracy: 0.6689453125\n",
      "Batch: 5, Loss: 1.0532379150390625, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.0192283391952515, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 1.0569517612457275, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 1.0058006048202515, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9852883815765381, Accuracy: 0.6826171875\n",
      "Batch: 10, Loss: 1.00436270236969, Accuracy: 0.66796875\n",
      "Batch: 11, Loss: 1.0100336074829102, Accuracy: 0.67578125\n",
      "Batch: 12, Loss: 1.0101258754730225, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.9523791074752808, Accuracy: 0.689453125\n",
      "Batch: 14, Loss: 0.9880441427230835, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9842044115066528, Accuracy: 0.6611328125\n",
      "Batch: 16, Loss: 1.0697096586227417, Accuracy: 0.6591796875\n",
      "Batch: 17, Loss: 1.1030131578445435, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1096973419189453, Accuracy: 0.63671875\n",
      "Batch: 19, Loss: 1.1940995454788208, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.1071207523345947, Accuracy: 0.642578125\n",
      "Batch: 21, Loss: 1.0772349834442139, Accuracy: 0.634765625\n",
      "Batch: 22, Loss: 1.2333248853683472, Accuracy: 0.62109375\n",
      "Batch: 23, Loss: 1.2120614051818848, Accuracy: 0.6005859375\n",
      "Batch: 24, Loss: 1.0918409824371338, Accuracy: 0.64453125\n",
      "Batch: 25, Loss: 1.169571876525879, Accuracy: 0.6171875\n",
      "Batch: 26, Loss: 1.1792347431182861, Accuracy: 0.5986328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 1.1026424169540405, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.0588454008102417, Accuracy: 0.6455078125\n",
      "Batch: 29, Loss: 1.0496928691864014, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.1513466835021973, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2573487758636475, Accuracy: 0.5947265625\n",
      "Batch: 32, Loss: 1.0358718633651733, Accuracy: 0.658203125\n",
      "Batch: 33, Loss: 1.0250880718231201, Accuracy: 0.662109375\n",
      "Batch: 34, Loss: 1.1243048906326294, Accuracy: 0.623046875\n",
      "Batch: 35, Loss: 1.0644445419311523, Accuracy: 0.65234375\n",
      "Batch: 36, Loss: 1.2149503231048584, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.1986839771270752, Accuracy: 0.603515625\n",
      "Batch: 38, Loss: 1.1384830474853516, Accuracy: 0.6474609375\n",
      "Batch: 39, Loss: 1.059868335723877, Accuracy: 0.626953125\n",
      "Batch: 40, Loss: 1.0601139068603516, Accuracy: 0.650390625\n",
      "Batch: 41, Loss: 1.0864298343658447, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 1.1123039722442627, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0637555122375488, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.0766265392303467, Accuracy: 0.625\n",
      "Batch: 45, Loss: 1.0726757049560547, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.145259141921997, Accuracy: 0.603515625\n",
      "Batch: 47, Loss: 1.1117602586746216, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1543920040130615, Accuracy: 0.6259765625\n",
      "Batch: 49, Loss: 1.2061495780944824, Accuracy: 0.6005859375\n",
      "Batch: 50, Loss: 1.1262067556381226, Accuracy: 0.6279296875\n",
      "Batch: 51, Loss: 1.146305799484253, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.2556686401367188, Accuracy: 0.5947265625\n",
      "Batch: 53, Loss: 1.1369061470031738, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.1752671003341675, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.1184744834899902, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.111032247543335, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.0908234119415283, Accuracy: 0.642578125\n",
      "Batch: 58, Loss: 1.1563301086425781, Accuracy: 0.62109375\n",
      "Batch: 59, Loss: 1.0833065509796143, Accuracy: 0.6552734375\n",
      "Batch: 60, Loss: 1.268898367881775, Accuracy: 0.5908203125\n",
      "Batch: 61, Loss: 1.2010408639907837, Accuracy: 0.6025390625\n",
      "Batch: 62, Loss: 1.1431610584259033, Accuracy: 0.6220703125\n",
      "Batch: 63, Loss: 1.2199088335037231, Accuracy: 0.5859375\n",
      "Batch: 64, Loss: 1.2511165142059326, Accuracy: 0.578125\n",
      "Batch: 65, Loss: 1.2311196327209473, Accuracy: 0.603515625\n",
      "Batch: 66, Loss: 1.1356576681137085, Accuracy: 0.646484375\n",
      "Batch: 67, Loss: 1.1624683141708374, Accuracy: 0.619140625\n",
      "Batch: 68, Loss: 1.156353235244751, Accuracy: 0.634765625\n",
      "Batch: 69, Loss: 1.1742836236953735, Accuracy: 0.625\n",
      "Batch: 70, Loss: 1.1677401065826416, Accuracy: 0.6142578125\n",
      "Batch: 71, Loss: 1.1112408638000488, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.0865752696990967, Accuracy: 0.630859375\n",
      "Batch: 73, Loss: 1.1579649448394775, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.0720317363739014, Accuracy: 0.6572265625\n",
      "Batch: 75, Loss: 1.0870835781097412, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.1270532608032227, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.0423978567123413, Accuracy: 0.65234375\n",
      "Batch: 78, Loss: 1.0932172536849976, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.121453046798706, Accuracy: 0.638671875\n",
      "Batch: 80, Loss: 1.20894193649292, Accuracy: 0.623046875\n",
      "Batch: 81, Loss: 1.1214014291763306, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1172666549682617, Accuracy: 0.6396484375\n",
      "Batch: 83, Loss: 1.230013132095337, Accuracy: 0.5888671875\n",
      "Batch: 84, Loss: 1.1114354133605957, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.1464014053344727, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.1797502040863037, Accuracy: 0.615234375\n",
      "Batch: 87, Loss: 1.1950303316116333, Accuracy: 0.6083984375\n",
      "Batch: 88, Loss: 1.148484706878662, Accuracy: 0.6337890625\n",
      "Batch: 89, Loss: 1.091385006904602, Accuracy: 0.65625\n",
      "Batch: 90, Loss: 1.1449131965637207, Accuracy: 0.6181640625\n",
      "Batch: 91, Loss: 1.1452505588531494, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1386891603469849, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.0778367519378662, Accuracy: 0.6416015625\n",
      "Batch: 94, Loss: 1.1677711009979248, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1260660886764526, Accuracy: 0.615234375\n",
      "Batch: 96, Loss: 1.2229135036468506, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.2033402919769287, Accuracy: 0.62109375\n",
      "Batch: 98, Loss: 1.1313133239746094, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.1282672882080078, Accuracy: 0.623046875\n",
      "Batch: 100, Loss: 1.047133445739746, Accuracy: 0.6591796875\n",
      "Batch: 101, Loss: 1.1287472248077393, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.1484110355377197, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.143824815750122, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1581323146820068, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.2206666469573975, Accuracy: 0.59375\n",
      "Batch: 106, Loss: 1.171675205230713, Accuracy: 0.5947265625\n",
      "Batch: 107, Loss: 1.2073101997375488, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.194543719291687, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.2006397247314453, Accuracy: 0.6220703125\n",
      "Batch: 110, Loss: 1.1810674667358398, Accuracy: 0.6240234375\n",
      "Batch: 111, Loss: 1.1265318393707275, Accuracy: 0.6025390625\n",
      "Batch: 112, Loss: 1.0512042045593262, Accuracy: 0.6484375\n",
      "Batch: 113, Loss: 1.1291515827178955, Accuracy: 0.6474609375\n",
      "Batch: 114, Loss: 1.1580473184585571, Accuracy: 0.599609375\n",
      "Batch: 115, Loss: 1.1459736824035645, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1804747581481934, Accuracy: 0.62109375\n",
      "Batch: 117, Loss: 1.1892194747924805, Accuracy: 0.6025390625\n",
      "Batch: 118, Loss: 1.217550277709961, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2420151233673096, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.2532215118408203, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.1700944900512695, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.2192718982696533, Accuracy: 0.607421875\n",
      "Batch: 123, Loss: 1.1997661590576172, Accuracy: 0.611328125\n",
      "Batch: 124, Loss: 1.2136874198913574, Accuracy: 0.609375\n",
      "Batch: 125, Loss: 1.1427996158599854, Accuracy: 0.6298828125\n",
      "Batch: 126, Loss: 1.2186720371246338, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.2280172109603882, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.2086031436920166, Accuracy: 0.62109375\n",
      "Batch: 129, Loss: 1.1579914093017578, Accuracy: 0.6328125\n",
      "Batch: 130, Loss: 1.1205030679702759, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.178952932357788, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0950742959976196, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.124800443649292, Accuracy: 0.6220703125\n",
      "Batch: 134, Loss: 1.1139771938323975, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 1.0416187047958374, Accuracy: 0.6630859375\n",
      "Batch: 136, Loss: 1.0798959732055664, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.2260183095932007, Accuracy: 0.6064453125\n",
      "Batch: 138, Loss: 1.237804889678955, Accuracy: 0.6142578125\n",
      "Batch: 139, Loss: 1.1673500537872314, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.2238874435424805, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.179382085800171, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.1915309429168701, Accuracy: 0.6083984375\n",
      "Batch: 143, Loss: 1.1966495513916016, Accuracy: 0.6025390625\n",
      "Batch: 144, Loss: 1.2536356449127197, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.2284595966339111, Accuracy: 0.5966796875\n",
      "Batch: 146, Loss: 1.1330921649932861, Accuracy: 0.634765625\n",
      "Batch: 147, Loss: 1.1755867004394531, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1255083084106445, Accuracy: 0.6357421875\n",
      "Batch: 149, Loss: 1.1616616249084473, Accuracy: 0.619140625\n",
      "Batch: 150, Loss: 1.164677619934082, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.2076280117034912, Accuracy: 0.6162109375\n",
      "Batch: 152, Loss: 1.1501398086547852, Accuracy: 0.6162109375\n",
      "Batch: 153, Loss: 1.1325263977050781, Accuracy: 0.62890625\n",
      "Batch: 154, Loss: 1.1014525890350342, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0893970727920532, Accuracy: 0.66015625\n",
      "Epoch 517/200\n",
      "Batch: 1, Loss: 1.2219831943511963, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.0751245021820068, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0352728366851807, Accuracy: 0.6455078125\n",
      "Batch: 4, Loss: 1.1083993911743164, Accuracy: 0.626953125\n",
      "Batch: 5, Loss: 1.0413461923599243, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 1.0530028343200684, Accuracy: 0.662109375\n",
      "Batch: 7, Loss: 1.0110385417938232, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9899924993515015, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 1.017599105834961, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.0577399730682373, Accuracy: 0.66015625\n",
      "Batch: 11, Loss: 0.9441896677017212, Accuracy: 0.69140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12, Loss: 1.043062448501587, Accuracy: 0.6484375\n",
      "Batch: 13, Loss: 1.0432391166687012, Accuracy: 0.658203125\n",
      "Batch: 14, Loss: 0.9550697803497314, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.9101728200912476, Accuracy: 0.705078125\n",
      "Batch: 16, Loss: 0.9671989679336548, Accuracy: 0.6884765625\n",
      "Batch: 17, Loss: 0.9858279824256897, Accuracy: 0.6640625\n",
      "Batch: 18, Loss: 1.1272480487823486, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.153098464012146, Accuracy: 0.609375\n",
      "Batch: 20, Loss: 1.1071884632110596, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.0849303007125854, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.2390122413635254, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2158145904541016, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.0604698657989502, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 1.16572904586792, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.1983318328857422, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.0930110216140747, Accuracy: 0.650390625\n",
      "Batch: 28, Loss: 1.0700039863586426, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.0277469158172607, Accuracy: 0.6728515625\n",
      "Batch: 30, Loss: 1.168424367904663, Accuracy: 0.6064453125\n",
      "Batch: 31, Loss: 1.19679856300354, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.0227586030960083, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 0.9842121005058289, Accuracy: 0.662109375\n",
      "Batch: 34, Loss: 1.0781784057617188, Accuracy: 0.6552734375\n",
      "Batch: 35, Loss: 1.0772730112075806, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.1201636791229248, Accuracy: 0.638671875\n",
      "Batch: 37, Loss: 1.163506031036377, Accuracy: 0.615234375\n",
      "Batch: 38, Loss: 1.1611864566802979, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0920779705047607, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0753700733184814, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1571414470672607, Accuracy: 0.6005859375\n",
      "Batch: 42, Loss: 1.0446068048477173, Accuracy: 0.6689453125\n",
      "Batch: 43, Loss: 1.0593461990356445, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0526483058929443, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 1.0288310050964355, Accuracy: 0.658203125\n",
      "Batch: 46, Loss: 1.1119458675384521, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.0715491771697998, Accuracy: 0.662109375\n",
      "Batch: 48, Loss: 1.1584948301315308, Accuracy: 0.6259765625\n",
      "Batch: 49, Loss: 1.1700398921966553, Accuracy: 0.611328125\n",
      "Batch: 50, Loss: 1.1310276985168457, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1497281789779663, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.2510786056518555, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.121244192123413, Accuracy: 0.6337890625\n",
      "Batch: 54, Loss: 1.1609770059585571, Accuracy: 0.611328125\n",
      "Batch: 55, Loss: 1.1286416053771973, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.079005479812622, Accuracy: 0.6572265625\n",
      "Batch: 57, Loss: 1.1122468709945679, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.0509729385375977, Accuracy: 0.658203125\n",
      "Batch: 59, Loss: 1.1286096572875977, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.2132136821746826, Accuracy: 0.623046875\n",
      "Batch: 61, Loss: 1.1631571054458618, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.0816222429275513, Accuracy: 0.65625\n",
      "Batch: 63, Loss: 1.1636712551116943, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.226992130279541, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.2096850872039795, Accuracy: 0.603515625\n",
      "Batch: 66, Loss: 1.148284673690796, Accuracy: 0.6396484375\n",
      "Batch: 67, Loss: 1.137306809425354, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.0699176788330078, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.1556520462036133, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.1407725811004639, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.1139483451843262, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.2027862071990967, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.1988784074783325, Accuracy: 0.607421875\n",
      "Batch: 74, Loss: 1.0652878284454346, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.0593608617782593, Accuracy: 0.6591796875\n",
      "Batch: 76, Loss: 1.099302053451538, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 1.0173633098602295, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.1056113243103027, Accuracy: 0.646484375\n",
      "Batch: 79, Loss: 1.143700122833252, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.1213181018829346, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.1676266193389893, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.1666345596313477, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.1526424884796143, Accuracy: 0.6416015625\n",
      "Batch: 84, Loss: 1.1355334520339966, Accuracy: 0.611328125\n",
      "Batch: 85, Loss: 1.1469004154205322, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.16168212890625, Accuracy: 0.619140625\n",
      "Batch: 87, Loss: 1.1902260780334473, Accuracy: 0.6044921875\n",
      "Batch: 88, Loss: 1.1594486236572266, Accuracy: 0.6181640625\n",
      "Batch: 89, Loss: 1.1213210821151733, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.1168485879898071, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.1303281784057617, Accuracy: 0.640625\n",
      "Batch: 92, Loss: 1.1639965772628784, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.1101627349853516, Accuracy: 0.6416015625\n",
      "Batch: 94, Loss: 1.1185023784637451, Accuracy: 0.6416015625\n",
      "Batch: 95, Loss: 1.136196494102478, Accuracy: 0.6298828125\n",
      "Batch: 96, Loss: 1.1755820512771606, Accuracy: 0.6376953125\n",
      "Batch: 97, Loss: 1.1790930032730103, Accuracy: 0.607421875\n",
      "Batch: 98, Loss: 1.0795286893844604, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.1223289966583252, Accuracy: 0.623046875\n",
      "Batch: 100, Loss: 1.0254076719284058, Accuracy: 0.6748046875\n",
      "Batch: 101, Loss: 1.1256738901138306, Accuracy: 0.642578125\n",
      "Batch: 102, Loss: 1.1942200660705566, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.1407887935638428, Accuracy: 0.6279296875\n",
      "Batch: 104, Loss: 1.1900362968444824, Accuracy: 0.6162109375\n",
      "Batch: 105, Loss: 1.2088518142700195, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.145676851272583, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.235119104385376, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.1364248991012573, Accuracy: 0.62109375\n",
      "Batch: 109, Loss: 1.1909263134002686, Accuracy: 0.595703125\n",
      "Batch: 110, Loss: 1.1113003492355347, Accuracy: 0.6435546875\n",
      "Batch: 111, Loss: 1.079984426498413, Accuracy: 0.65625\n",
      "Batch: 112, Loss: 1.0822489261627197, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.194507360458374, Accuracy: 0.6142578125\n",
      "Batch: 114, Loss: 1.204430103302002, Accuracy: 0.58984375\n",
      "Batch: 115, Loss: 1.164728045463562, Accuracy: 0.625\n",
      "Batch: 116, Loss: 1.1317733526229858, Accuracy: 0.6259765625\n",
      "Batch: 117, Loss: 1.1544365882873535, Accuracy: 0.6259765625\n",
      "Batch: 118, Loss: 1.1992806196212769, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.1900372505187988, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.2805811166763306, Accuracy: 0.6015625\n",
      "Batch: 121, Loss: 1.1875720024108887, Accuracy: 0.626953125\n",
      "Batch: 122, Loss: 1.1525404453277588, Accuracy: 0.6279296875\n",
      "Batch: 123, Loss: 1.0949459075927734, Accuracy: 0.658203125\n",
      "Batch: 124, Loss: 1.191376805305481, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1613843441009521, Accuracy: 0.642578125\n",
      "Batch: 126, Loss: 1.174325704574585, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.2924699783325195, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.194183349609375, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.1698212623596191, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.1545076370239258, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.1530972719192505, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.0307966470718384, Accuracy: 0.6943359375\n",
      "Batch: 133, Loss: 1.1148772239685059, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.11474609375, Accuracy: 0.6689453125\n",
      "Batch: 135, Loss: 1.0322010517120361, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.0613973140716553, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.1197013854980469, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.2511671781539917, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.1454094648361206, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.186570405960083, Accuracy: 0.6201171875\n",
      "Batch: 141, Loss: 1.215745449066162, Accuracy: 0.6220703125\n",
      "Batch: 142, Loss: 1.1695172786712646, Accuracy: 0.634765625\n",
      "Batch: 143, Loss: 1.172461748123169, Accuracy: 0.6318359375\n",
      "Batch: 144, Loss: 1.2009092569351196, Accuracy: 0.6005859375\n",
      "Batch: 145, Loss: 1.228324294090271, Accuracy: 0.607421875\n",
      "Batch: 146, Loss: 1.1812958717346191, Accuracy: 0.6181640625\n",
      "Batch: 147, Loss: 1.2000353336334229, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.2017416954040527, Accuracy: 0.6181640625\n",
      "Batch: 149, Loss: 1.160510540008545, Accuracy: 0.62109375\n",
      "Batch: 150, Loss: 1.1019560098648071, Accuracy: 0.6240234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 151, Loss: 1.1261694431304932, Accuracy: 0.634765625\n",
      "Batch: 152, Loss: 1.14852774143219, Accuracy: 0.640625\n",
      "Batch: 153, Loss: 1.1503548622131348, Accuracy: 0.6376953125\n",
      "Batch: 154, Loss: 1.090955376625061, Accuracy: 0.6494140625\n",
      "Batch: 155, Loss: 1.1419076919555664, Accuracy: 0.6318359375\n",
      "Epoch 518/200\n",
      "Batch: 1, Loss: 1.205658197402954, Accuracy: 0.626953125\n",
      "Batch: 2, Loss: 1.0505061149597168, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 1.0101573467254639, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.0759366750717163, Accuracy: 0.6328125\n",
      "Batch: 5, Loss: 1.0412838459014893, Accuracy: 0.6572265625\n",
      "Batch: 6, Loss: 1.0330013036727905, Accuracy: 0.66796875\n",
      "Batch: 7, Loss: 1.0149873495101929, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.9602472186088562, Accuracy: 0.6962890625\n",
      "Batch: 9, Loss: 0.988175094127655, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 0.9443379640579224, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 0.9478633403778076, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 1.0369327068328857, Accuracy: 0.646484375\n",
      "Batch: 13, Loss: 1.0581883192062378, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9908748269081116, Accuracy: 0.6748046875\n",
      "Batch: 15, Loss: 0.9703525304794312, Accuracy: 0.6552734375\n",
      "Batch: 16, Loss: 1.0066592693328857, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.0558502674102783, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.1452162265777588, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.1921290159225464, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0521576404571533, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0373035669326782, Accuracy: 0.6728515625\n",
      "Batch: 22, Loss: 1.230663537979126, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.2159055471420288, Accuracy: 0.6103515625\n",
      "Batch: 24, Loss: 1.0827486515045166, Accuracy: 0.6416015625\n",
      "Batch: 25, Loss: 1.104586124420166, Accuracy: 0.6455078125\n",
      "Batch: 26, Loss: 1.1822185516357422, Accuracy: 0.5908203125\n",
      "Batch: 27, Loss: 1.0913739204406738, Accuracy: 0.6376953125\n",
      "Batch: 28, Loss: 1.0628950595855713, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.0518488883972168, Accuracy: 0.642578125\n",
      "Batch: 30, Loss: 1.145972490310669, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.2461905479431152, Accuracy: 0.583984375\n",
      "Batch: 32, Loss: 1.0720763206481934, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 1.0494049787521362, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.1132383346557617, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.1657330989837646, Accuracy: 0.634765625\n",
      "Batch: 36, Loss: 1.1851850748062134, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.209143877029419, Accuracy: 0.6201171875\n",
      "Batch: 38, Loss: 1.1607333421707153, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.0885546207427979, Accuracy: 0.6611328125\n",
      "Batch: 40, Loss: 1.0823101997375488, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.1181138753890991, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.0569400787353516, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 1.0648982524871826, Accuracy: 0.6328125\n",
      "Batch: 44, Loss: 1.041027545928955, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 1.0716886520385742, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.0949063301086426, Accuracy: 0.6494140625\n",
      "Batch: 47, Loss: 1.099867582321167, Accuracy: 0.666015625\n",
      "Batch: 48, Loss: 1.1004749536514282, Accuracy: 0.6396484375\n",
      "Batch: 49, Loss: 1.1424555778503418, Accuracy: 0.6494140625\n",
      "Batch: 50, Loss: 1.135453701019287, Accuracy: 0.6298828125\n",
      "Batch: 51, Loss: 1.162611722946167, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.2547078132629395, Accuracy: 0.5791015625\n",
      "Batch: 53, Loss: 1.1070044040679932, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.1651239395141602, Accuracy: 0.615234375\n",
      "Batch: 55, Loss: 1.091447353363037, Accuracy: 0.658203125\n",
      "Batch: 56, Loss: 1.0816547870635986, Accuracy: 0.6572265625\n",
      "Batch: 57, Loss: 1.0799906253814697, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.103200912475586, Accuracy: 0.6337890625\n",
      "Batch: 59, Loss: 1.1851621866226196, Accuracy: 0.61328125\n",
      "Batch: 60, Loss: 1.2712721824645996, Accuracy: 0.591796875\n",
      "Batch: 61, Loss: 1.1286262273788452, Accuracy: 0.6220703125\n",
      "Batch: 62, Loss: 1.1474387645721436, Accuracy: 0.6181640625\n",
      "Batch: 63, Loss: 1.1017612218856812, Accuracy: 0.650390625\n",
      "Batch: 64, Loss: 1.212734341621399, Accuracy: 0.6064453125\n",
      "Batch: 65, Loss: 1.1292572021484375, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.1511549949645996, Accuracy: 0.6416015625\n",
      "Batch: 67, Loss: 1.1572120189666748, Accuracy: 0.60546875\n",
      "Batch: 68, Loss: 1.0650851726531982, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.1622529029846191, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1452194452285767, Accuracy: 0.6298828125\n",
      "Batch: 71, Loss: 1.136499285697937, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.2324676513671875, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.1572229862213135, Accuracy: 0.6337890625\n",
      "Batch: 74, Loss: 1.0765889883041382, Accuracy: 0.6533203125\n",
      "Batch: 75, Loss: 1.1451153755187988, Accuracy: 0.6083984375\n",
      "Batch: 76, Loss: 1.0158381462097168, Accuracy: 0.662109375\n",
      "Batch: 77, Loss: 1.0412518978118896, Accuracy: 0.646484375\n",
      "Batch: 78, Loss: 1.0977919101715088, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.0751724243164062, Accuracy: 0.6533203125\n",
      "Batch: 80, Loss: 1.1622567176818848, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.1399681568145752, Accuracy: 0.6162109375\n",
      "Batch: 82, Loss: 1.1603448390960693, Accuracy: 0.6220703125\n",
      "Batch: 83, Loss: 1.1614086627960205, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1296151876449585, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.1729398965835571, Accuracy: 0.6279296875\n",
      "Batch: 86, Loss: 1.0799590349197388, Accuracy: 0.646484375\n",
      "Batch: 87, Loss: 1.1360769271850586, Accuracy: 0.6376953125\n",
      "Batch: 88, Loss: 1.1817669868469238, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.148484468460083, Accuracy: 0.626953125\n",
      "Batch: 90, Loss: 1.0869860649108887, Accuracy: 0.64453125\n",
      "Batch: 91, Loss: 1.085646390914917, Accuracy: 0.6513671875\n",
      "Batch: 92, Loss: 1.1524608135223389, Accuracy: 0.626953125\n",
      "Batch: 93, Loss: 1.180558443069458, Accuracy: 0.62109375\n",
      "Batch: 94, Loss: 1.1528575420379639, Accuracy: 0.6171875\n",
      "Batch: 95, Loss: 1.1846870183944702, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.207077980041504, Accuracy: 0.62109375\n",
      "Batch: 97, Loss: 1.0885584354400635, Accuracy: 0.63671875\n",
      "Batch: 98, Loss: 1.1256524324417114, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.1418685913085938, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.0890014171600342, Accuracy: 0.630859375\n",
      "Batch: 101, Loss: 1.1146292686462402, Accuracy: 0.6123046875\n",
      "Batch: 102, Loss: 1.1968750953674316, Accuracy: 0.6015625\n",
      "Batch: 103, Loss: 1.1348516941070557, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.0925118923187256, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.1816446781158447, Accuracy: 0.615234375\n",
      "Batch: 106, Loss: 1.2146790027618408, Accuracy: 0.6181640625\n",
      "Batch: 107, Loss: 1.223036289215088, Accuracy: 0.578125\n",
      "Batch: 108, Loss: 1.1695960760116577, Accuracy: 0.62109375\n",
      "Batch: 109, Loss: 1.2244212627410889, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 1.1127703189849854, Accuracy: 0.634765625\n",
      "Batch: 111, Loss: 1.1313802003860474, Accuracy: 0.6259765625\n",
      "Batch: 112, Loss: 1.0604838132858276, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.1172218322753906, Accuracy: 0.6435546875\n",
      "Batch: 114, Loss: 1.1815252304077148, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.1574485301971436, Accuracy: 0.6337890625\n",
      "Batch: 116, Loss: 1.2119777202606201, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1245425939559937, Accuracy: 0.630859375\n",
      "Batch: 118, Loss: 1.1756412982940674, Accuracy: 0.607421875\n",
      "Batch: 119, Loss: 1.234797716140747, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2500061988830566, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.1075713634490967, Accuracy: 0.6572265625\n",
      "Batch: 122, Loss: 1.2070926427841187, Accuracy: 0.6142578125\n",
      "Batch: 123, Loss: 1.1395008563995361, Accuracy: 0.6201171875\n",
      "Batch: 124, Loss: 1.2043390274047852, Accuracy: 0.63671875\n",
      "Batch: 125, Loss: 1.2092046737670898, Accuracy: 0.6103515625\n",
      "Batch: 126, Loss: 1.178062915802002, Accuracy: 0.6162109375\n",
      "Batch: 127, Loss: 1.2505745887756348, Accuracy: 0.6171875\n",
      "Batch: 128, Loss: 1.2171504497528076, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.1670191287994385, Accuracy: 0.623046875\n",
      "Batch: 130, Loss: 1.1412200927734375, Accuracy: 0.6328125\n",
      "Batch: 131, Loss: 1.2024908065795898, Accuracy: 0.6015625\n",
      "Batch: 132, Loss: 1.1121654510498047, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.1740894317626953, Accuracy: 0.6298828125\n",
      "Batch: 134, Loss: 1.1141340732574463, Accuracy: 0.6572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 135, Loss: 1.0356090068817139, Accuracy: 0.6728515625\n",
      "Batch: 136, Loss: 1.080911636352539, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1319284439086914, Accuracy: 0.6318359375\n",
      "Batch: 138, Loss: 1.20863676071167, Accuracy: 0.6181640625\n",
      "Batch: 139, Loss: 1.1200504302978516, Accuracy: 0.6396484375\n",
      "Batch: 140, Loss: 1.2420405149459839, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.1404309272766113, Accuracy: 0.625\n",
      "Batch: 142, Loss: 1.130873441696167, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.209436297416687, Accuracy: 0.6083984375\n",
      "Batch: 144, Loss: 1.2203803062438965, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.2453892230987549, Accuracy: 0.6103515625\n",
      "Batch: 146, Loss: 1.1770122051239014, Accuracy: 0.625\n",
      "Batch: 147, Loss: 1.1577181816101074, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.2344155311584473, Accuracy: 0.5869140625\n",
      "Batch: 149, Loss: 1.1769726276397705, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.1474064588546753, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.1270134449005127, Accuracy: 0.6181640625\n",
      "Batch: 152, Loss: 1.164154052734375, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.1062979698181152, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.09071946144104, Accuracy: 0.6513671875\n",
      "Batch: 155, Loss: 1.0287055969238281, Accuracy: 0.658203125\n",
      "Epoch 519/200\n",
      "Batch: 1, Loss: 1.1955112218856812, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.0563056468963623, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 0.9514480829238892, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 1.063666820526123, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.0142645835876465, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0334665775299072, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 1.0494070053100586, Accuracy: 0.6533203125\n",
      "Batch: 8, Loss: 0.9665441513061523, Accuracy: 0.6943359375\n",
      "Batch: 9, Loss: 0.9794046878814697, Accuracy: 0.685546875\n",
      "Batch: 10, Loss: 1.0064536333084106, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 0.967700183391571, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 0.9921574592590332, Accuracy: 0.7080078125\n",
      "Batch: 13, Loss: 1.0152995586395264, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 0.9073601961135864, Accuracy: 0.7001953125\n",
      "Batch: 15, Loss: 0.9657344818115234, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0174095630645752, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.0713950395584106, Accuracy: 0.646484375\n",
      "Batch: 18, Loss: 1.1013374328613281, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.1848000288009644, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.0898334980010986, Accuracy: 0.6484375\n",
      "Batch: 21, Loss: 1.0719685554504395, Accuracy: 0.6484375\n",
      "Batch: 22, Loss: 1.2194353342056274, Accuracy: 0.6103515625\n",
      "Batch: 23, Loss: 1.2444148063659668, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.074829339981079, Accuracy: 0.650390625\n",
      "Batch: 25, Loss: 1.1397242546081543, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.148729920387268, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.0766804218292236, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.0819642543792725, Accuracy: 0.64453125\n",
      "Batch: 29, Loss: 1.0715209245681763, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.125220537185669, Accuracy: 0.630859375\n",
      "Batch: 31, Loss: 1.1684818267822266, Accuracy: 0.5947265625\n",
      "Batch: 32, Loss: 1.0260603427886963, Accuracy: 0.65234375\n",
      "Batch: 33, Loss: 1.0025408267974854, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.0884020328521729, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 1.1369929313659668, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.1549526453018188, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.2304291725158691, Accuracy: 0.59765625\n",
      "Batch: 38, Loss: 1.1593601703643799, Accuracy: 0.626953125\n",
      "Batch: 39, Loss: 1.031166434288025, Accuracy: 0.6513671875\n",
      "Batch: 40, Loss: 1.0800449848175049, Accuracy: 0.65234375\n",
      "Batch: 41, Loss: 1.07926607131958, Accuracy: 0.640625\n",
      "Batch: 42, Loss: 1.06340491771698, Accuracy: 0.66015625\n",
      "Batch: 43, Loss: 1.0535097122192383, Accuracy: 0.6640625\n",
      "Batch: 44, Loss: 1.0341224670410156, Accuracy: 0.640625\n",
      "Batch: 45, Loss: 1.0238392353057861, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.0886666774749756, Accuracy: 0.6484375\n",
      "Batch: 47, Loss: 1.0819543600082397, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 1.1283501386642456, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.1922874450683594, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.1104698181152344, Accuracy: 0.640625\n",
      "Batch: 51, Loss: 1.1495517492294312, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2405905723571777, Accuracy: 0.5869140625\n",
      "Batch: 53, Loss: 1.1357572078704834, Accuracy: 0.623046875\n",
      "Batch: 54, Loss: 1.2147114276885986, Accuracy: 0.595703125\n",
      "Batch: 55, Loss: 1.0925849676132202, Accuracy: 0.642578125\n",
      "Batch: 56, Loss: 1.110020399093628, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.0667834281921387, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.121442437171936, Accuracy: 0.6318359375\n",
      "Batch: 59, Loss: 1.0853499174118042, Accuracy: 0.6474609375\n",
      "Batch: 60, Loss: 1.2233116626739502, Accuracy: 0.6044921875\n",
      "Batch: 61, Loss: 1.1300865411758423, Accuracy: 0.6298828125\n",
      "Batch: 62, Loss: 1.0953243970870972, Accuracy: 0.658203125\n",
      "Batch: 63, Loss: 1.170536756515503, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.211498737335205, Accuracy: 0.5966796875\n",
      "Batch: 65, Loss: 1.1952089071273804, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.194830298423767, Accuracy: 0.6123046875\n",
      "Batch: 67, Loss: 1.1160331964492798, Accuracy: 0.6328125\n",
      "Batch: 68, Loss: 1.0306835174560547, Accuracy: 0.6630859375\n",
      "Batch: 69, Loss: 1.1462364196777344, Accuracy: 0.640625\n",
      "Batch: 70, Loss: 1.1582999229431152, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.1445492506027222, Accuracy: 0.6318359375\n",
      "Batch: 72, Loss: 1.1791162490844727, Accuracy: 0.6103515625\n",
      "Batch: 73, Loss: 1.1738851070404053, Accuracy: 0.6015625\n",
      "Batch: 74, Loss: 1.136738657951355, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.0803836584091187, Accuracy: 0.65234375\n",
      "Batch: 76, Loss: 1.0674855709075928, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0579488277435303, Accuracy: 0.6689453125\n",
      "Batch: 78, Loss: 1.0577609539031982, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.097238302230835, Accuracy: 0.6513671875\n",
      "Batch: 80, Loss: 1.127276062965393, Accuracy: 0.6396484375\n",
      "Batch: 81, Loss: 1.062517523765564, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.1159250736236572, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.1586097478866577, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.105669617652893, Accuracy: 0.650390625\n",
      "Batch: 85, Loss: 1.155980110168457, Accuracy: 0.6259765625\n",
      "Batch: 86, Loss: 1.0765342712402344, Accuracy: 0.65234375\n",
      "Batch: 87, Loss: 1.1387019157409668, Accuracy: 0.6318359375\n",
      "Batch: 88, Loss: 1.1548992395401, Accuracy: 0.6240234375\n",
      "Batch: 89, Loss: 1.1180307865142822, Accuracy: 0.6640625\n",
      "Batch: 90, Loss: 1.1029913425445557, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1169822216033936, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.067886233329773, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.1333309412002563, Accuracy: 0.64453125\n",
      "Batch: 94, Loss: 1.1773178577423096, Accuracy: 0.6181640625\n",
      "Batch: 95, Loss: 1.1211795806884766, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.1850966215133667, Accuracy: 0.6357421875\n",
      "Batch: 97, Loss: 1.143352746963501, Accuracy: 0.626953125\n",
      "Batch: 98, Loss: 1.1513214111328125, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.1209924221038818, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.1201229095458984, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.0679748058319092, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 1.1719367504119873, Accuracy: 0.6298828125\n",
      "Batch: 103, Loss: 1.1597144603729248, Accuracy: 0.630859375\n",
      "Batch: 104, Loss: 1.150670051574707, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.174471378326416, Accuracy: 0.6240234375\n",
      "Batch: 106, Loss: 1.181587815284729, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.1782240867614746, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.1242823600769043, Accuracy: 0.6162109375\n",
      "Batch: 109, Loss: 1.1883268356323242, Accuracy: 0.6259765625\n",
      "Batch: 110, Loss: 1.0755796432495117, Accuracy: 0.6474609375\n",
      "Batch: 111, Loss: 1.1325221061706543, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.0473257303237915, Accuracy: 0.650390625\n",
      "Batch: 113, Loss: 1.1235250234603882, Accuracy: 0.642578125\n",
      "Batch: 114, Loss: 1.132215976715088, Accuracy: 0.6376953125\n",
      "Batch: 115, Loss: 1.169428825378418, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.146121859550476, Accuracy: 0.634765625\n",
      "Batch: 117, Loss: 1.1868432760238647, Accuracy: 0.623046875\n",
      "Batch: 118, Loss: 1.2294390201568604, Accuracy: 0.5986328125\n",
      "Batch: 119, Loss: 1.287233591079712, Accuracy: 0.5986328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 1.2682980298995972, Accuracy: 0.59765625\n",
      "Batch: 121, Loss: 1.1652047634124756, Accuracy: 0.6240234375\n",
      "Batch: 122, Loss: 1.1862252950668335, Accuracy: 0.60546875\n",
      "Batch: 123, Loss: 1.1999168395996094, Accuracy: 0.6318359375\n",
      "Batch: 124, Loss: 1.1957616806030273, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.173034429550171, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.2535748481750488, Accuracy: 0.5966796875\n",
      "Batch: 127, Loss: 1.2280025482177734, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.1295377016067505, Accuracy: 0.6416015625\n",
      "Batch: 129, Loss: 1.1463900804519653, Accuracy: 0.6298828125\n",
      "Batch: 130, Loss: 1.1349472999572754, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.1717705726623535, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.0910775661468506, Accuracy: 0.65234375\n",
      "Batch: 133, Loss: 1.1148123741149902, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.1026155948638916, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.0161761045455933, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.084139347076416, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1420114040374756, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.2159415483474731, Accuracy: 0.623046875\n",
      "Batch: 139, Loss: 1.184072494506836, Accuracy: 0.61328125\n",
      "Batch: 140, Loss: 1.2451508045196533, Accuracy: 0.595703125\n",
      "Batch: 141, Loss: 1.1584973335266113, Accuracy: 0.6259765625\n",
      "Batch: 142, Loss: 1.1540260314941406, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.2149677276611328, Accuracy: 0.59375\n",
      "Batch: 144, Loss: 1.2823545932769775, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.2110276222229004, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.1522867679595947, Accuracy: 0.638671875\n",
      "Batch: 147, Loss: 1.222031831741333, Accuracy: 0.6279296875\n",
      "Batch: 148, Loss: 1.17807137966156, Accuracy: 0.609375\n",
      "Batch: 149, Loss: 1.1740243434906006, Accuracy: 0.5810546875\n",
      "Batch: 150, Loss: 1.124855875968933, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1534805297851562, Accuracy: 0.638671875\n",
      "Batch: 152, Loss: 1.131833791732788, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1292164325714111, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.0152710676193237, Accuracy: 0.65234375\n",
      "Batch: 155, Loss: 1.1069495677947998, Accuracy: 0.6474609375\n",
      "Epoch 520/200\n",
      "Batch: 1, Loss: 1.1801784038543701, Accuracy: 0.654296875\n",
      "Batch: 2, Loss: 1.0712230205535889, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.0266600847244263, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 1.0380022525787354, Accuracy: 0.662109375\n",
      "Batch: 5, Loss: 1.0240402221679688, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.0042341947555542, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 1.019575595855713, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9843066930770874, Accuracy: 0.669921875\n",
      "Batch: 9, Loss: 0.9834965467453003, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9532374143600464, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 0.9544649124145508, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 1.006216049194336, Accuracy: 0.6689453125\n",
      "Batch: 13, Loss: 1.0152297019958496, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 1.0051765441894531, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.9208205938339233, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 0.9844509363174438, Accuracy: 0.689453125\n",
      "Batch: 17, Loss: 1.0925341844558716, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.1105400323867798, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.2309777736663818, Accuracy: 0.5927734375\n",
      "Batch: 20, Loss: 1.1136846542358398, Accuracy: 0.654296875\n",
      "Batch: 21, Loss: 1.0931605100631714, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.231028437614441, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.2517755031585693, Accuracy: 0.58984375\n",
      "Batch: 24, Loss: 1.1078135967254639, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1220672130584717, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.1568742990493774, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.1136891841888428, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0890676975250244, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.115748643875122, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.1479871273040771, Accuracy: 0.6220703125\n",
      "Batch: 31, Loss: 1.173077940940857, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 1.0315897464752197, Accuracy: 0.66796875\n",
      "Batch: 33, Loss: 0.9915509819984436, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.1018975973129272, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.0750545263290405, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.1857467889785767, Accuracy: 0.5947265625\n",
      "Batch: 37, Loss: 1.2065985202789307, Accuracy: 0.5966796875\n",
      "Batch: 38, Loss: 1.1348845958709717, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.085355520248413, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.074000358581543, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1355571746826172, Accuracy: 0.62109375\n",
      "Batch: 42, Loss: 1.0751745700836182, Accuracy: 0.6416015625\n",
      "Batch: 43, Loss: 0.992313027381897, Accuracy: 0.673828125\n",
      "Batch: 44, Loss: 1.0466265678405762, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 1.0002412796020508, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.1266615390777588, Accuracy: 0.6328125\n",
      "Batch: 47, Loss: 1.1012076139450073, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.175166368484497, Accuracy: 0.61328125\n",
      "Batch: 49, Loss: 1.1212784051895142, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.1986898183822632, Accuracy: 0.599609375\n",
      "Batch: 51, Loss: 1.1206134557724, Accuracy: 0.6396484375\n",
      "Batch: 52, Loss: 1.2337615489959717, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.1628800630569458, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.110654592514038, Accuracy: 0.642578125\n",
      "Batch: 55, Loss: 1.1179898977279663, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.0822679996490479, Accuracy: 0.63671875\n",
      "Batch: 57, Loss: 1.1033302545547485, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.1331802606582642, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.0289356708526611, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.2437994480133057, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.100492000579834, Accuracy: 0.6318359375\n",
      "Batch: 62, Loss: 1.115917682647705, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.1643462181091309, Accuracy: 0.615234375\n",
      "Batch: 64, Loss: 1.2221980094909668, Accuracy: 0.6083984375\n",
      "Batch: 65, Loss: 1.1886411905288696, Accuracy: 0.62109375\n",
      "Batch: 66, Loss: 1.1922974586486816, Accuracy: 0.6005859375\n",
      "Batch: 67, Loss: 1.1230006217956543, Accuracy: 0.638671875\n",
      "Batch: 68, Loss: 1.052309513092041, Accuracy: 0.6669921875\n",
      "Batch: 69, Loss: 1.1452614068984985, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.1537635326385498, Accuracy: 0.60546875\n",
      "Batch: 71, Loss: 1.1754393577575684, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.1597458124160767, Accuracy: 0.6201171875\n",
      "Batch: 73, Loss: 1.1735303401947021, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.101186990737915, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.1310876607894897, Accuracy: 0.611328125\n",
      "Batch: 76, Loss: 1.0709125995635986, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0601837635040283, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0061324834823608, Accuracy: 0.6728515625\n",
      "Batch: 79, Loss: 1.1242645978927612, Accuracy: 0.62109375\n",
      "Batch: 80, Loss: 1.1459176540374756, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.0894140005111694, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.1632531881332397, Accuracy: 0.619140625\n",
      "Batch: 83, Loss: 1.1989549398422241, Accuracy: 0.6142578125\n",
      "Batch: 84, Loss: 1.108842372894287, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.1536691188812256, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.1189091205596924, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1416157484054565, Accuracy: 0.63671875\n",
      "Batch: 88, Loss: 1.2221137285232544, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.119229793548584, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.0938457250595093, Accuracy: 0.640625\n",
      "Batch: 91, Loss: 1.1370058059692383, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1364495754241943, Accuracy: 0.63671875\n",
      "Batch: 93, Loss: 1.157594919204712, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.1844264268875122, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.1680054664611816, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.1846390962600708, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.117993712425232, Accuracy: 0.6220703125\n",
      "Batch: 98, Loss: 1.0891450643539429, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.1575764417648315, Accuracy: 0.62109375\n",
      "Batch: 100, Loss: 1.0854442119598389, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.1038451194763184, Accuracy: 0.6337890625\n",
      "Batch: 102, Loss: 1.1925969123840332, Accuracy: 0.619140625\n",
      "Batch: 103, Loss: 1.2038755416870117, Accuracy: 0.6181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 1.1356393098831177, Accuracy: 0.6171875\n",
      "Batch: 105, Loss: 1.191839337348938, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.172349452972412, Accuracy: 0.6337890625\n",
      "Batch: 107, Loss: 1.2202794551849365, Accuracy: 0.5966796875\n",
      "Batch: 108, Loss: 1.2168655395507812, Accuracy: 0.595703125\n",
      "Batch: 109, Loss: 1.1690149307250977, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.1367696523666382, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1482664346694946, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.0776116847991943, Accuracy: 0.65234375\n",
      "Batch: 113, Loss: 1.13474702835083, Accuracy: 0.6298828125\n",
      "Batch: 114, Loss: 1.15632164478302, Accuracy: 0.5966796875\n",
      "Batch: 115, Loss: 1.1714050769805908, Accuracy: 0.6171875\n",
      "Batch: 116, Loss: 1.1998134851455688, Accuracy: 0.6181640625\n",
      "Batch: 117, Loss: 1.12797212600708, Accuracy: 0.62109375\n",
      "Batch: 118, Loss: 1.1533596515655518, Accuracy: 0.6240234375\n",
      "Batch: 119, Loss: 1.2259366512298584, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.2400422096252441, Accuracy: 0.6240234375\n",
      "Batch: 121, Loss: 1.1487042903900146, Accuracy: 0.626953125\n",
      "Batch: 122, Loss: 1.1720097064971924, Accuracy: 0.630859375\n",
      "Batch: 123, Loss: 1.2372517585754395, Accuracy: 0.60546875\n",
      "Batch: 124, Loss: 1.1919264793395996, Accuracy: 0.603515625\n",
      "Batch: 125, Loss: 1.1444337368011475, Accuracy: 0.626953125\n",
      "Batch: 126, Loss: 1.207605242729187, Accuracy: 0.615234375\n",
      "Batch: 127, Loss: 1.2316193580627441, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.1901935338974, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.166428565979004, Accuracy: 0.6416015625\n",
      "Batch: 130, Loss: 1.0742485523223877, Accuracy: 0.658203125\n",
      "Batch: 131, Loss: 1.185031533241272, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.0993268489837646, Accuracy: 0.640625\n",
      "Batch: 133, Loss: 1.2175030708312988, Accuracy: 0.6044921875\n",
      "Batch: 134, Loss: 1.0801728963851929, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 1.0465364456176758, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.075535535812378, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.1600195169448853, Accuracy: 0.638671875\n",
      "Batch: 138, Loss: 1.2442913055419922, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.1530585289001465, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.253911018371582, Accuracy: 0.6083984375\n",
      "Batch: 141, Loss: 1.1351507902145386, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.1752843856811523, Accuracy: 0.62109375\n",
      "Batch: 143, Loss: 1.1983642578125, Accuracy: 0.625\n",
      "Batch: 144, Loss: 1.233238935470581, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.269453525543213, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.200371265411377, Accuracy: 0.6064453125\n",
      "Batch: 147, Loss: 1.2398325204849243, Accuracy: 0.595703125\n",
      "Batch: 148, Loss: 1.174441933631897, Accuracy: 0.625\n",
      "Batch: 149, Loss: 1.140197515487671, Accuracy: 0.6181640625\n",
      "Batch: 150, Loss: 1.1122246980667114, Accuracy: 0.6298828125\n",
      "Batch: 151, Loss: 1.1221137046813965, Accuracy: 0.642578125\n",
      "Batch: 152, Loss: 1.1804077625274658, Accuracy: 0.619140625\n",
      "Batch: 153, Loss: 1.1542326211929321, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.1011042594909668, Accuracy: 0.650390625\n",
      "Batch: 155, Loss: 1.1323721408843994, Accuracy: 0.65625\n",
      "Saved Weights at epoch 520 to file Weights_520.h5\n",
      "Epoch 521/200\n",
      "Batch: 1, Loss: 1.2457480430603027, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.0786315202713013, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 0.9827322363853455, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0929820537567139, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 0.9509344100952148, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 1.0320326089859009, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.0414495468139648, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 0.9673399329185486, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 0.9667492508888245, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 0.9350428581237793, Accuracy: 0.697265625\n",
      "Batch: 11, Loss: 0.9881503582000732, Accuracy: 0.6748046875\n",
      "Batch: 12, Loss: 0.9973158836364746, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.032134771347046, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 0.9741292595863342, Accuracy: 0.6748046875\n",
      "Batch: 15, Loss: 0.9223436117172241, Accuracy: 0.685546875\n",
      "Batch: 16, Loss: 1.0629459619522095, Accuracy: 0.66796875\n",
      "Batch: 17, Loss: 1.0371404886245728, Accuracy: 0.6611328125\n",
      "Batch: 18, Loss: 1.081774115562439, Accuracy: 0.65234375\n",
      "Batch: 19, Loss: 1.152795433998108, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0436253547668457, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0803277492523193, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.2071504592895508, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.2305541038513184, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.0487456321716309, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.1321666240692139, Accuracy: 0.6220703125\n",
      "Batch: 26, Loss: 1.1832823753356934, Accuracy: 0.61328125\n",
      "Batch: 27, Loss: 1.0988786220550537, Accuracy: 0.6298828125\n",
      "Batch: 28, Loss: 1.04069983959198, Accuracy: 0.6552734375\n",
      "Batch: 29, Loss: 1.077939748764038, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1903107166290283, Accuracy: 0.6103515625\n",
      "Batch: 31, Loss: 1.2214889526367188, Accuracy: 0.591796875\n",
      "Batch: 32, Loss: 1.0650746822357178, Accuracy: 0.662109375\n",
      "Batch: 33, Loss: 1.0394259691238403, Accuracy: 0.6513671875\n",
      "Batch: 34, Loss: 1.146474003791809, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.1068130731582642, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.1378602981567383, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.1534359455108643, Accuracy: 0.615234375\n",
      "Batch: 38, Loss: 1.1417427062988281, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.0678921937942505, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.1437811851501465, Accuracy: 0.6376953125\n",
      "Batch: 41, Loss: 1.0991706848144531, Accuracy: 0.62890625\n",
      "Batch: 42, Loss: 1.096278429031372, Accuracy: 0.6357421875\n",
      "Batch: 43, Loss: 1.047966718673706, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 1.057340383529663, Accuracy: 0.662109375\n",
      "Batch: 45, Loss: 1.097015619277954, Accuracy: 0.6318359375\n",
      "Batch: 46, Loss: 1.1150000095367432, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.0754189491271973, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.124814748764038, Accuracy: 0.6396484375\n",
      "Batch: 49, Loss: 1.150864839553833, Accuracy: 0.59375\n",
      "Batch: 50, Loss: 1.107326865196228, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.1260721683502197, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.2582212686538696, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.2008540630340576, Accuracy: 0.603515625\n",
      "Batch: 54, Loss: 1.1543371677398682, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.0855693817138672, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.071608304977417, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.1246256828308105, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.0661720037460327, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 1.0863914489746094, Accuracy: 0.6494140625\n",
      "Batch: 60, Loss: 1.1778545379638672, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1299728155136108, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1206811666488647, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1566444635391235, Accuracy: 0.6240234375\n",
      "Batch: 64, Loss: 1.2117254734039307, Accuracy: 0.6025390625\n",
      "Batch: 65, Loss: 1.2405667304992676, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.1860158443450928, Accuracy: 0.6083984375\n",
      "Batch: 67, Loss: 1.1514334678649902, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.0292741060256958, Accuracy: 0.677734375\n",
      "Batch: 69, Loss: 1.0677661895751953, Accuracy: 0.6484375\n",
      "Batch: 70, Loss: 1.1621177196502686, Accuracy: 0.6357421875\n",
      "Batch: 71, Loss: 1.193964958190918, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.1457802057266235, Accuracy: 0.6240234375\n",
      "Batch: 73, Loss: 1.2019295692443848, Accuracy: 0.5966796875\n",
      "Batch: 74, Loss: 1.1026880741119385, Accuracy: 0.6533203125\n",
      "Batch: 75, Loss: 1.1306331157684326, Accuracy: 0.61328125\n",
      "Batch: 76, Loss: 1.0993000268936157, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.035710334777832, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.0408451557159424, Accuracy: 0.6650390625\n",
      "Batch: 79, Loss: 1.0874438285827637, Accuracy: 0.6396484375\n",
      "Batch: 80, Loss: 1.1834428310394287, Accuracy: 0.6201171875\n",
      "Batch: 81, Loss: 1.0856637954711914, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 1.0984766483306885, Accuracy: 0.6357421875\n",
      "Batch: 83, Loss: 1.1817796230316162, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.1139659881591797, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.167413353919983, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.1952601671218872, Accuracy: 0.6044921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 87, Loss: 1.1878061294555664, Accuracy: 0.6279296875\n",
      "Batch: 88, Loss: 1.139038324356079, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.1288034915924072, Accuracy: 0.615234375\n",
      "Batch: 90, Loss: 1.1242917776107788, Accuracy: 0.6357421875\n",
      "Batch: 91, Loss: 1.2012735605239868, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.1565324068069458, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.1507513523101807, Accuracy: 0.6162109375\n",
      "Batch: 94, Loss: 1.2156177759170532, Accuracy: 0.599609375\n",
      "Batch: 95, Loss: 1.1580867767333984, Accuracy: 0.634765625\n",
      "Batch: 96, Loss: 1.2133052349090576, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.1745691299438477, Accuracy: 0.626953125\n",
      "Batch: 98, Loss: 1.1834510564804077, Accuracy: 0.6259765625\n",
      "Batch: 99, Loss: 1.1338605880737305, Accuracy: 0.63671875\n",
      "Batch: 100, Loss: 1.0299711227416992, Accuracy: 0.66796875\n",
      "Batch: 101, Loss: 1.0797207355499268, Accuracy: 0.6474609375\n",
      "Batch: 102, Loss: 1.1405048370361328, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.173354148864746, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1344587802886963, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.188730239868164, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1512082815170288, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.211167573928833, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.2014870643615723, Accuracy: 0.5986328125\n",
      "Batch: 109, Loss: 1.1913502216339111, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.128273367881775, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.1168049573898315, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.0808955430984497, Accuracy: 0.662109375\n",
      "Batch: 113, Loss: 1.1947157382965088, Accuracy: 0.6123046875\n",
      "Batch: 114, Loss: 1.133352518081665, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1826108694076538, Accuracy: 0.6142578125\n",
      "Batch: 116, Loss: 1.2167558670043945, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.1488945484161377, Accuracy: 0.6162109375\n",
      "Batch: 118, Loss: 1.269492506980896, Accuracy: 0.5791015625\n",
      "Batch: 119, Loss: 1.196451187133789, Accuracy: 0.6298828125\n",
      "Batch: 120, Loss: 1.2508177757263184, Accuracy: 0.6064453125\n",
      "Batch: 121, Loss: 1.2027833461761475, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.2002640962600708, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.172438383102417, Accuracy: 0.61328125\n",
      "Batch: 124, Loss: 1.2482235431671143, Accuracy: 0.5927734375\n",
      "Batch: 125, Loss: 1.1480917930603027, Accuracy: 0.640625\n",
      "Batch: 126, Loss: 1.1455564498901367, Accuracy: 0.6357421875\n",
      "Batch: 127, Loss: 1.1688499450683594, Accuracy: 0.62890625\n",
      "Batch: 128, Loss: 1.2477631568908691, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.191197156906128, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.1737902164459229, Accuracy: 0.6162109375\n",
      "Batch: 131, Loss: 1.2164193391799927, Accuracy: 0.6015625\n",
      "Batch: 132, Loss: 1.081241488456726, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.1386973857879639, Accuracy: 0.6220703125\n",
      "Batch: 134, Loss: 1.0975397825241089, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 1.0084072351455688, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.085782527923584, Accuracy: 0.6337890625\n",
      "Batch: 137, Loss: 1.17220938205719, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.181452751159668, Accuracy: 0.6201171875\n",
      "Batch: 139, Loss: 1.1380258798599243, Accuracy: 0.6240234375\n",
      "Batch: 140, Loss: 1.265527367591858, Accuracy: 0.580078125\n",
      "Batch: 141, Loss: 1.1153240203857422, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1835849285125732, Accuracy: 0.626953125\n",
      "Batch: 143, Loss: 1.207381248474121, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.208287239074707, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.2569341659545898, Accuracy: 0.6015625\n",
      "Batch: 146, Loss: 1.2264071702957153, Accuracy: 0.580078125\n",
      "Batch: 147, Loss: 1.1885650157928467, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.2491525411605835, Accuracy: 0.5849609375\n",
      "Batch: 149, Loss: 1.1080626249313354, Accuracy: 0.650390625\n",
      "Batch: 150, Loss: 1.1187164783477783, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.168191909790039, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.1960039138793945, Accuracy: 0.59375\n",
      "Batch: 153, Loss: 1.130441665649414, Accuracy: 0.6455078125\n",
      "Batch: 154, Loss: 1.1254644393920898, Accuracy: 0.662109375\n",
      "Batch: 155, Loss: 1.1065174341201782, Accuracy: 0.640625\n",
      "Epoch 522/200\n",
      "Batch: 1, Loss: 1.2660386562347412, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.0771143436431885, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 0.9602559804916382, Accuracy: 0.681640625\n",
      "Batch: 4, Loss: 1.0805437564849854, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 1.044877529144287, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 1.0336260795593262, Accuracy: 0.65625\n",
      "Batch: 7, Loss: 1.0197428464889526, Accuracy: 0.66796875\n",
      "Batch: 8, Loss: 1.0044564008712769, Accuracy: 0.6728515625\n",
      "Batch: 9, Loss: 0.9798463582992554, Accuracy: 0.701171875\n",
      "Batch: 10, Loss: 0.955303966999054, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 0.9495275020599365, Accuracy: 0.6728515625\n",
      "Batch: 12, Loss: 1.0044373273849487, Accuracy: 0.6826171875\n",
      "Batch: 13, Loss: 0.9901016354560852, Accuracy: 0.671875\n",
      "Batch: 14, Loss: 0.9816538095474243, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.9211037158966064, Accuracy: 0.716796875\n",
      "Batch: 16, Loss: 1.0200791358947754, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.0727267265319824, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.0719083547592163, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.1578006744384766, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0710821151733398, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.0627453327178955, Accuracy: 0.646484375\n",
      "Batch: 22, Loss: 1.1726388931274414, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.2481193542480469, Accuracy: 0.58984375\n",
      "Batch: 24, Loss: 1.0612061023712158, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.0983883142471313, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1522736549377441, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.0604710578918457, Accuracy: 0.6484375\n",
      "Batch: 28, Loss: 1.0568909645080566, Accuracy: 0.6259765625\n",
      "Batch: 29, Loss: 1.075231909751892, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1273303031921387, Accuracy: 0.6396484375\n",
      "Batch: 31, Loss: 1.2137104272842407, Accuracy: 0.587890625\n",
      "Batch: 32, Loss: 1.0074448585510254, Accuracy: 0.669921875\n",
      "Batch: 33, Loss: 1.1067249774932861, Accuracy: 0.646484375\n",
      "Batch: 34, Loss: 1.1179434061050415, Accuracy: 0.6474609375\n",
      "Batch: 35, Loss: 1.0938621759414673, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.2098209857940674, Accuracy: 0.6025390625\n",
      "Batch: 37, Loss: 1.2525618076324463, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.1613900661468506, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.1026408672332764, Accuracy: 0.640625\n",
      "Batch: 40, Loss: 1.1176741123199463, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.0591421127319336, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 1.0856962203979492, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.0709917545318604, Accuracy: 0.6376953125\n",
      "Batch: 44, Loss: 1.0508544445037842, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.051304578781128, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.140596866607666, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.0985205173492432, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.1127296686172485, Accuracy: 0.626953125\n",
      "Batch: 49, Loss: 1.1102133989334106, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.152894377708435, Accuracy: 0.6005859375\n",
      "Batch: 51, Loss: 1.1243473291397095, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2156611680984497, Accuracy: 0.6201171875\n",
      "Batch: 53, Loss: 1.1376973390579224, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.2217679023742676, Accuracy: 0.591796875\n",
      "Batch: 55, Loss: 1.1486718654632568, Accuracy: 0.62890625\n",
      "Batch: 56, Loss: 1.11204195022583, Accuracy: 0.625\n",
      "Batch: 57, Loss: 1.158095121383667, Accuracy: 0.626953125\n",
      "Batch: 58, Loss: 1.0940388441085815, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 1.0663641691207886, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.215447187423706, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.145186185836792, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.161567211151123, Accuracy: 0.6416015625\n",
      "Batch: 63, Loss: 1.1760270595550537, Accuracy: 0.59765625\n",
      "Batch: 64, Loss: 1.1596043109893799, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.1788111925125122, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.1180918216705322, Accuracy: 0.6357421875\n",
      "Batch: 67, Loss: 1.170783281326294, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.0533452033996582, Accuracy: 0.673828125\n",
      "Batch: 69, Loss: 1.2373969554901123, Accuracy: 0.6015625\n",
      "Batch: 70, Loss: 1.1878809928894043, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.1122161149978638, Accuracy: 0.638671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 1.1536455154418945, Accuracy: 0.6201171875\n",
      "Batch: 73, Loss: 1.2025158405303955, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.0945109128952026, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.1213581562042236, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.1033133268356323, Accuracy: 0.640625\n",
      "Batch: 77, Loss: 1.0289257764816284, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 1.0501809120178223, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.1231698989868164, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.1269559860229492, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.0847293138504028, Accuracy: 0.6572265625\n",
      "Batch: 82, Loss: 1.1777698993682861, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.1078531742095947, Accuracy: 0.63671875\n",
      "Batch: 84, Loss: 1.1226279735565186, Accuracy: 0.6279296875\n",
      "Batch: 85, Loss: 1.1447761058807373, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.1755017042160034, Accuracy: 0.611328125\n",
      "Batch: 87, Loss: 1.1902861595153809, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.1188024282455444, Accuracy: 0.6474609375\n",
      "Batch: 89, Loss: 1.1453242301940918, Accuracy: 0.6455078125\n",
      "Batch: 90, Loss: 1.1061639785766602, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.1266573667526245, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.131021499633789, Accuracy: 0.6435546875\n",
      "Batch: 93, Loss: 1.1280689239501953, Accuracy: 0.615234375\n",
      "Batch: 94, Loss: 1.1993632316589355, Accuracy: 0.603515625\n",
      "Batch: 95, Loss: 1.1948168277740479, Accuracy: 0.6103515625\n",
      "Batch: 96, Loss: 1.181086778640747, Accuracy: 0.6318359375\n",
      "Batch: 97, Loss: 1.136275053024292, Accuracy: 0.638671875\n",
      "Batch: 98, Loss: 1.112900972366333, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.1459949016571045, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0628713369369507, Accuracy: 0.640625\n",
      "Batch: 101, Loss: 1.0813175439834595, Accuracy: 0.658203125\n",
      "Batch: 102, Loss: 1.10469388961792, Accuracy: 0.650390625\n",
      "Batch: 103, Loss: 1.1614747047424316, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.162832260131836, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.2008615732192993, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.162510633468628, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.1870753765106201, Accuracy: 0.6123046875\n",
      "Batch: 108, Loss: 1.1791632175445557, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.1879597902297974, Accuracy: 0.625\n",
      "Batch: 110, Loss: 1.1087143421173096, Accuracy: 0.6494140625\n",
      "Batch: 111, Loss: 1.1548223495483398, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.0963486433029175, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.166057825088501, Accuracy: 0.62109375\n",
      "Batch: 114, Loss: 1.1698265075683594, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2158373594284058, Accuracy: 0.5830078125\n",
      "Batch: 116, Loss: 1.1796634197235107, Accuracy: 0.6259765625\n",
      "Batch: 117, Loss: 1.1349788904190063, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.258035659790039, Accuracy: 0.5888671875\n",
      "Batch: 119, Loss: 1.1870646476745605, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.2970415353775024, Accuracy: 0.6015625\n",
      "Batch: 121, Loss: 1.1544398069381714, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.1600313186645508, Accuracy: 0.6064453125\n",
      "Batch: 123, Loss: 1.12330961227417, Accuracy: 0.650390625\n",
      "Batch: 124, Loss: 1.216918706893921, Accuracy: 0.5888671875\n",
      "Batch: 125, Loss: 1.1759952306747437, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.2314728498458862, Accuracy: 0.6064453125\n",
      "Batch: 127, Loss: 1.237821102142334, Accuracy: 0.6015625\n",
      "Batch: 128, Loss: 1.2144196033477783, Accuracy: 0.603515625\n",
      "Batch: 129, Loss: 1.1573991775512695, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.1197365522384644, Accuracy: 0.62109375\n",
      "Batch: 131, Loss: 1.2202802896499634, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.0987629890441895, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.1804691553115845, Accuracy: 0.6142578125\n",
      "Batch: 134, Loss: 1.112877607345581, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.009840965270996, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.0853722095489502, Accuracy: 0.6455078125\n",
      "Batch: 137, Loss: 1.0511298179626465, Accuracy: 0.662109375\n",
      "Batch: 138, Loss: 1.2044459581375122, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.2143923044204712, Accuracy: 0.5966796875\n",
      "Batch: 140, Loss: 1.2307624816894531, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.15220308303833, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.2049026489257812, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.2411872148513794, Accuracy: 0.5810546875\n",
      "Batch: 144, Loss: 1.2102508544921875, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.259076714515686, Accuracy: 0.5849609375\n",
      "Batch: 146, Loss: 1.1341307163238525, Accuracy: 0.625\n",
      "Batch: 147, Loss: 1.1401209831237793, Accuracy: 0.6279296875\n",
      "Batch: 148, Loss: 1.1930404901504517, Accuracy: 0.6259765625\n",
      "Batch: 149, Loss: 1.1668553352355957, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.0957307815551758, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.1541906595230103, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.1558879613876343, Accuracy: 0.62890625\n",
      "Batch: 153, Loss: 1.1227078437805176, Accuracy: 0.6279296875\n",
      "Batch: 154, Loss: 1.1053719520568848, Accuracy: 0.650390625\n",
      "Batch: 155, Loss: 1.1102150678634644, Accuracy: 0.6416015625\n",
      "Epoch 523/200\n",
      "Batch: 1, Loss: 1.2190980911254883, Accuracy: 0.61328125\n",
      "Batch: 2, Loss: 1.0609018802642822, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 0.9947567582130432, Accuracy: 0.685546875\n",
      "Batch: 4, Loss: 1.0509233474731445, Accuracy: 0.658203125\n",
      "Batch: 5, Loss: 1.0435993671417236, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.042575478553772, Accuracy: 0.65234375\n",
      "Batch: 7, Loss: 1.0512827634811401, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 0.9770302772521973, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 1.0026872158050537, Accuracy: 0.685546875\n",
      "Batch: 10, Loss: 0.9896179437637329, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 0.9387694597244263, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 0.9736401438713074, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 0.978165864944458, Accuracy: 0.677734375\n",
      "Batch: 14, Loss: 1.0236235857009888, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9650068283081055, Accuracy: 0.69140625\n",
      "Batch: 16, Loss: 1.0418992042541504, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.0129907131195068, Accuracy: 0.68359375\n",
      "Batch: 18, Loss: 1.1613926887512207, Accuracy: 0.6142578125\n",
      "Batch: 19, Loss: 1.1634938716888428, Accuracy: 0.609375\n",
      "Batch: 20, Loss: 1.0374351739883423, Accuracy: 0.677734375\n",
      "Batch: 21, Loss: 1.0561208724975586, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.2099310159683228, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.2313027381896973, Accuracy: 0.5810546875\n",
      "Batch: 24, Loss: 1.0369092226028442, Accuracy: 0.677734375\n",
      "Batch: 25, Loss: 1.1338913440704346, Accuracy: 0.619140625\n",
      "Batch: 26, Loss: 1.151505947113037, Accuracy: 0.625\n",
      "Batch: 27, Loss: 1.049422264099121, Accuracy: 0.6611328125\n",
      "Batch: 28, Loss: 1.0389564037322998, Accuracy: 0.6513671875\n",
      "Batch: 29, Loss: 1.0653955936431885, Accuracy: 0.6416015625\n",
      "Batch: 30, Loss: 1.166367530822754, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.2129817008972168, Accuracy: 0.59375\n",
      "Batch: 32, Loss: 1.0483005046844482, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 1.0126333236694336, Accuracy: 0.6806640625\n",
      "Batch: 34, Loss: 1.0995404720306396, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.0641555786132812, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.2433710098266602, Accuracy: 0.58984375\n",
      "Batch: 37, Loss: 1.2001869678497314, Accuracy: 0.5986328125\n",
      "Batch: 38, Loss: 1.159881591796875, Accuracy: 0.615234375\n",
      "Batch: 39, Loss: 1.0464165210723877, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.1092145442962646, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.1315102577209473, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.072553038597107, Accuracy: 0.6484375\n",
      "Batch: 43, Loss: 1.0641083717346191, Accuracy: 0.6455078125\n",
      "Batch: 44, Loss: 1.0310776233673096, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0881779193878174, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.139402151107788, Accuracy: 0.609375\n",
      "Batch: 47, Loss: 1.1395180225372314, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.0651530027389526, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.1641038656234741, Accuracy: 0.6064453125\n",
      "Batch: 50, Loss: 1.1217637062072754, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.1331360340118408, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.2365806102752686, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.1394171714782715, Accuracy: 0.626953125\n",
      "Batch: 54, Loss: 1.120429277420044, Accuracy: 0.646484375\n",
      "Batch: 55, Loss: 1.144277572631836, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.145956039428711, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 57, Loss: 1.0557467937469482, Accuracy: 0.6640625\n",
      "Batch: 58, Loss: 1.0932648181915283, Accuracy: 0.642578125\n",
      "Batch: 59, Loss: 1.1215379238128662, Accuracy: 0.64453125\n",
      "Batch: 60, Loss: 1.222945213317871, Accuracy: 0.5927734375\n",
      "Batch: 61, Loss: 1.1944588422775269, Accuracy: 0.5947265625\n",
      "Batch: 62, Loss: 1.0813637971878052, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.1794602870941162, Accuracy: 0.60546875\n",
      "Batch: 64, Loss: 1.147834062576294, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.1540149450302124, Accuracy: 0.6318359375\n",
      "Batch: 66, Loss: 1.1425864696502686, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1534605026245117, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.090367078781128, Accuracy: 0.642578125\n",
      "Batch: 69, Loss: 1.1576200723648071, Accuracy: 0.6298828125\n",
      "Batch: 70, Loss: 1.1884775161743164, Accuracy: 0.6455078125\n",
      "Batch: 71, Loss: 1.161903977394104, Accuracy: 0.6064453125\n",
      "Batch: 72, Loss: 1.1874363422393799, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.1700608730316162, Accuracy: 0.6220703125\n",
      "Batch: 74, Loss: 1.0843541622161865, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.1159297227859497, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.134230613708496, Accuracy: 0.62890625\n",
      "Batch: 77, Loss: 1.0827198028564453, Accuracy: 0.6318359375\n",
      "Batch: 78, Loss: 1.0775843858718872, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.110158920288086, Accuracy: 0.654296875\n",
      "Batch: 80, Loss: 1.1623663902282715, Accuracy: 0.623046875\n",
      "Batch: 81, Loss: 1.069177269935608, Accuracy: 0.62890625\n",
      "Batch: 82, Loss: 1.0872820615768433, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 1.1756126880645752, Accuracy: 0.6279296875\n",
      "Batch: 84, Loss: 1.1046568155288696, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.1441013813018799, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.1160169839859009, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.1597952842712402, Accuracy: 0.6279296875\n",
      "Batch: 88, Loss: 1.1922833919525146, Accuracy: 0.625\n",
      "Batch: 89, Loss: 1.1502119302749634, Accuracy: 0.619140625\n",
      "Batch: 90, Loss: 1.0699666738510132, Accuracy: 0.6494140625\n",
      "Batch: 91, Loss: 1.0798970460891724, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.0916640758514404, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.1392678022384644, Accuracy: 0.6201171875\n",
      "Batch: 94, Loss: 1.184788703918457, Accuracy: 0.6318359375\n",
      "Batch: 95, Loss: 1.1529701948165894, Accuracy: 0.6162109375\n",
      "Batch: 96, Loss: 1.1392145156860352, Accuracy: 0.6416015625\n",
      "Batch: 97, Loss: 1.1067984104156494, Accuracy: 0.6337890625\n",
      "Batch: 98, Loss: 1.0943496227264404, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.089491367340088, Accuracy: 0.6455078125\n",
      "Batch: 100, Loss: 1.0442535877227783, Accuracy: 0.6669921875\n",
      "Batch: 101, Loss: 1.0645676851272583, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.1109108924865723, Accuracy: 0.6357421875\n",
      "Batch: 103, Loss: 1.1231391429901123, Accuracy: 0.615234375\n",
      "Batch: 104, Loss: 1.187757968902588, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.2226896286010742, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.1662752628326416, Accuracy: 0.6142578125\n",
      "Batch: 107, Loss: 1.1683766841888428, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.1555156707763672, Accuracy: 0.61328125\n",
      "Batch: 109, Loss: 1.196487307548523, Accuracy: 0.59375\n",
      "Batch: 110, Loss: 1.1532127857208252, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.1436467170715332, Accuracy: 0.6396484375\n",
      "Batch: 112, Loss: 1.0812557935714722, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.115525484085083, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.1733527183532715, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1822912693023682, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.1807188987731934, Accuracy: 0.6162109375\n",
      "Batch: 117, Loss: 1.1881829500198364, Accuracy: 0.599609375\n",
      "Batch: 118, Loss: 1.2629035711288452, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.2005419731140137, Accuracy: 0.6181640625\n",
      "Batch: 120, Loss: 1.2439587116241455, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.1907932758331299, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.2003504037857056, Accuracy: 0.591796875\n",
      "Batch: 123, Loss: 1.1707557439804077, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.2496792078018188, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.219441294670105, Accuracy: 0.6162109375\n",
      "Batch: 126, Loss: 1.207667350769043, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.2660131454467773, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.2103075981140137, Accuracy: 0.5849609375\n",
      "Batch: 129, Loss: 1.1916890144348145, Accuracy: 0.6005859375\n",
      "Batch: 130, Loss: 1.1677830219268799, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.187964677810669, Accuracy: 0.62109375\n",
      "Batch: 132, Loss: 1.0672138929367065, Accuracy: 0.654296875\n",
      "Batch: 133, Loss: 1.1298508644104004, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.0940123796463013, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.079607367515564, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.0655243396759033, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.1548445224761963, Accuracy: 0.6181640625\n",
      "Batch: 138, Loss: 1.2150264978408813, Accuracy: 0.5986328125\n",
      "Batch: 139, Loss: 1.1510615348815918, Accuracy: 0.6357421875\n",
      "Batch: 140, Loss: 1.2334110736846924, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.137589693069458, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.1246405839920044, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.2141921520233154, Accuracy: 0.6142578125\n",
      "Batch: 144, Loss: 1.1546735763549805, Accuracy: 0.623046875\n",
      "Batch: 145, Loss: 1.2700504064559937, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.1870286464691162, Accuracy: 0.5927734375\n",
      "Batch: 147, Loss: 1.1734765768051147, Accuracy: 0.619140625\n",
      "Batch: 148, Loss: 1.2275187969207764, Accuracy: 0.6044921875\n",
      "Batch: 149, Loss: 1.1876803636550903, Accuracy: 0.6044921875\n",
      "Batch: 150, Loss: 1.1797385215759277, Accuracy: 0.6083984375\n",
      "Batch: 151, Loss: 1.1518712043762207, Accuracy: 0.6162109375\n",
      "Batch: 152, Loss: 1.1633472442626953, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.115858554840088, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.158937931060791, Accuracy: 0.609375\n",
      "Batch: 155, Loss: 1.1050512790679932, Accuracy: 0.6494140625\n",
      "Epoch 524/200\n",
      "Batch: 1, Loss: 1.1731364727020264, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.048912763595581, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 1.002786636352539, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0522311925888062, Accuracy: 0.6650390625\n",
      "Batch: 5, Loss: 1.0027744770050049, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.042088508605957, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.0216052532196045, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 1.0279698371887207, Accuracy: 0.6728515625\n",
      "Batch: 9, Loss: 0.9775390028953552, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 0.9222723841667175, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.9243601560592651, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 1.012990951538086, Accuracy: 0.654296875\n",
      "Batch: 13, Loss: 0.992679238319397, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9725009202957153, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.9628132581710815, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.0471842288970947, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0758204460144043, Accuracy: 0.66015625\n",
      "Batch: 18, Loss: 1.1167018413543701, Accuracy: 0.6455078125\n",
      "Batch: 19, Loss: 1.1827908754348755, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.0924361944198608, Accuracy: 0.640625\n",
      "Batch: 21, Loss: 1.0632476806640625, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.2021845579147339, Accuracy: 0.60546875\n",
      "Batch: 23, Loss: 1.2035632133483887, Accuracy: 0.6201171875\n",
      "Batch: 24, Loss: 1.076083779335022, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.1340817213058472, Accuracy: 0.6494140625\n",
      "Batch: 26, Loss: 1.1367886066436768, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.083418846130371, Accuracy: 0.6396484375\n",
      "Batch: 28, Loss: 1.0393822193145752, Accuracy: 0.6591796875\n",
      "Batch: 29, Loss: 1.0256588459014893, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1647028923034668, Accuracy: 0.6044921875\n",
      "Batch: 31, Loss: 1.2062435150146484, Accuracy: 0.6123046875\n",
      "Batch: 32, Loss: 1.032050609588623, Accuracy: 0.6591796875\n",
      "Batch: 33, Loss: 0.9897056221961975, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.0793976783752441, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.121124267578125, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.179614782333374, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.128558874130249, Accuracy: 0.630859375\n",
      "Batch: 38, Loss: 1.1203876733779907, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.125731348991394, Accuracy: 0.6279296875\n",
      "Batch: 40, Loss: 1.112403154373169, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 1.1278076171875, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.0499866008758545, Accuracy: 0.658203125\n",
      "Batch: 43, Loss: 1.0708403587341309, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0888092517852783, Accuracy: 0.6298828125\n",
      "Batch: 45, Loss: 1.0428452491760254, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.0961272716522217, Accuracy: 0.6494140625\n",
      "Batch: 47, Loss: 1.0994924306869507, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.1143296957015991, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.1491822004318237, Accuracy: 0.6455078125\n",
      "Batch: 50, Loss: 1.1124746799468994, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.157686471939087, Accuracy: 0.6171875\n",
      "Batch: 52, Loss: 1.243525505065918, Accuracy: 0.5947265625\n",
      "Batch: 53, Loss: 1.0816484689712524, Accuracy: 0.6337890625\n",
      "Batch: 54, Loss: 1.1931153535842896, Accuracy: 0.6240234375\n",
      "Batch: 55, Loss: 1.140367031097412, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.1048314571380615, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.1375162601470947, Accuracy: 0.642578125\n",
      "Batch: 58, Loss: 1.1260439157485962, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.1184839010238647, Accuracy: 0.6318359375\n",
      "Batch: 60, Loss: 1.203918695449829, Accuracy: 0.63671875\n",
      "Batch: 61, Loss: 1.1607117652893066, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.1709082126617432, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.1283376216888428, Accuracy: 0.625\n",
      "Batch: 64, Loss: 1.2095364332199097, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.161010980606079, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.1444118022918701, Accuracy: 0.625\n",
      "Batch: 67, Loss: 1.156795859336853, Accuracy: 0.6357421875\n",
      "Batch: 68, Loss: 1.1069865226745605, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1281262636184692, Accuracy: 0.6337890625\n",
      "Batch: 70, Loss: 1.1695501804351807, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.153477430343628, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.1793309450149536, Accuracy: 0.6181640625\n",
      "Batch: 73, Loss: 1.119214415550232, Accuracy: 0.630859375\n",
      "Batch: 74, Loss: 1.0979044437408447, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.0560201406478882, Accuracy: 0.6513671875\n",
      "Batch: 76, Loss: 1.079735279083252, Accuracy: 0.6318359375\n",
      "Batch: 77, Loss: 1.0477677583694458, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 1.1174604892730713, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.1281161308288574, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.1583997011184692, Accuracy: 0.62109375\n",
      "Batch: 81, Loss: 1.1398603916168213, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.071920394897461, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 1.181922197341919, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.138416051864624, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.1563527584075928, Accuracy: 0.6328125\n",
      "Batch: 86, Loss: 1.1182689666748047, Accuracy: 0.634765625\n",
      "Batch: 87, Loss: 1.1291046142578125, Accuracy: 0.6435546875\n",
      "Batch: 88, Loss: 1.1585934162139893, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.0986133813858032, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.1123366355895996, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1645491123199463, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1223630905151367, Accuracy: 0.6494140625\n",
      "Batch: 93, Loss: 1.1092442274093628, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.1727302074432373, Accuracy: 0.6181640625\n",
      "Batch: 95, Loss: 1.2040321826934814, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.1714136600494385, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.2044191360473633, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.150888204574585, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.0773361921310425, Accuracy: 0.6416015625\n",
      "Batch: 100, Loss: 1.0284373760223389, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.0736075639724731, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1543279886245728, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.1556384563446045, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.1251235008239746, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.2238001823425293, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.1518809795379639, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.1989690065383911, Accuracy: 0.6171875\n",
      "Batch: 108, Loss: 1.1508378982543945, Accuracy: 0.6103515625\n",
      "Batch: 109, Loss: 1.2173535823822021, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 1.1213929653167725, Accuracy: 0.6474609375\n",
      "Batch: 111, Loss: 1.0694680213928223, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.098286509513855, Accuracy: 0.6435546875\n",
      "Batch: 113, Loss: 1.1074326038360596, Accuracy: 0.6416015625\n",
      "Batch: 114, Loss: 1.1059376001358032, Accuracy: 0.6494140625\n",
      "Batch: 115, Loss: 1.2001352310180664, Accuracy: 0.6015625\n",
      "Batch: 116, Loss: 1.19968843460083, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.1646628379821777, Accuracy: 0.6171875\n",
      "Batch: 118, Loss: 1.246189832687378, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.1982296705245972, Accuracy: 0.6318359375\n",
      "Batch: 120, Loss: 1.28279709815979, Accuracy: 0.607421875\n",
      "Batch: 121, Loss: 1.1671017408370972, Accuracy: 0.61328125\n",
      "Batch: 122, Loss: 1.194582462310791, Accuracy: 0.6328125\n",
      "Batch: 123, Loss: 1.1606813669204712, Accuracy: 0.6279296875\n",
      "Batch: 124, Loss: 1.1670246124267578, Accuracy: 0.609375\n",
      "Batch: 125, Loss: 1.163165807723999, Accuracy: 0.640625\n",
      "Batch: 126, Loss: 1.221679925918579, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.2101752758026123, Accuracy: 0.619140625\n",
      "Batch: 128, Loss: 1.1952645778656006, Accuracy: 0.6201171875\n",
      "Batch: 129, Loss: 1.1940865516662598, Accuracy: 0.63671875\n",
      "Batch: 130, Loss: 1.130406141281128, Accuracy: 0.6328125\n",
      "Batch: 131, Loss: 1.2355542182922363, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.0516760349273682, Accuracy: 0.6591796875\n",
      "Batch: 133, Loss: 1.129253625869751, Accuracy: 0.642578125\n",
      "Batch: 134, Loss: 1.0490230321884155, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 1.0198668241500854, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.0807361602783203, Accuracy: 0.634765625\n",
      "Batch: 137, Loss: 1.097070336341858, Accuracy: 0.6474609375\n",
      "Batch: 138, Loss: 1.2147915363311768, Accuracy: 0.5986328125\n",
      "Batch: 139, Loss: 1.1804299354553223, Accuracy: 0.6396484375\n",
      "Batch: 140, Loss: 1.2517720460891724, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.1812021732330322, Accuracy: 0.607421875\n",
      "Batch: 142, Loss: 1.161938190460205, Accuracy: 0.6279296875\n",
      "Batch: 143, Loss: 1.193833589553833, Accuracy: 0.6103515625\n",
      "Batch: 144, Loss: 1.2328120470046997, Accuracy: 0.5947265625\n",
      "Batch: 145, Loss: 1.2178984880447388, Accuracy: 0.5966796875\n",
      "Batch: 146, Loss: 1.1979551315307617, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.1839146614074707, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.1305155754089355, Accuracy: 0.6240234375\n",
      "Batch: 149, Loss: 1.124729871749878, Accuracy: 0.62890625\n",
      "Batch: 150, Loss: 1.125099539756775, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.1515084505081177, Accuracy: 0.64453125\n",
      "Batch: 152, Loss: 1.1338257789611816, Accuracy: 0.634765625\n",
      "Batch: 153, Loss: 1.1113899946212769, Accuracy: 0.65234375\n",
      "Batch: 154, Loss: 1.1781525611877441, Accuracy: 0.62109375\n",
      "Batch: 155, Loss: 1.1169259548187256, Accuracy: 0.6162109375\n",
      "Epoch 525/200\n",
      "Batch: 1, Loss: 1.2017121315002441, Accuracy: 0.6484375\n",
      "Batch: 2, Loss: 1.0649745464324951, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 1.0671865940093994, Accuracy: 0.640625\n",
      "Batch: 4, Loss: 1.1062369346618652, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 0.9999974370002747, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0734905004501343, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.0370389223098755, Accuracy: 0.6640625\n",
      "Batch: 8, Loss: 0.9862592220306396, Accuracy: 0.6875\n",
      "Batch: 9, Loss: 1.0188342332839966, Accuracy: 0.685546875\n",
      "Batch: 10, Loss: 0.961933970451355, Accuracy: 0.6796875\n",
      "Batch: 11, Loss: 0.8967396020889282, Accuracy: 0.7060546875\n",
      "Batch: 12, Loss: 1.0282421112060547, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 1.0050454139709473, Accuracy: 0.658203125\n",
      "Batch: 14, Loss: 0.9631110429763794, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.9102730751037598, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 0.9774339199066162, Accuracy: 0.693359375\n",
      "Batch: 17, Loss: 1.064576506614685, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.0937800407409668, Accuracy: 0.6435546875\n",
      "Batch: 19, Loss: 1.1279866695404053, Accuracy: 0.62890625\n",
      "Batch: 20, Loss: 1.0907613039016724, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0475332736968994, Accuracy: 0.671875\n",
      "Batch: 22, Loss: 1.1629213094711304, Accuracy: 0.6279296875\n",
      "Batch: 23, Loss: 1.2943429946899414, Accuracy: 0.5751953125\n",
      "Batch: 24, Loss: 1.0970027446746826, Accuracy: 0.6171875\n",
      "Batch: 25, Loss: 1.150130033493042, Accuracy: 0.640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 1.2142140865325928, Accuracy: 0.6083984375\n",
      "Batch: 27, Loss: 1.0749191045761108, Accuracy: 0.64453125\n",
      "Batch: 28, Loss: 1.0486258268356323, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.1155999898910522, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.1556601524353027, Accuracy: 0.642578125\n",
      "Batch: 31, Loss: 1.1915974617004395, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.0704408884048462, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 0.9603508710861206, Accuracy: 0.7060546875\n",
      "Batch: 34, Loss: 1.103460431098938, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.1786375045776367, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.13957941532135, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.1444522142410278, Accuracy: 0.6220703125\n",
      "Batch: 38, Loss: 1.144761085510254, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.1303002834320068, Accuracy: 0.6220703125\n",
      "Batch: 40, Loss: 1.0839712619781494, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.130204439163208, Accuracy: 0.6162109375\n",
      "Batch: 42, Loss: 1.0766377449035645, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 1.0528442859649658, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0390948057174683, Accuracy: 0.6640625\n",
      "Batch: 45, Loss: 1.0045888423919678, Accuracy: 0.6640625\n",
      "Batch: 46, Loss: 1.0868194103240967, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.1120452880859375, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 1.0726358890533447, Accuracy: 0.6474609375\n",
      "Batch: 49, Loss: 1.107613205909729, Accuracy: 0.6396484375\n",
      "Batch: 50, Loss: 1.0969737768173218, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.1975274085998535, Accuracy: 0.6025390625\n",
      "Batch: 52, Loss: 1.1908657550811768, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1442325115203857, Accuracy: 0.6337890625\n",
      "Batch: 54, Loss: 1.1646313667297363, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.0482488870620728, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 1.0792901515960693, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.1247951984405518, Accuracy: 0.642578125\n",
      "Batch: 58, Loss: 1.0973109006881714, Accuracy: 0.6474609375\n",
      "Batch: 59, Loss: 1.0373737812042236, Accuracy: 0.669921875\n",
      "Batch: 60, Loss: 1.2142422199249268, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1371095180511475, Accuracy: 0.6220703125\n",
      "Batch: 62, Loss: 1.1568700075149536, Accuracy: 0.6201171875\n",
      "Batch: 63, Loss: 1.1703529357910156, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.1666706800460815, Accuracy: 0.623046875\n",
      "Batch: 65, Loss: 1.1558537483215332, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.1243481636047363, Accuracy: 0.634765625\n",
      "Batch: 67, Loss: 1.162868618965149, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0789586305618286, Accuracy: 0.6396484375\n",
      "Batch: 69, Loss: 1.1540534496307373, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.1121565103530884, Accuracy: 0.6416015625\n",
      "Batch: 71, Loss: 1.1533071994781494, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.2597777843475342, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.2173845767974854, Accuracy: 0.599609375\n",
      "Batch: 74, Loss: 1.1099662780761719, Accuracy: 0.634765625\n",
      "Batch: 75, Loss: 1.0760855674743652, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.0751899480819702, Accuracy: 0.6337890625\n",
      "Batch: 77, Loss: 1.0716092586517334, Accuracy: 0.634765625\n",
      "Batch: 78, Loss: 1.043079137802124, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.1826703548431396, Accuracy: 0.619140625\n",
      "Batch: 80, Loss: 1.1502091884613037, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.0812567472457886, Accuracy: 0.65625\n",
      "Batch: 82, Loss: 1.1502805948257446, Accuracy: 0.6142578125\n",
      "Batch: 83, Loss: 1.1709330081939697, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.0887278318405151, Accuracy: 0.646484375\n",
      "Batch: 85, Loss: 1.175012230873108, Accuracy: 0.6181640625\n",
      "Batch: 86, Loss: 1.1426520347595215, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1513257026672363, Accuracy: 0.630859375\n",
      "Batch: 88, Loss: 1.1588637828826904, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1120493412017822, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.1061043739318848, Accuracy: 0.638671875\n",
      "Batch: 91, Loss: 1.0976661443710327, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.1314520835876465, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.1640430688858032, Accuracy: 0.6162109375\n",
      "Batch: 94, Loss: 1.172336220741272, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.0925300121307373, Accuracy: 0.6513671875\n",
      "Batch: 96, Loss: 1.206174612045288, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.156404733657837, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.1208224296569824, Accuracy: 0.623046875\n",
      "Batch: 99, Loss: 1.0730630159378052, Accuracy: 0.6572265625\n",
      "Batch: 100, Loss: 1.0402803421020508, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0926519632339478, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.1345099210739136, Accuracy: 0.6240234375\n",
      "Batch: 103, Loss: 1.2067620754241943, Accuracy: 0.6083984375\n",
      "Batch: 104, Loss: 1.1320245265960693, Accuracy: 0.6484375\n",
      "Batch: 105, Loss: 1.1471164226531982, Accuracy: 0.634765625\n",
      "Batch: 106, Loss: 1.1801130771636963, Accuracy: 0.638671875\n",
      "Batch: 107, Loss: 1.2426607608795166, Accuracy: 0.5986328125\n",
      "Batch: 108, Loss: 1.1535475254058838, Accuracy: 0.615234375\n",
      "Batch: 109, Loss: 1.2009124755859375, Accuracy: 0.6123046875\n",
      "Batch: 110, Loss: 1.1629514694213867, Accuracy: 0.62890625\n",
      "Batch: 111, Loss: 1.1602892875671387, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.0861659049987793, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.1866289377212524, Accuracy: 0.615234375\n",
      "Batch: 114, Loss: 1.1230063438415527, Accuracy: 0.6240234375\n",
      "Batch: 115, Loss: 1.19057297706604, Accuracy: 0.6015625\n",
      "Batch: 116, Loss: 1.279954433441162, Accuracy: 0.6005859375\n",
      "Batch: 117, Loss: 1.148303508758545, Accuracy: 0.6171875\n",
      "Batch: 118, Loss: 1.2268693447113037, Accuracy: 0.58203125\n",
      "Batch: 119, Loss: 1.2171376943588257, Accuracy: 0.5986328125\n",
      "Batch: 120, Loss: 1.2746350765228271, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.1833195686340332, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.193542718887329, Accuracy: 0.6142578125\n",
      "Batch: 123, Loss: 1.1447179317474365, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.187382698059082, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.1711091995239258, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.190225601196289, Accuracy: 0.6083984375\n",
      "Batch: 127, Loss: 1.1831066608428955, Accuracy: 0.6181640625\n",
      "Batch: 128, Loss: 1.1895736455917358, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.1576366424560547, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.0864224433898926, Accuracy: 0.6513671875\n",
      "Batch: 131, Loss: 1.195381760597229, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0807559490203857, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.095333456993103, Accuracy: 0.66015625\n",
      "Batch: 134, Loss: 1.1014561653137207, Accuracy: 0.6640625\n",
      "Batch: 135, Loss: 0.9715700745582581, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.0572760105133057, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.119078516960144, Accuracy: 0.6396484375\n",
      "Batch: 138, Loss: 1.2262465953826904, Accuracy: 0.5986328125\n",
      "Batch: 139, Loss: 1.1127755641937256, Accuracy: 0.6396484375\n",
      "Batch: 140, Loss: 1.2226452827453613, Accuracy: 0.6181640625\n",
      "Batch: 141, Loss: 1.1418514251708984, Accuracy: 0.6298828125\n",
      "Batch: 142, Loss: 1.146181344985962, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.1649307012557983, Accuracy: 0.6298828125\n",
      "Batch: 144, Loss: 1.2675764560699463, Accuracy: 0.591796875\n",
      "Batch: 145, Loss: 1.2968875169754028, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.1910979747772217, Accuracy: 0.623046875\n",
      "Batch: 147, Loss: 1.1837137937545776, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.2200725078582764, Accuracy: 0.6064453125\n",
      "Batch: 149, Loss: 1.1328243017196655, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.1852397918701172, Accuracy: 0.6005859375\n",
      "Batch: 151, Loss: 1.144550085067749, Accuracy: 0.6396484375\n",
      "Batch: 152, Loss: 1.12298583984375, Accuracy: 0.6328125\n",
      "Batch: 153, Loss: 1.0827299356460571, Accuracy: 0.6650390625\n",
      "Batch: 154, Loss: 1.070727825164795, Accuracy: 0.6357421875\n",
      "Batch: 155, Loss: 1.0873544216156006, Accuracy: 0.6337890625\n",
      "Epoch 526/200\n",
      "Batch: 1, Loss: 1.2430167198181152, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 1.0258607864379883, Accuracy: 0.6865234375\n",
      "Batch: 3, Loss: 1.0000240802764893, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0674245357513428, Accuracy: 0.6484375\n",
      "Batch: 5, Loss: 1.0273691415786743, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.0341885089874268, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 1.0414886474609375, Accuracy: 0.66015625\n",
      "Batch: 8, Loss: 1.0484309196472168, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9, Loss: 1.0501773357391357, Accuracy: 0.662109375\n",
      "Batch: 10, Loss: 0.9740066528320312, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 0.9455899000167847, Accuracy: 0.6923828125\n",
      "Batch: 12, Loss: 0.9915227293968201, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 0.9989004731178284, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 0.9646917581558228, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.930074155330658, Accuracy: 0.6943359375\n",
      "Batch: 16, Loss: 1.0147371292114258, Accuracy: 0.6689453125\n",
      "Batch: 17, Loss: 1.0305482149124146, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 1.0565217733383179, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.1798489093780518, Accuracy: 0.64453125\n",
      "Batch: 20, Loss: 1.038917064666748, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.0998132228851318, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2399747371673584, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.236778974533081, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.0871068239212036, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.1713292598724365, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.1753698587417603, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.1057833433151245, Accuracy: 0.6328125\n",
      "Batch: 28, Loss: 1.041391372680664, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.0400984287261963, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1172075271606445, Accuracy: 0.6337890625\n",
      "Batch: 31, Loss: 1.1310861110687256, Accuracy: 0.63671875\n",
      "Batch: 32, Loss: 1.0833942890167236, Accuracy: 0.6376953125\n",
      "Batch: 33, Loss: 0.976371169090271, Accuracy: 0.685546875\n",
      "Batch: 34, Loss: 1.090906023979187, Accuracy: 0.64453125\n",
      "Batch: 35, Loss: 1.1337299346923828, Accuracy: 0.62890625\n",
      "Batch: 36, Loss: 1.1405525207519531, Accuracy: 0.63671875\n",
      "Batch: 37, Loss: 1.2404541969299316, Accuracy: 0.5966796875\n",
      "Batch: 38, Loss: 1.1955467462539673, Accuracy: 0.5908203125\n",
      "Batch: 39, Loss: 1.1050803661346436, Accuracy: 0.6357421875\n",
      "Batch: 40, Loss: 1.077713966369629, Accuracy: 0.6630859375\n",
      "Batch: 41, Loss: 1.1154835224151611, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.111708164215088, Accuracy: 0.62890625\n",
      "Batch: 43, Loss: 1.0574088096618652, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.042850375175476, Accuracy: 0.6484375\n",
      "Batch: 45, Loss: 0.994785487651825, Accuracy: 0.6640625\n",
      "Batch: 46, Loss: 1.113877296447754, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.098874807357788, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0733888149261475, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.1475886106491089, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.1170437335968018, Accuracy: 0.630859375\n",
      "Batch: 51, Loss: 1.1241251230239868, Accuracy: 0.626953125\n",
      "Batch: 52, Loss: 1.2106562852859497, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1585493087768555, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.2072250843048096, Accuracy: 0.6064453125\n",
      "Batch: 55, Loss: 1.0758676528930664, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0926313400268555, Accuracy: 0.654296875\n",
      "Batch: 57, Loss: 1.1238553524017334, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.045796275138855, Accuracy: 0.66796875\n",
      "Batch: 59, Loss: 1.1058636903762817, Accuracy: 0.6376953125\n",
      "Batch: 60, Loss: 1.2168004512786865, Accuracy: 0.6123046875\n",
      "Batch: 61, Loss: 1.160669207572937, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1579718589782715, Accuracy: 0.6181640625\n",
      "Batch: 63, Loss: 1.184722661972046, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.183506727218628, Accuracy: 0.609375\n",
      "Batch: 65, Loss: 1.1569814682006836, Accuracy: 0.62890625\n",
      "Batch: 66, Loss: 1.1374945640563965, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.1689519882202148, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.0750391483306885, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.1646233797073364, Accuracy: 0.6220703125\n",
      "Batch: 70, Loss: 1.1397260427474976, Accuracy: 0.623046875\n",
      "Batch: 71, Loss: 1.1398286819458008, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.1491353511810303, Accuracy: 0.607421875\n",
      "Batch: 73, Loss: 1.184341549873352, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.063275933265686, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.0739772319793701, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.093596339225769, Accuracy: 0.6376953125\n",
      "Batch: 77, Loss: 1.0791058540344238, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.1000713109970093, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.1277190446853638, Accuracy: 0.6357421875\n",
      "Batch: 80, Loss: 1.1083769798278809, Accuracy: 0.640625\n",
      "Batch: 81, Loss: 1.099388599395752, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.1109060049057007, Accuracy: 0.6259765625\n",
      "Batch: 83, Loss: 1.1971319913864136, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.1374150514602661, Accuracy: 0.6396484375\n",
      "Batch: 85, Loss: 1.1700398921966553, Accuracy: 0.62109375\n",
      "Batch: 86, Loss: 1.1787947416305542, Accuracy: 0.6142578125\n",
      "Batch: 87, Loss: 1.1327736377716064, Accuracy: 0.6201171875\n",
      "Batch: 88, Loss: 1.1386582851409912, Accuracy: 0.6259765625\n",
      "Batch: 89, Loss: 1.1526353359222412, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.143591046333313, Accuracy: 0.6259765625\n",
      "Batch: 91, Loss: 1.1162647008895874, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1292171478271484, Accuracy: 0.6552734375\n",
      "Batch: 93, Loss: 1.1621835231781006, Accuracy: 0.638671875\n",
      "Batch: 94, Loss: 1.2122893333435059, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.1483559608459473, Accuracy: 0.6494140625\n",
      "Batch: 96, Loss: 1.1504969596862793, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.2155026197433472, Accuracy: 0.6083984375\n",
      "Batch: 98, Loss: 1.1265835762023926, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1324549913406372, Accuracy: 0.638671875\n",
      "Batch: 100, Loss: 1.0869933366775513, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.1425912380218506, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.146664023399353, Accuracy: 0.63671875\n",
      "Batch: 103, Loss: 1.1500548124313354, Accuracy: 0.623046875\n",
      "Batch: 104, Loss: 1.1433134078979492, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.1961874961853027, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1780633926391602, Accuracy: 0.6416015625\n",
      "Batch: 107, Loss: 1.2041316032409668, Accuracy: 0.6044921875\n",
      "Batch: 108, Loss: 1.1778689622879028, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.2221885919570923, Accuracy: 0.5908203125\n",
      "Batch: 110, Loss: 1.1186060905456543, Accuracy: 0.6318359375\n",
      "Batch: 111, Loss: 1.1518536806106567, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.0808292627334595, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1856117248535156, Accuracy: 0.619140625\n",
      "Batch: 114, Loss: 1.1149274110794067, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1917860507965088, Accuracy: 0.6142578125\n",
      "Batch: 116, Loss: 1.1757032871246338, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1566053628921509, Accuracy: 0.6240234375\n",
      "Batch: 118, Loss: 1.1936925649642944, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.22238290309906, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.2675570249557495, Accuracy: 0.6064453125\n",
      "Batch: 121, Loss: 1.1857662200927734, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.185589075088501, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.2068071365356445, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.1610040664672852, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.224210262298584, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.195708990097046, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.1797165870666504, Accuracy: 0.615234375\n",
      "Batch: 128, Loss: 1.2436423301696777, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.13236665725708, Accuracy: 0.642578125\n",
      "Batch: 130, Loss: 1.1482670307159424, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.228750467300415, Accuracy: 0.609375\n",
      "Batch: 132, Loss: 1.1240986585617065, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.160988211631775, Accuracy: 0.6259765625\n",
      "Batch: 134, Loss: 1.1280972957611084, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 1.062488079071045, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.1230361461639404, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.1536448001861572, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.1751008033752441, Accuracy: 0.6123046875\n",
      "Batch: 139, Loss: 1.1870980262756348, Accuracy: 0.6396484375\n",
      "Batch: 140, Loss: 1.1919450759887695, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1603590250015259, Accuracy: 0.6298828125\n",
      "Batch: 142, Loss: 1.143855333328247, Accuracy: 0.62890625\n",
      "Batch: 143, Loss: 1.2289502620697021, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.1818125247955322, Accuracy: 0.6259765625\n",
      "Batch: 145, Loss: 1.2395789623260498, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.2447178363800049, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.2393115758895874, Accuracy: 0.5927734375\n",
      "Batch: 148, Loss: 1.193027377128601, Accuracy: 0.6103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 1.1369402408599854, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.0980572700500488, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1303021907806396, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.1190145015716553, Accuracy: 0.6416015625\n",
      "Batch: 153, Loss: 1.1510274410247803, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.1157863140106201, Accuracy: 0.6318359375\n",
      "Batch: 155, Loss: 1.0974100828170776, Accuracy: 0.634765625\n",
      "Epoch 527/200\n",
      "Batch: 1, Loss: 1.2045280933380127, Accuracy: 0.6171875\n",
      "Batch: 2, Loss: 1.054417610168457, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 1.0373773574829102, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0410841703414917, Accuracy: 0.6708984375\n",
      "Batch: 5, Loss: 0.9778956770896912, Accuracy: 0.6826171875\n",
      "Batch: 6, Loss: 1.0501627922058105, Accuracy: 0.646484375\n",
      "Batch: 7, Loss: 1.0158512592315674, Accuracy: 0.6513671875\n",
      "Batch: 8, Loss: 1.0175632238388062, Accuracy: 0.650390625\n",
      "Batch: 9, Loss: 1.0199767351150513, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 0.9708786606788635, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9691095948219299, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 1.0031425952911377, Accuracy: 0.6865234375\n",
      "Batch: 13, Loss: 1.0149402618408203, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 1.0116130113601685, Accuracy: 0.6484375\n",
      "Batch: 15, Loss: 0.9320275783538818, Accuracy: 0.705078125\n",
      "Batch: 16, Loss: 0.9872323870658875, Accuracy: 0.6787109375\n",
      "Batch: 17, Loss: 1.05237877368927, Accuracy: 0.6611328125\n",
      "Batch: 18, Loss: 1.0971505641937256, Accuracy: 0.6484375\n",
      "Batch: 19, Loss: 1.1818293333053589, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.1123532056808472, Accuracy: 0.640625\n",
      "Batch: 21, Loss: 1.118744134902954, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.1931591033935547, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.1998834609985352, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.0764778852462769, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1932719945907593, Accuracy: 0.6181640625\n",
      "Batch: 26, Loss: 1.1725733280181885, Accuracy: 0.6171875\n",
      "Batch: 27, Loss: 1.162426471710205, Accuracy: 0.623046875\n",
      "Batch: 28, Loss: 1.0273841619491577, Accuracy: 0.650390625\n",
      "Batch: 29, Loss: 1.0575785636901855, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1233643293380737, Accuracy: 0.623046875\n",
      "Batch: 31, Loss: 1.1690032482147217, Accuracy: 0.6044921875\n",
      "Batch: 32, Loss: 0.9900709390640259, Accuracy: 0.6640625\n",
      "Batch: 33, Loss: 0.980426549911499, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.0682547092437744, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.073708176612854, Accuracy: 0.6484375\n",
      "Batch: 36, Loss: 1.1964247226715088, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.2214990854263306, Accuracy: 0.6162109375\n",
      "Batch: 38, Loss: 1.1740108728408813, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.0960979461669922, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.1066200733184814, Accuracy: 0.6318359375\n",
      "Batch: 41, Loss: 1.1235183477401733, Accuracy: 0.619140625\n",
      "Batch: 42, Loss: 1.0695384740829468, Accuracy: 0.662109375\n",
      "Batch: 43, Loss: 1.06223726272583, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.0519201755523682, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 1.0241559743881226, Accuracy: 0.662109375\n",
      "Batch: 46, Loss: 1.1372767686843872, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.0874686241149902, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.161989688873291, Accuracy: 0.609375\n",
      "Batch: 49, Loss: 1.1261351108551025, Accuracy: 0.634765625\n",
      "Batch: 50, Loss: 1.1212165355682373, Accuracy: 0.625\n",
      "Batch: 51, Loss: 1.1493821144104004, Accuracy: 0.630859375\n",
      "Batch: 52, Loss: 1.2140116691589355, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1308414936065674, Accuracy: 0.623046875\n",
      "Batch: 54, Loss: 1.1299426555633545, Accuracy: 0.6337890625\n",
      "Batch: 55, Loss: 1.1487069129943848, Accuracy: 0.6171875\n",
      "Batch: 56, Loss: 1.1280711889266968, Accuracy: 0.65234375\n",
      "Batch: 57, Loss: 1.1183642148971558, Accuracy: 0.63671875\n",
      "Batch: 58, Loss: 1.0696789026260376, Accuracy: 0.6455078125\n",
      "Batch: 59, Loss: 1.0806357860565186, Accuracy: 0.6533203125\n",
      "Batch: 60, Loss: 1.2469723224639893, Accuracy: 0.607421875\n",
      "Batch: 61, Loss: 1.1281980276107788, Accuracy: 0.6416015625\n",
      "Batch: 62, Loss: 1.089597225189209, Accuracy: 0.662109375\n",
      "Batch: 63, Loss: 1.15924072265625, Accuracy: 0.6083984375\n",
      "Batch: 64, Loss: 1.1875784397125244, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1737109422683716, Accuracy: 0.6318359375\n",
      "Batch: 66, Loss: 1.1101394891738892, Accuracy: 0.6357421875\n",
      "Batch: 67, Loss: 1.0780531167984009, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0776128768920898, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1827536821365356, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.1628788709640503, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.1498029232025146, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.1673979759216309, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.199637532234192, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.1157972812652588, Accuracy: 0.625\n",
      "Batch: 75, Loss: 1.140578269958496, Accuracy: 0.6259765625\n",
      "Batch: 76, Loss: 1.10590660572052, Accuracy: 0.6318359375\n",
      "Batch: 77, Loss: 1.0323089361190796, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.04868745803833, Accuracy: 0.666015625\n",
      "Batch: 79, Loss: 1.1043591499328613, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.154419183731079, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.1281745433807373, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.173337459564209, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 1.1878255605697632, Accuracy: 0.634765625\n",
      "Batch: 84, Loss: 1.1376992464065552, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.1459993124008179, Accuracy: 0.611328125\n",
      "Batch: 86, Loss: 1.1875684261322021, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.124680757522583, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.1153345108032227, Accuracy: 0.64453125\n",
      "Batch: 89, Loss: 1.1244404315948486, Accuracy: 0.6572265625\n",
      "Batch: 90, Loss: 1.0864567756652832, Accuracy: 0.6513671875\n",
      "Batch: 91, Loss: 1.1073119640350342, Accuracy: 0.62890625\n",
      "Batch: 92, Loss: 1.1128720045089722, Accuracy: 0.6484375\n",
      "Batch: 93, Loss: 1.2177636623382568, Accuracy: 0.60546875\n",
      "Batch: 94, Loss: 1.1600329875946045, Accuracy: 0.6162109375\n",
      "Batch: 95, Loss: 1.1498942375183105, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.1765997409820557, Accuracy: 0.6376953125\n",
      "Batch: 97, Loss: 1.1556100845336914, Accuracy: 0.6328125\n",
      "Batch: 98, Loss: 1.0818943977355957, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.095414400100708, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.0805282592773438, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.1475615501403809, Accuracy: 0.6220703125\n",
      "Batch: 102, Loss: 1.1424078941345215, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.156768560409546, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1167778968811035, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.212302803993225, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1345956325531006, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.2500596046447754, Accuracy: 0.6044921875\n",
      "Batch: 108, Loss: 1.1764589548110962, Accuracy: 0.615234375\n",
      "Batch: 109, Loss: 1.1766016483306885, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 1.1754322052001953, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.203155755996704, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.0946555137634277, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.1234309673309326, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.1622880697250366, Accuracy: 0.6005859375\n",
      "Batch: 115, Loss: 1.1734848022460938, Accuracy: 0.6279296875\n",
      "Batch: 116, Loss: 1.1539841890335083, Accuracy: 0.6328125\n",
      "Batch: 117, Loss: 1.1747100353240967, Accuracy: 0.60546875\n",
      "Batch: 118, Loss: 1.1731910705566406, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.1716152429580688, Accuracy: 0.6142578125\n",
      "Batch: 120, Loss: 1.2372322082519531, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.216778039932251, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.2217166423797607, Accuracy: 0.625\n",
      "Batch: 123, Loss: 1.1369719505310059, Accuracy: 0.6240234375\n",
      "Batch: 124, Loss: 1.1750924587249756, Accuracy: 0.634765625\n",
      "Batch: 125, Loss: 1.1644022464752197, Accuracy: 0.6240234375\n",
      "Batch: 126, Loss: 1.1997121572494507, Accuracy: 0.62890625\n",
      "Batch: 127, Loss: 1.1997582912445068, Accuracy: 0.6357421875\n",
      "Batch: 128, Loss: 1.2475306987762451, Accuracy: 0.6025390625\n",
      "Batch: 129, Loss: 1.2013163566589355, Accuracy: 0.6171875\n",
      "Batch: 130, Loss: 1.1736087799072266, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.1977468729019165, Accuracy: 0.583984375\n",
      "Batch: 132, Loss: 1.0531620979309082, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.2116782665252686, Accuracy: 0.611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 134, Loss: 1.0951991081237793, Accuracy: 0.6669921875\n",
      "Batch: 135, Loss: 1.0571128129959106, Accuracy: 0.646484375\n",
      "Batch: 136, Loss: 1.0689213275909424, Accuracy: 0.6298828125\n",
      "Batch: 137, Loss: 1.101607322692871, Accuracy: 0.6533203125\n",
      "Batch: 138, Loss: 1.197174072265625, Accuracy: 0.599609375\n",
      "Batch: 139, Loss: 1.214113712310791, Accuracy: 0.6142578125\n",
      "Batch: 140, Loss: 1.242849349975586, Accuracy: 0.6123046875\n",
      "Batch: 141, Loss: 1.1459633111953735, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.1491888761520386, Accuracy: 0.6455078125\n",
      "Batch: 143, Loss: 1.1934821605682373, Accuracy: 0.6171875\n",
      "Batch: 144, Loss: 1.2131094932556152, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.2406779527664185, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.1810779571533203, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.2004741430282593, Accuracy: 0.623046875\n",
      "Batch: 148, Loss: 1.17738676071167, Accuracy: 0.6123046875\n",
      "Batch: 149, Loss: 1.1410973072052002, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.1228587627410889, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.1318267583847046, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1154557466506958, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.1249501705169678, Accuracy: 0.6337890625\n",
      "Batch: 154, Loss: 1.0974187850952148, Accuracy: 0.634765625\n",
      "Batch: 155, Loss: 1.0979052782058716, Accuracy: 0.6572265625\n",
      "Epoch 528/200\n",
      "Batch: 1, Loss: 1.1687290668487549, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 1.0512635707855225, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.9828339219093323, Accuracy: 0.677734375\n",
      "Batch: 4, Loss: 1.0707817077636719, Accuracy: 0.6396484375\n",
      "Batch: 5, Loss: 1.01426362991333, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0481996536254883, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 0.9972570538520813, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 0.9615239500999451, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 0.9952644109725952, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9251638650894165, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9596587419509888, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 1.018968105316162, Accuracy: 0.650390625\n",
      "Batch: 13, Loss: 1.0237869024276733, Accuracy: 0.673828125\n",
      "Batch: 14, Loss: 0.9885159730911255, Accuracy: 0.6748046875\n",
      "Batch: 15, Loss: 0.9217316508293152, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.011583924293518, Accuracy: 0.67578125\n",
      "Batch: 17, Loss: 1.0624514818191528, Accuracy: 0.6552734375\n",
      "Batch: 18, Loss: 1.1409080028533936, Accuracy: 0.623046875\n",
      "Batch: 19, Loss: 1.1841590404510498, Accuracy: 0.623046875\n",
      "Batch: 20, Loss: 1.0563067197799683, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.0650041103363037, Accuracy: 0.6650390625\n",
      "Batch: 22, Loss: 1.146896243095398, Accuracy: 0.6279296875\n",
      "Batch: 23, Loss: 1.2026665210723877, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.1059796810150146, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.102941632270813, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.168668270111084, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.1008013486862183, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.0725934505462646, Accuracy: 0.6455078125\n",
      "Batch: 29, Loss: 1.0986591577529907, Accuracy: 0.6376953125\n",
      "Batch: 30, Loss: 1.1626307964324951, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.156121015548706, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 0.9771000146865845, Accuracy: 0.6787109375\n",
      "Batch: 33, Loss: 0.9528928995132446, Accuracy: 0.67578125\n",
      "Batch: 34, Loss: 1.0668861865997314, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.080054759979248, Accuracy: 0.6533203125\n",
      "Batch: 36, Loss: 1.1795523166656494, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.1872869729995728, Accuracy: 0.615234375\n",
      "Batch: 38, Loss: 1.162233829498291, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.1114473342895508, Accuracy: 0.63671875\n",
      "Batch: 40, Loss: 1.076507329940796, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.104736089706421, Accuracy: 0.6455078125\n",
      "Batch: 42, Loss: 1.0604453086853027, Accuracy: 0.65625\n",
      "Batch: 43, Loss: 1.03223717212677, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0128496885299683, Accuracy: 0.6484375\n",
      "Batch: 45, Loss: 1.0545692443847656, Accuracy: 0.646484375\n",
      "Batch: 46, Loss: 1.149947166442871, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1036715507507324, Accuracy: 0.65234375\n",
      "Batch: 48, Loss: 1.1380634307861328, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.0799893140792847, Accuracy: 0.65234375\n",
      "Batch: 50, Loss: 1.0848474502563477, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.1439988613128662, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.2024027109146118, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 1.19236421585083, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.101381778717041, Accuracy: 0.6337890625\n",
      "Batch: 55, Loss: 1.1044392585754395, Accuracy: 0.650390625\n",
      "Batch: 56, Loss: 1.1025923490524292, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 1.091982126235962, Accuracy: 0.6396484375\n",
      "Batch: 58, Loss: 1.1199676990509033, Accuracy: 0.630859375\n",
      "Batch: 59, Loss: 1.1059396266937256, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.2041655778884888, Accuracy: 0.619140625\n",
      "Batch: 61, Loss: 1.1522942781448364, Accuracy: 0.62109375\n",
      "Batch: 62, Loss: 1.1787153482437134, Accuracy: 0.6123046875\n",
      "Batch: 63, Loss: 1.2106459140777588, Accuracy: 0.6025390625\n",
      "Batch: 64, Loss: 1.1889371871948242, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.177964210510254, Accuracy: 0.6298828125\n",
      "Batch: 66, Loss: 1.156087040901184, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.1336451768875122, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.0929088592529297, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.1932836771011353, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.1370360851287842, Accuracy: 0.6435546875\n",
      "Batch: 71, Loss: 1.1350483894348145, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.161562204360962, Accuracy: 0.62890625\n",
      "Batch: 73, Loss: 1.1617376804351807, Accuracy: 0.6259765625\n",
      "Batch: 74, Loss: 1.0884978771209717, Accuracy: 0.654296875\n",
      "Batch: 75, Loss: 1.0893117189407349, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.0274362564086914, Accuracy: 0.658203125\n",
      "Batch: 77, Loss: 1.0120010375976562, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0624561309814453, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.1407885551452637, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.1740089654922485, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.069353461265564, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.0704879760742188, Accuracy: 0.6572265625\n",
      "Batch: 83, Loss: 1.0824358463287354, Accuracy: 0.6484375\n",
      "Batch: 84, Loss: 1.1601202487945557, Accuracy: 0.6220703125\n",
      "Batch: 85, Loss: 1.1387243270874023, Accuracy: 0.6298828125\n",
      "Batch: 86, Loss: 1.1373610496520996, Accuracy: 0.6064453125\n",
      "Batch: 87, Loss: 1.1624679565429688, Accuracy: 0.6318359375\n",
      "Batch: 88, Loss: 1.0909745693206787, Accuracy: 0.6474609375\n",
      "Batch: 89, Loss: 1.0985796451568604, Accuracy: 0.6494140625\n",
      "Batch: 90, Loss: 1.0880330801010132, Accuracy: 0.64453125\n",
      "Batch: 91, Loss: 1.182219386100769, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.1065654754638672, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.0698636770248413, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.1513335704803467, Accuracy: 0.6376953125\n",
      "Batch: 95, Loss: 1.1604795455932617, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.2058663368225098, Accuracy: 0.6171875\n",
      "Batch: 97, Loss: 1.1020469665527344, Accuracy: 0.642578125\n",
      "Batch: 98, Loss: 1.0990360975265503, Accuracy: 0.6474609375\n",
      "Batch: 99, Loss: 1.1017723083496094, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.0375568866729736, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.0734241008758545, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.1077301502227783, Accuracy: 0.646484375\n",
      "Batch: 103, Loss: 1.1833018064498901, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.1216462850570679, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.2248954772949219, Accuracy: 0.5986328125\n",
      "Batch: 106, Loss: 1.1351841688156128, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.2269278764724731, Accuracy: 0.603515625\n",
      "Batch: 108, Loss: 1.1807948350906372, Accuracy: 0.62109375\n",
      "Batch: 109, Loss: 1.1535248756408691, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.113410234451294, Accuracy: 0.6376953125\n",
      "Batch: 111, Loss: 1.1374731063842773, Accuracy: 0.626953125\n",
      "Batch: 112, Loss: 1.0805968046188354, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.126278042793274, Accuracy: 0.64453125\n",
      "Batch: 114, Loss: 1.1556315422058105, Accuracy: 0.599609375\n",
      "Batch: 115, Loss: 1.1734941005706787, Accuracy: 0.6181640625\n",
      "Batch: 116, Loss: 1.0953502655029297, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.1658265590667725, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 1.2567830085754395, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.2759672403335571, Accuracy: 0.5703125\n",
      "Batch: 120, Loss: 1.2327537536621094, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.1910831928253174, Accuracy: 0.607421875\n",
      "Batch: 122, Loss: 1.1917091608047485, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.1569578647613525, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.1760520935058594, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.172481894493103, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.2554609775543213, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.2132400274276733, Accuracy: 0.6220703125\n",
      "Batch: 128, Loss: 1.174264669418335, Accuracy: 0.625\n",
      "Batch: 129, Loss: 1.1353076696395874, Accuracy: 0.6298828125\n",
      "Batch: 130, Loss: 1.1449990272521973, Accuracy: 0.640625\n",
      "Batch: 131, Loss: 1.1651939153671265, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.0540510416030884, Accuracy: 0.638671875\n",
      "Batch: 133, Loss: 1.1201629638671875, Accuracy: 0.6328125\n",
      "Batch: 134, Loss: 1.1482144594192505, Accuracy: 0.64453125\n",
      "Batch: 135, Loss: 1.0304878950119019, Accuracy: 0.6396484375\n",
      "Batch: 136, Loss: 1.0880236625671387, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.1134004592895508, Accuracy: 0.6513671875\n",
      "Batch: 138, Loss: 1.2546777725219727, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.2095929384231567, Accuracy: 0.6015625\n",
      "Batch: 140, Loss: 1.2153575420379639, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.1598743200302124, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.1795291900634766, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.2303411960601807, Accuracy: 0.599609375\n",
      "Batch: 144, Loss: 1.2819271087646484, Accuracy: 0.5810546875\n",
      "Batch: 145, Loss: 1.237180233001709, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.2266473770141602, Accuracy: 0.59375\n",
      "Batch: 147, Loss: 1.1692090034484863, Accuracy: 0.62109375\n",
      "Batch: 148, Loss: 1.2163417339324951, Accuracy: 0.615234375\n",
      "Batch: 149, Loss: 1.1404492855072021, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.083629846572876, Accuracy: 0.662109375\n",
      "Batch: 151, Loss: 1.2242794036865234, Accuracy: 0.6083984375\n",
      "Batch: 152, Loss: 1.1768949031829834, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.1374876499176025, Accuracy: 0.6357421875\n",
      "Batch: 154, Loss: 1.0910377502441406, Accuracy: 0.666015625\n",
      "Batch: 155, Loss: 1.0966832637786865, Accuracy: 0.6435546875\n",
      "Epoch 529/200\n",
      "Batch: 1, Loss: 1.1969761848449707, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.0703538656234741, Accuracy: 0.6689453125\n",
      "Batch: 3, Loss: 1.0185329914093018, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.0548248291015625, Accuracy: 0.64453125\n",
      "Batch: 5, Loss: 1.0374921560287476, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.0266082286834717, Accuracy: 0.6650390625\n",
      "Batch: 7, Loss: 1.0505499839782715, Accuracy: 0.6455078125\n",
      "Batch: 8, Loss: 0.9821728467941284, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 1.012164831161499, Accuracy: 0.6591796875\n",
      "Batch: 10, Loss: 0.9487509727478027, Accuracy: 0.69140625\n",
      "Batch: 11, Loss: 0.9667108058929443, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 1.0674145221710205, Accuracy: 0.654296875\n",
      "Batch: 13, Loss: 1.0526793003082275, Accuracy: 0.6435546875\n",
      "Batch: 14, Loss: 0.927066445350647, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.913163423538208, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0091568231582642, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.0507371425628662, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.0894057750701904, Accuracy: 0.666015625\n",
      "Batch: 19, Loss: 1.1467934846878052, Accuracy: 0.6376953125\n",
      "Batch: 20, Loss: 1.0973272323608398, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.08695650100708, Accuracy: 0.65234375\n",
      "Batch: 22, Loss: 1.2341279983520508, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.203648328781128, Accuracy: 0.611328125\n",
      "Batch: 24, Loss: 1.0967073440551758, Accuracy: 0.6533203125\n",
      "Batch: 25, Loss: 1.14617121219635, Accuracy: 0.6259765625\n",
      "Batch: 26, Loss: 1.2344717979431152, Accuracy: 0.6005859375\n",
      "Batch: 27, Loss: 1.0880680084228516, Accuracy: 0.650390625\n",
      "Batch: 28, Loss: 1.0173001289367676, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.0865912437438965, Accuracy: 0.6591796875\n",
      "Batch: 30, Loss: 1.1161293983459473, Accuracy: 0.638671875\n",
      "Batch: 31, Loss: 1.1420867443084717, Accuracy: 0.6064453125\n",
      "Batch: 32, Loss: 1.0447731018066406, Accuracy: 0.638671875\n",
      "Batch: 33, Loss: 0.9495917558670044, Accuracy: 0.685546875\n",
      "Batch: 34, Loss: 1.0852124691009521, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.0860464572906494, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.1741063594818115, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1910680532455444, Accuracy: 0.609375\n",
      "Batch: 38, Loss: 1.1320242881774902, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0484715700149536, Accuracy: 0.6650390625\n",
      "Batch: 40, Loss: 1.1310999393463135, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.0604794025421143, Accuracy: 0.6650390625\n",
      "Batch: 42, Loss: 1.0549328327178955, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.1041688919067383, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.0253335237503052, Accuracy: 0.6748046875\n",
      "Batch: 45, Loss: 1.0123100280761719, Accuracy: 0.6669921875\n",
      "Batch: 46, Loss: 1.0808100700378418, Accuracy: 0.64453125\n",
      "Batch: 47, Loss: 1.0365084409713745, Accuracy: 0.6669921875\n",
      "Batch: 48, Loss: 1.1295876502990723, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.1826145648956299, Accuracy: 0.6220703125\n",
      "Batch: 50, Loss: 1.1185262203216553, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.1685658693313599, Accuracy: 0.5859375\n",
      "Batch: 52, Loss: 1.2112988233566284, Accuracy: 0.615234375\n",
      "Batch: 53, Loss: 1.1478698253631592, Accuracy: 0.607421875\n",
      "Batch: 54, Loss: 1.171276330947876, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.0816243886947632, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.1205265522003174, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.0401456356048584, Accuracy: 0.6611328125\n",
      "Batch: 58, Loss: 1.0803818702697754, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.1089937686920166, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.2252284288406372, Accuracy: 0.6240234375\n",
      "Batch: 61, Loss: 1.112652063369751, Accuracy: 0.6318359375\n",
      "Batch: 62, Loss: 1.140479326248169, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.1190299987792969, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.1974296569824219, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1420385837554932, Accuracy: 0.6240234375\n",
      "Batch: 66, Loss: 1.114217758178711, Accuracy: 0.64453125\n",
      "Batch: 67, Loss: 1.1448092460632324, Accuracy: 0.6298828125\n",
      "Batch: 68, Loss: 1.106751561164856, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1682138442993164, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.1970500946044922, Accuracy: 0.6064453125\n",
      "Batch: 71, Loss: 1.132516860961914, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.1940871477127075, Accuracy: 0.634765625\n",
      "Batch: 73, Loss: 1.1530249118804932, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.1391503810882568, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.090341329574585, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.0522749423980713, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0829564332962036, Accuracy: 0.6533203125\n",
      "Batch: 78, Loss: 1.0739574432373047, Accuracy: 0.662109375\n",
      "Batch: 79, Loss: 1.0766019821166992, Accuracy: 0.650390625\n",
      "Batch: 80, Loss: 1.162498950958252, Accuracy: 0.61328125\n",
      "Batch: 81, Loss: 1.0828568935394287, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.1124889850616455, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.1690216064453125, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.1750876903533936, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.167685866355896, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.1346426010131836, Accuracy: 0.619140625\n",
      "Batch: 87, Loss: 1.1221764087677002, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.1193515062332153, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.1109532117843628, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.040348768234253, Accuracy: 0.6611328125\n",
      "Batch: 91, Loss: 1.1416189670562744, Accuracy: 0.62890625\n",
      "Batch: 92, Loss: 1.1228854656219482, Accuracy: 0.658203125\n",
      "Batch: 93, Loss: 1.1249010562896729, Accuracy: 0.623046875\n",
      "Batch: 94, Loss: 1.2118282318115234, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.1269996166229248, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.1878774166107178, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.1663570404052734, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.1285544633865356, Accuracy: 0.63671875\n",
      "Batch: 99, Loss: 1.1394543647766113, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 1.0450376272201538, Accuracy: 0.671875\n",
      "Batch: 101, Loss: 1.1129964590072632, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.1761733293533325, Accuracy: 0.6201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 1.2067487239837646, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.1135340929031372, Accuracy: 0.654296875\n",
      "Batch: 105, Loss: 1.1899464130401611, Accuracy: 0.6240234375\n",
      "Batch: 106, Loss: 1.1924481391906738, Accuracy: 0.6162109375\n",
      "Batch: 107, Loss: 1.1880470514297485, Accuracy: 0.623046875\n",
      "Batch: 108, Loss: 1.1709274053573608, Accuracy: 0.6123046875\n",
      "Batch: 109, Loss: 1.1838903427124023, Accuracy: 0.619140625\n",
      "Batch: 110, Loss: 1.1261556148529053, Accuracy: 0.63671875\n",
      "Batch: 111, Loss: 1.1069486141204834, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.076910138130188, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.1653380393981934, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.1171494722366333, Accuracy: 0.6318359375\n",
      "Batch: 115, Loss: 1.151068925857544, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.165352463722229, Accuracy: 0.603515625\n",
      "Batch: 117, Loss: 1.11506986618042, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 1.2111153602600098, Accuracy: 0.587890625\n",
      "Batch: 119, Loss: 1.1746039390563965, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.330668568611145, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.140933632850647, Accuracy: 0.646484375\n",
      "Batch: 122, Loss: 1.2514617443084717, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.1872005462646484, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.1423709392547607, Accuracy: 0.6494140625\n",
      "Batch: 125, Loss: 1.1806399822235107, Accuracy: 0.59765625\n",
      "Batch: 126, Loss: 1.287428617477417, Accuracy: 0.591796875\n",
      "Batch: 127, Loss: 1.2027792930603027, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2023826837539673, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.1634098291397095, Accuracy: 0.63671875\n",
      "Batch: 130, Loss: 1.1355003118515015, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.2078368663787842, Accuracy: 0.5927734375\n",
      "Batch: 132, Loss: 1.0497496128082275, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.1596786975860596, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.0995162725448608, Accuracy: 0.6572265625\n",
      "Batch: 135, Loss: 1.0380160808563232, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.06373929977417, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.1622891426086426, Accuracy: 0.6103515625\n",
      "Batch: 138, Loss: 1.2049133777618408, Accuracy: 0.5966796875\n",
      "Batch: 139, Loss: 1.1916308403015137, Accuracy: 0.63671875\n",
      "Batch: 140, Loss: 1.2260503768920898, Accuracy: 0.61328125\n",
      "Batch: 141, Loss: 1.2028861045837402, Accuracy: 0.6240234375\n",
      "Batch: 142, Loss: 1.187512755393982, Accuracy: 0.62109375\n",
      "Batch: 143, Loss: 1.2145116329193115, Accuracy: 0.5927734375\n",
      "Batch: 144, Loss: 1.2831478118896484, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.2248259782791138, Accuracy: 0.61328125\n",
      "Batch: 146, Loss: 1.172285795211792, Accuracy: 0.619140625\n",
      "Batch: 147, Loss: 1.1396068334579468, Accuracy: 0.623046875\n",
      "Batch: 148, Loss: 1.2024118900299072, Accuracy: 0.6181640625\n",
      "Batch: 149, Loss: 1.0830744504928589, Accuracy: 0.6279296875\n",
      "Batch: 150, Loss: 1.1630196571350098, Accuracy: 0.6064453125\n",
      "Batch: 151, Loss: 1.0779459476470947, Accuracy: 0.662109375\n",
      "Batch: 152, Loss: 1.1909232139587402, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.1071815490722656, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.1258383989334106, Accuracy: 0.630859375\n",
      "Batch: 155, Loss: 1.0704119205474854, Accuracy: 0.671875\n",
      "Epoch 530/200\n",
      "Batch: 1, Loss: 1.2423746585845947, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 1.060427188873291, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 0.9946812391281128, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 1.0683627128601074, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 1.0531433820724487, Accuracy: 0.6435546875\n",
      "Batch: 6, Loss: 1.0320664644241333, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 1.0304840803146362, Accuracy: 0.640625\n",
      "Batch: 8, Loss: 0.9306610822677612, Accuracy: 0.7041015625\n",
      "Batch: 9, Loss: 1.0004979372024536, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 0.9862995743751526, Accuracy: 0.6796875\n",
      "Batch: 11, Loss: 0.9438298940658569, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 1.0149283409118652, Accuracy: 0.6572265625\n",
      "Batch: 13, Loss: 1.0106532573699951, Accuracy: 0.669921875\n",
      "Batch: 14, Loss: 0.9672203660011292, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.9213330149650574, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 1.0122549533843994, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.0403411388397217, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.0869865417480469, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.147933840751648, Accuracy: 0.630859375\n",
      "Batch: 20, Loss: 1.041317105293274, Accuracy: 0.6748046875\n",
      "Batch: 21, Loss: 1.007521152496338, Accuracy: 0.67578125\n",
      "Batch: 22, Loss: 1.197952151298523, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.2160362005233765, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.0677664279937744, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.1207282543182373, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1752374172210693, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.1538056135177612, Accuracy: 0.607421875\n",
      "Batch: 28, Loss: 1.0200488567352295, Accuracy: 0.662109375\n",
      "Batch: 29, Loss: 1.0512616634368896, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.1203083992004395, Accuracy: 0.640625\n",
      "Batch: 31, Loss: 1.1195132732391357, Accuracy: 0.6376953125\n",
      "Batch: 32, Loss: 1.0636694431304932, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.0038450956344604, Accuracy: 0.66015625\n",
      "Batch: 34, Loss: 1.0715651512145996, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.1413971185684204, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.1785235404968262, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.206515908241272, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.0958175659179688, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.0493123531341553, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.0447688102722168, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.1258916854858398, Accuracy: 0.6259765625\n",
      "Batch: 42, Loss: 1.1046866178512573, Accuracy: 0.646484375\n",
      "Batch: 43, Loss: 1.088078260421753, Accuracy: 0.6337890625\n",
      "Batch: 44, Loss: 1.0369486808776855, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.039109468460083, Accuracy: 0.6640625\n",
      "Batch: 46, Loss: 1.1094532012939453, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.1029722690582275, Accuracy: 0.6591796875\n",
      "Batch: 48, Loss: 1.077590823173523, Accuracy: 0.650390625\n",
      "Batch: 49, Loss: 1.1158897876739502, Accuracy: 0.65234375\n",
      "Batch: 50, Loss: 1.1480928659439087, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.1490179300308228, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.171875, Accuracy: 0.630859375\n",
      "Batch: 53, Loss: 1.1095914840698242, Accuracy: 0.6435546875\n",
      "Batch: 54, Loss: 1.1209914684295654, Accuracy: 0.630859375\n",
      "Batch: 55, Loss: 1.1036598682403564, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.1193870306015015, Accuracy: 0.634765625\n",
      "Batch: 57, Loss: 1.1073386669158936, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.0848352909088135, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 1.0991300344467163, Accuracy: 0.634765625\n",
      "Batch: 60, Loss: 1.232799768447876, Accuracy: 0.59375\n",
      "Batch: 61, Loss: 1.105468511581421, Accuracy: 0.6416015625\n",
      "Batch: 62, Loss: 1.070111632347107, Accuracy: 0.666015625\n",
      "Batch: 63, Loss: 1.1664245128631592, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.25553560256958, Accuracy: 0.5908203125\n",
      "Batch: 65, Loss: 1.153722882270813, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.1429922580718994, Accuracy: 0.6318359375\n",
      "Batch: 67, Loss: 1.1933393478393555, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.0217413902282715, Accuracy: 0.673828125\n",
      "Batch: 69, Loss: 1.1609373092651367, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1386971473693848, Accuracy: 0.623046875\n",
      "Batch: 71, Loss: 1.1273746490478516, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.142463207244873, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.1587625741958618, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.100339651107788, Accuracy: 0.654296875\n",
      "Batch: 75, Loss: 1.115112066268921, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.0873024463653564, Accuracy: 0.6474609375\n",
      "Batch: 77, Loss: 1.0320849418640137, Accuracy: 0.6708984375\n",
      "Batch: 78, Loss: 1.0449559688568115, Accuracy: 0.65625\n",
      "Batch: 79, Loss: 1.1089410781860352, Accuracy: 0.6298828125\n",
      "Batch: 80, Loss: 1.1327245235443115, Accuracy: 0.640625\n",
      "Batch: 81, Loss: 1.1128065586090088, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.080213189125061, Accuracy: 0.65234375\n",
      "Batch: 83, Loss: 1.1687768697738647, Accuracy: 0.6318359375\n",
      "Batch: 84, Loss: 1.1120582818984985, Accuracy: 0.6318359375\n",
      "Batch: 85, Loss: 1.1553747653961182, Accuracy: 0.6240234375\n",
      "Batch: 86, Loss: 1.1409587860107422, Accuracy: 0.625\n",
      "Batch: 87, Loss: 1.0806013345718384, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 88, Loss: 1.1167612075805664, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.1396458148956299, Accuracy: 0.6201171875\n",
      "Batch: 90, Loss: 1.1324281692504883, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1459262371063232, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.1587202548980713, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.1497488021850586, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.1284642219543457, Accuracy: 0.626953125\n",
      "Batch: 95, Loss: 1.1876866817474365, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.172481656074524, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.1514747142791748, Accuracy: 0.615234375\n",
      "Batch: 98, Loss: 1.0902912616729736, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.101789116859436, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.0455232858657837, Accuracy: 0.666015625\n",
      "Batch: 101, Loss: 1.080425500869751, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.16977059841156, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.1183466911315918, Accuracy: 0.65234375\n",
      "Batch: 104, Loss: 1.1115193367004395, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.2157639265060425, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.1412461996078491, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2003271579742432, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.1543411016464233, Accuracy: 0.634765625\n",
      "Batch: 109, Loss: 1.1821832656860352, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.1227188110351562, Accuracy: 0.63671875\n",
      "Batch: 111, Loss: 1.0951677560806274, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.1135823726654053, Accuracy: 0.6181640625\n",
      "Batch: 113, Loss: 1.0819299221038818, Accuracy: 0.6455078125\n",
      "Batch: 114, Loss: 1.1520087718963623, Accuracy: 0.6015625\n",
      "Batch: 115, Loss: 1.159832239151001, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.1986544132232666, Accuracy: 0.6083984375\n",
      "Batch: 117, Loss: 1.124137282371521, Accuracy: 0.63671875\n",
      "Batch: 118, Loss: 1.1827653646469116, Accuracy: 0.6171875\n",
      "Batch: 119, Loss: 1.182294487953186, Accuracy: 0.6318359375\n",
      "Batch: 120, Loss: 1.2944917678833008, Accuracy: 0.5810546875\n",
      "Batch: 121, Loss: 1.1798075437545776, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.2092580795288086, Accuracy: 0.6142578125\n",
      "Batch: 123, Loss: 1.170703411102295, Accuracy: 0.6416015625\n",
      "Batch: 124, Loss: 1.17609441280365, Accuracy: 0.603515625\n",
      "Batch: 125, Loss: 1.1709966659545898, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.2063363790512085, Accuracy: 0.623046875\n",
      "Batch: 127, Loss: 1.1679801940917969, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.2260994911193848, Accuracy: 0.5927734375\n",
      "Batch: 129, Loss: 1.1678508520126343, Accuracy: 0.626953125\n",
      "Batch: 130, Loss: 1.1255567073822021, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.1824018955230713, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 1.035099744796753, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.1382639408111572, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.1318023204803467, Accuracy: 0.642578125\n",
      "Batch: 135, Loss: 1.0385322570800781, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.0822101831436157, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.0930354595184326, Accuracy: 0.6298828125\n",
      "Batch: 138, Loss: 1.244598150253296, Accuracy: 0.6123046875\n",
      "Batch: 139, Loss: 1.1842204332351685, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.2152808904647827, Accuracy: 0.6064453125\n",
      "Batch: 141, Loss: 1.1214637756347656, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.1405097246170044, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.1960937976837158, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.2510392665863037, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.286653757095337, Accuracy: 0.58203125\n",
      "Batch: 146, Loss: 1.155957818031311, Accuracy: 0.6357421875\n",
      "Batch: 147, Loss: 1.1618292331695557, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.1490825414657593, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.2053619623184204, Accuracy: 0.59765625\n",
      "Batch: 150, Loss: 1.1277225017547607, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.1095473766326904, Accuracy: 0.642578125\n",
      "Batch: 152, Loss: 1.2106350660324097, Accuracy: 0.5986328125\n",
      "Batch: 153, Loss: 1.093738317489624, Accuracy: 0.6474609375\n",
      "Batch: 154, Loss: 1.0635311603546143, Accuracy: 0.6484375\n",
      "Batch: 155, Loss: 1.1073901653289795, Accuracy: 0.6376953125\n",
      "Saved Weights at epoch 530 to file Weights_530.h5\n",
      "Epoch 531/200\n",
      "Batch: 1, Loss: 1.2026770114898682, Accuracy: 0.6533203125\n",
      "Batch: 2, Loss: 1.0602924823760986, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.0144219398498535, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.0532143115997314, Accuracy: 0.6708984375\n",
      "Batch: 5, Loss: 1.0046889781951904, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0339195728302002, Accuracy: 0.646484375\n",
      "Batch: 7, Loss: 0.990652322769165, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 0.9973413944244385, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0063072443008423, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 0.8963429927825928, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 0.978905200958252, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 1.016554594039917, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 1.0099456310272217, Accuracy: 0.6806640625\n",
      "Batch: 14, Loss: 0.9517853260040283, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.9249093532562256, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 0.9901880025863647, Accuracy: 0.6806640625\n",
      "Batch: 17, Loss: 1.044538140296936, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.1375101804733276, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.1959583759307861, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0850789546966553, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.095860242843628, Accuracy: 0.6630859375\n",
      "Batch: 22, Loss: 1.1632369756698608, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.2637115716934204, Accuracy: 0.6064453125\n",
      "Batch: 24, Loss: 1.0803961753845215, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.096729040145874, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.1639492511749268, Accuracy: 0.646484375\n",
      "Batch: 27, Loss: 1.1197288036346436, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.0623096227645874, Accuracy: 0.642578125\n",
      "Batch: 29, Loss: 1.029130458831787, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1455910205841064, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.185107946395874, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.0019289255142212, Accuracy: 0.6767578125\n",
      "Batch: 33, Loss: 1.008093237876892, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.068697214126587, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.1247074604034424, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.171491026878357, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.1836585998535156, Accuracy: 0.619140625\n",
      "Batch: 38, Loss: 1.1995083093643188, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.0844430923461914, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.0677125453948975, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.1045560836791992, Accuracy: 0.6474609375\n",
      "Batch: 42, Loss: 1.0682860612869263, Accuracy: 0.6416015625\n",
      "Batch: 43, Loss: 1.0583100318908691, Accuracy: 0.640625\n",
      "Batch: 44, Loss: 1.020115613937378, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.0402202606201172, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.089406967163086, Accuracy: 0.6474609375\n",
      "Batch: 47, Loss: 1.062577486038208, Accuracy: 0.6572265625\n",
      "Batch: 48, Loss: 1.0761001110076904, Accuracy: 0.6513671875\n",
      "Batch: 49, Loss: 1.1547865867614746, Accuracy: 0.619140625\n",
      "Batch: 50, Loss: 1.1085057258605957, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.1420000791549683, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.1941726207733154, Accuracy: 0.609375\n",
      "Batch: 53, Loss: 1.1681735515594482, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.1354714632034302, Accuracy: 0.625\n",
      "Batch: 55, Loss: 1.089708685874939, Accuracy: 0.638671875\n",
      "Batch: 56, Loss: 1.0932104587554932, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.009892225265503, Accuracy: 0.6650390625\n",
      "Batch: 58, Loss: 1.045637607574463, Accuracy: 0.6494140625\n",
      "Batch: 59, Loss: 1.0574287176132202, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.2024643421173096, Accuracy: 0.6044921875\n",
      "Batch: 61, Loss: 1.103210687637329, Accuracy: 0.6474609375\n",
      "Batch: 62, Loss: 1.1051185131072998, Accuracy: 0.638671875\n",
      "Batch: 63, Loss: 1.1626091003417969, Accuracy: 0.6201171875\n",
      "Batch: 64, Loss: 1.1257587671279907, Accuracy: 0.6279296875\n",
      "Batch: 65, Loss: 1.1345841884613037, Accuracy: 0.63671875\n",
      "Batch: 66, Loss: 1.126175880432129, Accuracy: 0.6416015625\n",
      "Batch: 67, Loss: 1.1350994110107422, Accuracy: 0.6376953125\n",
      "Batch: 68, Loss: 1.069467544555664, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1886564493179321, Accuracy: 0.60546875\n",
      "Batch: 70, Loss: 1.091514229774475, Accuracy: 0.6484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 71, Loss: 1.0768465995788574, Accuracy: 0.638671875\n",
      "Batch: 72, Loss: 1.1702241897583008, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.1081249713897705, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.10467529296875, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.1476727724075317, Accuracy: 0.6435546875\n",
      "Batch: 76, Loss: 1.030570149421692, Accuracy: 0.65625\n",
      "Batch: 77, Loss: 1.030644178390503, Accuracy: 0.6630859375\n",
      "Batch: 78, Loss: 1.0353777408599854, Accuracy: 0.650390625\n",
      "Batch: 79, Loss: 1.0737029314041138, Accuracy: 0.6669921875\n",
      "Batch: 80, Loss: 1.1500611305236816, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.1107559204101562, Accuracy: 0.6650390625\n",
      "Batch: 82, Loss: 1.0776053667068481, Accuracy: 0.658203125\n",
      "Batch: 83, Loss: 1.1892633438110352, Accuracy: 0.630859375\n",
      "Batch: 84, Loss: 1.098043441772461, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.1753588914871216, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.1598303318023682, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.114948034286499, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.1354310512542725, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.1201508045196533, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 1.0764553546905518, Accuracy: 0.638671875\n",
      "Batch: 91, Loss: 1.1200611591339111, Accuracy: 0.6357421875\n",
      "Batch: 92, Loss: 1.114255666732788, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 1.1702923774719238, Accuracy: 0.6396484375\n",
      "Batch: 94, Loss: 1.1331835985183716, Accuracy: 0.6455078125\n",
      "Batch: 95, Loss: 1.159745216369629, Accuracy: 0.62109375\n",
      "Batch: 96, Loss: 1.165607213973999, Accuracy: 0.6259765625\n",
      "Batch: 97, Loss: 1.1946744918823242, Accuracy: 0.6025390625\n",
      "Batch: 98, Loss: 1.1264677047729492, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.1089203357696533, Accuracy: 0.6455078125\n",
      "Batch: 100, Loss: 1.078221082687378, Accuracy: 0.6533203125\n",
      "Batch: 101, Loss: 1.0768496990203857, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.168604850769043, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.1756048202514648, Accuracy: 0.6279296875\n",
      "Batch: 104, Loss: 1.1190606355667114, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.2026640176773071, Accuracy: 0.6240234375\n",
      "Batch: 106, Loss: 1.197892665863037, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2835891246795654, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.1686475276947021, Accuracy: 0.5947265625\n",
      "Batch: 109, Loss: 1.1845645904541016, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 1.1161993741989136, Accuracy: 0.646484375\n",
      "Batch: 111, Loss: 1.1148402690887451, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.083457589149475, Accuracy: 0.630859375\n",
      "Batch: 113, Loss: 1.1176862716674805, Accuracy: 0.6591796875\n",
      "Batch: 114, Loss: 1.110262155532837, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.144773006439209, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1445949077606201, Accuracy: 0.6181640625\n",
      "Batch: 117, Loss: 1.1609156131744385, Accuracy: 0.62890625\n",
      "Batch: 118, Loss: 1.1911852359771729, Accuracy: 0.595703125\n",
      "Batch: 119, Loss: 1.2455687522888184, Accuracy: 0.619140625\n",
      "Batch: 120, Loss: 1.2843832969665527, Accuracy: 0.5830078125\n",
      "Batch: 121, Loss: 1.1950657367706299, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.1670831441879272, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.1299383640289307, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.214493989944458, Accuracy: 0.59375\n",
      "Batch: 125, Loss: 1.1329405307769775, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.24550199508667, Accuracy: 0.595703125\n",
      "Batch: 127, Loss: 1.1990041732788086, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2335360050201416, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.1842199563980103, Accuracy: 0.6171875\n",
      "Batch: 130, Loss: 1.1193418502807617, Accuracy: 0.6494140625\n",
      "Batch: 131, Loss: 1.2231184244155884, Accuracy: 0.6083984375\n",
      "Batch: 132, Loss: 1.0759553909301758, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.19063138961792, Accuracy: 0.59765625\n",
      "Batch: 134, Loss: 1.0971837043762207, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 1.0455121994018555, Accuracy: 0.6533203125\n",
      "Batch: 136, Loss: 1.1231892108917236, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.1643120050430298, Accuracy: 0.6171875\n",
      "Batch: 138, Loss: 1.2350198030471802, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.1418676376342773, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.1959228515625, Accuracy: 0.6298828125\n",
      "Batch: 141, Loss: 1.234518051147461, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.1458301544189453, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.1626698970794678, Accuracy: 0.6328125\n",
      "Batch: 144, Loss: 1.2403446435928345, Accuracy: 0.5791015625\n",
      "Batch: 145, Loss: 1.2347979545593262, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.1590166091918945, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.2186698913574219, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.1846520900726318, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.1631178855895996, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.119782567024231, Accuracy: 0.6357421875\n",
      "Batch: 151, Loss: 1.1408848762512207, Accuracy: 0.623046875\n",
      "Batch: 152, Loss: 1.154766321182251, Accuracy: 0.6044921875\n",
      "Batch: 153, Loss: 1.0885498523712158, Accuracy: 0.650390625\n",
      "Batch: 154, Loss: 1.0999014377593994, Accuracy: 0.64453125\n",
      "Batch: 155, Loss: 1.0671398639678955, Accuracy: 0.650390625\n",
      "Epoch 532/200\n",
      "Batch: 1, Loss: 1.2193303108215332, Accuracy: 0.630859375\n",
      "Batch: 2, Loss: 1.0284541845321655, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.9948482513427734, Accuracy: 0.6484375\n",
      "Batch: 4, Loss: 1.0111215114593506, Accuracy: 0.669921875\n",
      "Batch: 5, Loss: 1.0009727478027344, Accuracy: 0.677734375\n",
      "Batch: 6, Loss: 1.0883204936981201, Accuracy: 0.6591796875\n",
      "Batch: 7, Loss: 0.9681371450424194, Accuracy: 0.6884765625\n",
      "Batch: 8, Loss: 0.9625667929649353, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 1.0093655586242676, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 0.9186863899230957, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 0.9274773001670837, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 0.9941717386245728, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.038489580154419, Accuracy: 0.6435546875\n",
      "Batch: 14, Loss: 0.9999240636825562, Accuracy: 0.666015625\n",
      "Batch: 15, Loss: 0.9419444799423218, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.031641960144043, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.0080935955047607, Accuracy: 0.6689453125\n",
      "Batch: 18, Loss: 1.099033236503601, Accuracy: 0.6416015625\n",
      "Batch: 19, Loss: 1.2228643894195557, Accuracy: 0.6103515625\n",
      "Batch: 20, Loss: 1.1040098667144775, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.1212904453277588, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.215138554573059, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.2319576740264893, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.1020176410675049, Accuracy: 0.6474609375\n",
      "Batch: 25, Loss: 1.120788812637329, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1844086647033691, Accuracy: 0.6015625\n",
      "Batch: 27, Loss: 1.1256866455078125, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.096548318862915, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.0365557670593262, Accuracy: 0.6533203125\n",
      "Batch: 30, Loss: 1.1185493469238281, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.1941593885421753, Accuracy: 0.62109375\n",
      "Batch: 32, Loss: 1.073839783668518, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 1.044924259185791, Accuracy: 0.6484375\n",
      "Batch: 34, Loss: 1.0679683685302734, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 1.1030441522598267, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.210923433303833, Accuracy: 0.6171875\n",
      "Batch: 37, Loss: 1.2487683296203613, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.2250280380249023, Accuracy: 0.5859375\n",
      "Batch: 39, Loss: 1.0583827495574951, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.0924880504608154, Accuracy: 0.6396484375\n",
      "Batch: 41, Loss: 1.1488864421844482, Accuracy: 0.6357421875\n",
      "Batch: 42, Loss: 1.087350606918335, Accuracy: 0.6474609375\n",
      "Batch: 43, Loss: 1.070622205734253, Accuracy: 0.6279296875\n",
      "Batch: 44, Loss: 1.0376181602478027, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0403610467910767, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.054180383682251, Accuracy: 0.64453125\n",
      "Batch: 47, Loss: 1.1201708316802979, Accuracy: 0.638671875\n",
      "Batch: 48, Loss: 1.140270471572876, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.1973881721496582, Accuracy: 0.6123046875\n",
      "Batch: 50, Loss: 1.1143922805786133, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.1776087284088135, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.2155725955963135, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1292872428894043, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1233384609222412, Accuracy: 0.6318359375\n",
      "Batch: 55, Loss: 1.0961987972259521, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 56, Loss: 1.066333532333374, Accuracy: 0.6689453125\n",
      "Batch: 57, Loss: 1.103329062461853, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.093214988708496, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 1.1349495649337769, Accuracy: 0.630859375\n",
      "Batch: 60, Loss: 1.196098804473877, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1520044803619385, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1584100723266602, Accuracy: 0.6240234375\n",
      "Batch: 63, Loss: 1.172247052192688, Accuracy: 0.6171875\n",
      "Batch: 64, Loss: 1.239591360092163, Accuracy: 0.599609375\n",
      "Batch: 65, Loss: 1.185240387916565, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.1683478355407715, Accuracy: 0.6044921875\n",
      "Batch: 67, Loss: 1.117192029953003, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.0845125913619995, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.1838879585266113, Accuracy: 0.615234375\n",
      "Batch: 70, Loss: 1.1619179248809814, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.1799737215042114, Accuracy: 0.626953125\n",
      "Batch: 72, Loss: 1.1771132946014404, Accuracy: 0.640625\n",
      "Batch: 73, Loss: 1.1548906564712524, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.1223249435424805, Accuracy: 0.6220703125\n",
      "Batch: 75, Loss: 1.1438862085342407, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.0832033157348633, Accuracy: 0.6318359375\n",
      "Batch: 77, Loss: 1.0216495990753174, Accuracy: 0.6708984375\n",
      "Batch: 78, Loss: 1.082176685333252, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.1710410118103027, Accuracy: 0.607421875\n",
      "Batch: 80, Loss: 1.1344228982925415, Accuracy: 0.638671875\n",
      "Batch: 81, Loss: 1.0966382026672363, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.1555856466293335, Accuracy: 0.6201171875\n",
      "Batch: 83, Loss: 1.157287359237671, Accuracy: 0.6240234375\n",
      "Batch: 84, Loss: 1.099344253540039, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.1023720502853394, Accuracy: 0.6416015625\n",
      "Batch: 86, Loss: 1.1230682134628296, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.1876224279403687, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.1548376083374023, Accuracy: 0.607421875\n",
      "Batch: 89, Loss: 1.1664873361587524, Accuracy: 0.6328125\n",
      "Batch: 90, Loss: 1.099869966506958, Accuracy: 0.638671875\n",
      "Batch: 91, Loss: 1.1480424404144287, Accuracy: 0.62890625\n",
      "Batch: 92, Loss: 1.086371898651123, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 1.0726165771484375, Accuracy: 0.6484375\n",
      "Batch: 94, Loss: 1.1741724014282227, Accuracy: 0.623046875\n",
      "Batch: 95, Loss: 1.1536643505096436, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.200989007949829, Accuracy: 0.6201171875\n",
      "Batch: 97, Loss: 1.1542463302612305, Accuracy: 0.611328125\n",
      "Batch: 98, Loss: 1.0885605812072754, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.0952022075653076, Accuracy: 0.63671875\n",
      "Batch: 100, Loss: 1.0317708253860474, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.1058553457260132, Accuracy: 0.6328125\n",
      "Batch: 102, Loss: 1.1331562995910645, Accuracy: 0.6328125\n",
      "Batch: 103, Loss: 1.1345040798187256, Accuracy: 0.646484375\n",
      "Batch: 104, Loss: 1.1618475914001465, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.2166184186935425, Accuracy: 0.6083984375\n",
      "Batch: 106, Loss: 1.1435589790344238, Accuracy: 0.6396484375\n",
      "Batch: 107, Loss: 1.2334133386611938, Accuracy: 0.6083984375\n",
      "Batch: 108, Loss: 1.1627609729766846, Accuracy: 0.611328125\n",
      "Batch: 109, Loss: 1.1868171691894531, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1423442363739014, Accuracy: 0.61328125\n",
      "Batch: 111, Loss: 1.1686756610870361, Accuracy: 0.6220703125\n",
      "Batch: 112, Loss: 1.1224303245544434, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1626269817352295, Accuracy: 0.6201171875\n",
      "Batch: 114, Loss: 1.126631736755371, Accuracy: 0.62890625\n",
      "Batch: 115, Loss: 1.1803090572357178, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.1320581436157227, Accuracy: 0.626953125\n",
      "Batch: 117, Loss: 1.1583083868026733, Accuracy: 0.6279296875\n",
      "Batch: 118, Loss: 1.2446656227111816, Accuracy: 0.5986328125\n",
      "Batch: 119, Loss: 1.2135233879089355, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.2567651271820068, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.1277374029159546, Accuracy: 0.6396484375\n",
      "Batch: 122, Loss: 1.1911659240722656, Accuracy: 0.6376953125\n",
      "Batch: 123, Loss: 1.1265959739685059, Accuracy: 0.6513671875\n",
      "Batch: 124, Loss: 1.1926887035369873, Accuracy: 0.6142578125\n",
      "Batch: 125, Loss: 1.1418267488479614, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.2020058631896973, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.2173714637756348, Accuracy: 0.611328125\n",
      "Batch: 128, Loss: 1.2369732856750488, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.1762187480926514, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.1405558586120605, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.1847875118255615, Accuracy: 0.609375\n",
      "Batch: 132, Loss: 1.0685721635818481, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.0946186780929565, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.0890787839889526, Accuracy: 0.6533203125\n",
      "Batch: 135, Loss: 1.0703177452087402, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.0747655630111694, Accuracy: 0.66796875\n",
      "Batch: 137, Loss: 1.14859938621521, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 1.2165839672088623, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.127303957939148, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.207653284072876, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.112496256828308, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1619981527328491, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.200148105621338, Accuracy: 0.6181640625\n",
      "Batch: 144, Loss: 1.2864147424697876, Accuracy: 0.572265625\n",
      "Batch: 145, Loss: 1.1925008296966553, Accuracy: 0.6064453125\n",
      "Batch: 146, Loss: 1.1685996055603027, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1928417682647705, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.188511848449707, Accuracy: 0.60546875\n",
      "Batch: 149, Loss: 1.168021321296692, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.1254054307937622, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.0675987005233765, Accuracy: 0.65625\n",
      "Batch: 152, Loss: 1.1741695404052734, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.1324540376663208, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.1126716136932373, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0766555070877075, Accuracy: 0.6416015625\n",
      "Epoch 533/200\n",
      "Batch: 1, Loss: 1.2541239261627197, Accuracy: 0.6376953125\n",
      "Batch: 2, Loss: 1.0351967811584473, Accuracy: 0.669921875\n",
      "Batch: 3, Loss: 1.0119274854660034, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 1.051270604133606, Accuracy: 0.6484375\n",
      "Batch: 5, Loss: 1.0444684028625488, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 1.0456836223602295, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 1.0543973445892334, Accuracy: 0.650390625\n",
      "Batch: 8, Loss: 1.0168019533157349, Accuracy: 0.662109375\n",
      "Batch: 9, Loss: 0.9846878051757812, Accuracy: 0.6884765625\n",
      "Batch: 10, Loss: 0.9897735118865967, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 0.9237092733383179, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9884451031684875, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 0.9878073334693909, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.945881724357605, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.9563347697257996, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.0489121675491333, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 0.9975410103797913, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.0764662027359009, Accuracy: 0.6474609375\n",
      "Batch: 19, Loss: 1.1864415407180786, Accuracy: 0.625\n",
      "Batch: 20, Loss: 1.0534816980361938, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.094904899597168, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.2616596221923828, Accuracy: 0.609375\n",
      "Batch: 23, Loss: 1.2498962879180908, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.1076687574386597, Accuracy: 0.64453125\n",
      "Batch: 25, Loss: 1.1879608631134033, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.1497256755828857, Accuracy: 0.623046875\n",
      "Batch: 27, Loss: 1.1268407106399536, Accuracy: 0.6376953125\n",
      "Batch: 28, Loss: 1.041572093963623, Accuracy: 0.6416015625\n",
      "Batch: 29, Loss: 1.0657129287719727, Accuracy: 0.650390625\n",
      "Batch: 30, Loss: 1.1393922567367554, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.1486235857009888, Accuracy: 0.6298828125\n",
      "Batch: 32, Loss: 0.9949774742126465, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 0.9771937131881714, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.0987212657928467, Accuracy: 0.646484375\n",
      "Batch: 35, Loss: 1.1588871479034424, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.1914647817611694, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.1933045387268066, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.14707612991333, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.0731940269470215, Accuracy: 0.6416015625\n",
      "Batch: 40, Loss: 1.1285834312438965, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 1.1555147171020508, Accuracy: 0.6298828125\n",
      "Batch: 42, Loss: 1.096498966217041, Accuracy: 0.642578125\n",
      "Batch: 43, Loss: 1.0564663410186768, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.0816985368728638, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0428475141525269, Accuracy: 0.6494140625\n",
      "Batch: 46, Loss: 1.112443208694458, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.1086770296096802, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.2090730667114258, Accuracy: 0.6103515625\n",
      "Batch: 49, Loss: 1.152353286743164, Accuracy: 0.634765625\n",
      "Batch: 50, Loss: 1.1643650531768799, Accuracy: 0.6171875\n",
      "Batch: 51, Loss: 1.151244878768921, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.2256368398666382, Accuracy: 0.619140625\n",
      "Batch: 53, Loss: 1.1550178527832031, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.1913036108016968, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.07285475730896, Accuracy: 0.6474609375\n",
      "Batch: 56, Loss: 1.1269570589065552, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.0899583101272583, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.1289955377578735, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.173750400543213, Accuracy: 0.626953125\n",
      "Batch: 60, Loss: 1.2307953834533691, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1453909873962402, Accuracy: 0.6162109375\n",
      "Batch: 62, Loss: 1.173296570777893, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.175586462020874, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.157240390777588, Accuracy: 0.634765625\n",
      "Batch: 65, Loss: 1.1621589660644531, Accuracy: 0.6455078125\n",
      "Batch: 66, Loss: 1.1548173427581787, Accuracy: 0.6259765625\n",
      "Batch: 67, Loss: 1.1319674253463745, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.0711719989776611, Accuracy: 0.6572265625\n",
      "Batch: 69, Loss: 1.1392534971237183, Accuracy: 0.6376953125\n",
      "Batch: 70, Loss: 1.2069897651672363, Accuracy: 0.6181640625\n",
      "Batch: 71, Loss: 1.1617971658706665, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.1047356128692627, Accuracy: 0.650390625\n",
      "Batch: 73, Loss: 1.152545690536499, Accuracy: 0.638671875\n",
      "Batch: 74, Loss: 1.1200523376464844, Accuracy: 0.634765625\n",
      "Batch: 75, Loss: 1.1114985942840576, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0950639247894287, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.0350568294525146, Accuracy: 0.654296875\n",
      "Batch: 78, Loss: 1.0545568466186523, Accuracy: 0.6728515625\n",
      "Batch: 79, Loss: 1.1243001222610474, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.1530600786209106, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.0880234241485596, Accuracy: 0.646484375\n",
      "Batch: 82, Loss: 1.116330862045288, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.1556048393249512, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.105520248413086, Accuracy: 0.6337890625\n",
      "Batch: 85, Loss: 1.128375768661499, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1868536472320557, Accuracy: 0.6015625\n",
      "Batch: 87, Loss: 1.1588423252105713, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.1902320384979248, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.1281200647354126, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.0262765884399414, Accuracy: 0.6708984375\n",
      "Batch: 91, Loss: 1.116138219833374, Accuracy: 0.6328125\n",
      "Batch: 92, Loss: 1.1090811491012573, Accuracy: 0.6640625\n",
      "Batch: 93, Loss: 1.1182048320770264, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.1027562618255615, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.2020349502563477, Accuracy: 0.6162109375\n",
      "Batch: 96, Loss: 1.2044188976287842, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.0762354135513306, Accuracy: 0.6416015625\n",
      "Batch: 98, Loss: 1.1248791217803955, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.0967731475830078, Accuracy: 0.6220703125\n",
      "Batch: 100, Loss: 1.0980250835418701, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.125090479850769, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.1447423696517944, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.1714973449707031, Accuracy: 0.62109375\n",
      "Batch: 104, Loss: 1.1000999212265015, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.2028181552886963, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1246058940887451, Accuracy: 0.6474609375\n",
      "Batch: 107, Loss: 1.2390096187591553, Accuracy: 0.583984375\n",
      "Batch: 108, Loss: 1.188485860824585, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.1419283151626587, Accuracy: 0.6318359375\n",
      "Batch: 110, Loss: 1.081251859664917, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1200178861618042, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0803782939910889, Accuracy: 0.6640625\n",
      "Batch: 113, Loss: 1.1814357042312622, Accuracy: 0.611328125\n",
      "Batch: 114, Loss: 1.077434778213501, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.199589490890503, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.1728670597076416, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1961252689361572, Accuracy: 0.59375\n",
      "Batch: 118, Loss: 1.2394006252288818, Accuracy: 0.595703125\n",
      "Batch: 119, Loss: 1.202907919883728, Accuracy: 0.611328125\n",
      "Batch: 120, Loss: 1.258734107017517, Accuracy: 0.587890625\n",
      "Batch: 121, Loss: 1.1979925632476807, Accuracy: 0.6083984375\n",
      "Batch: 122, Loss: 1.2074658870697021, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.1310210227966309, Accuracy: 0.6318359375\n",
      "Batch: 124, Loss: 1.1783438920974731, Accuracy: 0.623046875\n",
      "Batch: 125, Loss: 1.1252474784851074, Accuracy: 0.6474609375\n",
      "Batch: 126, Loss: 1.1873700618743896, Accuracy: 0.6328125\n",
      "Batch: 127, Loss: 1.2685120105743408, Accuracy: 0.599609375\n",
      "Batch: 128, Loss: 1.182332992553711, Accuracy: 0.6064453125\n",
      "Batch: 129, Loss: 1.1456341743469238, Accuracy: 0.626953125\n",
      "Batch: 130, Loss: 1.1129913330078125, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.1965044736862183, Accuracy: 0.625\n",
      "Batch: 132, Loss: 1.0804816484451294, Accuracy: 0.650390625\n",
      "Batch: 133, Loss: 1.1583006381988525, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.1094636917114258, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 1.0493724346160889, Accuracy: 0.671875\n",
      "Batch: 136, Loss: 1.0903997421264648, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.1804336309432983, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 1.260614037513733, Accuracy: 0.58984375\n",
      "Batch: 139, Loss: 1.106378197669983, Accuracy: 0.6494140625\n",
      "Batch: 140, Loss: 1.164354920387268, Accuracy: 0.6376953125\n",
      "Batch: 141, Loss: 1.112913727760315, Accuracy: 0.642578125\n",
      "Batch: 142, Loss: 1.1754515171051025, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.1882381439208984, Accuracy: 0.626953125\n",
      "Batch: 144, Loss: 1.1895735263824463, Accuracy: 0.619140625\n",
      "Batch: 145, Loss: 1.234267234802246, Accuracy: 0.607421875\n",
      "Batch: 146, Loss: 1.1855233907699585, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.2091161012649536, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.2006423473358154, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.1533514261245728, Accuracy: 0.611328125\n",
      "Batch: 150, Loss: 1.1326074600219727, Accuracy: 0.6279296875\n",
      "Batch: 151, Loss: 1.1353745460510254, Accuracy: 0.638671875\n",
      "Batch: 152, Loss: 1.2013620138168335, Accuracy: 0.5986328125\n",
      "Batch: 153, Loss: 1.1099306344985962, Accuracy: 0.6552734375\n",
      "Batch: 154, Loss: 1.1106808185577393, Accuracy: 0.640625\n",
      "Batch: 155, Loss: 1.0791842937469482, Accuracy: 0.6484375\n",
      "Epoch 534/200\n",
      "Batch: 1, Loss: 1.2222826480865479, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 1.0202288627624512, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 1.0190073251724243, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 1.0084295272827148, Accuracy: 0.677734375\n",
      "Batch: 5, Loss: 1.0075474977493286, Accuracy: 0.673828125\n",
      "Batch: 6, Loss: 0.9932242631912231, Accuracy: 0.6875\n",
      "Batch: 7, Loss: 1.0158162117004395, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 1.0011476278305054, Accuracy: 0.67578125\n",
      "Batch: 9, Loss: 0.9881439805030823, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9814717769622803, Accuracy: 0.6708984375\n",
      "Batch: 11, Loss: 0.9622769951820374, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 1.031496524810791, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 0.992681622505188, Accuracy: 0.6650390625\n",
      "Batch: 14, Loss: 0.9305737614631653, Accuracy: 0.6953125\n",
      "Batch: 15, Loss: 0.95933997631073, Accuracy: 0.671875\n",
      "Batch: 16, Loss: 0.9720296859741211, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.0503944158554077, Accuracy: 0.65625\n",
      "Batch: 18, Loss: 1.0706480741500854, Accuracy: 0.65234375\n",
      "Batch: 19, Loss: 1.120866298675537, Accuracy: 0.642578125\n",
      "Batch: 20, Loss: 1.0429697036743164, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0644301176071167, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.2046645879745483, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.2671817541122437, Accuracy: 0.578125\n",
      "Batch: 24, Loss: 1.0834226608276367, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.1341946125030518, Accuracy: 0.6435546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 1.1409053802490234, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.0575923919677734, Accuracy: 0.638671875\n",
      "Batch: 28, Loss: 1.0437062978744507, Accuracy: 0.6650390625\n",
      "Batch: 29, Loss: 1.0329800844192505, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 1.1088156700134277, Accuracy: 0.6279296875\n",
      "Batch: 31, Loss: 1.1786903142929077, Accuracy: 0.6123046875\n",
      "Batch: 32, Loss: 1.046982765197754, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.000126600265503, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.1122692823410034, Accuracy: 0.6318359375\n",
      "Batch: 35, Loss: 1.1706572771072388, Accuracy: 0.6162109375\n",
      "Batch: 36, Loss: 1.1951656341552734, Accuracy: 0.6015625\n",
      "Batch: 37, Loss: 1.2412707805633545, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.1481045484542847, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.07456374168396, Accuracy: 0.6337890625\n",
      "Batch: 40, Loss: 1.0260276794433594, Accuracy: 0.6787109375\n",
      "Batch: 41, Loss: 1.0636193752288818, Accuracy: 0.6572265625\n",
      "Batch: 42, Loss: 1.0489026308059692, Accuracy: 0.65625\n",
      "Batch: 43, Loss: 1.0336966514587402, Accuracy: 0.6650390625\n",
      "Batch: 44, Loss: 1.02238929271698, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 1.0306614637374878, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.0606951713562012, Accuracy: 0.640625\n",
      "Batch: 47, Loss: 1.0744261741638184, Accuracy: 0.6513671875\n",
      "Batch: 48, Loss: 1.1313890218734741, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.1152349710464478, Accuracy: 0.6513671875\n",
      "Batch: 50, Loss: 1.0968244075775146, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.1763648986816406, Accuracy: 0.607421875\n",
      "Batch: 52, Loss: 1.2161507606506348, Accuracy: 0.626953125\n",
      "Batch: 53, Loss: 1.1594231128692627, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.1266614198684692, Accuracy: 0.6435546875\n",
      "Batch: 55, Loss: 1.123766541481018, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.102273941040039, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 1.0998820066452026, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.0566883087158203, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 1.08638334274292, Accuracy: 0.669921875\n",
      "Batch: 60, Loss: 1.2197844982147217, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.1346590518951416, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.0785027742385864, Accuracy: 0.6611328125\n",
      "Batch: 63, Loss: 1.1306982040405273, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.2195073366165161, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1811758279800415, Accuracy: 0.599609375\n",
      "Batch: 66, Loss: 1.1273102760314941, Accuracy: 0.642578125\n",
      "Batch: 67, Loss: 1.1140353679656982, Accuracy: 0.6494140625\n",
      "Batch: 68, Loss: 1.0913031101226807, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.092390537261963, Accuracy: 0.6435546875\n",
      "Batch: 70, Loss: 1.1453726291656494, Accuracy: 0.6416015625\n",
      "Batch: 71, Loss: 1.130150556564331, Accuracy: 0.6376953125\n",
      "Batch: 72, Loss: 1.1984384059906006, Accuracy: 0.6201171875\n",
      "Batch: 73, Loss: 1.1401314735412598, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.0808830261230469, Accuracy: 0.65234375\n",
      "Batch: 75, Loss: 1.1280767917633057, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0993719100952148, Accuracy: 0.6318359375\n",
      "Batch: 77, Loss: 1.0568032264709473, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0758137702941895, Accuracy: 0.6376953125\n",
      "Batch: 79, Loss: 1.0556907653808594, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1575405597686768, Accuracy: 0.623046875\n",
      "Batch: 81, Loss: 1.0631170272827148, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 1.1411099433898926, Accuracy: 0.6484375\n",
      "Batch: 83, Loss: 1.175727367401123, Accuracy: 0.6318359375\n",
      "Batch: 84, Loss: 1.1151368618011475, Accuracy: 0.65234375\n",
      "Batch: 85, Loss: 1.1744396686553955, Accuracy: 0.5947265625\n",
      "Batch: 86, Loss: 1.1535625457763672, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.0843547582626343, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.105191707611084, Accuracy: 0.64453125\n",
      "Batch: 89, Loss: 1.1323418617248535, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.0650120973587036, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 1.1726245880126953, Accuracy: 0.6220703125\n",
      "Batch: 92, Loss: 1.1338324546813965, Accuracy: 0.66015625\n",
      "Batch: 93, Loss: 1.1126649379730225, Accuracy: 0.6279296875\n",
      "Batch: 94, Loss: 1.180642008781433, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1425504684448242, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.2456797361373901, Accuracy: 0.603515625\n",
      "Batch: 97, Loss: 1.1333037614822388, Accuracy: 0.634765625\n",
      "Batch: 98, Loss: 1.0531892776489258, Accuracy: 0.650390625\n",
      "Batch: 99, Loss: 1.148026943206787, Accuracy: 0.6259765625\n",
      "Batch: 100, Loss: 1.058455228805542, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.092825174331665, Accuracy: 0.658203125\n",
      "Batch: 102, Loss: 1.149417519569397, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.094251275062561, Accuracy: 0.6494140625\n",
      "Batch: 104, Loss: 1.127467393875122, Accuracy: 0.6416015625\n",
      "Batch: 105, Loss: 1.1349403858184814, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.1886446475982666, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.1790095567703247, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.2544422149658203, Accuracy: 0.5751953125\n",
      "Batch: 109, Loss: 1.146289587020874, Accuracy: 0.6357421875\n",
      "Batch: 110, Loss: 1.0963068008422852, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1454901695251465, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.0632359981536865, Accuracy: 0.6640625\n",
      "Batch: 113, Loss: 1.1615276336669922, Accuracy: 0.6162109375\n",
      "Batch: 114, Loss: 1.1127374172210693, Accuracy: 0.6279296875\n",
      "Batch: 115, Loss: 1.1261796951293945, Accuracy: 0.640625\n",
      "Batch: 116, Loss: 1.1670279502868652, Accuracy: 0.619140625\n",
      "Batch: 117, Loss: 1.1373002529144287, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.1547400951385498, Accuracy: 0.62890625\n",
      "Batch: 119, Loss: 1.1539199352264404, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.2265915870666504, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.190500020980835, Accuracy: 0.6416015625\n",
      "Batch: 122, Loss: 1.1409281492233276, Accuracy: 0.61328125\n",
      "Batch: 123, Loss: 1.155888557434082, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.2016957998275757, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.0950249433517456, Accuracy: 0.646484375\n",
      "Batch: 126, Loss: 1.2005090713500977, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.1602401733398438, Accuracy: 0.6416015625\n",
      "Batch: 128, Loss: 1.147577166557312, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1610058546066284, Accuracy: 0.6357421875\n",
      "Batch: 130, Loss: 1.0702590942382812, Accuracy: 0.67578125\n",
      "Batch: 131, Loss: 1.2030057907104492, Accuracy: 0.607421875\n",
      "Batch: 132, Loss: 1.0372967720031738, Accuracy: 0.6591796875\n",
      "Batch: 133, Loss: 1.1671762466430664, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.0437331199645996, Accuracy: 0.6806640625\n",
      "Batch: 135, Loss: 1.0014828443527222, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.0088412761688232, Accuracy: 0.68359375\n",
      "Batch: 137, Loss: 1.0909640789031982, Accuracy: 0.6279296875\n",
      "Batch: 138, Loss: 1.1718332767486572, Accuracy: 0.6328125\n",
      "Batch: 139, Loss: 1.1442434787750244, Accuracy: 0.603515625\n",
      "Batch: 140, Loss: 1.226499319076538, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.1342792510986328, Accuracy: 0.6220703125\n",
      "Batch: 142, Loss: 1.112476110458374, Accuracy: 0.6484375\n",
      "Batch: 143, Loss: 1.1753262281417847, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.2181243896484375, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.1947484016418457, Accuracy: 0.6083984375\n",
      "Batch: 146, Loss: 1.1583117246627808, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.186375379562378, Accuracy: 0.611328125\n",
      "Batch: 148, Loss: 1.1596051454544067, Accuracy: 0.6328125\n",
      "Batch: 149, Loss: 1.1444628238677979, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.1436784267425537, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.1718889474868774, Accuracy: 0.62109375\n",
      "Batch: 152, Loss: 1.1747660636901855, Accuracy: 0.6171875\n",
      "Batch: 153, Loss: 1.0871517658233643, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.0974434614181519, Accuracy: 0.6455078125\n",
      "Batch: 155, Loss: 1.073242425918579, Accuracy: 0.640625\n",
      "Epoch 535/200\n",
      "Batch: 1, Loss: 1.1790060997009277, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0145759582519531, Accuracy: 0.6904296875\n",
      "Batch: 3, Loss: 0.9839327931404114, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0661380290985107, Accuracy: 0.634765625\n",
      "Batch: 5, Loss: 1.0086004734039307, Accuracy: 0.6865234375\n",
      "Batch: 6, Loss: 1.0156750679016113, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.9983169436454773, Accuracy: 0.673828125\n",
      "Batch: 8, Loss: 0.9752193093299866, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 0.9706337451934814, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9706381559371948, Accuracy: 0.6611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 0.9427398443222046, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.9706593751907349, Accuracy: 0.6865234375\n",
      "Batch: 13, Loss: 1.0176382064819336, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 0.9522325992584229, Accuracy: 0.6923828125\n",
      "Batch: 15, Loss: 0.8999671339988708, Accuracy: 0.6962890625\n",
      "Batch: 16, Loss: 0.986809492111206, Accuracy: 0.6884765625\n",
      "Batch: 17, Loss: 1.0310828685760498, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.0195245742797852, Accuracy: 0.6552734375\n",
      "Batch: 19, Loss: 1.1987111568450928, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.101125955581665, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.078945517539978, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.2389733791351318, Accuracy: 0.6015625\n",
      "Batch: 23, Loss: 1.1762146949768066, Accuracy: 0.6220703125\n",
      "Batch: 24, Loss: 1.044547438621521, Accuracy: 0.638671875\n",
      "Batch: 25, Loss: 1.1426774263381958, Accuracy: 0.609375\n",
      "Batch: 26, Loss: 1.1932573318481445, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.117220401763916, Accuracy: 0.611328125\n",
      "Batch: 28, Loss: 1.0272303819656372, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.0909568071365356, Accuracy: 0.6533203125\n",
      "Batch: 30, Loss: 1.0768741369247437, Accuracy: 0.638671875\n",
      "Batch: 31, Loss: 1.1476333141326904, Accuracy: 0.634765625\n",
      "Batch: 32, Loss: 1.0233737230300903, Accuracy: 0.6474609375\n",
      "Batch: 33, Loss: 0.957830548286438, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.1016234159469604, Accuracy: 0.654296875\n",
      "Batch: 35, Loss: 1.04038405418396, Accuracy: 0.6513671875\n",
      "Batch: 36, Loss: 1.187260627746582, Accuracy: 0.6044921875\n",
      "Batch: 37, Loss: 1.2356061935424805, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.1981985569000244, Accuracy: 0.61328125\n",
      "Batch: 39, Loss: 1.0900673866271973, Accuracy: 0.640625\n",
      "Batch: 40, Loss: 1.1191203594207764, Accuracy: 0.6240234375\n",
      "Batch: 41, Loss: 1.1269843578338623, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.0680031776428223, Accuracy: 0.6455078125\n",
      "Batch: 43, Loss: 1.068364143371582, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 0.9704620242118835, Accuracy: 0.6669921875\n",
      "Batch: 45, Loss: 1.0237722396850586, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.1004664897918701, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.0626182556152344, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1185288429260254, Accuracy: 0.61328125\n",
      "Batch: 49, Loss: 1.1349520683288574, Accuracy: 0.6396484375\n",
      "Batch: 50, Loss: 1.089046835899353, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.1323503255844116, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.1529228687286377, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 1.1422572135925293, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.1507463455200195, Accuracy: 0.6044921875\n",
      "Batch: 55, Loss: 1.0806325674057007, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 1.0754892826080322, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.1052544116973877, Accuracy: 0.65625\n",
      "Batch: 58, Loss: 1.0820305347442627, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.134329080581665, Accuracy: 0.626953125\n",
      "Batch: 60, Loss: 1.2133498191833496, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1307480335235596, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.1296687126159668, Accuracy: 0.6494140625\n",
      "Batch: 63, Loss: 1.2031714916229248, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.1521427631378174, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.1444993019104004, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1522573232650757, Accuracy: 0.62109375\n",
      "Batch: 67, Loss: 1.0715932846069336, Accuracy: 0.6435546875\n",
      "Batch: 68, Loss: 1.1356170177459717, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.1892770528793335, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.1575794219970703, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.1213902235031128, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.153398036956787, Accuracy: 0.6015625\n",
      "Batch: 73, Loss: 1.161510705947876, Accuracy: 0.640625\n",
      "Batch: 74, Loss: 1.1250460147857666, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.09491765499115, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.047260046005249, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 1.0643407106399536, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.129371166229248, Accuracy: 0.63671875\n",
      "Batch: 79, Loss: 1.1145803928375244, Accuracy: 0.6279296875\n",
      "Batch: 80, Loss: 1.125659465789795, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.078026294708252, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.1132285594940186, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.214768648147583, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.0791385173797607, Accuracy: 0.658203125\n",
      "Batch: 85, Loss: 1.131531834602356, Accuracy: 0.6298828125\n",
      "Batch: 86, Loss: 1.1696250438690186, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.166420578956604, Accuracy: 0.6240234375\n",
      "Batch: 88, Loss: 1.127347707748413, Accuracy: 0.640625\n",
      "Batch: 89, Loss: 1.1010503768920898, Accuracy: 0.6591796875\n",
      "Batch: 90, Loss: 1.1281546354293823, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.0895349979400635, Accuracy: 0.64453125\n",
      "Batch: 92, Loss: 1.1084909439086914, Accuracy: 0.6396484375\n",
      "Batch: 93, Loss: 1.1563715934753418, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.210627555847168, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.089186668395996, Accuracy: 0.6416015625\n",
      "Batch: 96, Loss: 1.1713716983795166, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.1717978715896606, Accuracy: 0.6240234375\n",
      "Batch: 98, Loss: 1.0995111465454102, Accuracy: 0.6630859375\n",
      "Batch: 99, Loss: 1.1715775728225708, Accuracy: 0.6240234375\n",
      "Batch: 100, Loss: 1.048033356666565, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0544062852859497, Accuracy: 0.6669921875\n",
      "Batch: 102, Loss: 1.1181354522705078, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.111990213394165, Accuracy: 0.642578125\n",
      "Batch: 104, Loss: 1.1218948364257812, Accuracy: 0.646484375\n",
      "Batch: 105, Loss: 1.2096378803253174, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.1022746562957764, Accuracy: 0.6669921875\n",
      "Batch: 107, Loss: 1.182613492012024, Accuracy: 0.6201171875\n",
      "Batch: 108, Loss: 1.1618709564208984, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.1812986135482788, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1324719190597534, Accuracy: 0.6337890625\n",
      "Batch: 111, Loss: 1.1367377042770386, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.0664913654327393, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.0820616483688354, Accuracy: 0.650390625\n",
      "Batch: 114, Loss: 1.1292197704315186, Accuracy: 0.6220703125\n",
      "Batch: 115, Loss: 1.2034848928451538, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1503299474716187, Accuracy: 0.6357421875\n",
      "Batch: 117, Loss: 1.1248111724853516, Accuracy: 0.625\n",
      "Batch: 118, Loss: 1.1673420667648315, Accuracy: 0.623046875\n",
      "Batch: 119, Loss: 1.1845130920410156, Accuracy: 0.6142578125\n",
      "Batch: 120, Loss: 1.2370660305023193, Accuracy: 0.6201171875\n",
      "Batch: 121, Loss: 1.1551847457885742, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.19808030128479, Accuracy: 0.6328125\n",
      "Batch: 123, Loss: 1.15726900100708, Accuracy: 0.619140625\n",
      "Batch: 124, Loss: 1.1932857036590576, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.1092002391815186, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.2517569065093994, Accuracy: 0.5859375\n",
      "Batch: 127, Loss: 1.2717571258544922, Accuracy: 0.599609375\n",
      "Batch: 128, Loss: 1.1961764097213745, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1526442766189575, Accuracy: 0.6435546875\n",
      "Batch: 130, Loss: 1.1285591125488281, Accuracy: 0.6396484375\n",
      "Batch: 131, Loss: 1.212284803390503, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.0404833555221558, Accuracy: 0.650390625\n",
      "Batch: 133, Loss: 1.1284723281860352, Accuracy: 0.642578125\n",
      "Batch: 134, Loss: 1.1273393630981445, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 0.9916131496429443, Accuracy: 0.677734375\n",
      "Batch: 136, Loss: 1.1194238662719727, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.114537239074707, Accuracy: 0.65625\n",
      "Batch: 138, Loss: 1.2179741859436035, Accuracy: 0.599609375\n",
      "Batch: 139, Loss: 1.1408592462539673, Accuracy: 0.650390625\n",
      "Batch: 140, Loss: 1.2680609226226807, Accuracy: 0.6083984375\n",
      "Batch: 141, Loss: 1.1413195133209229, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.181623935699463, Accuracy: 0.62890625\n",
      "Batch: 143, Loss: 1.19438898563385, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.2057303190231323, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.237564206123352, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.155921459197998, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.182843804359436, Accuracy: 0.6103515625\n",
      "Batch: 148, Loss: 1.17100191116333, Accuracy: 0.6318359375\n",
      "Batch: 149, Loss: 1.1256341934204102, Accuracy: 0.634765625\n",
      "Batch: 150, Loss: 1.0974031686782837, Accuracy: 0.6533203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 151, Loss: 1.1176496744155884, Accuracy: 0.6396484375\n",
      "Batch: 152, Loss: 1.1622971296310425, Accuracy: 0.607421875\n",
      "Batch: 153, Loss: 1.1328654289245605, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.1183407306671143, Accuracy: 0.623046875\n",
      "Batch: 155, Loss: 1.0810165405273438, Accuracy: 0.6669921875\n",
      "Epoch 536/200\n",
      "Batch: 1, Loss: 1.2548346519470215, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.0581060647964478, Accuracy: 0.6650390625\n",
      "Batch: 3, Loss: 1.0323479175567627, Accuracy: 0.6640625\n",
      "Batch: 4, Loss: 1.1015245914459229, Accuracy: 0.6591796875\n",
      "Batch: 5, Loss: 1.009568691253662, Accuracy: 0.6787109375\n",
      "Batch: 6, Loss: 1.066753625869751, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 1.0124530792236328, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 1.0314271450042725, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 0.9797446131706238, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 0.9109993577003479, Accuracy: 0.6953125\n",
      "Batch: 11, Loss: 0.9514771699905396, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9842818379402161, Accuracy: 0.66796875\n",
      "Batch: 13, Loss: 1.0153192281723022, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9931547045707703, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9308246374130249, Accuracy: 0.673828125\n",
      "Batch: 16, Loss: 1.0051915645599365, Accuracy: 0.69921875\n",
      "Batch: 17, Loss: 1.05672025680542, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.0741045475006104, Accuracy: 0.6435546875\n",
      "Batch: 19, Loss: 1.186887502670288, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.0543601512908936, Accuracy: 0.6435546875\n",
      "Batch: 21, Loss: 1.0770580768585205, Accuracy: 0.6572265625\n",
      "Batch: 22, Loss: 1.2344473600387573, Accuracy: 0.603515625\n",
      "Batch: 23, Loss: 1.269068956375122, Accuracy: 0.583984375\n",
      "Batch: 24, Loss: 1.0971183776855469, Accuracy: 0.6220703125\n",
      "Batch: 25, Loss: 1.1615116596221924, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.1425087451934814, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.0710498094558716, Accuracy: 0.654296875\n",
      "Batch: 28, Loss: 1.0464423894882202, Accuracy: 0.6650390625\n",
      "Batch: 29, Loss: 1.0576303005218506, Accuracy: 0.6396484375\n",
      "Batch: 30, Loss: 1.158350944519043, Accuracy: 0.62109375\n",
      "Batch: 31, Loss: 1.1706702709197998, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.0442025661468506, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 0.9944667816162109, Accuracy: 0.666015625\n",
      "Batch: 34, Loss: 1.0868337154388428, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.155465006828308, Accuracy: 0.6279296875\n",
      "Batch: 36, Loss: 1.1608831882476807, Accuracy: 0.6240234375\n",
      "Batch: 37, Loss: 1.1435651779174805, Accuracy: 0.62890625\n",
      "Batch: 38, Loss: 1.0785791873931885, Accuracy: 0.646484375\n",
      "Batch: 39, Loss: 1.0879850387573242, Accuracy: 0.6513671875\n",
      "Batch: 40, Loss: 1.0813722610473633, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1124614477157593, Accuracy: 0.6572265625\n",
      "Batch: 42, Loss: 1.0374865531921387, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.0149272680282593, Accuracy: 0.6630859375\n",
      "Batch: 44, Loss: 1.0161712169647217, Accuracy: 0.6669921875\n",
      "Batch: 45, Loss: 1.0262131690979004, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.0633327960968018, Accuracy: 0.6298828125\n",
      "Batch: 47, Loss: 1.0749611854553223, Accuracy: 0.63671875\n",
      "Batch: 48, Loss: 1.0905888080596924, Accuracy: 0.623046875\n",
      "Batch: 49, Loss: 1.1639426946640015, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.1278058290481567, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.1389710903167725, Accuracy: 0.623046875\n",
      "Batch: 52, Loss: 1.2208225727081299, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1088075637817383, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.108372449874878, Accuracy: 0.65625\n",
      "Batch: 55, Loss: 1.1175400018692017, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.049023151397705, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.05137038230896, Accuracy: 0.6767578125\n",
      "Batch: 58, Loss: 1.066907286643982, Accuracy: 0.6474609375\n",
      "Batch: 59, Loss: 1.1051887273788452, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.1842039823532104, Accuracy: 0.615234375\n",
      "Batch: 61, Loss: 1.184335470199585, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.0547455549240112, Accuracy: 0.6474609375\n",
      "Batch: 63, Loss: 1.1277599334716797, Accuracy: 0.630859375\n",
      "Batch: 64, Loss: 1.159477949142456, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.2011312246322632, Accuracy: 0.6240234375\n",
      "Batch: 66, Loss: 1.1375025510787964, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.1646199226379395, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.0770487785339355, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.0894334316253662, Accuracy: 0.6494140625\n",
      "Batch: 70, Loss: 1.1003319025039673, Accuracy: 0.658203125\n",
      "Batch: 71, Loss: 1.1538584232330322, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.1629362106323242, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.1800116300582886, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.1056206226348877, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.065001130104065, Accuracy: 0.6669921875\n",
      "Batch: 76, Loss: 1.097535252571106, Accuracy: 0.6240234375\n",
      "Batch: 77, Loss: 1.078420639038086, Accuracy: 0.63671875\n",
      "Batch: 78, Loss: 1.1136095523834229, Accuracy: 0.6494140625\n",
      "Batch: 79, Loss: 1.1581695079803467, Accuracy: 0.6357421875\n",
      "Batch: 80, Loss: 1.1603761911392212, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.103499174118042, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.099055290222168, Accuracy: 0.6533203125\n",
      "Batch: 83, Loss: 1.2155075073242188, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.154679298400879, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1262199878692627, Accuracy: 0.638671875\n",
      "Batch: 86, Loss: 1.1433852910995483, Accuracy: 0.63671875\n",
      "Batch: 87, Loss: 1.1423304080963135, Accuracy: 0.6259765625\n",
      "Batch: 88, Loss: 1.1644810438156128, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.1317410469055176, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.1358656883239746, Accuracy: 0.62890625\n",
      "Batch: 91, Loss: 1.0972758531570435, Accuracy: 0.6533203125\n",
      "Batch: 92, Loss: 1.057263731956482, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 1.140791654586792, Accuracy: 0.630859375\n",
      "Batch: 94, Loss: 1.1692489385604858, Accuracy: 0.6123046875\n",
      "Batch: 95, Loss: 1.1233654022216797, Accuracy: 0.640625\n",
      "Batch: 96, Loss: 1.2005417346954346, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.1435171365737915, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.1355748176574707, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.139374852180481, Accuracy: 0.619140625\n",
      "Batch: 100, Loss: 1.064847707748413, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0813515186309814, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 1.1132932901382446, Accuracy: 0.6240234375\n",
      "Batch: 103, Loss: 1.166778326034546, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.0907869338989258, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.209545373916626, Accuracy: 0.640625\n",
      "Batch: 106, Loss: 1.1374629735946655, Accuracy: 0.62109375\n",
      "Batch: 107, Loss: 1.2457751035690308, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.136047601699829, Accuracy: 0.615234375\n",
      "Batch: 109, Loss: 1.1673449277877808, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.134490966796875, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.0857776403427124, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0741021633148193, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.1090775728225708, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.0924782752990723, Accuracy: 0.638671875\n",
      "Batch: 115, Loss: 1.1745505332946777, Accuracy: 0.5986328125\n",
      "Batch: 116, Loss: 1.1430459022521973, Accuracy: 0.6240234375\n",
      "Batch: 117, Loss: 1.1175897121429443, Accuracy: 0.630859375\n",
      "Batch: 118, Loss: 1.215179443359375, Accuracy: 0.59765625\n",
      "Batch: 119, Loss: 1.2046096324920654, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.2512884140014648, Accuracy: 0.619140625\n",
      "Batch: 121, Loss: 1.1804217100143433, Accuracy: 0.640625\n",
      "Batch: 122, Loss: 1.2298476696014404, Accuracy: 0.607421875\n",
      "Batch: 123, Loss: 1.1212598085403442, Accuracy: 0.6533203125\n",
      "Batch: 124, Loss: 1.1809543371200562, Accuracy: 0.625\n",
      "Batch: 125, Loss: 1.1386396884918213, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.1715389490127563, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.2169790267944336, Accuracy: 0.6201171875\n",
      "Batch: 128, Loss: 1.174525260925293, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.1594514846801758, Accuracy: 0.634765625\n",
      "Batch: 130, Loss: 1.1060129404067993, Accuracy: 0.646484375\n",
      "Batch: 131, Loss: 1.1985511779785156, Accuracy: 0.6015625\n",
      "Batch: 132, Loss: 1.0335079431533813, Accuracy: 0.654296875\n",
      "Batch: 133, Loss: 1.0967230796813965, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.0820050239562988, Accuracy: 0.6806640625\n",
      "Batch: 135, Loss: 1.001293420791626, Accuracy: 0.6640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 1.0388565063476562, Accuracy: 0.65625\n",
      "Batch: 137, Loss: 1.177239179611206, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.2659165859222412, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1160132884979248, Accuracy: 0.646484375\n",
      "Batch: 140, Loss: 1.1619352102279663, Accuracy: 0.630859375\n",
      "Batch: 141, Loss: 1.121822714805603, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.1421022415161133, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.2230384349822998, Accuracy: 0.6123046875\n",
      "Batch: 144, Loss: 1.1820698976516724, Accuracy: 0.6171875\n",
      "Batch: 145, Loss: 1.2269229888916016, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.1874254941940308, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.193753957748413, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.1738758087158203, Accuracy: 0.6513671875\n",
      "Batch: 149, Loss: 1.095574140548706, Accuracy: 0.630859375\n",
      "Batch: 150, Loss: 1.1068965196609497, Accuracy: 0.6259765625\n",
      "Batch: 151, Loss: 1.114702582359314, Accuracy: 0.6494140625\n",
      "Batch: 152, Loss: 1.1320016384124756, Accuracy: 0.6240234375\n",
      "Batch: 153, Loss: 1.0894355773925781, Accuracy: 0.650390625\n",
      "Batch: 154, Loss: 1.0887324810028076, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.0884852409362793, Accuracy: 0.65625\n",
      "Epoch 537/200\n",
      "Batch: 1, Loss: 1.2298673391342163, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.055753469467163, Accuracy: 0.646484375\n",
      "Batch: 3, Loss: 1.0602853298187256, Accuracy: 0.6328125\n",
      "Batch: 4, Loss: 1.0329426527023315, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 1.0126539468765259, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 0.9881782531738281, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 0.9792308807373047, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 1.0151180028915405, Accuracy: 0.6767578125\n",
      "Batch: 9, Loss: 0.9936436414718628, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9487471580505371, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9820829033851624, Accuracy: 0.685546875\n",
      "Batch: 12, Loss: 1.0241155624389648, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0201029777526855, Accuracy: 0.6826171875\n",
      "Batch: 14, Loss: 0.9309560060501099, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.885016918182373, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 1.008504867553711, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.0071533918380737, Accuracy: 0.6748046875\n",
      "Batch: 18, Loss: 1.083407998085022, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.1941725015640259, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.0862267017364502, Accuracy: 0.6533203125\n",
      "Batch: 21, Loss: 1.0698602199554443, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.167604923248291, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.2199735641479492, Accuracy: 0.578125\n",
      "Batch: 24, Loss: 1.058391809463501, Accuracy: 0.65625\n",
      "Batch: 25, Loss: 1.195526123046875, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.160266399383545, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.083486795425415, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.0456891059875488, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 1.031293511390686, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.088634729385376, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.189147710800171, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.012077808380127, Accuracy: 0.654296875\n",
      "Batch: 33, Loss: 1.030203104019165, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.102283239364624, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 1.1246315240859985, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.1700633764266968, Accuracy: 0.587890625\n",
      "Batch: 37, Loss: 1.1707823276519775, Accuracy: 0.6171875\n",
      "Batch: 38, Loss: 1.2285618782043457, Accuracy: 0.6064453125\n",
      "Batch: 39, Loss: 1.0155187845230103, Accuracy: 0.666015625\n",
      "Batch: 40, Loss: 1.1068499088287354, Accuracy: 0.6328125\n",
      "Batch: 41, Loss: 1.144002914428711, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.0582389831542969, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.0363318920135498, Accuracy: 0.642578125\n",
      "Batch: 44, Loss: 1.0240072011947632, Accuracy: 0.654296875\n",
      "Batch: 45, Loss: 1.0054166316986084, Accuracy: 0.6640625\n",
      "Batch: 46, Loss: 1.0793461799621582, Accuracy: 0.6455078125\n",
      "Batch: 47, Loss: 1.0914803743362427, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.0614632368087769, Accuracy: 0.6591796875\n",
      "Batch: 49, Loss: 1.1676911115646362, Accuracy: 0.626953125\n",
      "Batch: 50, Loss: 1.2069028615951538, Accuracy: 0.5986328125\n",
      "Batch: 51, Loss: 1.1851927042007446, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.2270917892456055, Accuracy: 0.619140625\n",
      "Batch: 53, Loss: 1.1245020627975464, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.1438043117523193, Accuracy: 0.623046875\n",
      "Batch: 55, Loss: 1.1098558902740479, Accuracy: 0.62890625\n",
      "Batch: 56, Loss: 1.130353331565857, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.0343875885009766, Accuracy: 0.673828125\n",
      "Batch: 58, Loss: 1.074627161026001, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 1.0696368217468262, Accuracy: 0.6630859375\n",
      "Batch: 60, Loss: 1.1738193035125732, Accuracy: 0.62109375\n",
      "Batch: 61, Loss: 1.1651463508605957, Accuracy: 0.6162109375\n",
      "Batch: 62, Loss: 1.157179355621338, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.1728124618530273, Accuracy: 0.6181640625\n",
      "Batch: 64, Loss: 1.188725233078003, Accuracy: 0.6240234375\n",
      "Batch: 65, Loss: 1.1678491830825806, Accuracy: 0.6123046875\n",
      "Batch: 66, Loss: 1.1086616516113281, Accuracy: 0.63671875\n",
      "Batch: 67, Loss: 1.177916407585144, Accuracy: 0.611328125\n",
      "Batch: 68, Loss: 1.09259033203125, Accuracy: 0.62890625\n",
      "Batch: 69, Loss: 1.133721947669983, Accuracy: 0.6435546875\n",
      "Batch: 70, Loss: 1.1609389781951904, Accuracy: 0.6142578125\n",
      "Batch: 71, Loss: 1.144407033920288, Accuracy: 0.6357421875\n",
      "Batch: 72, Loss: 1.1613304615020752, Accuracy: 0.62890625\n",
      "Batch: 73, Loss: 1.1624367237091064, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.0767245292663574, Accuracy: 0.654296875\n",
      "Batch: 75, Loss: 1.1840097904205322, Accuracy: 0.6171875\n",
      "Batch: 76, Loss: 1.0681837797164917, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.0528135299682617, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0694739818572998, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.1657531261444092, Accuracy: 0.6123046875\n",
      "Batch: 80, Loss: 1.137514591217041, Accuracy: 0.6298828125\n",
      "Batch: 81, Loss: 1.1054120063781738, Accuracy: 0.6484375\n",
      "Batch: 82, Loss: 1.140625, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.1757327318191528, Accuracy: 0.611328125\n",
      "Batch: 84, Loss: 1.1156127452850342, Accuracy: 0.6484375\n",
      "Batch: 85, Loss: 1.1272099018096924, Accuracy: 0.6474609375\n",
      "Batch: 86, Loss: 1.1696702241897583, Accuracy: 0.615234375\n",
      "Batch: 87, Loss: 1.1121068000793457, Accuracy: 0.6513671875\n",
      "Batch: 88, Loss: 1.1295442581176758, Accuracy: 0.6259765625\n",
      "Batch: 89, Loss: 1.100214958190918, Accuracy: 0.6396484375\n",
      "Batch: 90, Loss: 1.072540521621704, Accuracy: 0.6357421875\n",
      "Batch: 91, Loss: 1.0985126495361328, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.127786636352539, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.1253485679626465, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.184753656387329, Accuracy: 0.62109375\n",
      "Batch: 95, Loss: 1.1525614261627197, Accuracy: 0.6552734375\n",
      "Batch: 96, Loss: 1.161778450012207, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.1276386976242065, Accuracy: 0.634765625\n",
      "Batch: 98, Loss: 1.0929570198059082, Accuracy: 0.630859375\n",
      "Batch: 99, Loss: 1.137284278869629, Accuracy: 0.6396484375\n",
      "Batch: 100, Loss: 1.0264732837677002, Accuracy: 0.6533203125\n",
      "Batch: 101, Loss: 1.1035363674163818, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.186321496963501, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.0976496934890747, Accuracy: 0.65625\n",
      "Batch: 104, Loss: 1.071183443069458, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.195322036743164, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.1563818454742432, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.1901370286941528, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.1400216817855835, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1486057043075562, Accuracy: 0.625\n",
      "Batch: 110, Loss: 1.1130568981170654, Accuracy: 0.6279296875\n",
      "Batch: 111, Loss: 1.0787659883499146, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.0705572366714478, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1285182237625122, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.165624737739563, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.18426513671875, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.1439586877822876, Accuracy: 0.6455078125\n",
      "Batch: 117, Loss: 1.0816748142242432, Accuracy: 0.65625\n",
      "Batch: 118, Loss: 1.182273268699646, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.2553071975708008, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2809463739395142, Accuracy: 0.603515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 121, Loss: 1.2080919742584229, Accuracy: 0.62109375\n",
      "Batch: 122, Loss: 1.1772792339324951, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.1436837911605835, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.1394516229629517, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1310217380523682, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.2145822048187256, Accuracy: 0.609375\n",
      "Batch: 127, Loss: 1.210521936416626, Accuracy: 0.619140625\n",
      "Batch: 128, Loss: 1.1772680282592773, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.122412085533142, Accuracy: 0.6416015625\n",
      "Batch: 130, Loss: 1.11793851852417, Accuracy: 0.65625\n",
      "Batch: 131, Loss: 1.1820727586746216, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.0471813678741455, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 1.115696668624878, Accuracy: 0.609375\n",
      "Batch: 134, Loss: 1.0697855949401855, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.016547441482544, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.0834991931915283, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.0973341464996338, Accuracy: 0.6484375\n",
      "Batch: 138, Loss: 1.2008531093597412, Accuracy: 0.58984375\n",
      "Batch: 139, Loss: 1.1431171894073486, Accuracy: 0.623046875\n",
      "Batch: 140, Loss: 1.2474786043167114, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.108745813369751, Accuracy: 0.6552734375\n",
      "Batch: 142, Loss: 1.1647353172302246, Accuracy: 0.640625\n",
      "Batch: 143, Loss: 1.15623140335083, Accuracy: 0.6376953125\n",
      "Batch: 144, Loss: 1.2081658840179443, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.2108983993530273, Accuracy: 0.609375\n",
      "Batch: 146, Loss: 1.1941595077514648, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.185420036315918, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.1388750076293945, Accuracy: 0.626953125\n",
      "Batch: 149, Loss: 1.165771722793579, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.1029024124145508, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.1343439817428589, Accuracy: 0.6298828125\n",
      "Batch: 152, Loss: 1.210737943649292, Accuracy: 0.59765625\n",
      "Batch: 153, Loss: 1.0575417280197144, Accuracy: 0.658203125\n",
      "Batch: 154, Loss: 1.1344958543777466, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0331594944000244, Accuracy: 0.6611328125\n",
      "Epoch 538/200\n",
      "Batch: 1, Loss: 1.2242622375488281, Accuracy: 0.626953125\n",
      "Batch: 2, Loss: 1.1353068351745605, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0017540454864502, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0222580432891846, Accuracy: 0.6640625\n",
      "Batch: 5, Loss: 1.007869839668274, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.018981695175171, Accuracy: 0.662109375\n",
      "Batch: 7, Loss: 0.9876388907432556, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9798763394355774, Accuracy: 0.68359375\n",
      "Batch: 9, Loss: 1.020442008972168, Accuracy: 0.6650390625\n",
      "Batch: 10, Loss: 0.9478778839111328, Accuracy: 0.7060546875\n",
      "Batch: 11, Loss: 0.9608153104782104, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 1.0231951475143433, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.9907823801040649, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.9304397106170654, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9377129673957825, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 1.0290775299072266, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.110190749168396, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.0967576503753662, Accuracy: 0.6533203125\n",
      "Batch: 19, Loss: 1.220909595489502, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.125844955444336, Accuracy: 0.6484375\n",
      "Batch: 21, Loss: 1.0695277452468872, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1660116910934448, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.199995517730713, Accuracy: 0.6015625\n",
      "Batch: 24, Loss: 1.0584324598312378, Accuracy: 0.66015625\n",
      "Batch: 25, Loss: 1.0990020036697388, Accuracy: 0.6484375\n",
      "Batch: 26, Loss: 1.1436288356781006, Accuracy: 0.630859375\n",
      "Batch: 27, Loss: 1.0481410026550293, Accuracy: 0.6630859375\n",
      "Batch: 28, Loss: 1.1322166919708252, Accuracy: 0.6259765625\n",
      "Batch: 29, Loss: 1.0431967973709106, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1573410034179688, Accuracy: 0.6240234375\n",
      "Batch: 31, Loss: 1.1604458093643188, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.0719749927520752, Accuracy: 0.6611328125\n",
      "Batch: 33, Loss: 0.9965250492095947, Accuracy: 0.677734375\n",
      "Batch: 34, Loss: 1.0841970443725586, Accuracy: 0.6494140625\n",
      "Batch: 35, Loss: 1.1704909801483154, Accuracy: 0.609375\n",
      "Batch: 36, Loss: 1.1168476343154907, Accuracy: 0.6318359375\n",
      "Batch: 37, Loss: 1.166677474975586, Accuracy: 0.611328125\n",
      "Batch: 38, Loss: 1.0680193901062012, Accuracy: 0.662109375\n",
      "Batch: 39, Loss: 1.0928936004638672, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.08878493309021, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.1585197448730469, Accuracy: 0.607421875\n",
      "Batch: 42, Loss: 1.0821272134780884, Accuracy: 0.6318359375\n",
      "Batch: 43, Loss: 1.028356671333313, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.02662992477417, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.0417768955230713, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.1110295057296753, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.0703365802764893, Accuracy: 0.6552734375\n",
      "Batch: 48, Loss: 1.105782389640808, Accuracy: 0.658203125\n",
      "Batch: 49, Loss: 1.1637568473815918, Accuracy: 0.6474609375\n",
      "Batch: 50, Loss: 1.0595269203186035, Accuracy: 0.64453125\n",
      "Batch: 51, Loss: 1.1345845460891724, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.1788136959075928, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.1488549709320068, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.0898035764694214, Accuracy: 0.6435546875\n",
      "Batch: 55, Loss: 1.0776376724243164, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.1293411254882812, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.0680935382843018, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.0774178504943848, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 1.0854506492614746, Accuracy: 0.6494140625\n",
      "Batch: 60, Loss: 1.2152389287948608, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1714962720870972, Accuracy: 0.6015625\n",
      "Batch: 62, Loss: 1.081018090248108, Accuracy: 0.6484375\n",
      "Batch: 63, Loss: 1.1822540760040283, Accuracy: 0.615234375\n",
      "Batch: 64, Loss: 1.2335395812988281, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.1445972919464111, Accuracy: 0.62109375\n",
      "Batch: 66, Loss: 1.1581799983978271, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1145448684692383, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.1042029857635498, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.1272562742233276, Accuracy: 0.63671875\n",
      "Batch: 70, Loss: 1.2021727561950684, Accuracy: 0.6162109375\n",
      "Batch: 71, Loss: 1.172813057899475, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.1580941677093506, Accuracy: 0.638671875\n",
      "Batch: 73, Loss: 1.0945796966552734, Accuracy: 0.642578125\n",
      "Batch: 74, Loss: 1.1031025648117065, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.0659387111663818, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.096010446548462, Accuracy: 0.6494140625\n",
      "Batch: 77, Loss: 1.0335911512374878, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0554814338684082, Accuracy: 0.6533203125\n",
      "Batch: 79, Loss: 1.1022329330444336, Accuracy: 0.638671875\n",
      "Batch: 80, Loss: 1.1503541469573975, Accuracy: 0.6416015625\n",
      "Batch: 81, Loss: 1.0974681377410889, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 1.1133177280426025, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.1894010305404663, Accuracy: 0.60546875\n",
      "Batch: 84, Loss: 1.1201900243759155, Accuracy: 0.62890625\n",
      "Batch: 85, Loss: 1.1529313325881958, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.1504788398742676, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.1841318607330322, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.16615629196167, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1431632041931152, Accuracy: 0.642578125\n",
      "Batch: 90, Loss: 1.0823365449905396, Accuracy: 0.6396484375\n",
      "Batch: 91, Loss: 1.1229164600372314, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.099593162536621, Accuracy: 0.658203125\n",
      "Batch: 93, Loss: 1.1586410999298096, Accuracy: 0.6220703125\n",
      "Batch: 94, Loss: 1.1499814987182617, Accuracy: 0.6337890625\n",
      "Batch: 95, Loss: 1.1454658508300781, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.1681349277496338, Accuracy: 0.6416015625\n",
      "Batch: 97, Loss: 1.1388756036758423, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.125408411026001, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.076300859451294, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.0464451313018799, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.1058669090270996, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1867716312408447, Accuracy: 0.61328125\n",
      "Batch: 103, Loss: 1.1790180206298828, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1811747550964355, Accuracy: 0.6259765625\n",
      "Batch: 105, Loss: 1.1776021718978882, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 1.1467256546020508, Accuracy: 0.615234375\n",
      "Batch: 107, Loss: 1.1910452842712402, Accuracy: 0.6064453125\n",
      "Batch: 108, Loss: 1.1753206253051758, Accuracy: 0.6201171875\n",
      "Batch: 109, Loss: 1.2076072692871094, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.179142951965332, Accuracy: 0.609375\n",
      "Batch: 111, Loss: 1.1257644891738892, Accuracy: 0.6171875\n",
      "Batch: 112, Loss: 1.0966492891311646, Accuracy: 0.6591796875\n",
      "Batch: 113, Loss: 1.1362025737762451, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.1829540729522705, Accuracy: 0.62109375\n",
      "Batch: 115, Loss: 1.1889634132385254, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1801049709320068, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.1559542417526245, Accuracy: 0.6240234375\n",
      "Batch: 118, Loss: 1.205232858657837, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.2289358377456665, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2843739986419678, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.2164454460144043, Accuracy: 0.6025390625\n",
      "Batch: 122, Loss: 1.2333320379257202, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.1413052082061768, Accuracy: 0.6162109375\n",
      "Batch: 124, Loss: 1.1957083940505981, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.1335735321044922, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.2488985061645508, Accuracy: 0.587890625\n",
      "Batch: 127, Loss: 1.24750554561615, Accuracy: 0.5869140625\n",
      "Batch: 128, Loss: 1.144436240196228, Accuracy: 0.634765625\n",
      "Batch: 129, Loss: 1.2010769844055176, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.133966326713562, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1807087659835815, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.0791252851486206, Accuracy: 0.64453125\n",
      "Batch: 133, Loss: 1.0904732942581177, Accuracy: 0.625\n",
      "Batch: 134, Loss: 1.1106960773468018, Accuracy: 0.6640625\n",
      "Batch: 135, Loss: 1.0170228481292725, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.0940576791763306, Accuracy: 0.638671875\n",
      "Batch: 137, Loss: 1.1721440553665161, Accuracy: 0.62109375\n",
      "Batch: 138, Loss: 1.2484347820281982, Accuracy: 0.5908203125\n",
      "Batch: 139, Loss: 1.2110908031463623, Accuracy: 0.6064453125\n",
      "Batch: 140, Loss: 1.2690315246582031, Accuracy: 0.6015625\n",
      "Batch: 141, Loss: 1.1406971216201782, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.1499189138412476, Accuracy: 0.62890625\n",
      "Batch: 143, Loss: 1.225661277770996, Accuracy: 0.6064453125\n",
      "Batch: 144, Loss: 1.3328322172164917, Accuracy: 0.576171875\n",
      "Batch: 145, Loss: 1.250198245048523, Accuracy: 0.59765625\n",
      "Batch: 146, Loss: 1.166906714439392, Accuracy: 0.6318359375\n",
      "Batch: 147, Loss: 1.1878728866577148, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.2259411811828613, Accuracy: 0.5830078125\n",
      "Batch: 149, Loss: 1.2524745464324951, Accuracy: 0.5888671875\n",
      "Batch: 150, Loss: 1.1402992010116577, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.1565814018249512, Accuracy: 0.6201171875\n",
      "Batch: 152, Loss: 1.158300518989563, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1040399074554443, Accuracy: 0.6435546875\n",
      "Batch: 154, Loss: 1.1110835075378418, Accuracy: 0.646484375\n",
      "Batch: 155, Loss: 1.099879503250122, Accuracy: 0.634765625\n",
      "Epoch 539/200\n",
      "Batch: 1, Loss: 1.2256715297698975, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.1156361103057861, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 1.0798664093017578, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.1475634574890137, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0504722595214844, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.1018933057785034, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.05479896068573, Accuracy: 0.654296875\n",
      "Batch: 8, Loss: 0.963691234588623, Accuracy: 0.6962890625\n",
      "Batch: 9, Loss: 1.0405545234680176, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 1.0075747966766357, Accuracy: 0.6865234375\n",
      "Batch: 11, Loss: 0.9842338562011719, Accuracy: 0.6728515625\n",
      "Batch: 12, Loss: 0.9905191659927368, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 1.0600495338439941, Accuracy: 0.666015625\n",
      "Batch: 14, Loss: 1.0268818140029907, Accuracy: 0.65625\n",
      "Batch: 15, Loss: 0.9690783023834229, Accuracy: 0.66796875\n",
      "Batch: 16, Loss: 1.0608155727386475, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.0270538330078125, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.109871506690979, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2370551824569702, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.084566354751587, Accuracy: 0.642578125\n",
      "Batch: 21, Loss: 1.0830214023590088, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.2149189710617065, Accuracy: 0.6220703125\n",
      "Batch: 23, Loss: 1.2510930299758911, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1088275909423828, Accuracy: 0.6455078125\n",
      "Batch: 25, Loss: 1.106055736541748, Accuracy: 0.6435546875\n",
      "Batch: 26, Loss: 1.192629098892212, Accuracy: 0.62109375\n",
      "Batch: 27, Loss: 1.1308343410491943, Accuracy: 0.6083984375\n",
      "Batch: 28, Loss: 1.0847164392471313, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 1.0697953701019287, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.1569902896881104, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.18445885181427, Accuracy: 0.6220703125\n",
      "Batch: 32, Loss: 1.0530039072036743, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.001068115234375, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.1613856554031372, Accuracy: 0.6259765625\n",
      "Batch: 35, Loss: 1.0969315767288208, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.2210352420806885, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.2565269470214844, Accuracy: 0.603515625\n",
      "Batch: 38, Loss: 1.2752935886383057, Accuracy: 0.578125\n",
      "Batch: 39, Loss: 1.0875537395477295, Accuracy: 0.6240234375\n",
      "Batch: 40, Loss: 1.0867619514465332, Accuracy: 0.646484375\n",
      "Batch: 41, Loss: 1.1494592428207397, Accuracy: 0.6201171875\n",
      "Batch: 42, Loss: 1.1110941171646118, Accuracy: 0.6298828125\n",
      "Batch: 43, Loss: 1.0142616033554077, Accuracy: 0.6767578125\n",
      "Batch: 44, Loss: 1.0587894916534424, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 1.0122156143188477, Accuracy: 0.666015625\n",
      "Batch: 46, Loss: 1.1387497186660767, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.0755290985107422, Accuracy: 0.6435546875\n",
      "Batch: 48, Loss: 1.126828670501709, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1458035707473755, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.0917072296142578, Accuracy: 0.6552734375\n",
      "Batch: 51, Loss: 1.134083867073059, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.219632625579834, Accuracy: 0.5986328125\n",
      "Batch: 53, Loss: 1.1415112018585205, Accuracy: 0.6279296875\n",
      "Batch: 54, Loss: 1.1932209730148315, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.117638111114502, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.1356449127197266, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1171561479568481, Accuracy: 0.6396484375\n",
      "Batch: 58, Loss: 1.122531771659851, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.095947504043579, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.3032000064849854, Accuracy: 0.57421875\n",
      "Batch: 61, Loss: 1.1894662380218506, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.1409536600112915, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.1384003162384033, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.1762545108795166, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.1624270677566528, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.2165390253067017, Accuracy: 0.603515625\n",
      "Batch: 67, Loss: 1.1322274208068848, Accuracy: 0.6494140625\n",
      "Batch: 68, Loss: 1.036508321762085, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 1.1796634197235107, Accuracy: 0.626953125\n",
      "Batch: 70, Loss: 1.1221091747283936, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.155846357345581, Accuracy: 0.6162109375\n",
      "Batch: 72, Loss: 1.1639862060546875, Accuracy: 0.6181640625\n",
      "Batch: 73, Loss: 1.165578842163086, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.0740598440170288, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.0611159801483154, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.0410115718841553, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 1.040757417678833, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.0057823657989502, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.097841501235962, Accuracy: 0.6533203125\n",
      "Batch: 80, Loss: 1.1535063982009888, Accuracy: 0.6240234375\n",
      "Batch: 81, Loss: 1.1408953666687012, Accuracy: 0.6259765625\n",
      "Batch: 82, Loss: 1.1489830017089844, Accuracy: 0.63671875\n",
      "Batch: 83, Loss: 1.21669340133667, Accuracy: 0.599609375\n",
      "Batch: 84, Loss: 1.1239367723464966, Accuracy: 0.62890625\n",
      "Batch: 85, Loss: 1.1501432657241821, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.1517448425292969, Accuracy: 0.6220703125\n",
      "Batch: 87, Loss: 1.2024005651474, Accuracy: 0.6064453125\n",
      "Batch: 88, Loss: 1.1947739124298096, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1467350721359253, Accuracy: 0.6171875\n",
      "Batch: 90, Loss: 1.0705008506774902, Accuracy: 0.6494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 91, Loss: 1.124610185623169, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.1154401302337646, Accuracy: 0.6484375\n",
      "Batch: 93, Loss: 1.0929691791534424, Accuracy: 0.6591796875\n",
      "Batch: 94, Loss: 1.1647310256958008, Accuracy: 0.6083984375\n",
      "Batch: 95, Loss: 1.1883119344711304, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.2335375547409058, Accuracy: 0.6123046875\n",
      "Batch: 97, Loss: 1.188220739364624, Accuracy: 0.6123046875\n",
      "Batch: 98, Loss: 1.0824837684631348, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.1330623626708984, Accuracy: 0.623046875\n",
      "Batch: 100, Loss: 1.0440030097961426, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0546224117279053, Accuracy: 0.6552734375\n",
      "Batch: 102, Loss: 1.1569559574127197, Accuracy: 0.6494140625\n",
      "Batch: 103, Loss: 1.1390786170959473, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.1359655857086182, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.182154893875122, Accuracy: 0.634765625\n",
      "Batch: 106, Loss: 1.1454901695251465, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.240735411643982, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.1059391498565674, Accuracy: 0.63671875\n",
      "Batch: 109, Loss: 1.1979162693023682, Accuracy: 0.5966796875\n",
      "Batch: 110, Loss: 1.1248228549957275, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.0974762439727783, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.0990781784057617, Accuracy: 0.625\n",
      "Batch: 113, Loss: 1.1179146766662598, Accuracy: 0.6455078125\n",
      "Batch: 114, Loss: 1.1739835739135742, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.1434303522109985, Accuracy: 0.6318359375\n",
      "Batch: 116, Loss: 1.2129526138305664, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.1507554054260254, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 1.18772554397583, Accuracy: 0.61328125\n",
      "Batch: 119, Loss: 1.1873832941055298, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.2748854160308838, Accuracy: 0.6083984375\n",
      "Batch: 121, Loss: 1.18040132522583, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.1963461637496948, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.131734013557434, Accuracy: 0.6337890625\n",
      "Batch: 124, Loss: 1.2254611253738403, Accuracy: 0.6015625\n",
      "Batch: 125, Loss: 1.1700890064239502, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.1789450645446777, Accuracy: 0.6181640625\n",
      "Batch: 127, Loss: 1.2251336574554443, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.1744507551193237, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.1577786207199097, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.0912399291992188, Accuracy: 0.64453125\n",
      "Batch: 131, Loss: 1.198302149772644, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0562829971313477, Accuracy: 0.6494140625\n",
      "Batch: 133, Loss: 1.1443032026290894, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.1048219203948975, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.0611343383789062, Accuracy: 0.6298828125\n",
      "Batch: 136, Loss: 1.0892765522003174, Accuracy: 0.642578125\n",
      "Batch: 137, Loss: 1.1365396976470947, Accuracy: 0.6298828125\n",
      "Batch: 138, Loss: 1.2583556175231934, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.2195892333984375, Accuracy: 0.6005859375\n",
      "Batch: 140, Loss: 1.237334966659546, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.1846263408660889, Accuracy: 0.6044921875\n",
      "Batch: 142, Loss: 1.2270934581756592, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.2503385543823242, Accuracy: 0.578125\n",
      "Batch: 144, Loss: 1.2099688053131104, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.191676378250122, Accuracy: 0.6181640625\n",
      "Batch: 146, Loss: 1.198330044746399, Accuracy: 0.6279296875\n",
      "Batch: 147, Loss: 1.1905529499053955, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.2060338258743286, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.1314948797225952, Accuracy: 0.625\n",
      "Batch: 150, Loss: 1.1092519760131836, Accuracy: 0.6337890625\n",
      "Batch: 151, Loss: 1.1736390590667725, Accuracy: 0.623046875\n",
      "Batch: 152, Loss: 1.180664300918579, Accuracy: 0.6201171875\n",
      "Batch: 153, Loss: 1.115898609161377, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.0835473537445068, Accuracy: 0.6259765625\n",
      "Batch: 155, Loss: 1.1061551570892334, Accuracy: 0.6318359375\n",
      "Epoch 540/200\n",
      "Batch: 1, Loss: 1.1982433795928955, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0744116306304932, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0080567598342896, Accuracy: 0.6640625\n",
      "Batch: 4, Loss: 1.1105225086212158, Accuracy: 0.6357421875\n",
      "Batch: 5, Loss: 1.0071430206298828, Accuracy: 0.6591796875\n",
      "Batch: 6, Loss: 1.0614889860153198, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.047734022140503, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9566380977630615, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9993159770965576, Accuracy: 0.6728515625\n",
      "Batch: 10, Loss: 0.9626058340072632, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 0.9858987331390381, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 0.9985889196395874, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 1.0116641521453857, Accuracy: 0.6416015625\n",
      "Batch: 14, Loss: 0.9602429866790771, Accuracy: 0.6787109375\n",
      "Batch: 15, Loss: 0.9193335771560669, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 1.0396158695220947, Accuracy: 0.658203125\n",
      "Batch: 17, Loss: 1.0204938650131226, Accuracy: 0.6748046875\n",
      "Batch: 18, Loss: 1.1273767948150635, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.159052848815918, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0543755292892456, Accuracy: 0.671875\n",
      "Batch: 21, Loss: 1.1016905307769775, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2030093669891357, Accuracy: 0.6103515625\n",
      "Batch: 23, Loss: 1.2133350372314453, Accuracy: 0.5966796875\n",
      "Batch: 24, Loss: 1.1115037202835083, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 1.1067636013031006, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.1523857116699219, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.0659540891647339, Accuracy: 0.66015625\n",
      "Batch: 28, Loss: 1.0441219806671143, Accuracy: 0.654296875\n",
      "Batch: 29, Loss: 1.0497369766235352, Accuracy: 0.6533203125\n",
      "Batch: 30, Loss: 1.1972012519836426, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.1715086698532104, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.0297904014587402, Accuracy: 0.646484375\n",
      "Batch: 33, Loss: 0.951817512512207, Accuracy: 0.70703125\n",
      "Batch: 34, Loss: 1.0707968473434448, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.1022480726242065, Accuracy: 0.6337890625\n",
      "Batch: 36, Loss: 1.1776337623596191, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.2120904922485352, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.1112738847732544, Accuracy: 0.6337890625\n",
      "Batch: 39, Loss: 1.1140468120574951, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.0150541067123413, Accuracy: 0.6572265625\n",
      "Batch: 41, Loss: 1.0708940029144287, Accuracy: 0.65625\n",
      "Batch: 42, Loss: 1.0552701950073242, Accuracy: 0.6484375\n",
      "Batch: 43, Loss: 1.0302255153656006, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0882879495620728, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 1.0288007259368896, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.1211531162261963, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.0803083181381226, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.1512625217437744, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.1253693103790283, Accuracy: 0.625\n",
      "Batch: 50, Loss: 1.077155590057373, Accuracy: 0.640625\n",
      "Batch: 51, Loss: 1.1642991304397583, Accuracy: 0.6005859375\n",
      "Batch: 52, Loss: 1.2350847721099854, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1704447269439697, Accuracy: 0.60546875\n",
      "Batch: 54, Loss: 1.148878574371338, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.0572588443756104, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.1421453952789307, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.1127400398254395, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.0644809007644653, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 1.077233076095581, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.2135343551635742, Accuracy: 0.61328125\n",
      "Batch: 61, Loss: 1.1271696090698242, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.0985498428344727, Accuracy: 0.623046875\n",
      "Batch: 63, Loss: 1.15195631980896, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.1745631694793701, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.178072452545166, Accuracy: 0.6357421875\n",
      "Batch: 66, Loss: 1.087386131286621, Accuracy: 0.6494140625\n",
      "Batch: 67, Loss: 1.071108341217041, Accuracy: 0.642578125\n",
      "Batch: 68, Loss: 1.1087960004806519, Accuracy: 0.64453125\n",
      "Batch: 69, Loss: 1.1915849447250366, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.148943543434143, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.0938081741333008, Accuracy: 0.638671875\n",
      "Batch: 72, Loss: 1.1877697706222534, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.1802220344543457, Accuracy: 0.6064453125\n",
      "Batch: 74, Loss: 1.104049801826477, Accuracy: 0.6494140625\n",
      "Batch: 75, Loss: 1.106048345565796, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 1.0324960947036743, Accuracy: 0.677734375\n",
      "Batch: 77, Loss: 1.0512549877166748, Accuracy: 0.6337890625\n",
      "Batch: 78, Loss: 1.1288774013519287, Accuracy: 0.6357421875\n",
      "Batch: 79, Loss: 1.1351772546768188, Accuracy: 0.611328125\n",
      "Batch: 80, Loss: 1.1315852403640747, Accuracy: 0.625\n",
      "Batch: 81, Loss: 1.1001390218734741, Accuracy: 0.640625\n",
      "Batch: 82, Loss: 1.0876848697662354, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 1.1803255081176758, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.1040068864822388, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.1302504539489746, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.1285340785980225, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 1.1586239337921143, Accuracy: 0.615234375\n",
      "Batch: 88, Loss: 1.116601824760437, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.1097450256347656, Accuracy: 0.642578125\n",
      "Batch: 90, Loss: 1.0810997486114502, Accuracy: 0.638671875\n",
      "Batch: 91, Loss: 1.1312483549118042, Accuracy: 0.6171875\n",
      "Batch: 92, Loss: 1.1059589385986328, Accuracy: 0.6552734375\n",
      "Batch: 93, Loss: 1.1432981491088867, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.2142088413238525, Accuracy: 0.599609375\n",
      "Batch: 95, Loss: 1.138276219367981, Accuracy: 0.6318359375\n",
      "Batch: 96, Loss: 1.207352876663208, Accuracy: 0.6103515625\n",
      "Batch: 97, Loss: 1.185057520866394, Accuracy: 0.607421875\n",
      "Batch: 98, Loss: 1.1176490783691406, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1236095428466797, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.0037791728973389, Accuracy: 0.666015625\n",
      "Batch: 101, Loss: 1.0807499885559082, Accuracy: 0.64453125\n",
      "Batch: 102, Loss: 1.2070558071136475, Accuracy: 0.6103515625\n",
      "Batch: 103, Loss: 1.1520819664001465, Accuracy: 0.6142578125\n",
      "Batch: 104, Loss: 1.100126028060913, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.1977510452270508, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.1517497301101685, Accuracy: 0.6328125\n",
      "Batch: 107, Loss: 1.194810152053833, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.1420345306396484, Accuracy: 0.625\n",
      "Batch: 109, Loss: 1.1694884300231934, Accuracy: 0.626953125\n",
      "Batch: 110, Loss: 1.1350363492965698, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.1447467803955078, Accuracy: 0.623046875\n",
      "Batch: 112, Loss: 1.0680830478668213, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.1722242832183838, Accuracy: 0.6240234375\n",
      "Batch: 114, Loss: 1.1050260066986084, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.176377534866333, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1785719394683838, Accuracy: 0.607421875\n",
      "Batch: 117, Loss: 1.1647207736968994, Accuracy: 0.638671875\n",
      "Batch: 118, Loss: 1.206252098083496, Accuracy: 0.599609375\n",
      "Batch: 119, Loss: 1.2451512813568115, Accuracy: 0.5849609375\n",
      "Batch: 120, Loss: 1.2132000923156738, Accuracy: 0.634765625\n",
      "Batch: 121, Loss: 1.1849828958511353, Accuracy: 0.603515625\n",
      "Batch: 122, Loss: 1.173769474029541, Accuracy: 0.6220703125\n",
      "Batch: 123, Loss: 1.105181097984314, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.218271017074585, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.1590851545333862, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.1594607830047607, Accuracy: 0.6494140625\n",
      "Batch: 127, Loss: 1.1964647769927979, Accuracy: 0.6259765625\n",
      "Batch: 128, Loss: 1.2197448015213013, Accuracy: 0.611328125\n",
      "Batch: 129, Loss: 1.1683498620986938, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.1502048969268799, Accuracy: 0.6328125\n",
      "Batch: 131, Loss: 1.1826691627502441, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 0.9988170862197876, Accuracy: 0.6728515625\n",
      "Batch: 133, Loss: 1.0955005884170532, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.1345442533493042, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 1.0206379890441895, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.0771287679672241, Accuracy: 0.6552734375\n",
      "Batch: 137, Loss: 1.1348395347595215, Accuracy: 0.6318359375\n",
      "Batch: 138, Loss: 1.1644333600997925, Accuracy: 0.615234375\n",
      "Batch: 139, Loss: 1.169783115386963, Accuracy: 0.619140625\n",
      "Batch: 140, Loss: 1.1977002620697021, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.1891590356826782, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.112135410308838, Accuracy: 0.6435546875\n",
      "Batch: 143, Loss: 1.1605510711669922, Accuracy: 0.623046875\n",
      "Batch: 144, Loss: 1.2068288326263428, Accuracy: 0.6005859375\n",
      "Batch: 145, Loss: 1.2374985218048096, Accuracy: 0.580078125\n",
      "Batch: 146, Loss: 1.207744836807251, Accuracy: 0.6181640625\n",
      "Batch: 147, Loss: 1.1973445415496826, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.1688547134399414, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.1592224836349487, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.1381118297576904, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.0978705883026123, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.1522127389907837, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.1177854537963867, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.0708434581756592, Accuracy: 0.66015625\n",
      "Batch: 155, Loss: 1.0604782104492188, Accuracy: 0.642578125\n",
      "Saved Weights at epoch 540 to file Weights_540.h5\n",
      "Epoch 541/200\n",
      "Batch: 1, Loss: 1.1774485111236572, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.1103492975234985, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 1.0513861179351807, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 1.0724215507507324, Accuracy: 0.6552734375\n",
      "Batch: 5, Loss: 0.989893913269043, Accuracy: 0.673828125\n",
      "Batch: 6, Loss: 1.019653558731079, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 1.0025616884231567, Accuracy: 0.6826171875\n",
      "Batch: 8, Loss: 0.9648156762123108, Accuracy: 0.6943359375\n",
      "Batch: 9, Loss: 0.9814632534980774, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9714508056640625, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9999954700469971, Accuracy: 0.6689453125\n",
      "Batch: 12, Loss: 1.012831211090088, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.0750571489334106, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 0.973300576210022, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.9340803623199463, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.066742181777954, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.0329749584197998, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.089385986328125, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.1590062379837036, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 1.0952636003494263, Accuracy: 0.6435546875\n",
      "Batch: 21, Loss: 1.0500054359436035, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1814703941345215, Accuracy: 0.6220703125\n",
      "Batch: 23, Loss: 1.2220925092697144, Accuracy: 0.5947265625\n",
      "Batch: 24, Loss: 1.1132457256317139, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1394954919815063, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.1924052238464355, Accuracy: 0.6083984375\n",
      "Batch: 27, Loss: 1.1263121366500854, Accuracy: 0.630859375\n",
      "Batch: 28, Loss: 1.0574376583099365, Accuracy: 0.650390625\n",
      "Batch: 29, Loss: 1.06965970993042, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1180405616760254, Accuracy: 0.6240234375\n",
      "Batch: 31, Loss: 1.1807419061660767, Accuracy: 0.6142578125\n",
      "Batch: 32, Loss: 1.0435940027236938, Accuracy: 0.6533203125\n",
      "Batch: 33, Loss: 1.0039918422698975, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1151129007339478, Accuracy: 0.64453125\n",
      "Batch: 35, Loss: 1.1155827045440674, Accuracy: 0.6298828125\n",
      "Batch: 36, Loss: 1.1406166553497314, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.1963752508163452, Accuracy: 0.591796875\n",
      "Batch: 38, Loss: 1.1087236404418945, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.0666494369506836, Accuracy: 0.6513671875\n",
      "Batch: 40, Loss: 1.0703250169754028, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1570477485656738, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.0989758968353271, Accuracy: 0.640625\n",
      "Batch: 43, Loss: 1.0494619607925415, Accuracy: 0.6396484375\n",
      "Batch: 44, Loss: 1.0523748397827148, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 1.0621399879455566, Accuracy: 0.65625\n",
      "Batch: 46, Loss: 1.1086479425430298, Accuracy: 0.6298828125\n",
      "Batch: 47, Loss: 1.0854111909866333, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.1613733768463135, Accuracy: 0.59765625\n",
      "Batch: 49, Loss: 1.146350622177124, Accuracy: 0.638671875\n",
      "Batch: 50, Loss: 1.1415574550628662, Accuracy: 0.619140625\n",
      "Batch: 51, Loss: 1.086849570274353, Accuracy: 0.650390625\n",
      "Batch: 52, Loss: 1.2264459133148193, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.1349315643310547, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1428444385528564, Accuracy: 0.6455078125\n",
      "Batch: 55, Loss: 1.1105482578277588, Accuracy: 0.638671875\n",
      "Batch: 56, Loss: 1.0701675415039062, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.0575191974639893, Accuracy: 0.6435546875\n",
      "Batch: 58, Loss: 1.0804637670516968, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 1.087435007095337, Accuracy: 0.6533203125\n",
      "Batch: 60, Loss: 1.248892068862915, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1504111289978027, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1319700479507446, Accuracy: 0.638671875\n",
      "Batch: 63, Loss: 1.0989576578140259, Accuracy: 0.6416015625\n",
      "Batch: 64, Loss: 1.1724436283111572, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.1780815124511719, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.2062100172042847, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1246206760406494, Accuracy: 0.6328125\n",
      "Batch: 68, Loss: 1.0939455032348633, Accuracy: 0.6328125\n",
      "Batch: 69, Loss: 1.1274635791778564, Accuracy: 0.6328125\n",
      "Batch: 70, Loss: 1.140554428100586, Accuracy: 0.640625\n",
      "Batch: 71, Loss: 1.0849640369415283, Accuracy: 0.6435546875\n",
      "Batch: 72, Loss: 1.1831214427947998, Accuracy: 0.6083984375\n",
      "Batch: 73, Loss: 1.1199941635131836, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.0506755113601685, Accuracy: 0.6611328125\n",
      "Batch: 75, Loss: 1.0647271871566772, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.0261895656585693, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 1.055519461631775, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.033632755279541, Accuracy: 0.65625\n",
      "Batch: 79, Loss: 1.138198733329773, Accuracy: 0.630859375\n",
      "Batch: 80, Loss: 1.1849548816680908, Accuracy: 0.611328125\n",
      "Batch: 81, Loss: 1.0888887643814087, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.100234031677246, Accuracy: 0.6484375\n",
      "Batch: 83, Loss: 1.1427500247955322, Accuracy: 0.626953125\n",
      "Batch: 84, Loss: 1.091294288635254, Accuracy: 0.638671875\n",
      "Batch: 85, Loss: 1.1572818756103516, Accuracy: 0.6259765625\n",
      "Batch: 86, Loss: 1.1638603210449219, Accuracy: 0.64453125\n",
      "Batch: 87, Loss: 1.0826271772384644, Accuracy: 0.6328125\n",
      "Batch: 88, Loss: 1.1820557117462158, Accuracy: 0.6396484375\n",
      "Batch: 89, Loss: 1.1243655681610107, Accuracy: 0.6572265625\n",
      "Batch: 90, Loss: 1.084221601486206, Accuracy: 0.623046875\n",
      "Batch: 91, Loss: 1.0363526344299316, Accuracy: 0.6630859375\n",
      "Batch: 92, Loss: 1.0953505039215088, Accuracy: 0.6533203125\n",
      "Batch: 93, Loss: 1.083792805671692, Accuracy: 0.62890625\n",
      "Batch: 94, Loss: 1.17789888381958, Accuracy: 0.6435546875\n",
      "Batch: 95, Loss: 1.1150898933410645, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.151320457458496, Accuracy: 0.64453125\n",
      "Batch: 97, Loss: 1.106602430343628, Accuracy: 0.630859375\n",
      "Batch: 98, Loss: 1.065701961517334, Accuracy: 0.6494140625\n",
      "Batch: 99, Loss: 1.1468172073364258, Accuracy: 0.6328125\n",
      "Batch: 100, Loss: 1.0457005500793457, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.077374815940857, Accuracy: 0.642578125\n",
      "Batch: 102, Loss: 1.1912040710449219, Accuracy: 0.5947265625\n",
      "Batch: 103, Loss: 1.1256074905395508, Accuracy: 0.6591796875\n",
      "Batch: 104, Loss: 1.134066104888916, Accuracy: 0.625\n",
      "Batch: 105, Loss: 1.1624844074249268, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1521666049957275, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.222519874572754, Accuracy: 0.6064453125\n",
      "Batch: 108, Loss: 1.196179986000061, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.1536537408828735, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 1.1224682331085205, Accuracy: 0.6279296875\n",
      "Batch: 111, Loss: 1.139815092086792, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.084193468093872, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.164759635925293, Accuracy: 0.61328125\n",
      "Batch: 114, Loss: 1.1892393827438354, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.2135403156280518, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1677273511886597, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.121071696281433, Accuracy: 0.6474609375\n",
      "Batch: 118, Loss: 1.1731572151184082, Accuracy: 0.626953125\n",
      "Batch: 119, Loss: 1.1414849758148193, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.237015962600708, Accuracy: 0.6015625\n",
      "Batch: 121, Loss: 1.1247003078460693, Accuracy: 0.6376953125\n",
      "Batch: 122, Loss: 1.216115951538086, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.115752100944519, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.1323150396347046, Accuracy: 0.642578125\n",
      "Batch: 125, Loss: 1.2142707109451294, Accuracy: 0.6318359375\n",
      "Batch: 126, Loss: 1.2196533679962158, Accuracy: 0.6416015625\n",
      "Batch: 127, Loss: 1.1618695259094238, Accuracy: 0.642578125\n",
      "Batch: 128, Loss: 1.1468608379364014, Accuracy: 0.6328125\n",
      "Batch: 129, Loss: 1.1320877075195312, Accuracy: 0.646484375\n",
      "Batch: 130, Loss: 1.1628906726837158, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1884852647781372, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.0425705909729004, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 1.0680967569351196, Accuracy: 0.6533203125\n",
      "Batch: 134, Loss: 1.1132233142852783, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 1.0635989904403687, Accuracy: 0.66015625\n",
      "Batch: 136, Loss: 1.026533603668213, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 1.1627686023712158, Accuracy: 0.6123046875\n",
      "Batch: 138, Loss: 1.2216027975082397, Accuracy: 0.6044921875\n",
      "Batch: 139, Loss: 1.1028242111206055, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.1727900505065918, Accuracy: 0.6416015625\n",
      "Batch: 141, Loss: 1.1743595600128174, Accuracy: 0.619140625\n",
      "Batch: 142, Loss: 1.1493659019470215, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.2028567790985107, Accuracy: 0.607421875\n",
      "Batch: 144, Loss: 1.222780466079712, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.2476001977920532, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.1781911849975586, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.1563516855239868, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.1683658361434937, Accuracy: 0.60546875\n",
      "Batch: 149, Loss: 1.141345739364624, Accuracy: 0.6298828125\n",
      "Batch: 150, Loss: 1.1483021974563599, Accuracy: 0.6201171875\n",
      "Batch: 151, Loss: 1.1460466384887695, Accuracy: 0.6513671875\n",
      "Batch: 152, Loss: 1.1727855205535889, Accuracy: 0.6103515625\n",
      "Batch: 153, Loss: 1.0923469066619873, Accuracy: 0.6455078125\n",
      "Batch: 154, Loss: 1.1482954025268555, Accuracy: 0.615234375\n",
      "Batch: 155, Loss: 1.0519168376922607, Accuracy: 0.6728515625\n",
      "Epoch 542/200\n",
      "Batch: 1, Loss: 1.1839778423309326, Accuracy: 0.650390625\n",
      "Batch: 2, Loss: 1.0158841609954834, Accuracy: 0.671875\n",
      "Batch: 3, Loss: 0.9765846729278564, Accuracy: 0.671875\n",
      "Batch: 4, Loss: 1.016173243522644, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 0.992308497428894, Accuracy: 0.673828125\n",
      "Batch: 6, Loss: 0.9973208904266357, Accuracy: 0.6689453125\n",
      "Batch: 7, Loss: 1.0017316341400146, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9459595680236816, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 0.9970254898071289, Accuracy: 0.6689453125\n",
      "Batch: 10, Loss: 0.9341157674789429, Accuracy: 0.69140625\n",
      "Batch: 11, Loss: 0.9577354192733765, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 1.0004750490188599, Accuracy: 0.666015625\n",
      "Batch: 13, Loss: 0.9891175627708435, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9669786691665649, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.887319028377533, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 1.0059587955474854, Accuracy: 0.673828125\n",
      "Batch: 17, Loss: 1.0119719505310059, Accuracy: 0.650390625\n",
      "Batch: 18, Loss: 1.0813238620758057, Accuracy: 0.662109375\n",
      "Batch: 19, Loss: 1.1639676094055176, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0557737350463867, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.0972371101379395, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.1911261081695557, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.2236831188201904, Accuracy: 0.591796875\n",
      "Batch: 24, Loss: 1.0820295810699463, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.1435920000076294, Accuracy: 0.62109375\n",
      "Batch: 26, Loss: 1.1380863189697266, Accuracy: 0.625\n",
      "Batch: 27, Loss: 1.1516404151916504, Accuracy: 0.607421875\n",
      "Batch: 28, Loss: 1.0650171041488647, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.0480756759643555, Accuracy: 0.6513671875\n",
      "Batch: 30, Loss: 1.1468467712402344, Accuracy: 0.6279296875\n",
      "Batch: 31, Loss: 1.18839693069458, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.0695348978042603, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 0.9706557989120483, Accuracy: 0.673828125\n",
      "Batch: 34, Loss: 1.0976591110229492, Accuracy: 0.658203125\n",
      "Batch: 35, Loss: 1.1374247074127197, Accuracy: 0.6201171875\n",
      "Batch: 36, Loss: 1.1425145864486694, Accuracy: 0.626953125\n",
      "Batch: 37, Loss: 1.163492202758789, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.1428676843643188, Accuracy: 0.6162109375\n",
      "Batch: 39, Loss: 1.0600743293762207, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 1.1008880138397217, Accuracy: 0.6328125\n",
      "Batch: 41, Loss: 1.1070619821548462, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.0367693901062012, Accuracy: 0.6611328125\n",
      "Batch: 43, Loss: 1.035046935081482, Accuracy: 0.6474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 1.047739028930664, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.0477173328399658, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.1045030355453491, Accuracy: 0.6298828125\n",
      "Batch: 47, Loss: 1.0813472270965576, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0879526138305664, Accuracy: 0.654296875\n",
      "Batch: 49, Loss: 1.1401338577270508, Accuracy: 0.626953125\n",
      "Batch: 50, Loss: 1.1997030973434448, Accuracy: 0.59765625\n",
      "Batch: 51, Loss: 1.1867843866348267, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.1840003728866577, Accuracy: 0.615234375\n",
      "Batch: 53, Loss: 1.141850233078003, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1374460458755493, Accuracy: 0.6328125\n",
      "Batch: 55, Loss: 1.1140029430389404, Accuracy: 0.6416015625\n",
      "Batch: 56, Loss: 1.030397891998291, Accuracy: 0.66796875\n",
      "Batch: 57, Loss: 1.0877273082733154, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.1202986240386963, Accuracy: 0.6484375\n",
      "Batch: 59, Loss: 1.1512831449508667, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.2416954040527344, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.1864752769470215, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.139377474784851, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.1866192817687988, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2307369709014893, Accuracy: 0.603515625\n",
      "Batch: 65, Loss: 1.1748322248458862, Accuracy: 0.625\n",
      "Batch: 66, Loss: 1.136441946029663, Accuracy: 0.650390625\n",
      "Batch: 67, Loss: 1.0975154638290405, Accuracy: 0.642578125\n",
      "Batch: 68, Loss: 1.072462797164917, Accuracy: 0.6728515625\n",
      "Batch: 69, Loss: 1.1436797380447388, Accuracy: 0.6201171875\n",
      "Batch: 70, Loss: 1.157282829284668, Accuracy: 0.6328125\n",
      "Batch: 71, Loss: 1.1037309169769287, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.171147346496582, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.159308671951294, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.1398899555206299, Accuracy: 0.6181640625\n",
      "Batch: 75, Loss: 1.151369571685791, Accuracy: 0.615234375\n",
      "Batch: 76, Loss: 1.0594149827957153, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 1.0481816530227661, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0336968898773193, Accuracy: 0.669921875\n",
      "Batch: 79, Loss: 1.1446712017059326, Accuracy: 0.634765625\n",
      "Batch: 80, Loss: 1.1302695274353027, Accuracy: 0.634765625\n",
      "Batch: 81, Loss: 1.0723211765289307, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.0981214046478271, Accuracy: 0.6533203125\n",
      "Batch: 83, Loss: 1.1836023330688477, Accuracy: 0.626953125\n",
      "Batch: 84, Loss: 1.1359939575195312, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.1262011528015137, Accuracy: 0.63671875\n",
      "Batch: 86, Loss: 1.1526761054992676, Accuracy: 0.6220703125\n",
      "Batch: 87, Loss: 1.1276637315750122, Accuracy: 0.640625\n",
      "Batch: 88, Loss: 1.150687575340271, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.1232423782348633, Accuracy: 0.6455078125\n",
      "Batch: 90, Loss: 1.0321598052978516, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.1215097904205322, Accuracy: 0.634765625\n",
      "Batch: 92, Loss: 1.0435523986816406, Accuracy: 0.6748046875\n",
      "Batch: 93, Loss: 1.2036885023117065, Accuracy: 0.6220703125\n",
      "Batch: 94, Loss: 1.1423882246017456, Accuracy: 0.625\n",
      "Batch: 95, Loss: 1.1650118827819824, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.1835962533950806, Accuracy: 0.6337890625\n",
      "Batch: 97, Loss: 1.1003766059875488, Accuracy: 0.6376953125\n",
      "Batch: 98, Loss: 1.1124202013015747, Accuracy: 0.62890625\n",
      "Batch: 99, Loss: 1.1239755153656006, Accuracy: 0.6455078125\n",
      "Batch: 100, Loss: 1.026741623878479, Accuracy: 0.6591796875\n",
      "Batch: 101, Loss: 1.1123340129852295, Accuracy: 0.65625\n",
      "Batch: 102, Loss: 1.1674277782440186, Accuracy: 0.6328125\n",
      "Batch: 103, Loss: 1.1133304834365845, Accuracy: 0.6474609375\n",
      "Batch: 104, Loss: 1.15492844581604, Accuracy: 0.611328125\n",
      "Batch: 105, Loss: 1.1884169578552246, Accuracy: 0.6181640625\n",
      "Batch: 106, Loss: 1.1159424781799316, Accuracy: 0.6298828125\n",
      "Batch: 107, Loss: 1.1505422592163086, Accuracy: 0.611328125\n",
      "Batch: 108, Loss: 1.1329076290130615, Accuracy: 0.6142578125\n",
      "Batch: 109, Loss: 1.1599071025848389, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 1.0979084968566895, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.0861577987670898, Accuracy: 0.6572265625\n",
      "Batch: 112, Loss: 1.0909103155136108, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1930146217346191, Accuracy: 0.6259765625\n",
      "Batch: 114, Loss: 1.1447601318359375, Accuracy: 0.6142578125\n",
      "Batch: 115, Loss: 1.1439316272735596, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.1145778894424438, Accuracy: 0.6474609375\n",
      "Batch: 117, Loss: 1.127495288848877, Accuracy: 0.64453125\n",
      "Batch: 118, Loss: 1.186774492263794, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.2036938667297363, Accuracy: 0.619140625\n",
      "Batch: 120, Loss: 1.2723034620285034, Accuracy: 0.609375\n",
      "Batch: 121, Loss: 1.1563359498977661, Accuracy: 0.619140625\n",
      "Batch: 122, Loss: 1.2494548559188843, Accuracy: 0.5966796875\n",
      "Batch: 123, Loss: 1.1262948513031006, Accuracy: 0.654296875\n",
      "Batch: 124, Loss: 1.2103114128112793, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.136471152305603, Accuracy: 0.6455078125\n",
      "Batch: 126, Loss: 1.196111798286438, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2131046056747437, Accuracy: 0.619140625\n",
      "Batch: 128, Loss: 1.1569457054138184, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.1452317237854004, Accuracy: 0.623046875\n",
      "Batch: 130, Loss: 1.0697216987609863, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.179835557937622, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.0445983409881592, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.1069519519805908, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.149183988571167, Accuracy: 0.646484375\n",
      "Batch: 135, Loss: 1.007554531097412, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.0837624073028564, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.07796311378479, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.1529420614242554, Accuracy: 0.6298828125\n",
      "Batch: 139, Loss: 1.1838300228118896, Accuracy: 0.6162109375\n",
      "Batch: 140, Loss: 1.2004035711288452, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1667225360870361, Accuracy: 0.6416015625\n",
      "Batch: 142, Loss: 1.1672930717468262, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.1535813808441162, Accuracy: 0.6396484375\n",
      "Batch: 144, Loss: 1.2353051900863647, Accuracy: 0.5859375\n",
      "Batch: 145, Loss: 1.2625086307525635, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.1763501167297363, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.1706753969192505, Accuracy: 0.6005859375\n",
      "Batch: 148, Loss: 1.1235331296920776, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.2358558177947998, Accuracy: 0.5966796875\n",
      "Batch: 150, Loss: 1.0429654121398926, Accuracy: 0.662109375\n",
      "Batch: 151, Loss: 1.1902422904968262, Accuracy: 0.611328125\n",
      "Batch: 152, Loss: 1.158689022064209, Accuracy: 0.6201171875\n",
      "Batch: 153, Loss: 1.1213668584823608, Accuracy: 0.640625\n",
      "Batch: 154, Loss: 1.1119334697723389, Accuracy: 0.640625\n",
      "Batch: 155, Loss: 1.0719914436340332, Accuracy: 0.6494140625\n",
      "Epoch 543/200\n",
      "Batch: 1, Loss: 1.1891489028930664, Accuracy: 0.6533203125\n",
      "Batch: 2, Loss: 1.0852432250976562, Accuracy: 0.6455078125\n",
      "Batch: 3, Loss: 1.041738748550415, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.0346091985702515, Accuracy: 0.658203125\n",
      "Batch: 5, Loss: 1.0135486125946045, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.044138789176941, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 1.034489631652832, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 1.0304524898529053, Accuracy: 0.646484375\n",
      "Batch: 9, Loss: 0.9574716687202454, Accuracy: 0.6787109375\n",
      "Batch: 10, Loss: 0.9077427387237549, Accuracy: 0.697265625\n",
      "Batch: 11, Loss: 0.9090061187744141, Accuracy: 0.7080078125\n",
      "Batch: 12, Loss: 0.9965578317642212, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 0.9870779514312744, Accuracy: 0.671875\n",
      "Batch: 14, Loss: 0.9719340205192566, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.9922857284545898, Accuracy: 0.6845703125\n",
      "Batch: 16, Loss: 1.0409915447235107, Accuracy: 0.63671875\n",
      "Batch: 17, Loss: 1.0417689085006714, Accuracy: 0.6435546875\n",
      "Batch: 18, Loss: 1.0444389581680298, Accuracy: 0.6689453125\n",
      "Batch: 19, Loss: 1.2647712230682373, Accuracy: 0.5849609375\n",
      "Batch: 20, Loss: 1.0459387302398682, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.0790836811065674, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.1367065906524658, Accuracy: 0.6396484375\n",
      "Batch: 23, Loss: 1.2244832515716553, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.1000263690948486, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.1441289186477661, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.1506218910217285, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.011869192123413, Accuracy: 0.666015625\n",
      "Batch: 28, Loss: 1.0530805587768555, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 1.0512038469314575, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 1.1663228273391724, Accuracy: 0.623046875\n",
      "Batch: 31, Loss: 1.235390543937683, Accuracy: 0.5908203125\n",
      "Batch: 32, Loss: 1.0488309860229492, Accuracy: 0.658203125\n",
      "Batch: 33, Loss: 1.0100975036621094, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.1328980922698975, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.1133579015731812, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.1713857650756836, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.1584668159484863, Accuracy: 0.6240234375\n",
      "Batch: 38, Loss: 1.1487281322479248, Accuracy: 0.6123046875\n",
      "Batch: 39, Loss: 1.0775777101516724, Accuracy: 0.6552734375\n",
      "Batch: 40, Loss: 1.0983860492706299, Accuracy: 0.6259765625\n",
      "Batch: 41, Loss: 1.1021273136138916, Accuracy: 0.640625\n",
      "Batch: 42, Loss: 1.0948508977890015, Accuracy: 0.64453125\n",
      "Batch: 43, Loss: 0.9986579418182373, Accuracy: 0.6611328125\n",
      "Batch: 44, Loss: 1.0435500144958496, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.0532888174057007, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.076499104499817, Accuracy: 0.640625\n",
      "Batch: 47, Loss: 1.0705647468566895, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1345545053482056, Accuracy: 0.6171875\n",
      "Batch: 49, Loss: 1.1048446893692017, Accuracy: 0.6455078125\n",
      "Batch: 50, Loss: 1.1465355157852173, Accuracy: 0.6279296875\n",
      "Batch: 51, Loss: 1.1473219394683838, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.2351770401000977, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.1387789249420166, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.1490155458450317, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.107800006866455, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.0796328783035278, Accuracy: 0.6552734375\n",
      "Batch: 57, Loss: 1.0958079099655151, Accuracy: 0.65625\n",
      "Batch: 58, Loss: 1.0957155227661133, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 1.0868170261383057, Accuracy: 0.6640625\n",
      "Batch: 60, Loss: 1.239571213722229, Accuracy: 0.59375\n",
      "Batch: 61, Loss: 1.1595091819763184, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.167140007019043, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.1246980428695679, Accuracy: 0.6396484375\n",
      "Batch: 64, Loss: 1.1958332061767578, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1332228183746338, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.1213555335998535, Accuracy: 0.64453125\n",
      "Batch: 67, Loss: 1.1563775539398193, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0674290657043457, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1730051040649414, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.1549830436706543, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.1411296129226685, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.1906020641326904, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.1660428047180176, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.0845941305160522, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.0672435760498047, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.0697259902954102, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 0.9710581302642822, Accuracy: 0.681640625\n",
      "Batch: 78, Loss: 1.0522007942199707, Accuracy: 0.6572265625\n",
      "Batch: 79, Loss: 1.0986865758895874, Accuracy: 0.666015625\n",
      "Batch: 80, Loss: 1.1314691305160522, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.1033785343170166, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.1219916343688965, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.1828612089157104, Accuracy: 0.6357421875\n",
      "Batch: 84, Loss: 1.101003646850586, Accuracy: 0.6474609375\n",
      "Batch: 85, Loss: 1.1217148303985596, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.210745930671692, Accuracy: 0.595703125\n",
      "Batch: 87, Loss: 1.1357660293579102, Accuracy: 0.6259765625\n",
      "Batch: 88, Loss: 1.1494433879852295, Accuracy: 0.619140625\n",
      "Batch: 89, Loss: 1.1055996417999268, Accuracy: 0.6513671875\n",
      "Batch: 90, Loss: 1.0841240882873535, Accuracy: 0.66015625\n",
      "Batch: 91, Loss: 1.1217079162597656, Accuracy: 0.640625\n",
      "Batch: 92, Loss: 1.107215404510498, Accuracy: 0.6416015625\n",
      "Batch: 93, Loss: 1.1046943664550781, Accuracy: 0.6474609375\n",
      "Batch: 94, Loss: 1.1600446701049805, Accuracy: 0.6328125\n",
      "Batch: 95, Loss: 1.1242398023605347, Accuracy: 0.646484375\n",
      "Batch: 96, Loss: 1.2004058361053467, Accuracy: 0.6103515625\n",
      "Batch: 97, Loss: 1.103082299232483, Accuracy: 0.6376953125\n",
      "Batch: 98, Loss: 1.1200642585754395, Accuracy: 0.63671875\n",
      "Batch: 99, Loss: 1.1557323932647705, Accuracy: 0.6455078125\n",
      "Batch: 100, Loss: 1.0730299949645996, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.034576416015625, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 1.1098501682281494, Accuracy: 0.6357421875\n",
      "Batch: 103, Loss: 1.149694800376892, Accuracy: 0.6455078125\n",
      "Batch: 104, Loss: 1.0958781242370605, Accuracy: 0.65234375\n",
      "Batch: 105, Loss: 1.2183668613433838, Accuracy: 0.6064453125\n",
      "Batch: 106, Loss: 1.1819093227386475, Accuracy: 0.62890625\n",
      "Batch: 107, Loss: 1.2174986600875854, Accuracy: 0.5908203125\n",
      "Batch: 108, Loss: 1.1649272441864014, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.1767386198043823, Accuracy: 0.6201171875\n",
      "Batch: 110, Loss: 1.1161222457885742, Accuracy: 0.6513671875\n",
      "Batch: 111, Loss: 1.1063060760498047, Accuracy: 0.6328125\n",
      "Batch: 112, Loss: 1.017274260520935, Accuracy: 0.6787109375\n",
      "Batch: 113, Loss: 1.1491559743881226, Accuracy: 0.6298828125\n",
      "Batch: 114, Loss: 1.1208720207214355, Accuracy: 0.6318359375\n",
      "Batch: 115, Loss: 1.1241934299468994, Accuracy: 0.634765625\n",
      "Batch: 116, Loss: 1.1607699394226074, Accuracy: 0.6201171875\n",
      "Batch: 117, Loss: 1.1046504974365234, Accuracy: 0.6240234375\n",
      "Batch: 118, Loss: 1.1612751483917236, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.1521711349487305, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.2939822673797607, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.1507066488265991, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.2201602458953857, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.1373995542526245, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.1818015575408936, Accuracy: 0.6318359375\n",
      "Batch: 125, Loss: 1.1120600700378418, Accuracy: 0.65625\n",
      "Batch: 126, Loss: 1.1643145084381104, Accuracy: 0.640625\n",
      "Batch: 127, Loss: 1.2212105989456177, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.1820083856582642, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.2104628086090088, Accuracy: 0.6025390625\n",
      "Batch: 130, Loss: 1.1025936603546143, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.195094347000122, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.0325672626495361, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.1181801557540894, Accuracy: 0.62109375\n",
      "Batch: 134, Loss: 1.1211907863616943, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 1.0031131505966187, Accuracy: 0.671875\n",
      "Batch: 136, Loss: 1.0734872817993164, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.1097850799560547, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 1.205562949180603, Accuracy: 0.6103515625\n",
      "Batch: 139, Loss: 1.2149704694747925, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.2441015243530273, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.129082441329956, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.1456102132797241, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.1558160781860352, Accuracy: 0.6103515625\n",
      "Batch: 144, Loss: 1.2338674068450928, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2661030292510986, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.2259747982025146, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1853013038635254, Accuracy: 0.6142578125\n",
      "Batch: 148, Loss: 1.1584824323654175, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.1074724197387695, Accuracy: 0.6240234375\n",
      "Batch: 150, Loss: 1.1382722854614258, Accuracy: 0.6396484375\n",
      "Batch: 151, Loss: 1.1256463527679443, Accuracy: 0.65234375\n",
      "Batch: 152, Loss: 1.1004561185836792, Accuracy: 0.6328125\n",
      "Batch: 153, Loss: 1.1211013793945312, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.0952568054199219, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.0994683504104614, Accuracy: 0.6376953125\n",
      "Epoch 544/200\n",
      "Batch: 1, Loss: 1.1922850608825684, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 1.0347760915756226, Accuracy: 0.671875\n",
      "Batch: 3, Loss: 1.0502674579620361, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 1.066867470741272, Accuracy: 0.6396484375\n",
      "Batch: 5, Loss: 1.0027034282684326, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.0449976921081543, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 1.0309481620788574, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9484188556671143, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 0.9650624394416809, Accuracy: 0.6904296875\n",
      "Batch: 10, Loss: 0.9885194301605225, Accuracy: 0.6552734375\n",
      "Batch: 11, Loss: 0.9336646795272827, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 0.9938451051712036, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 1.0222816467285156, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.939456582069397, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.9207422733306885, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 0.9948679804801941, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.0881555080413818, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.1280087232589722, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.167447566986084, Accuracy: 0.6328125\n",
      "Batch: 20, Loss: 1.0730209350585938, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0823866128921509, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.1997859477996826, Accuracy: 0.6181640625\n",
      "Batch: 23, Loss: 1.1725441217422485, Accuracy: 0.630859375\n",
      "Batch: 24, Loss: 1.071624517440796, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.1418635845184326, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.135498285293579, Accuracy: 0.62890625\n",
      "Batch: 27, Loss: 1.1150318384170532, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0900468826293945, Accuracy: 0.6376953125\n",
      "Batch: 29, Loss: 1.000763177871704, Accuracy: 0.67578125\n",
      "Batch: 30, Loss: 1.1132895946502686, Accuracy: 0.6328125\n",
      "Batch: 31, Loss: 1.187070369720459, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.0609341859817505, Accuracy: 0.6474609375\n",
      "Batch: 33, Loss: 0.9823689460754395, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.0431976318359375, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 1.054053544998169, Accuracy: 0.6513671875\n",
      "Batch: 36, Loss: 1.1567376852035522, Accuracy: 0.634765625\n",
      "Batch: 37, Loss: 1.1603666543960571, Accuracy: 0.625\n",
      "Batch: 38, Loss: 1.119408369064331, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.0866018533706665, Accuracy: 0.6533203125\n",
      "Batch: 40, Loss: 1.0531728267669678, Accuracy: 0.6611328125\n",
      "Batch: 41, Loss: 1.131086826324463, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.0272302627563477, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.0233099460601807, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 1.0569344758987427, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 1.034698486328125, Accuracy: 0.6533203125\n",
      "Batch: 46, Loss: 1.11716890335083, Accuracy: 0.6357421875\n",
      "Batch: 47, Loss: 1.0904741287231445, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0814907550811768, Accuracy: 0.6455078125\n",
      "Batch: 49, Loss: 1.167384147644043, Accuracy: 0.626953125\n",
      "Batch: 50, Loss: 1.0639426708221436, Accuracy: 0.6494140625\n",
      "Batch: 51, Loss: 1.1287169456481934, Accuracy: 0.630859375\n",
      "Batch: 52, Loss: 1.1861541271209717, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1684263944625854, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.140913486480713, Accuracy: 0.630859375\n",
      "Batch: 55, Loss: 1.0650718212127686, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.071026086807251, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 1.0713952779769897, Accuracy: 0.66015625\n",
      "Batch: 58, Loss: 1.0836067199707031, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.1446664333343506, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.2195459604263306, Accuracy: 0.5966796875\n",
      "Batch: 61, Loss: 1.1313982009887695, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.1061553955078125, Accuracy: 0.646484375\n",
      "Batch: 63, Loss: 1.106451153755188, Accuracy: 0.6416015625\n",
      "Batch: 64, Loss: 1.1588799953460693, Accuracy: 0.6240234375\n",
      "Batch: 65, Loss: 1.1735901832580566, Accuracy: 0.62109375\n",
      "Batch: 66, Loss: 1.1460882425308228, Accuracy: 0.6181640625\n",
      "Batch: 67, Loss: 1.162660002708435, Accuracy: 0.6162109375\n",
      "Batch: 68, Loss: 1.0646162033081055, Accuracy: 0.65234375\n",
      "Batch: 69, Loss: 1.217298984527588, Accuracy: 0.6220703125\n",
      "Batch: 70, Loss: 1.135244607925415, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.0802549123764038, Accuracy: 0.6455078125\n",
      "Batch: 72, Loss: 1.2182600498199463, Accuracy: 0.59375\n",
      "Batch: 73, Loss: 1.1725183725357056, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.0764764547348022, Accuracy: 0.66015625\n",
      "Batch: 75, Loss: 1.099820613861084, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.0480494499206543, Accuracy: 0.6650390625\n",
      "Batch: 77, Loss: 1.0549280643463135, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.0539507865905762, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.0886669158935547, Accuracy: 0.65234375\n",
      "Batch: 80, Loss: 1.128584384918213, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.1112935543060303, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.0919244289398193, Accuracy: 0.65234375\n",
      "Batch: 83, Loss: 1.2133300304412842, Accuracy: 0.603515625\n",
      "Batch: 84, Loss: 1.1833782196044922, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.1290974617004395, Accuracy: 0.6396484375\n",
      "Batch: 86, Loss: 1.151834487915039, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 1.112432599067688, Accuracy: 0.6357421875\n",
      "Batch: 88, Loss: 1.1154024600982666, Accuracy: 0.6162109375\n",
      "Batch: 89, Loss: 1.0791064500808716, Accuracy: 0.6689453125\n",
      "Batch: 90, Loss: 1.0675034523010254, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.1222736835479736, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.0690041780471802, Accuracy: 0.669921875\n",
      "Batch: 93, Loss: 1.1034765243530273, Accuracy: 0.6650390625\n",
      "Batch: 94, Loss: 1.188812494277954, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.1142655611038208, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.1636455059051514, Accuracy: 0.6259765625\n",
      "Batch: 97, Loss: 1.1484512090682983, Accuracy: 0.625\n",
      "Batch: 98, Loss: 1.0908865928649902, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.106544017791748, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.0182100534439087, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 1.0613970756530762, Accuracy: 0.666015625\n",
      "Batch: 102, Loss: 1.1610174179077148, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.0899910926818848, Accuracy: 0.6513671875\n",
      "Batch: 104, Loss: 1.1229196786880493, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.1836538314819336, Accuracy: 0.6328125\n",
      "Batch: 106, Loss: 1.1935832500457764, Accuracy: 0.60546875\n",
      "Batch: 107, Loss: 1.2625302076339722, Accuracy: 0.58984375\n",
      "Batch: 108, Loss: 1.1218619346618652, Accuracy: 0.6220703125\n",
      "Batch: 109, Loss: 1.1865272521972656, Accuracy: 0.599609375\n",
      "Batch: 110, Loss: 1.1566016674041748, Accuracy: 0.6240234375\n",
      "Batch: 111, Loss: 1.1005027294158936, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.0860636234283447, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.150343418121338, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.1219768524169922, Accuracy: 0.6474609375\n",
      "Batch: 115, Loss: 1.1253782510757446, Accuracy: 0.625\n",
      "Batch: 116, Loss: 1.1370248794555664, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1379036903381348, Accuracy: 0.599609375\n",
      "Batch: 118, Loss: 1.207632303237915, Accuracy: 0.595703125\n",
      "Batch: 119, Loss: 1.1794555187225342, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.2311127185821533, Accuracy: 0.6083984375\n",
      "Batch: 121, Loss: 1.1409738063812256, Accuracy: 0.6279296875\n",
      "Batch: 122, Loss: 1.1333239078521729, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1140408515930176, Accuracy: 0.6474609375\n",
      "Batch: 124, Loss: 1.1831073760986328, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1110036373138428, Accuracy: 0.640625\n",
      "Batch: 126, Loss: 1.2072536945343018, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2109379768371582, Accuracy: 0.6162109375\n",
      "Batch: 128, Loss: 1.1895631551742554, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.1534900665283203, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.1010750532150269, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.1663963794708252, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 1.0482776165008545, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.1826505661010742, Accuracy: 0.6279296875\n",
      "Batch: 134, Loss: 1.0769124031066895, Accuracy: 0.66796875\n",
      "Batch: 135, Loss: 1.015917181968689, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.075000286102295, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.149409294128418, Accuracy: 0.634765625\n",
      "Batch: 138, Loss: 1.2432891130447388, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.153934121131897, Accuracy: 0.6376953125\n",
      "Batch: 140, Loss: 1.16441011428833, Accuracy: 0.6328125\n",
      "Batch: 141, Loss: 1.1278259754180908, Accuracy: 0.62109375\n",
      "Batch: 142, Loss: 1.1087223291397095, Accuracy: 0.630859375\n",
      "Batch: 143, Loss: 1.2131518125534058, Accuracy: 0.6123046875\n",
      "Batch: 144, Loss: 1.205371379852295, Accuracy: 0.607421875\n",
      "Batch: 145, Loss: 1.2120587825775146, Accuracy: 0.6064453125\n",
      "Batch: 146, Loss: 1.1772186756134033, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.2076683044433594, Accuracy: 0.603515625\n",
      "Batch: 148, Loss: 1.1689461469650269, Accuracy: 0.6181640625\n",
      "Batch: 149, Loss: 1.1795734167099, Accuracy: 0.6142578125\n",
      "Batch: 150, Loss: 1.1228752136230469, Accuracy: 0.623046875\n",
      "Batch: 151, Loss: 1.0945653915405273, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1714205741882324, Accuracy: 0.6025390625\n",
      "Batch: 153, Loss: 1.1041886806488037, Accuracy: 0.6279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 154, Loss: 1.0966906547546387, Accuracy: 0.65234375\n",
      "Batch: 155, Loss: 1.025113582611084, Accuracy: 0.6689453125\n",
      "Epoch 545/200\n",
      "Batch: 1, Loss: 1.1954231262207031, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 1.0488917827606201, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0423771142959595, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.0479987859725952, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 1.0561718940734863, Accuracy: 0.6552734375\n",
      "Batch: 6, Loss: 1.058030366897583, Accuracy: 0.6396484375\n",
      "Batch: 7, Loss: 0.9932721853256226, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9801089763641357, Accuracy: 0.6728515625\n",
      "Batch: 9, Loss: 0.9704523682594299, Accuracy: 0.6865234375\n",
      "Batch: 10, Loss: 0.9490739107131958, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 0.9377874135971069, Accuracy: 0.681640625\n",
      "Batch: 12, Loss: 0.9676181077957153, Accuracy: 0.681640625\n",
      "Batch: 13, Loss: 1.0033423900604248, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 0.9426279067993164, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.9393355846405029, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 0.9701296091079712, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.0301244258880615, Accuracy: 0.6435546875\n",
      "Batch: 18, Loss: 1.0781917572021484, Accuracy: 0.6435546875\n",
      "Batch: 19, Loss: 1.190798282623291, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.0921577215194702, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.0823472738265991, Accuracy: 0.64453125\n",
      "Batch: 22, Loss: 1.2028095722198486, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.2308530807495117, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.0458709001541138, Accuracy: 0.66796875\n",
      "Batch: 25, Loss: 1.1621812582015991, Accuracy: 0.6240234375\n",
      "Batch: 26, Loss: 1.1490387916564941, Accuracy: 0.6298828125\n",
      "Batch: 27, Loss: 1.0851987600326538, Accuracy: 0.650390625\n",
      "Batch: 28, Loss: 1.0518290996551514, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.0270512104034424, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.0971429347991943, Accuracy: 0.6318359375\n",
      "Batch: 31, Loss: 1.1967417001724243, Accuracy: 0.6044921875\n",
      "Batch: 32, Loss: 1.042663812637329, Accuracy: 0.6611328125\n",
      "Batch: 33, Loss: 0.9577406644821167, Accuracy: 0.685546875\n",
      "Batch: 34, Loss: 1.002779245376587, Accuracy: 0.6572265625\n",
      "Batch: 35, Loss: 1.1280804872512817, Accuracy: 0.6279296875\n",
      "Batch: 36, Loss: 1.1340618133544922, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.2210288047790527, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.1355679035186768, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.0509819984436035, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.032928705215454, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.1177631616592407, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.074089765548706, Accuracy: 0.6435546875\n",
      "Batch: 43, Loss: 1.051546573638916, Accuracy: 0.640625\n",
      "Batch: 44, Loss: 1.0285899639129639, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.062488317489624, Accuracy: 0.6494140625\n",
      "Batch: 46, Loss: 1.0614067316055298, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.072571873664856, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.090915322303772, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.1552631855010986, Accuracy: 0.619140625\n",
      "Batch: 50, Loss: 1.0800647735595703, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.15769362449646, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.1721118688583374, Accuracy: 0.6201171875\n",
      "Batch: 53, Loss: 1.200946569442749, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.1844172477722168, Accuracy: 0.6142578125\n",
      "Batch: 55, Loss: 1.067917823791504, Accuracy: 0.638671875\n",
      "Batch: 56, Loss: 1.0660319328308105, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.0244321823120117, Accuracy: 0.6767578125\n",
      "Batch: 58, Loss: 1.082659363746643, Accuracy: 0.662109375\n",
      "Batch: 59, Loss: 1.053168535232544, Accuracy: 0.6572265625\n",
      "Batch: 60, Loss: 1.1877782344818115, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1124770641326904, Accuracy: 0.6455078125\n",
      "Batch: 62, Loss: 1.1248440742492676, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.165149450302124, Accuracy: 0.619140625\n",
      "Batch: 64, Loss: 1.1795287132263184, Accuracy: 0.626953125\n",
      "Batch: 65, Loss: 1.1502759456634521, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.163940191268921, Accuracy: 0.623046875\n",
      "Batch: 67, Loss: 1.1138865947723389, Accuracy: 0.654296875\n",
      "Batch: 68, Loss: 1.0364353656768799, Accuracy: 0.673828125\n",
      "Batch: 69, Loss: 1.1480374336242676, Accuracy: 0.6376953125\n",
      "Batch: 70, Loss: 1.123990774154663, Accuracy: 0.638671875\n",
      "Batch: 71, Loss: 1.1480677127838135, Accuracy: 0.6201171875\n",
      "Batch: 72, Loss: 1.1903905868530273, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.1754629611968994, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.0548603534698486, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.1009738445281982, Accuracy: 0.6376953125\n",
      "Batch: 76, Loss: 1.0318074226379395, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 1.0579431056976318, Accuracy: 0.6455078125\n",
      "Batch: 78, Loss: 1.0792582035064697, Accuracy: 0.6337890625\n",
      "Batch: 79, Loss: 1.1029056310653687, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.2073975801467896, Accuracy: 0.5947265625\n",
      "Batch: 81, Loss: 1.0738697052001953, Accuracy: 0.646484375\n",
      "Batch: 82, Loss: 1.0746641159057617, Accuracy: 0.6494140625\n",
      "Batch: 83, Loss: 1.2030047178268433, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.094818353652954, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.1688141822814941, Accuracy: 0.61328125\n",
      "Batch: 86, Loss: 1.1426138877868652, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.1305029392242432, Accuracy: 0.6220703125\n",
      "Batch: 88, Loss: 1.1459580659866333, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.1094059944152832, Accuracy: 0.650390625\n",
      "Batch: 90, Loss: 1.1019468307495117, Accuracy: 0.6611328125\n",
      "Batch: 91, Loss: 1.15280020236969, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.1065890789031982, Accuracy: 0.6337890625\n",
      "Batch: 93, Loss: 1.0721900463104248, Accuracy: 0.662109375\n",
      "Batch: 94, Loss: 1.1967897415161133, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.125058889389038, Accuracy: 0.6337890625\n",
      "Batch: 96, Loss: 1.2234523296356201, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.14418363571167, Accuracy: 0.607421875\n",
      "Batch: 98, Loss: 1.1038405895233154, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.1503727436065674, Accuracy: 0.6328125\n",
      "Batch: 100, Loss: 1.0552843809127808, Accuracy: 0.646484375\n",
      "Batch: 101, Loss: 1.0651865005493164, Accuracy: 0.6708984375\n",
      "Batch: 102, Loss: 1.2022063732147217, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.1625950336456299, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1507829427719116, Accuracy: 0.6181640625\n",
      "Batch: 105, Loss: 1.1799678802490234, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1406476497650146, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.19637930393219, Accuracy: 0.607421875\n",
      "Batch: 108, Loss: 1.1435308456420898, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.1928207874298096, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 1.1113744974136353, Accuracy: 0.6572265625\n",
      "Batch: 111, Loss: 1.1156229972839355, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.02894926071167, Accuracy: 0.6728515625\n",
      "Batch: 113, Loss: 1.0913445949554443, Accuracy: 0.6533203125\n",
      "Batch: 114, Loss: 1.1829572916030884, Accuracy: 0.599609375\n",
      "Batch: 115, Loss: 1.1318855285644531, Accuracy: 0.6279296875\n",
      "Batch: 116, Loss: 1.205023169517517, Accuracy: 0.6015625\n",
      "Batch: 117, Loss: 1.151145100593567, Accuracy: 0.6201171875\n",
      "Batch: 118, Loss: 1.22194504737854, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.1764271259307861, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.2546634674072266, Accuracy: 0.6015625\n",
      "Batch: 121, Loss: 1.1896833181381226, Accuracy: 0.625\n",
      "Batch: 122, Loss: 1.1529195308685303, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.1556260585784912, Accuracy: 0.626953125\n",
      "Batch: 124, Loss: 1.1872303485870361, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.1585984230041504, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.2223420143127441, Accuracy: 0.6201171875\n",
      "Batch: 127, Loss: 1.193897008895874, Accuracy: 0.6357421875\n",
      "Batch: 128, Loss: 1.2127169370651245, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.138831615447998, Accuracy: 0.6259765625\n",
      "Batch: 130, Loss: 1.0742123126983643, Accuracy: 0.66015625\n",
      "Batch: 131, Loss: 1.2283287048339844, Accuracy: 0.6025390625\n",
      "Batch: 132, Loss: 1.1037689447402954, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.1425632238388062, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1154954433441162, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.012431263923645, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.0851688385009766, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.1937665939331055, Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 138, Loss: 1.2351152896881104, Accuracy: 0.591796875\n",
      "Batch: 139, Loss: 1.18547523021698, Accuracy: 0.6015625\n",
      "Batch: 140, Loss: 1.1712435483932495, Accuracy: 0.623046875\n",
      "Batch: 141, Loss: 1.0976474285125732, Accuracy: 0.650390625\n",
      "Batch: 142, Loss: 1.120086669921875, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.1946436166763306, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.2427680492401123, Accuracy: 0.5947265625\n",
      "Batch: 145, Loss: 1.3070647716522217, Accuracy: 0.5732421875\n",
      "Batch: 146, Loss: 1.2647135257720947, Accuracy: 0.5908203125\n",
      "Batch: 147, Loss: 1.150502324104309, Accuracy: 0.6328125\n",
      "Batch: 148, Loss: 1.1885032653808594, Accuracy: 0.615234375\n",
      "Batch: 149, Loss: 1.1104551553726196, Accuracy: 0.62109375\n",
      "Batch: 150, Loss: 1.118504285812378, Accuracy: 0.646484375\n",
      "Batch: 151, Loss: 1.1654784679412842, Accuracy: 0.6201171875\n",
      "Batch: 152, Loss: 1.1339423656463623, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.1150974035263062, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.0926432609558105, Accuracy: 0.6474609375\n",
      "Batch: 155, Loss: 1.0344792604446411, Accuracy: 0.6708984375\n",
      "Epoch 546/200\n",
      "Batch: 1, Loss: 1.2158342599868774, Accuracy: 0.6328125\n",
      "Batch: 2, Loss: 1.0229978561401367, Accuracy: 0.654296875\n",
      "Batch: 3, Loss: 1.0358327627182007, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.0784825086593628, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 1.011975646018982, Accuracy: 0.6630859375\n",
      "Batch: 6, Loss: 0.9996199011802673, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 0.9919729232788086, Accuracy: 0.6748046875\n",
      "Batch: 8, Loss: 1.0158511400222778, Accuracy: 0.662109375\n",
      "Batch: 9, Loss: 1.0032645463943481, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9148246049880981, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 0.9692874550819397, Accuracy: 0.669921875\n",
      "Batch: 12, Loss: 0.9849247932434082, Accuracy: 0.6845703125\n",
      "Batch: 13, Loss: 1.0189216136932373, Accuracy: 0.66015625\n",
      "Batch: 14, Loss: 0.9615486860275269, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9310592412948608, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 1.0287317037582397, Accuracy: 0.6806640625\n",
      "Batch: 17, Loss: 1.0114684104919434, Accuracy: 0.673828125\n",
      "Batch: 18, Loss: 1.0928373336791992, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.1477491855621338, Accuracy: 0.615234375\n",
      "Batch: 20, Loss: 1.0423420667648315, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.0727381706237793, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1602087020874023, Accuracy: 0.6337890625\n",
      "Batch: 23, Loss: 1.2164041996002197, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.0481181144714355, Accuracy: 0.6533203125\n",
      "Batch: 25, Loss: 1.1537847518920898, Accuracy: 0.6171875\n",
      "Batch: 26, Loss: 1.1369140148162842, Accuracy: 0.6376953125\n",
      "Batch: 27, Loss: 1.0718979835510254, Accuracy: 0.640625\n",
      "Batch: 28, Loss: 1.0926142930984497, Accuracy: 0.6552734375\n",
      "Batch: 29, Loss: 1.0348336696624756, Accuracy: 0.6669921875\n",
      "Batch: 30, Loss: 1.1483216285705566, Accuracy: 0.619140625\n",
      "Batch: 31, Loss: 1.1547776460647583, Accuracy: 0.6279296875\n",
      "Batch: 32, Loss: 0.9992499351501465, Accuracy: 0.650390625\n",
      "Batch: 33, Loss: 0.9953516721725464, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.0952215194702148, Accuracy: 0.6328125\n",
      "Batch: 35, Loss: 1.1176170110702515, Accuracy: 0.6474609375\n",
      "Batch: 36, Loss: 1.1707556247711182, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.1499991416931152, Accuracy: 0.6201171875\n",
      "Batch: 38, Loss: 1.1623890399932861, Accuracy: 0.625\n",
      "Batch: 39, Loss: 1.0446059703826904, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.0644643306732178, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.0825443267822266, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.0485886335372925, Accuracy: 0.6591796875\n",
      "Batch: 43, Loss: 1.0677639245986938, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0107440948486328, Accuracy: 0.6875\n",
      "Batch: 45, Loss: 0.9993904829025269, Accuracy: 0.6494140625\n",
      "Batch: 46, Loss: 1.0777287483215332, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.1013846397399902, Accuracy: 0.658203125\n",
      "Batch: 48, Loss: 1.1384168863296509, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1496047973632812, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.0855071544647217, Accuracy: 0.6328125\n",
      "Batch: 51, Loss: 1.156021237373352, Accuracy: 0.6064453125\n",
      "Batch: 52, Loss: 1.2631207704544067, Accuracy: 0.58203125\n",
      "Batch: 53, Loss: 1.127837896347046, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.16447114944458, Accuracy: 0.603515625\n",
      "Batch: 55, Loss: 1.0900793075561523, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.0476164817810059, Accuracy: 0.6572265625\n",
      "Batch: 57, Loss: 1.112605094909668, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.0656766891479492, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 1.0807209014892578, Accuracy: 0.6474609375\n",
      "Batch: 60, Loss: 1.2085630893707275, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.1125571727752686, Accuracy: 0.64453125\n",
      "Batch: 62, Loss: 1.1459599733352661, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.1447782516479492, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.1845154762268066, Accuracy: 0.6240234375\n",
      "Batch: 65, Loss: 1.095674991607666, Accuracy: 0.638671875\n",
      "Batch: 66, Loss: 1.1205207109451294, Accuracy: 0.6416015625\n",
      "Batch: 67, Loss: 1.15578031539917, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0195887088775635, Accuracy: 0.6845703125\n",
      "Batch: 69, Loss: 1.1169090270996094, Accuracy: 0.63671875\n",
      "Batch: 70, Loss: 1.1432414054870605, Accuracy: 0.630859375\n",
      "Batch: 71, Loss: 1.1015923023223877, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.1736304759979248, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.2083384990692139, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.1081221103668213, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.1279959678649902, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.0374152660369873, Accuracy: 0.6650390625\n",
      "Batch: 77, Loss: 1.0758442878723145, Accuracy: 0.642578125\n",
      "Batch: 78, Loss: 1.0942747592926025, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.1127099990844727, Accuracy: 0.654296875\n",
      "Batch: 80, Loss: 1.1087284088134766, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.1105403900146484, Accuracy: 0.6396484375\n",
      "Batch: 82, Loss: 1.0878112316131592, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 1.1741008758544922, Accuracy: 0.609375\n",
      "Batch: 84, Loss: 1.0815074443817139, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1432654857635498, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.1121442317962646, Accuracy: 0.6396484375\n",
      "Batch: 87, Loss: 1.1308634281158447, Accuracy: 0.6533203125\n",
      "Batch: 88, Loss: 1.1732828617095947, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.0975077152252197, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.0794916152954102, Accuracy: 0.6298828125\n",
      "Batch: 91, Loss: 1.0902966260910034, Accuracy: 0.646484375\n",
      "Batch: 92, Loss: 1.1232481002807617, Accuracy: 0.6416015625\n",
      "Batch: 93, Loss: 1.098073959350586, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.1663308143615723, Accuracy: 0.6279296875\n",
      "Batch: 95, Loss: 1.1217275857925415, Accuracy: 0.646484375\n",
      "Batch: 96, Loss: 1.1887454986572266, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.0786194801330566, Accuracy: 0.6416015625\n",
      "Batch: 98, Loss: 1.1045477390289307, Accuracy: 0.642578125\n",
      "Batch: 99, Loss: 1.1297600269317627, Accuracy: 0.6396484375\n",
      "Batch: 100, Loss: 1.0116631984710693, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.0674844980239868, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.168972373008728, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.1672568321228027, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.0953726768493652, Accuracy: 0.66796875\n",
      "Batch: 105, Loss: 1.186530590057373, Accuracy: 0.6162109375\n",
      "Batch: 106, Loss: 1.1267434358596802, Accuracy: 0.6650390625\n",
      "Batch: 107, Loss: 1.183985710144043, Accuracy: 0.6181640625\n",
      "Batch: 108, Loss: 1.1698389053344727, Accuracy: 0.5908203125\n",
      "Batch: 109, Loss: 1.1880204677581787, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 1.1168707609176636, Accuracy: 0.646484375\n",
      "Batch: 111, Loss: 1.1231671571731567, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.042451024055481, Accuracy: 0.66796875\n",
      "Batch: 113, Loss: 1.1783039569854736, Accuracy: 0.6103515625\n",
      "Batch: 114, Loss: 1.153928518295288, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.160754680633545, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.166003704071045, Accuracy: 0.6162109375\n",
      "Batch: 117, Loss: 1.136073112487793, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 1.2312641143798828, Accuracy: 0.5947265625\n",
      "Batch: 119, Loss: 1.140148639678955, Accuracy: 0.6376953125\n",
      "Batch: 120, Loss: 1.2744030952453613, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.1587858200073242, Accuracy: 0.6240234375\n",
      "Batch: 122, Loss: 1.1500577926635742, Accuracy: 0.62890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 123, Loss: 1.1846861839294434, Accuracy: 0.625\n",
      "Batch: 124, Loss: 1.2107133865356445, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.1364103555679321, Accuracy: 0.638671875\n",
      "Batch: 126, Loss: 1.200797438621521, Accuracy: 0.623046875\n",
      "Batch: 127, Loss: 1.1919617652893066, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.1858129501342773, Accuracy: 0.6025390625\n",
      "Batch: 129, Loss: 1.1527493000030518, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.1232351064682007, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.2013640403747559, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.0751756429672241, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 1.1327803134918213, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.0886540412902832, Accuracy: 0.6748046875\n",
      "Batch: 135, Loss: 1.0507597923278809, Accuracy: 0.6630859375\n",
      "Batch: 136, Loss: 1.082270622253418, Accuracy: 0.65234375\n",
      "Batch: 137, Loss: 1.1273393630981445, Accuracy: 0.654296875\n",
      "Batch: 138, Loss: 1.2611037492752075, Accuracy: 0.591796875\n",
      "Batch: 139, Loss: 1.1315243244171143, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.1942343711853027, Accuracy: 0.6396484375\n",
      "Batch: 141, Loss: 1.1587868928909302, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1243393421173096, Accuracy: 0.6474609375\n",
      "Batch: 143, Loss: 1.1200945377349854, Accuracy: 0.6513671875\n",
      "Batch: 144, Loss: 1.2216885089874268, Accuracy: 0.607421875\n",
      "Batch: 145, Loss: 1.2846317291259766, Accuracy: 0.578125\n",
      "Batch: 146, Loss: 1.1788662672042847, Accuracy: 0.6123046875\n",
      "Batch: 147, Loss: 1.129067063331604, Accuracy: 0.62890625\n",
      "Batch: 148, Loss: 1.1679294109344482, Accuracy: 0.6103515625\n",
      "Batch: 149, Loss: 1.1697769165039062, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.1294264793395996, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.1767563819885254, Accuracy: 0.619140625\n",
      "Batch: 152, Loss: 1.1358393430709839, Accuracy: 0.6337890625\n",
      "Batch: 153, Loss: 1.103609561920166, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.0726109743118286, Accuracy: 0.6484375\n",
      "Batch: 155, Loss: 1.0240813493728638, Accuracy: 0.6708984375\n",
      "Epoch 547/200\n",
      "Batch: 1, Loss: 1.2734959125518799, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 1.0811192989349365, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 1.0179667472839355, Accuracy: 0.6650390625\n",
      "Batch: 4, Loss: 1.1369705200195312, Accuracy: 0.62109375\n",
      "Batch: 5, Loss: 0.991593599319458, Accuracy: 0.6611328125\n",
      "Batch: 6, Loss: 0.9966791868209839, Accuracy: 0.6845703125\n",
      "Batch: 7, Loss: 1.0101503133773804, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9899835586547852, Accuracy: 0.68359375\n",
      "Batch: 9, Loss: 0.962135910987854, Accuracy: 0.6748046875\n",
      "Batch: 10, Loss: 0.9773960113525391, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 0.9274760484695435, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.9878572821617126, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0089380741119385, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.9259027242660522, Accuracy: 0.7158203125\n",
      "Batch: 15, Loss: 0.9241527318954468, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 1.0326637029647827, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 1.0595837831497192, Accuracy: 0.6474609375\n",
      "Batch: 18, Loss: 1.1132228374481201, Accuracy: 0.6396484375\n",
      "Batch: 19, Loss: 1.1221442222595215, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.0778440237045288, Accuracy: 0.6669921875\n",
      "Batch: 21, Loss: 1.0250306129455566, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.2434861660003662, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.2520902156829834, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1123429536819458, Accuracy: 0.638671875\n",
      "Batch: 25, Loss: 1.083839774131775, Accuracy: 0.658203125\n",
      "Batch: 26, Loss: 1.1377590894699097, Accuracy: 0.63671875\n",
      "Batch: 27, Loss: 1.0834614038467407, Accuracy: 0.6533203125\n",
      "Batch: 28, Loss: 1.0987269878387451, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 0.9844995737075806, Accuracy: 0.673828125\n",
      "Batch: 30, Loss: 1.1488597393035889, Accuracy: 0.642578125\n",
      "Batch: 31, Loss: 1.1383111476898193, Accuracy: 0.615234375\n",
      "Batch: 32, Loss: 0.9931682348251343, Accuracy: 0.6630859375\n",
      "Batch: 33, Loss: 1.018226146697998, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.0341088771820068, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 1.108178973197937, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.1913139820098877, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1924240589141846, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.1331816911697388, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.0256474018096924, Accuracy: 0.6640625\n",
      "Batch: 40, Loss: 1.0547689199447632, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.1077706813812256, Accuracy: 0.6474609375\n",
      "Batch: 42, Loss: 1.0417275428771973, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 0.9880022406578064, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.0252104997634888, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.038522481918335, Accuracy: 0.6630859375\n",
      "Batch: 46, Loss: 1.1075356006622314, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.0556291341781616, Accuracy: 0.6611328125\n",
      "Batch: 48, Loss: 1.1583735942840576, Accuracy: 0.623046875\n",
      "Batch: 49, Loss: 1.1275697946548462, Accuracy: 0.65234375\n",
      "Batch: 50, Loss: 1.0886293649673462, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.1321814060211182, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.1936440467834473, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 1.0948129892349243, Accuracy: 0.6337890625\n",
      "Batch: 54, Loss: 1.1699515581130981, Accuracy: 0.607421875\n",
      "Batch: 55, Loss: 1.1289750337600708, Accuracy: 0.640625\n",
      "Batch: 56, Loss: 1.1027814149856567, Accuracy: 0.6572265625\n",
      "Batch: 57, Loss: 1.0898127555847168, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.139271855354309, Accuracy: 0.666015625\n",
      "Batch: 59, Loss: 1.105912446975708, Accuracy: 0.6416015625\n",
      "Batch: 60, Loss: 1.210564374923706, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.1108782291412354, Accuracy: 0.623046875\n",
      "Batch: 62, Loss: 1.1031386852264404, Accuracy: 0.6455078125\n",
      "Batch: 63, Loss: 1.1263997554779053, Accuracy: 0.6455078125\n",
      "Batch: 64, Loss: 1.1586657762527466, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.125258445739746, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.1343345642089844, Accuracy: 0.6240234375\n",
      "Batch: 67, Loss: 1.0819717645645142, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.11116623878479, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.1192400455474854, Accuracy: 0.6416015625\n",
      "Batch: 70, Loss: 1.1077274084091187, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.1562296152114868, Accuracy: 0.6103515625\n",
      "Batch: 72, Loss: 1.1358749866485596, Accuracy: 0.642578125\n",
      "Batch: 73, Loss: 1.1696140766143799, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.0566761493682861, Accuracy: 0.6572265625\n",
      "Batch: 75, Loss: 1.070876121520996, Accuracy: 0.6337890625\n",
      "Batch: 76, Loss: 1.057145118713379, Accuracy: 0.6494140625\n",
      "Batch: 77, Loss: 1.0697531700134277, Accuracy: 0.65234375\n",
      "Batch: 78, Loss: 1.0002883672714233, Accuracy: 0.6689453125\n",
      "Batch: 79, Loss: 1.0925002098083496, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.1403460502624512, Accuracy: 0.6474609375\n",
      "Batch: 81, Loss: 1.1016496419906616, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.1050838232040405, Accuracy: 0.6572265625\n",
      "Batch: 83, Loss: 1.133994460105896, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.0941734313964844, Accuracy: 0.650390625\n",
      "Batch: 85, Loss: 1.110009789466858, Accuracy: 0.6513671875\n",
      "Batch: 86, Loss: 1.1727871894836426, Accuracy: 0.5966796875\n",
      "Batch: 87, Loss: 1.129536509513855, Accuracy: 0.6572265625\n",
      "Batch: 88, Loss: 1.0826706886291504, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.1199653148651123, Accuracy: 0.62890625\n",
      "Batch: 90, Loss: 1.1089458465576172, Accuracy: 0.6416015625\n",
      "Batch: 91, Loss: 1.1022634506225586, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.0868933200836182, Accuracy: 0.658203125\n",
      "Batch: 93, Loss: 1.0904922485351562, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.1279621124267578, Accuracy: 0.6337890625\n",
      "Batch: 95, Loss: 1.0811514854431152, Accuracy: 0.6640625\n",
      "Batch: 96, Loss: 1.172497272491455, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.1664929389953613, Accuracy: 0.6220703125\n",
      "Batch: 98, Loss: 1.0799176692962646, Accuracy: 0.6572265625\n",
      "Batch: 99, Loss: 1.0575309991836548, Accuracy: 0.65625\n",
      "Batch: 100, Loss: 1.1018146276474, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.1058704853057861, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 1.1565823554992676, Accuracy: 0.6337890625\n",
      "Batch: 103, Loss: 1.1443235874176025, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.1061232089996338, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.1770697832107544, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.086573600769043, Accuracy: 0.65234375\n",
      "Batch: 107, Loss: 1.216410517692566, Accuracy: 0.6171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 1.148679494857788, Accuracy: 0.6123046875\n",
      "Batch: 109, Loss: 1.1502289772033691, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.1178159713745117, Accuracy: 0.634765625\n",
      "Batch: 111, Loss: 1.130967617034912, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.07188880443573, Accuracy: 0.6416015625\n",
      "Batch: 113, Loss: 1.1276283264160156, Accuracy: 0.6220703125\n",
      "Batch: 114, Loss: 1.158768892288208, Accuracy: 0.630859375\n",
      "Batch: 115, Loss: 1.1601009368896484, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.18048894405365, Accuracy: 0.5888671875\n",
      "Batch: 117, Loss: 1.1645610332489014, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.1915680170059204, Accuracy: 0.61328125\n",
      "Batch: 119, Loss: 1.2205071449279785, Accuracy: 0.6015625\n",
      "Batch: 120, Loss: 1.260574460029602, Accuracy: 0.59765625\n",
      "Batch: 121, Loss: 1.1271294355392456, Accuracy: 0.646484375\n",
      "Batch: 122, Loss: 1.161412000656128, Accuracy: 0.6376953125\n",
      "Batch: 123, Loss: 1.1750130653381348, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.1819883584976196, Accuracy: 0.6279296875\n",
      "Batch: 125, Loss: 1.1722824573516846, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.1703300476074219, Accuracy: 0.634765625\n",
      "Batch: 127, Loss: 1.2151834964752197, Accuracy: 0.6328125\n",
      "Batch: 128, Loss: 1.1538405418395996, Accuracy: 0.630859375\n",
      "Batch: 129, Loss: 1.1657817363739014, Accuracy: 0.62109375\n",
      "Batch: 130, Loss: 1.1238198280334473, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1375465393066406, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.0559055805206299, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.1017820835113525, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.0554660558700562, Accuracy: 0.6572265625\n",
      "Batch: 135, Loss: 1.0095164775848389, Accuracy: 0.6787109375\n",
      "Batch: 136, Loss: 1.0530987977981567, Accuracy: 0.6474609375\n",
      "Batch: 137, Loss: 1.1188204288482666, Accuracy: 0.638671875\n",
      "Batch: 138, Loss: 1.1982836723327637, Accuracy: 0.6025390625\n",
      "Batch: 139, Loss: 1.162015438079834, Accuracy: 0.62109375\n",
      "Batch: 140, Loss: 1.214738130569458, Accuracy: 0.6181640625\n",
      "Batch: 141, Loss: 1.120504379272461, Accuracy: 0.6298828125\n",
      "Batch: 142, Loss: 1.1018569469451904, Accuracy: 0.6435546875\n",
      "Batch: 143, Loss: 1.1681199073791504, Accuracy: 0.625\n",
      "Batch: 144, Loss: 1.1823012828826904, Accuracy: 0.6220703125\n",
      "Batch: 145, Loss: 1.2170987129211426, Accuracy: 0.611328125\n",
      "Batch: 146, Loss: 1.1282371282577515, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.147834062576294, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.1592059135437012, Accuracy: 0.61328125\n",
      "Batch: 149, Loss: 1.143263816833496, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1040490865707397, Accuracy: 0.6474609375\n",
      "Batch: 151, Loss: 1.1109542846679688, Accuracy: 0.6396484375\n",
      "Batch: 152, Loss: 1.1839985847473145, Accuracy: 0.5947265625\n",
      "Batch: 153, Loss: 1.115774393081665, Accuracy: 0.6533203125\n",
      "Batch: 154, Loss: 1.1811188459396362, Accuracy: 0.6201171875\n",
      "Batch: 155, Loss: 1.0953885316848755, Accuracy: 0.6396484375\n",
      "Epoch 548/200\n",
      "Batch: 1, Loss: 1.1762487888336182, Accuracy: 0.6591796875\n",
      "Batch: 2, Loss: 1.077632188796997, Accuracy: 0.6279296875\n",
      "Batch: 3, Loss: 0.954204797744751, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 1.0678484439849854, Accuracy: 0.6474609375\n",
      "Batch: 5, Loss: 0.9466077089309692, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.02217698097229, Accuracy: 0.6796875\n",
      "Batch: 7, Loss: 0.9612448215484619, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9658651351928711, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 0.9587364196777344, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 0.9491312503814697, Accuracy: 0.6748046875\n",
      "Batch: 11, Loss: 0.9242426156997681, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 0.9329973459243774, Accuracy: 0.697265625\n",
      "Batch: 13, Loss: 1.0098237991333008, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9600521326065063, Accuracy: 0.689453125\n",
      "Batch: 15, Loss: 0.9101202487945557, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0044138431549072, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.059218168258667, Accuracy: 0.634765625\n",
      "Batch: 18, Loss: 1.0988337993621826, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.1410717964172363, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 1.0386154651641846, Accuracy: 0.6552734375\n",
      "Batch: 21, Loss: 1.043222427368164, Accuracy: 0.6630859375\n",
      "Batch: 22, Loss: 1.2174134254455566, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.2161872386932373, Accuracy: 0.611328125\n",
      "Batch: 24, Loss: 1.132089614868164, Accuracy: 0.6357421875\n",
      "Batch: 25, Loss: 1.0926101207733154, Accuracy: 0.6494140625\n",
      "Batch: 26, Loss: 1.207295536994934, Accuracy: 0.603515625\n",
      "Batch: 27, Loss: 1.1105713844299316, Accuracy: 0.638671875\n",
      "Batch: 28, Loss: 1.0855686664581299, Accuracy: 0.6337890625\n",
      "Batch: 29, Loss: 1.036336898803711, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1288323402404785, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.1645268201828003, Accuracy: 0.62890625\n",
      "Batch: 32, Loss: 0.9914939403533936, Accuracy: 0.6806640625\n",
      "Batch: 33, Loss: 0.9696491956710815, Accuracy: 0.6806640625\n",
      "Batch: 34, Loss: 1.0492808818817139, Accuracy: 0.6708984375\n",
      "Batch: 35, Loss: 1.0846095085144043, Accuracy: 0.6591796875\n",
      "Batch: 36, Loss: 1.131147861480713, Accuracy: 0.6318359375\n",
      "Batch: 37, Loss: 1.220253348350525, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.0888888835906982, Accuracy: 0.6494140625\n",
      "Batch: 39, Loss: 1.035475254058838, Accuracy: 0.6494140625\n",
      "Batch: 40, Loss: 1.0439848899841309, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.0797193050384521, Accuracy: 0.6494140625\n",
      "Batch: 42, Loss: 1.0234417915344238, Accuracy: 0.6669921875\n",
      "Batch: 43, Loss: 1.0517947673797607, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 0.9940579533576965, Accuracy: 0.6796875\n",
      "Batch: 45, Loss: 1.0073609352111816, Accuracy: 0.64453125\n",
      "Batch: 46, Loss: 1.1280101537704468, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.0612192153930664, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.138427972793579, Accuracy: 0.6240234375\n",
      "Batch: 49, Loss: 1.1655237674713135, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.0467517375946045, Accuracy: 0.65625\n",
      "Batch: 51, Loss: 1.1272475719451904, Accuracy: 0.6318359375\n",
      "Batch: 52, Loss: 1.2164661884307861, Accuracy: 0.6171875\n",
      "Batch: 53, Loss: 1.1096584796905518, Accuracy: 0.640625\n",
      "Batch: 54, Loss: 1.1403746604919434, Accuracy: 0.6298828125\n",
      "Batch: 55, Loss: 1.107132911682129, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.0967553853988647, Accuracy: 0.6591796875\n",
      "Batch: 57, Loss: 1.0878876447677612, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.1099640130996704, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.1021878719329834, Accuracy: 0.6416015625\n",
      "Batch: 60, Loss: 1.181738257408142, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.081756353378296, Accuracy: 0.6376953125\n",
      "Batch: 62, Loss: 1.0965871810913086, Accuracy: 0.63671875\n",
      "Batch: 63, Loss: 1.1516069173812866, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.2556862831115723, Accuracy: 0.5986328125\n",
      "Batch: 65, Loss: 1.1031997203826904, Accuracy: 0.6611328125\n",
      "Batch: 66, Loss: 1.1420631408691406, Accuracy: 0.611328125\n",
      "Batch: 67, Loss: 1.1057755947113037, Accuracy: 0.6455078125\n",
      "Batch: 68, Loss: 1.0902903079986572, Accuracy: 0.6611328125\n",
      "Batch: 69, Loss: 1.12636137008667, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.1701353788375854, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.1409456729888916, Accuracy: 0.638671875\n",
      "Batch: 72, Loss: 1.106299877166748, Accuracy: 0.6337890625\n",
      "Batch: 73, Loss: 1.179203987121582, Accuracy: 0.6220703125\n",
      "Batch: 74, Loss: 1.1397525072097778, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.138092041015625, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.083139419555664, Accuracy: 0.65234375\n",
      "Batch: 77, Loss: 1.0490494966506958, Accuracy: 0.6640625\n",
      "Batch: 78, Loss: 1.083320140838623, Accuracy: 0.6474609375\n",
      "Batch: 79, Loss: 1.108290433883667, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.1391654014587402, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.08207368850708, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 1.142011284828186, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 1.1645662784576416, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.1057977676391602, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.1648598909378052, Accuracy: 0.6484375\n",
      "Batch: 86, Loss: 1.122652292251587, Accuracy: 0.626953125\n",
      "Batch: 87, Loss: 1.1204731464385986, Accuracy: 0.6494140625\n",
      "Batch: 88, Loss: 1.1059257984161377, Accuracy: 0.6689453125\n",
      "Batch: 89, Loss: 1.1231930255889893, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.12228524684906, Accuracy: 0.6279296875\n",
      "Batch: 91, Loss: 1.1278873682022095, Accuracy: 0.626953125\n",
      "Batch: 92, Loss: 1.1211082935333252, Accuracy: 0.66015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 93, Loss: 1.12052583694458, Accuracy: 0.62890625\n",
      "Batch: 94, Loss: 1.1543207168579102, Accuracy: 0.6318359375\n",
      "Batch: 95, Loss: 1.077527642250061, Accuracy: 0.6416015625\n",
      "Batch: 96, Loss: 1.174321174621582, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.1952400207519531, Accuracy: 0.59375\n",
      "Batch: 98, Loss: 1.1616239547729492, Accuracy: 0.6083984375\n",
      "Batch: 99, Loss: 1.1641361713409424, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0488375425338745, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.0611268281936646, Accuracy: 0.6474609375\n",
      "Batch: 102, Loss: 1.1496583223342896, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1260297298431396, Accuracy: 0.6513671875\n",
      "Batch: 104, Loss: 1.11661958694458, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.1862704753875732, Accuracy: 0.611328125\n",
      "Batch: 106, Loss: 1.1853492259979248, Accuracy: 0.6064453125\n",
      "Batch: 107, Loss: 1.1908414363861084, Accuracy: 0.6103515625\n",
      "Batch: 108, Loss: 1.1424896717071533, Accuracy: 0.625\n",
      "Batch: 109, Loss: 1.1868468523025513, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 1.1594040393829346, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.1206142902374268, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.0502820014953613, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1838964223861694, Accuracy: 0.6181640625\n",
      "Batch: 114, Loss: 1.1883749961853027, Accuracy: 0.6123046875\n",
      "Batch: 115, Loss: 1.1030828952789307, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.1603361368179321, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.1621849536895752, Accuracy: 0.6328125\n",
      "Batch: 118, Loss: 1.145194411277771, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.267012357711792, Accuracy: 0.5791015625\n",
      "Batch: 120, Loss: 1.3203343152999878, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.094308853149414, Accuracy: 0.6513671875\n",
      "Batch: 122, Loss: 1.2274445295333862, Accuracy: 0.6025390625\n",
      "Batch: 123, Loss: 1.1277912855148315, Accuracy: 0.6484375\n",
      "Batch: 124, Loss: 1.2397239208221436, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.1349503993988037, Accuracy: 0.6484375\n",
      "Batch: 126, Loss: 1.2049508094787598, Accuracy: 0.60546875\n",
      "Batch: 127, Loss: 1.2260651588439941, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.2124156951904297, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.066526174545288, Accuracy: 0.654296875\n",
      "Batch: 130, Loss: 1.1258760690689087, Accuracy: 0.6484375\n",
      "Batch: 131, Loss: 1.1656394004821777, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.0741357803344727, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.120035171508789, Accuracy: 0.6533203125\n",
      "Batch: 134, Loss: 1.1258156299591064, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 1.023369550704956, Accuracy: 0.6611328125\n",
      "Batch: 136, Loss: 1.076013207435608, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.0958576202392578, Accuracy: 0.650390625\n",
      "Batch: 138, Loss: 1.2647089958190918, Accuracy: 0.595703125\n",
      "Batch: 139, Loss: 1.1507794857025146, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.1725811958312988, Accuracy: 0.61328125\n",
      "Batch: 141, Loss: 1.1471138000488281, Accuracy: 0.6259765625\n",
      "Batch: 142, Loss: 1.1104694604873657, Accuracy: 0.63671875\n",
      "Batch: 143, Loss: 1.201845645904541, Accuracy: 0.6142578125\n",
      "Batch: 144, Loss: 1.2552199363708496, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.2400734424591064, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.1402432918548584, Accuracy: 0.6298828125\n",
      "Batch: 147, Loss: 1.1709825992584229, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.1331806182861328, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 1.1604368686676025, Accuracy: 0.6357421875\n",
      "Batch: 150, Loss: 1.0820754766464233, Accuracy: 0.640625\n",
      "Batch: 151, Loss: 1.141035795211792, Accuracy: 0.626953125\n",
      "Batch: 152, Loss: 1.1557844877243042, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.0649561882019043, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.1085963249206543, Accuracy: 0.6220703125\n",
      "Batch: 155, Loss: 1.1035349369049072, Accuracy: 0.64453125\n",
      "Epoch 549/200\n",
      "Batch: 1, Loss: 1.222005844116211, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.0604420900344849, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 0.9904422163963318, Accuracy: 0.6728515625\n",
      "Batch: 4, Loss: 1.023975133895874, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 1.0017497539520264, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.0061464309692383, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 0.9910488724708557, Accuracy: 0.6640625\n",
      "Batch: 8, Loss: 0.9379588961601257, Accuracy: 0.6982421875\n",
      "Batch: 9, Loss: 0.984718918800354, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9541153907775879, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 0.8902567625045776, Accuracy: 0.6943359375\n",
      "Batch: 12, Loss: 0.9992239475250244, Accuracy: 0.6689453125\n",
      "Batch: 13, Loss: 1.0024731159210205, Accuracy: 0.671875\n",
      "Batch: 14, Loss: 0.9804446697235107, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9205700159072876, Accuracy: 0.6826171875\n",
      "Batch: 16, Loss: 0.9734668135643005, Accuracy: 0.705078125\n",
      "Batch: 17, Loss: 1.0252928733825684, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.1079046726226807, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.1385467052459717, Accuracy: 0.6220703125\n",
      "Batch: 20, Loss: 1.0565437078475952, Accuracy: 0.6435546875\n",
      "Batch: 21, Loss: 1.0362261533737183, Accuracy: 0.6611328125\n",
      "Batch: 22, Loss: 1.1461052894592285, Accuracy: 0.623046875\n",
      "Batch: 23, Loss: 1.2215750217437744, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.0484899282455444, Accuracy: 0.6611328125\n",
      "Batch: 25, Loss: 1.1464934349060059, Accuracy: 0.63671875\n",
      "Batch: 26, Loss: 1.1603537797927856, Accuracy: 0.61328125\n",
      "Batch: 27, Loss: 1.119985818862915, Accuracy: 0.6328125\n",
      "Batch: 28, Loss: 1.0453274250030518, Accuracy: 0.65625\n",
      "Batch: 29, Loss: 1.0366904735565186, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.1253409385681152, Accuracy: 0.619140625\n",
      "Batch: 31, Loss: 1.142228364944458, Accuracy: 0.6162109375\n",
      "Batch: 32, Loss: 1.0772099494934082, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 0.9501907825469971, Accuracy: 0.701171875\n",
      "Batch: 34, Loss: 1.114057183265686, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.1040873527526855, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.2207577228546143, Accuracy: 0.583984375\n",
      "Batch: 37, Loss: 1.1663321256637573, Accuracy: 0.62890625\n",
      "Batch: 38, Loss: 1.1578178405761719, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.0727317333221436, Accuracy: 0.646484375\n",
      "Batch: 40, Loss: 1.0508495569229126, Accuracy: 0.646484375\n",
      "Batch: 41, Loss: 1.0711557865142822, Accuracy: 0.6474609375\n",
      "Batch: 42, Loss: 1.0298662185668945, Accuracy: 0.658203125\n",
      "Batch: 43, Loss: 1.0374109745025635, Accuracy: 0.6357421875\n",
      "Batch: 44, Loss: 1.0268440246582031, Accuracy: 0.66796875\n",
      "Batch: 45, Loss: 1.0792789459228516, Accuracy: 0.6318359375\n",
      "Batch: 46, Loss: 1.0878510475158691, Accuracy: 0.6484375\n",
      "Batch: 47, Loss: 1.0956693887710571, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.1378893852233887, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.1607805490493774, Accuracy: 0.638671875\n",
      "Batch: 50, Loss: 1.0851938724517822, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.0416357517242432, Accuracy: 0.666015625\n",
      "Batch: 52, Loss: 1.1993768215179443, Accuracy: 0.63671875\n",
      "Batch: 53, Loss: 1.1616168022155762, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.1591765880584717, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.1108055114746094, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.0349926948547363, Accuracy: 0.67578125\n",
      "Batch: 57, Loss: 1.0909459590911865, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.0810762643814087, Accuracy: 0.6513671875\n",
      "Batch: 59, Loss: 1.103536605834961, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.2143237590789795, Accuracy: 0.615234375\n",
      "Batch: 61, Loss: 1.1190550327301025, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1163372993469238, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.1201138496398926, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.184009313583374, Accuracy: 0.6396484375\n",
      "Batch: 65, Loss: 1.195892572402954, Accuracy: 0.6083984375\n",
      "Batch: 66, Loss: 1.1432979106903076, Accuracy: 0.65234375\n",
      "Batch: 67, Loss: 1.1989706754684448, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.0218945741653442, Accuracy: 0.6689453125\n",
      "Batch: 69, Loss: 1.1809165477752686, Accuracy: 0.6357421875\n",
      "Batch: 70, Loss: 1.158612847328186, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.1236934661865234, Accuracy: 0.64453125\n",
      "Batch: 72, Loss: 1.2118703126907349, Accuracy: 0.5947265625\n",
      "Batch: 73, Loss: 1.1733856201171875, Accuracy: 0.6298828125\n",
      "Batch: 74, Loss: 1.1372815370559692, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.0582613945007324, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.0671892166137695, Accuracy: 0.6416015625\n",
      "Batch: 77, Loss: 1.0251402854919434, Accuracy: 0.65234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 78, Loss: 1.0413506031036377, Accuracy: 0.6572265625\n",
      "Batch: 79, Loss: 1.0680782794952393, Accuracy: 0.6767578125\n",
      "Batch: 80, Loss: 1.0882083177566528, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.1187989711761475, Accuracy: 0.625\n",
      "Batch: 82, Loss: 1.0776591300964355, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.1349494457244873, Accuracy: 0.6298828125\n",
      "Batch: 84, Loss: 1.0523457527160645, Accuracy: 0.6640625\n",
      "Batch: 85, Loss: 1.1615285873413086, Accuracy: 0.611328125\n",
      "Batch: 86, Loss: 1.1676318645477295, Accuracy: 0.61328125\n",
      "Batch: 87, Loss: 1.1505454778671265, Accuracy: 0.6455078125\n",
      "Batch: 88, Loss: 1.136819839477539, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1351971626281738, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 1.112572193145752, Accuracy: 0.626953125\n",
      "Batch: 91, Loss: 1.1005678176879883, Accuracy: 0.6337890625\n",
      "Batch: 92, Loss: 1.1046003103256226, Accuracy: 0.6435546875\n",
      "Batch: 93, Loss: 1.1000823974609375, Accuracy: 0.630859375\n",
      "Batch: 94, Loss: 1.1546870470046997, Accuracy: 0.6416015625\n",
      "Batch: 95, Loss: 1.1173317432403564, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.148794174194336, Accuracy: 0.646484375\n",
      "Batch: 97, Loss: 1.164048671722412, Accuracy: 0.6181640625\n",
      "Batch: 98, Loss: 1.13228178024292, Accuracy: 0.6142578125\n",
      "Batch: 99, Loss: 1.1291285753250122, Accuracy: 0.625\n",
      "Batch: 100, Loss: 1.0426695346832275, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.0738184452056885, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.171715259552002, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.069385290145874, Accuracy: 0.6650390625\n",
      "Batch: 104, Loss: 1.145186424255371, Accuracy: 0.6064453125\n",
      "Batch: 105, Loss: 1.1465332508087158, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.1255557537078857, Accuracy: 0.6455078125\n",
      "Batch: 107, Loss: 1.2216691970825195, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.1352523565292358, Accuracy: 0.6103515625\n",
      "Batch: 109, Loss: 1.1477022171020508, Accuracy: 0.6220703125\n",
      "Batch: 110, Loss: 1.1405175924301147, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.0783848762512207, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0918762683868408, Accuracy: 0.6279296875\n",
      "Batch: 113, Loss: 1.073753833770752, Accuracy: 0.638671875\n",
      "Batch: 114, Loss: 1.160919427871704, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.172120213508606, Accuracy: 0.6171875\n",
      "Batch: 116, Loss: 1.157123327255249, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.1308276653289795, Accuracy: 0.630859375\n",
      "Batch: 118, Loss: 1.18833327293396, Accuracy: 0.607421875\n",
      "Batch: 119, Loss: 1.1528582572937012, Accuracy: 0.6357421875\n",
      "Batch: 120, Loss: 1.3180961608886719, Accuracy: 0.59765625\n",
      "Batch: 121, Loss: 1.1562488079071045, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.1428289413452148, Accuracy: 0.646484375\n",
      "Batch: 123, Loss: 1.128812551498413, Accuracy: 0.6396484375\n",
      "Batch: 124, Loss: 1.1665822267532349, Accuracy: 0.640625\n",
      "Batch: 125, Loss: 1.1888957023620605, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.194082260131836, Accuracy: 0.62109375\n",
      "Batch: 127, Loss: 1.1574643850326538, Accuracy: 0.625\n",
      "Batch: 128, Loss: 1.182190179824829, Accuracy: 0.6181640625\n",
      "Batch: 129, Loss: 1.0939743518829346, Accuracy: 0.646484375\n",
      "Batch: 130, Loss: 1.1376343965530396, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.23036527633667, Accuracy: 0.6015625\n",
      "Batch: 132, Loss: 1.0909807682037354, Accuracy: 0.646484375\n",
      "Batch: 133, Loss: 1.1132442951202393, Accuracy: 0.6552734375\n",
      "Batch: 134, Loss: 1.094387412071228, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 1.0683236122131348, Accuracy: 0.6591796875\n",
      "Batch: 136, Loss: 1.0891129970550537, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.1523840427398682, Accuracy: 0.6259765625\n",
      "Batch: 138, Loss: 1.1842451095581055, Accuracy: 0.611328125\n",
      "Batch: 139, Loss: 1.1708474159240723, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.1875591278076172, Accuracy: 0.6298828125\n",
      "Batch: 141, Loss: 1.1586461067199707, Accuracy: 0.63671875\n",
      "Batch: 142, Loss: 1.1182105541229248, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.2061265707015991, Accuracy: 0.5966796875\n",
      "Batch: 144, Loss: 1.1971023082733154, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2245357036590576, Accuracy: 0.6103515625\n",
      "Batch: 146, Loss: 1.126652479171753, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.122135877609253, Accuracy: 0.642578125\n",
      "Batch: 148, Loss: 1.1724035739898682, Accuracy: 0.6240234375\n",
      "Batch: 149, Loss: 1.1250810623168945, Accuracy: 0.6435546875\n",
      "Batch: 150, Loss: 1.1515552997589111, Accuracy: 0.6201171875\n",
      "Batch: 151, Loss: 1.1297662258148193, Accuracy: 0.62109375\n",
      "Batch: 152, Loss: 1.1469942331314087, Accuracy: 0.6083984375\n",
      "Batch: 153, Loss: 1.1084468364715576, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.1495035886764526, Accuracy: 0.6328125\n",
      "Batch: 155, Loss: 1.0542118549346924, Accuracy: 0.673828125\n",
      "Epoch 550/200\n",
      "Batch: 1, Loss: 1.2862435579299927, Accuracy: 0.62890625\n",
      "Batch: 2, Loss: 1.0470962524414062, Accuracy: 0.6650390625\n",
      "Batch: 3, Loss: 0.9980049133300781, Accuracy: 0.671875\n",
      "Batch: 4, Loss: 1.0651620626449585, Accuracy: 0.6396484375\n",
      "Batch: 5, Loss: 0.9555671215057373, Accuracy: 0.697265625\n",
      "Batch: 6, Loss: 1.0596733093261719, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.0115665197372437, Accuracy: 0.6572265625\n",
      "Batch: 8, Loss: 1.002351999282837, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 0.9992682933807373, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 1.0183074474334717, Accuracy: 0.6630859375\n",
      "Batch: 11, Loss: 0.9451907873153687, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.9477819204330444, Accuracy: 0.689453125\n",
      "Batch: 13, Loss: 0.9745593070983887, Accuracy: 0.6875\n",
      "Batch: 14, Loss: 0.9461091756820679, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.9499534368515015, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 0.9660098552703857, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.021111249923706, Accuracy: 0.654296875\n",
      "Batch: 18, Loss: 1.059267520904541, Accuracy: 0.6640625\n",
      "Batch: 19, Loss: 1.1906026601791382, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.0508427619934082, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.1154769659042358, Accuracy: 0.6357421875\n",
      "Batch: 22, Loss: 1.1443421840667725, Accuracy: 0.62109375\n",
      "Batch: 23, Loss: 1.2700793743133545, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.0666999816894531, Accuracy: 0.6630859375\n",
      "Batch: 25, Loss: 1.1564323902130127, Accuracy: 0.6328125\n",
      "Batch: 26, Loss: 1.189405918121338, Accuracy: 0.623046875\n",
      "Batch: 27, Loss: 1.1089794635772705, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.0421936511993408, Accuracy: 0.6552734375\n",
      "Batch: 29, Loss: 0.9959656000137329, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 1.1883363723754883, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.1719105243682861, Accuracy: 0.6220703125\n",
      "Batch: 32, Loss: 1.0019469261169434, Accuracy: 0.6748046875\n",
      "Batch: 33, Loss: 0.9646244049072266, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.0501198768615723, Accuracy: 0.66796875\n",
      "Batch: 35, Loss: 1.0947248935699463, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.1450905799865723, Accuracy: 0.6162109375\n",
      "Batch: 37, Loss: 1.1917829513549805, Accuracy: 0.609375\n",
      "Batch: 38, Loss: 1.1648039817810059, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.0965462923049927, Accuracy: 0.6552734375\n",
      "Batch: 40, Loss: 1.0790715217590332, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.1054829359054565, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.0275715589523315, Accuracy: 0.677734375\n",
      "Batch: 43, Loss: 0.9863746166229248, Accuracy: 0.6748046875\n",
      "Batch: 44, Loss: 0.9768816828727722, Accuracy: 0.68359375\n",
      "Batch: 45, Loss: 1.0371019840240479, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.1232304573059082, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.1085474491119385, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.1100126504898071, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.0968410968780518, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.1270369291305542, Accuracy: 0.6318359375\n",
      "Batch: 51, Loss: 1.121875286102295, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.1503994464874268, Accuracy: 0.6103515625\n",
      "Batch: 53, Loss: 1.1540294885635376, Accuracy: 0.6318359375\n",
      "Batch: 54, Loss: 1.1160483360290527, Accuracy: 0.6240234375\n",
      "Batch: 55, Loss: 1.0767006874084473, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0100195407867432, Accuracy: 0.6865234375\n",
      "Batch: 57, Loss: 1.0774683952331543, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.0880342721939087, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 1.0784538984298706, Accuracy: 0.6455078125\n",
      "Batch: 60, Loss: 1.2200424671173096, Accuracy: 0.5927734375\n",
      "Batch: 61, Loss: 1.0917268991470337, Accuracy: 0.6298828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 1.1150456666946411, Accuracy: 0.638671875\n",
      "Batch: 63, Loss: 1.1328082084655762, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.1473627090454102, Accuracy: 0.625\n",
      "Batch: 65, Loss: 1.1161537170410156, Accuracy: 0.634765625\n",
      "Batch: 66, Loss: 1.1108920574188232, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.132390022277832, Accuracy: 0.63671875\n",
      "Batch: 68, Loss: 1.0472440719604492, Accuracy: 0.6552734375\n",
      "Batch: 69, Loss: 1.1376073360443115, Accuracy: 0.640625\n",
      "Batch: 70, Loss: 1.0817790031433105, Accuracy: 0.6484375\n",
      "Batch: 71, Loss: 1.0786077976226807, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.1687266826629639, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.1910061836242676, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.0278911590576172, Accuracy: 0.646484375\n",
      "Batch: 75, Loss: 1.0887682437896729, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.055676817893982, Accuracy: 0.6640625\n",
      "Batch: 77, Loss: 1.056321382522583, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0680958032608032, Accuracy: 0.6357421875\n",
      "Batch: 79, Loss: 1.0658565759658813, Accuracy: 0.650390625\n",
      "Batch: 80, Loss: 1.1489462852478027, Accuracy: 0.64453125\n",
      "Batch: 81, Loss: 1.0633728504180908, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.095777153968811, Accuracy: 0.6396484375\n",
      "Batch: 83, Loss: 1.19943368434906, Accuracy: 0.5947265625\n",
      "Batch: 84, Loss: 1.0773510932922363, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.1381229162216187, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.1147695779800415, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.1740520000457764, Accuracy: 0.6455078125\n",
      "Batch: 88, Loss: 1.1357548236846924, Accuracy: 0.6181640625\n",
      "Batch: 89, Loss: 1.0644696950912476, Accuracy: 0.6708984375\n",
      "Batch: 90, Loss: 1.0604392290115356, Accuracy: 0.6650390625\n",
      "Batch: 91, Loss: 1.1346631050109863, Accuracy: 0.61328125\n",
      "Batch: 92, Loss: 1.1122193336486816, Accuracy: 0.662109375\n",
      "Batch: 93, Loss: 1.126191258430481, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.1515040397644043, Accuracy: 0.62109375\n",
      "Batch: 95, Loss: 1.1702762842178345, Accuracy: 0.6318359375\n",
      "Batch: 96, Loss: 1.1642000675201416, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.1544437408447266, Accuracy: 0.62890625\n",
      "Batch: 98, Loss: 1.072195053100586, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.0659458637237549, Accuracy: 0.6533203125\n",
      "Batch: 100, Loss: 1.048258900642395, Accuracy: 0.666015625\n",
      "Batch: 101, Loss: 1.0818735361099243, Accuracy: 0.65625\n",
      "Batch: 102, Loss: 1.1617159843444824, Accuracy: 0.6337890625\n",
      "Batch: 103, Loss: 1.1370830535888672, Accuracy: 0.6142578125\n",
      "Batch: 104, Loss: 1.135176420211792, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.1506896018981934, Accuracy: 0.6484375\n",
      "Batch: 106, Loss: 1.1330926418304443, Accuracy: 0.6328125\n",
      "Batch: 107, Loss: 1.1779334545135498, Accuracy: 0.6142578125\n",
      "Batch: 108, Loss: 1.1765248775482178, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.2419519424438477, Accuracy: 0.6123046875\n",
      "Batch: 110, Loss: 1.1595888137817383, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.1294817924499512, Accuracy: 0.6318359375\n",
      "Batch: 112, Loss: 1.0948100090026855, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.1133792400360107, Accuracy: 0.6396484375\n",
      "Batch: 114, Loss: 1.095981478691101, Accuracy: 0.62109375\n",
      "Batch: 115, Loss: 1.1057488918304443, Accuracy: 0.6142578125\n",
      "Batch: 116, Loss: 1.1441370248794556, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.1381549835205078, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.1942789554595947, Accuracy: 0.6142578125\n",
      "Batch: 119, Loss: 1.2493292093276978, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.3116557598114014, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.2105984687805176, Accuracy: 0.607421875\n",
      "Batch: 122, Loss: 1.2220538854599, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.1845577955245972, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.1503452062606812, Accuracy: 0.6298828125\n",
      "Batch: 125, Loss: 1.1231019496917725, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.2589406967163086, Accuracy: 0.5986328125\n",
      "Batch: 127, Loss: 1.1686429977416992, Accuracy: 0.6064453125\n",
      "Batch: 128, Loss: 1.1022751331329346, Accuracy: 0.6416015625\n",
      "Batch: 129, Loss: 1.1873741149902344, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.0973646640777588, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.1632556915283203, Accuracy: 0.6279296875\n",
      "Batch: 132, Loss: 1.0594780445098877, Accuracy: 0.6474609375\n",
      "Batch: 133, Loss: 1.1674127578735352, Accuracy: 0.6328125\n",
      "Batch: 134, Loss: 1.0963727235794067, Accuracy: 0.6279296875\n",
      "Batch: 135, Loss: 1.0362040996551514, Accuracy: 0.669921875\n",
      "Batch: 136, Loss: 1.0112180709838867, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.1087133884429932, Accuracy: 0.6552734375\n",
      "Batch: 138, Loss: 1.2237672805786133, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.1335598230361938, Accuracy: 0.642578125\n",
      "Batch: 140, Loss: 1.2020916938781738, Accuracy: 0.630859375\n",
      "Batch: 141, Loss: 1.0872852802276611, Accuracy: 0.6474609375\n",
      "Batch: 142, Loss: 1.144356369972229, Accuracy: 0.63671875\n",
      "Batch: 143, Loss: 1.1970322132110596, Accuracy: 0.6005859375\n",
      "Batch: 144, Loss: 1.1622881889343262, Accuracy: 0.6298828125\n",
      "Batch: 145, Loss: 1.2255723476409912, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.2206138372421265, Accuracy: 0.58984375\n",
      "Batch: 147, Loss: 1.1803662776947021, Accuracy: 0.611328125\n",
      "Batch: 148, Loss: 1.2002419233322144, Accuracy: 0.60546875\n",
      "Batch: 149, Loss: 1.160990595817566, Accuracy: 0.6357421875\n",
      "Batch: 150, Loss: 1.1320728063583374, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.1346864700317383, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1412039995193481, Accuracy: 0.6171875\n",
      "Batch: 153, Loss: 1.1235480308532715, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.070683240890503, Accuracy: 0.6572265625\n",
      "Batch: 155, Loss: 1.0589709281921387, Accuracy: 0.65234375\n",
      "Saved Weights at epoch 550 to file Weights_550.h5\n",
      "Epoch 551/200\n",
      "Batch: 1, Loss: 1.2137165069580078, Accuracy: 0.6376953125\n",
      "Batch: 2, Loss: 1.088433027267456, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 1.0170459747314453, Accuracy: 0.69140625\n",
      "Batch: 4, Loss: 1.0410261154174805, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 1.0008515119552612, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.0059654712677002, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 0.9976750612258911, Accuracy: 0.66015625\n",
      "Batch: 8, Loss: 0.9607036113739014, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9864140748977661, Accuracy: 0.6826171875\n",
      "Batch: 10, Loss: 0.9842348098754883, Accuracy: 0.669921875\n",
      "Batch: 11, Loss: 0.9605858325958252, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.9792420268058777, Accuracy: 0.6845703125\n",
      "Batch: 13, Loss: 1.0314419269561768, Accuracy: 0.6572265625\n",
      "Batch: 14, Loss: 0.8953323364257812, Accuracy: 0.703125\n",
      "Batch: 15, Loss: 0.9342386722564697, Accuracy: 0.689453125\n",
      "Batch: 16, Loss: 1.043590784072876, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.112699031829834, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.087904691696167, Accuracy: 0.6298828125\n",
      "Batch: 19, Loss: 1.1487905979156494, Accuracy: 0.62109375\n",
      "Batch: 20, Loss: 1.0333913564682007, Accuracy: 0.6767578125\n",
      "Batch: 21, Loss: 1.037847638130188, Accuracy: 0.658203125\n",
      "Batch: 22, Loss: 1.210737943649292, Accuracy: 0.5986328125\n",
      "Batch: 23, Loss: 1.1814143657684326, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.0864131450653076, Accuracy: 0.650390625\n",
      "Batch: 25, Loss: 1.1207497119903564, Accuracy: 0.6474609375\n",
      "Batch: 26, Loss: 1.1828203201293945, Accuracy: 0.6015625\n",
      "Batch: 27, Loss: 1.1018574237823486, Accuracy: 0.642578125\n",
      "Batch: 28, Loss: 1.1027419567108154, Accuracy: 0.6162109375\n",
      "Batch: 29, Loss: 1.016194224357605, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 1.1132097244262695, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.1384458541870117, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.0397143363952637, Accuracy: 0.65234375\n",
      "Batch: 33, Loss: 0.9836603403091431, Accuracy: 0.67578125\n",
      "Batch: 34, Loss: 1.0794150829315186, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.0799328088760376, Accuracy: 0.658203125\n",
      "Batch: 36, Loss: 1.1949183940887451, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.1769392490386963, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.177612066268921, Accuracy: 0.615234375\n",
      "Batch: 39, Loss: 1.096550464630127, Accuracy: 0.6396484375\n",
      "Batch: 40, Loss: 1.0919826030731201, Accuracy: 0.6484375\n",
      "Batch: 41, Loss: 1.108986258506775, Accuracy: 0.6396484375\n",
      "Batch: 42, Loss: 1.0712876319885254, Accuracy: 0.6455078125\n",
      "Batch: 43, Loss: 1.0002334117889404, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.048564076423645, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 0.992518424987793, Accuracy: 0.66796875\n",
      "Batch: 46, Loss: 1.114081859588623, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.0913987159729004, Accuracy: 0.6474609375\n",
      "Batch: 48, Loss: 1.0994417667388916, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.1078044176101685, Accuracy: 0.6435546875\n",
      "Batch: 50, Loss: 1.1468292474746704, Accuracy: 0.6416015625\n",
      "Batch: 51, Loss: 1.1400988101959229, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.2470197677612305, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.2006480693817139, Accuracy: 0.5947265625\n",
      "Batch: 54, Loss: 1.1121822595596313, Accuracy: 0.6376953125\n",
      "Batch: 55, Loss: 1.1369860172271729, Accuracy: 0.6298828125\n",
      "Batch: 56, Loss: 1.031947374343872, Accuracy: 0.6748046875\n",
      "Batch: 57, Loss: 1.062693476676941, Accuracy: 0.6708984375\n",
      "Batch: 58, Loss: 1.1104543209075928, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.112779140472412, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2324963808059692, Accuracy: 0.626953125\n",
      "Batch: 61, Loss: 1.19032883644104, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.1771178245544434, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.1704041957855225, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.2259914875030518, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.1640201807022095, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1355124711990356, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.1761771440505981, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.0663535594940186, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.1786574125289917, Accuracy: 0.6298828125\n",
      "Batch: 70, Loss: 1.1627238988876343, Accuracy: 0.6279296875\n",
      "Batch: 71, Loss: 1.1033790111541748, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 1.2115397453308105, Accuracy: 0.607421875\n",
      "Batch: 73, Loss: 1.1721794605255127, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.0858123302459717, Accuracy: 0.6357421875\n",
      "Batch: 75, Loss: 1.0948764085769653, Accuracy: 0.6455078125\n",
      "Batch: 76, Loss: 1.064363718032837, Accuracy: 0.6474609375\n",
      "Batch: 77, Loss: 1.067359447479248, Accuracy: 0.6630859375\n",
      "Batch: 78, Loss: 1.0453654527664185, Accuracy: 0.6484375\n",
      "Batch: 79, Loss: 1.0736397504806519, Accuracy: 0.6591796875\n",
      "Batch: 80, Loss: 1.142284870147705, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.15049147605896, Accuracy: 0.640625\n",
      "Batch: 82, Loss: 1.084883689880371, Accuracy: 0.6337890625\n",
      "Batch: 83, Loss: 1.137455940246582, Accuracy: 0.626953125\n",
      "Batch: 84, Loss: 1.105621099472046, Accuracy: 0.642578125\n",
      "Batch: 85, Loss: 1.1120632886886597, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.1963664293289185, Accuracy: 0.6220703125\n",
      "Batch: 87, Loss: 1.1535847187042236, Accuracy: 0.630859375\n",
      "Batch: 88, Loss: 1.1412737369537354, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1512980461120605, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.1290645599365234, Accuracy: 0.630859375\n",
      "Batch: 91, Loss: 1.129399299621582, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.0974518060684204, Accuracy: 0.662109375\n",
      "Batch: 93, Loss: 1.1408889293670654, Accuracy: 0.6328125\n",
      "Batch: 94, Loss: 1.2305467128753662, Accuracy: 0.5947265625\n",
      "Batch: 95, Loss: 1.1125524044036865, Accuracy: 0.6435546875\n",
      "Batch: 96, Loss: 1.1636396646499634, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.1352019309997559, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.0648491382598877, Accuracy: 0.6396484375\n",
      "Batch: 99, Loss: 1.0997915267944336, Accuracy: 0.65234375\n",
      "Batch: 100, Loss: 1.0558067560195923, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.1183167695999146, Accuracy: 0.6376953125\n",
      "Batch: 102, Loss: 1.190941333770752, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.1179733276367188, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.1233904361724854, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.1872559785842896, Accuracy: 0.6181640625\n",
      "Batch: 106, Loss: 1.2269067764282227, Accuracy: 0.60546875\n",
      "Batch: 107, Loss: 1.1995131969451904, Accuracy: 0.615234375\n",
      "Batch: 108, Loss: 1.177304744720459, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.1408963203430176, Accuracy: 0.6396484375\n",
      "Batch: 110, Loss: 1.1475634574890137, Accuracy: 0.607421875\n",
      "Batch: 111, Loss: 1.1221612691879272, Accuracy: 0.630859375\n",
      "Batch: 112, Loss: 1.0969370603561401, Accuracy: 0.630859375\n",
      "Batch: 113, Loss: 1.1561734676361084, Accuracy: 0.6083984375\n",
      "Batch: 114, Loss: 1.144601583480835, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1862561702728271, Accuracy: 0.6259765625\n",
      "Batch: 116, Loss: 1.18215012550354, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1748663187026978, Accuracy: 0.6279296875\n",
      "Batch: 118, Loss: 1.189125418663025, Accuracy: 0.62109375\n",
      "Batch: 119, Loss: 1.139896035194397, Accuracy: 0.62890625\n",
      "Batch: 120, Loss: 1.2824405431747437, Accuracy: 0.6064453125\n",
      "Batch: 121, Loss: 1.211954116821289, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.196343183517456, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.0945451259613037, Accuracy: 0.6630859375\n",
      "Batch: 124, Loss: 1.1457929611206055, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.1471219062805176, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.2066123485565186, Accuracy: 0.609375\n",
      "Batch: 127, Loss: 1.2316045761108398, Accuracy: 0.60546875\n",
      "Batch: 128, Loss: 1.1360700130462646, Accuracy: 0.619140625\n",
      "Batch: 129, Loss: 1.1003670692443848, Accuracy: 0.6435546875\n",
      "Batch: 130, Loss: 1.115079641342163, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1598570346832275, Accuracy: 0.6318359375\n",
      "Batch: 132, Loss: 1.080042839050293, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.1306755542755127, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1128463745117188, Accuracy: 0.6572265625\n",
      "Batch: 135, Loss: 0.9926366806030273, Accuracy: 0.6748046875\n",
      "Batch: 136, Loss: 1.0536737442016602, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.1384586095809937, Accuracy: 0.634765625\n",
      "Batch: 138, Loss: 1.2023566961288452, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1231648921966553, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.2436656951904297, Accuracy: 0.5810546875\n",
      "Batch: 141, Loss: 1.0994515419006348, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1411608457565308, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.215976595878601, Accuracy: 0.6025390625\n",
      "Batch: 144, Loss: 1.2431001663208008, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.2216746807098389, Accuracy: 0.626953125\n",
      "Batch: 146, Loss: 1.175313949584961, Accuracy: 0.619140625\n",
      "Batch: 147, Loss: 1.1171504259109497, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.202587366104126, Accuracy: 0.58984375\n",
      "Batch: 149, Loss: 1.127838373184204, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.133152961730957, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.1464194059371948, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.1633877754211426, Accuracy: 0.6025390625\n",
      "Batch: 153, Loss: 1.1233083009719849, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.0798578262329102, Accuracy: 0.65625\n",
      "Batch: 155, Loss: 1.0461671352386475, Accuracy: 0.6552734375\n",
      "Epoch 552/200\n",
      "Batch: 1, Loss: 1.2340233325958252, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0461530685424805, Accuracy: 0.671875\n",
      "Batch: 3, Loss: 1.018295407295227, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0518848896026611, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 0.954573929309845, Accuracy: 0.6748046875\n",
      "Batch: 6, Loss: 1.0199854373931885, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 1.066151738166809, Accuracy: 0.6533203125\n",
      "Batch: 8, Loss: 0.9754592180252075, Accuracy: 0.6962890625\n",
      "Batch: 9, Loss: 1.0311335325241089, Accuracy: 0.654296875\n",
      "Batch: 10, Loss: 0.9247624278068542, Accuracy: 0.689453125\n",
      "Batch: 11, Loss: 0.9303847551345825, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9438883066177368, Accuracy: 0.685546875\n",
      "Batch: 13, Loss: 0.9676517248153687, Accuracy: 0.669921875\n",
      "Batch: 14, Loss: 0.9294775724411011, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.9055944681167603, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 1.0050606727600098, Accuracy: 0.685546875\n",
      "Batch: 17, Loss: 1.0456979274749756, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.0927646160125732, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.140860915184021, Accuracy: 0.6220703125\n",
      "Batch: 20, Loss: 1.0423604249954224, Accuracy: 0.66796875\n",
      "Batch: 21, Loss: 1.0726885795593262, Accuracy: 0.6494140625\n",
      "Batch: 22, Loss: 1.1761465072631836, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.1874330043792725, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.0957121849060059, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.1125212907791138, Accuracy: 0.6435546875\n",
      "Batch: 26, Loss: 1.132501482963562, Accuracy: 0.625\n",
      "Batch: 27, Loss: 1.165069580078125, Accuracy: 0.5908203125\n",
      "Batch: 28, Loss: 1.0752453804016113, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.0059726238250732, Accuracy: 0.677734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 1.2003018856048584, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.1940057277679443, Accuracy: 0.5986328125\n",
      "Batch: 32, Loss: 1.0158993005752563, Accuracy: 0.662109375\n",
      "Batch: 33, Loss: 1.0056473016738892, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.075390338897705, Accuracy: 0.654296875\n",
      "Batch: 35, Loss: 1.1007578372955322, Accuracy: 0.640625\n",
      "Batch: 36, Loss: 1.162463665008545, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.2202091217041016, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.1419758796691895, Accuracy: 0.6328125\n",
      "Batch: 39, Loss: 1.060847520828247, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.077462911605835, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.1337103843688965, Accuracy: 0.6162109375\n",
      "Batch: 42, Loss: 1.0677573680877686, Accuracy: 0.6376953125\n",
      "Batch: 43, Loss: 1.039563775062561, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.0763658285140991, Accuracy: 0.6259765625\n",
      "Batch: 45, Loss: 1.0415681600570679, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.0891749858856201, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.0577785968780518, Accuracy: 0.65625\n",
      "Batch: 48, Loss: 1.0934600830078125, Accuracy: 0.6259765625\n",
      "Batch: 49, Loss: 1.0970300436019897, Accuracy: 0.6591796875\n",
      "Batch: 50, Loss: 1.1340584754943848, Accuracy: 0.642578125\n",
      "Batch: 51, Loss: 1.147755742073059, Accuracy: 0.6123046875\n",
      "Batch: 52, Loss: 1.2152390480041504, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.096794605255127, Accuracy: 0.6376953125\n",
      "Batch: 54, Loss: 1.1750638484954834, Accuracy: 0.61328125\n",
      "Batch: 55, Loss: 1.1189202070236206, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.0886645317077637, Accuracy: 0.65625\n",
      "Batch: 57, Loss: 1.0749974250793457, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.0832349061965942, Accuracy: 0.6513671875\n",
      "Batch: 59, Loss: 1.0808354616165161, Accuracy: 0.6650390625\n",
      "Batch: 60, Loss: 1.2705206871032715, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.1420286893844604, Accuracy: 0.6171875\n",
      "Batch: 62, Loss: 1.0752389430999756, Accuracy: 0.6416015625\n",
      "Batch: 63, Loss: 1.1976312398910522, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.1611063480377197, Accuracy: 0.609375\n",
      "Batch: 65, Loss: 1.1531927585601807, Accuracy: 0.6240234375\n",
      "Batch: 66, Loss: 1.0773799419403076, Accuracy: 0.6484375\n",
      "Batch: 67, Loss: 1.1301344633102417, Accuracy: 0.6318359375\n",
      "Batch: 68, Loss: 1.1194477081298828, Accuracy: 0.63671875\n",
      "Batch: 69, Loss: 1.1781437397003174, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.1197257041931152, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.1449224948883057, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.1953089237213135, Accuracy: 0.61328125\n",
      "Batch: 73, Loss: 1.1924573183059692, Accuracy: 0.6025390625\n",
      "Batch: 74, Loss: 1.0570670366287231, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.109498143196106, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.040311574935913, Accuracy: 0.64453125\n",
      "Batch: 77, Loss: 0.9853610992431641, Accuracy: 0.67578125\n",
      "Batch: 78, Loss: 1.0307291746139526, Accuracy: 0.65234375\n",
      "Batch: 79, Loss: 1.0895284414291382, Accuracy: 0.6484375\n",
      "Batch: 80, Loss: 1.1134220361709595, Accuracy: 0.6298828125\n",
      "Batch: 81, Loss: 1.0756314992904663, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 1.0878537893295288, Accuracy: 0.6484375\n",
      "Batch: 83, Loss: 1.143242597579956, Accuracy: 0.6416015625\n",
      "Batch: 84, Loss: 1.0680567026138306, Accuracy: 0.6552734375\n",
      "Batch: 85, Loss: 1.1438976526260376, Accuracy: 0.625\n",
      "Batch: 86, Loss: 1.168260097503662, Accuracy: 0.626953125\n",
      "Batch: 87, Loss: 1.1654634475708008, Accuracy: 0.6259765625\n",
      "Batch: 88, Loss: 1.1513134241104126, Accuracy: 0.6357421875\n",
      "Batch: 89, Loss: 1.1237715482711792, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.1255218982696533, Accuracy: 0.623046875\n",
      "Batch: 91, Loss: 1.080690622329712, Accuracy: 0.6591796875\n",
      "Batch: 92, Loss: 1.1596238613128662, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.0758306980133057, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.1058237552642822, Accuracy: 0.638671875\n",
      "Batch: 95, Loss: 1.1365370750427246, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.1722267866134644, Accuracy: 0.62890625\n",
      "Batch: 97, Loss: 1.175899624824524, Accuracy: 0.60546875\n",
      "Batch: 98, Loss: 1.0857462882995605, Accuracy: 0.6435546875\n",
      "Batch: 99, Loss: 1.1031794548034668, Accuracy: 0.642578125\n",
      "Batch: 100, Loss: 1.0717211961746216, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.1060569286346436, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.13688325881958, Accuracy: 0.638671875\n",
      "Batch: 103, Loss: 1.1439831256866455, Accuracy: 0.6279296875\n",
      "Batch: 104, Loss: 1.098684310913086, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.1950892210006714, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.1082890033721924, Accuracy: 0.6416015625\n",
      "Batch: 107, Loss: 1.189400553703308, Accuracy: 0.619140625\n",
      "Batch: 108, Loss: 1.221481204032898, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.1558125019073486, Accuracy: 0.6318359375\n",
      "Batch: 110, Loss: 1.1576848030090332, Accuracy: 0.62890625\n",
      "Batch: 111, Loss: 1.08060622215271, Accuracy: 0.64453125\n",
      "Batch: 112, Loss: 1.0654053688049316, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1041510105133057, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.1329338550567627, Accuracy: 0.626953125\n",
      "Batch: 115, Loss: 1.1551674604415894, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.1611143350601196, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.2055306434631348, Accuracy: 0.5830078125\n",
      "Batch: 118, Loss: 1.1744129657745361, Accuracy: 0.60546875\n",
      "Batch: 119, Loss: 1.1929742097854614, Accuracy: 0.61328125\n",
      "Batch: 120, Loss: 1.254740595817566, Accuracy: 0.609375\n",
      "Batch: 121, Loss: 1.1337189674377441, Accuracy: 0.6396484375\n",
      "Batch: 122, Loss: 1.1796331405639648, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1491360664367676, Accuracy: 0.619140625\n",
      "Batch: 124, Loss: 1.1729055643081665, Accuracy: 0.6318359375\n",
      "Batch: 125, Loss: 1.1703038215637207, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.209317684173584, Accuracy: 0.6337890625\n",
      "Batch: 127, Loss: 1.229557991027832, Accuracy: 0.607421875\n",
      "Batch: 128, Loss: 1.2169380187988281, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.1351337432861328, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.1230921745300293, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.210230827331543, Accuracy: 0.626953125\n",
      "Batch: 132, Loss: 1.0442042350769043, Accuracy: 0.6630859375\n",
      "Batch: 133, Loss: 1.1090261936187744, Accuracy: 0.646484375\n",
      "Batch: 134, Loss: 1.1396620273590088, Accuracy: 0.638671875\n",
      "Batch: 135, Loss: 1.0043690204620361, Accuracy: 0.685546875\n",
      "Batch: 136, Loss: 1.043971061706543, Accuracy: 0.669921875\n",
      "Batch: 137, Loss: 1.1781387329101562, Accuracy: 0.611328125\n",
      "Batch: 138, Loss: 1.2302484512329102, Accuracy: 0.5908203125\n",
      "Batch: 139, Loss: 1.1883193254470825, Accuracy: 0.62890625\n",
      "Batch: 140, Loss: 1.2042560577392578, Accuracy: 0.6318359375\n",
      "Batch: 141, Loss: 1.1402682065963745, Accuracy: 0.6259765625\n",
      "Batch: 142, Loss: 1.132511854171753, Accuracy: 0.654296875\n",
      "Batch: 143, Loss: 1.1825371980667114, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.1692465543746948, Accuracy: 0.6142578125\n",
      "Batch: 145, Loss: 1.224660038948059, Accuracy: 0.5927734375\n",
      "Batch: 146, Loss: 1.1989684104919434, Accuracy: 0.6220703125\n",
      "Batch: 147, Loss: 1.1627897024154663, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.2183821201324463, Accuracy: 0.60546875\n",
      "Batch: 149, Loss: 1.1919727325439453, Accuracy: 0.599609375\n",
      "Batch: 150, Loss: 1.1133904457092285, Accuracy: 0.6484375\n",
      "Batch: 151, Loss: 1.081537127494812, Accuracy: 0.6494140625\n",
      "Batch: 152, Loss: 1.0868525505065918, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.1406501531600952, Accuracy: 0.6259765625\n",
      "Batch: 154, Loss: 1.120872974395752, Accuracy: 0.6279296875\n",
      "Batch: 155, Loss: 1.0528271198272705, Accuracy: 0.6611328125\n",
      "Epoch 553/200\n",
      "Batch: 1, Loss: 1.212148904800415, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 1.0316929817199707, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 1.0958011150360107, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.1098624467849731, Accuracy: 0.6259765625\n",
      "Batch: 5, Loss: 0.987808883190155, Accuracy: 0.662109375\n",
      "Batch: 6, Loss: 1.0013954639434814, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.014375925064087, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9841697812080383, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 0.9733801484107971, Accuracy: 0.6865234375\n",
      "Batch: 10, Loss: 0.9244414567947388, Accuracy: 0.7001953125\n",
      "Batch: 11, Loss: 0.9318536520004272, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.9901765584945679, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 0.9853572249412537, Accuracy: 0.6767578125\n",
      "Batch: 14, Loss: 0.9242179989814758, Accuracy: 0.703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 0.9757112264633179, Accuracy: 0.6796875\n",
      "Batch: 16, Loss: 0.984995424747467, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.0295612812042236, Accuracy: 0.666015625\n",
      "Batch: 18, Loss: 1.0709223747253418, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.192929744720459, Accuracy: 0.6025390625\n",
      "Batch: 20, Loss: 1.044051170349121, Accuracy: 0.6513671875\n",
      "Batch: 21, Loss: 1.0376355648040771, Accuracy: 0.6796875\n",
      "Batch: 22, Loss: 1.1784168481826782, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.2126171588897705, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.0955982208251953, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.1108155250549316, Accuracy: 0.6396484375\n",
      "Batch: 26, Loss: 1.0828804969787598, Accuracy: 0.650390625\n",
      "Batch: 27, Loss: 1.0911388397216797, Accuracy: 0.6328125\n",
      "Batch: 28, Loss: 1.0628024339675903, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 1.0533993244171143, Accuracy: 0.6484375\n",
      "Batch: 30, Loss: 1.1325442790985107, Accuracy: 0.634765625\n",
      "Batch: 31, Loss: 1.198845624923706, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 1.0422043800354004, Accuracy: 0.6630859375\n",
      "Batch: 33, Loss: 0.9782466888427734, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.0858643054962158, Accuracy: 0.640625\n",
      "Batch: 35, Loss: 1.1143113374710083, Accuracy: 0.6220703125\n",
      "Batch: 36, Loss: 1.07294762134552, Accuracy: 0.640625\n",
      "Batch: 37, Loss: 1.18965744972229, Accuracy: 0.5869140625\n",
      "Batch: 38, Loss: 1.1173734664916992, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.004544973373413, Accuracy: 0.6923828125\n",
      "Batch: 40, Loss: 1.072584867477417, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.1240687370300293, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.00861394405365, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.03798246383667, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 0.9974454641342163, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 0.9899322390556335, Accuracy: 0.66796875\n",
      "Batch: 46, Loss: 1.1033791303634644, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.0632842779159546, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.1028672456741333, Accuracy: 0.638671875\n",
      "Batch: 49, Loss: 1.1814873218536377, Accuracy: 0.619140625\n",
      "Batch: 50, Loss: 1.1295177936553955, Accuracy: 0.6279296875\n",
      "Batch: 51, Loss: 1.1055412292480469, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.2349412441253662, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1678128242492676, Accuracy: 0.611328125\n",
      "Batch: 54, Loss: 1.1616014242172241, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.0605920553207397, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0630948543548584, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.0896344184875488, Accuracy: 0.6669921875\n",
      "Batch: 58, Loss: 1.104997158050537, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.1156545877456665, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.1701884269714355, Accuracy: 0.634765625\n",
      "Batch: 61, Loss: 1.1528949737548828, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.138649821281433, Accuracy: 0.6435546875\n",
      "Batch: 63, Loss: 1.1617348194122314, Accuracy: 0.6279296875\n",
      "Batch: 64, Loss: 1.265173077583313, Accuracy: 0.5859375\n",
      "Batch: 65, Loss: 1.1470001935958862, Accuracy: 0.6416015625\n",
      "Batch: 66, Loss: 1.1482713222503662, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1030555963516235, Accuracy: 0.6376953125\n",
      "Batch: 68, Loss: 1.0460898876190186, Accuracy: 0.673828125\n",
      "Batch: 69, Loss: 1.1098196506500244, Accuracy: 0.6357421875\n",
      "Batch: 70, Loss: 1.1457430124282837, Accuracy: 0.634765625\n",
      "Batch: 71, Loss: 1.1431198120117188, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.1740518808364868, Accuracy: 0.6142578125\n",
      "Batch: 73, Loss: 1.113653540611267, Accuracy: 0.6435546875\n",
      "Batch: 74, Loss: 1.046556830406189, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.0735448598861694, Accuracy: 0.6455078125\n",
      "Batch: 76, Loss: 1.1013038158416748, Accuracy: 0.638671875\n",
      "Batch: 77, Loss: 1.0136361122131348, Accuracy: 0.681640625\n",
      "Batch: 78, Loss: 1.07883882522583, Accuracy: 0.654296875\n",
      "Batch: 79, Loss: 1.1109035015106201, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.1313252449035645, Accuracy: 0.6259765625\n",
      "Batch: 81, Loss: 1.1247726678848267, Accuracy: 0.6455078125\n",
      "Batch: 82, Loss: 1.0860424041748047, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.1446819305419922, Accuracy: 0.6337890625\n",
      "Batch: 84, Loss: 1.060089349746704, Accuracy: 0.658203125\n",
      "Batch: 85, Loss: 1.1497745513916016, Accuracy: 0.6298828125\n",
      "Batch: 86, Loss: 1.1738381385803223, Accuracy: 0.630859375\n",
      "Batch: 87, Loss: 1.1381806135177612, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.1376417875289917, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.1118295192718506, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.0326787233352661, Accuracy: 0.658203125\n",
      "Batch: 91, Loss: 1.0960044860839844, Accuracy: 0.6484375\n",
      "Batch: 92, Loss: 1.0641900300979614, Accuracy: 0.6640625\n",
      "Batch: 93, Loss: 1.0980099439620972, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.2187272310256958, Accuracy: 0.603515625\n",
      "Batch: 95, Loss: 1.1039462089538574, Accuracy: 0.646484375\n",
      "Batch: 96, Loss: 1.142812728881836, Accuracy: 0.650390625\n",
      "Batch: 97, Loss: 1.0888309478759766, Accuracy: 0.640625\n",
      "Batch: 98, Loss: 1.0630230903625488, Accuracy: 0.6494140625\n",
      "Batch: 99, Loss: 1.119512915611267, Accuracy: 0.6435546875\n",
      "Batch: 100, Loss: 1.06320321559906, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.115013599395752, Accuracy: 0.62109375\n",
      "Batch: 102, Loss: 1.1212294101715088, Accuracy: 0.6455078125\n",
      "Batch: 103, Loss: 1.061819314956665, Accuracy: 0.658203125\n",
      "Batch: 104, Loss: 1.16448974609375, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.2208272218704224, Accuracy: 0.6181640625\n",
      "Batch: 106, Loss: 1.133428692817688, Accuracy: 0.638671875\n",
      "Batch: 107, Loss: 1.2114574909210205, Accuracy: 0.62890625\n",
      "Batch: 108, Loss: 1.1506671905517578, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.200845718383789, Accuracy: 0.591796875\n",
      "Batch: 110, Loss: 1.1507478952407837, Accuracy: 0.638671875\n",
      "Batch: 111, Loss: 1.062917709350586, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.074334740638733, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.1294550895690918, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.1172593832015991, Accuracy: 0.615234375\n",
      "Batch: 115, Loss: 1.2008368968963623, Accuracy: 0.607421875\n",
      "Batch: 116, Loss: 1.1090326309204102, Accuracy: 0.6328125\n",
      "Batch: 117, Loss: 1.1507813930511475, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.1750564575195312, Accuracy: 0.6171875\n",
      "Batch: 119, Loss: 1.1890790462493896, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.231418490409851, Accuracy: 0.6298828125\n",
      "Batch: 121, Loss: 1.2143031358718872, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.1270065307617188, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.1476309299468994, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.2080457210540771, Accuracy: 0.6103515625\n",
      "Batch: 125, Loss: 1.1240447759628296, Accuracy: 0.650390625\n",
      "Batch: 126, Loss: 1.240997314453125, Accuracy: 0.62109375\n",
      "Batch: 127, Loss: 1.2456152439117432, Accuracy: 0.611328125\n",
      "Batch: 128, Loss: 1.1581778526306152, Accuracy: 0.626953125\n",
      "Batch: 129, Loss: 1.1891474723815918, Accuracy: 0.611328125\n",
      "Batch: 130, Loss: 1.136693000793457, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.1644209623336792, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.0424489974975586, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 1.0672059059143066, Accuracy: 0.6708984375\n",
      "Batch: 134, Loss: 1.0810710191726685, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 0.9995831251144409, Accuracy: 0.67578125\n",
      "Batch: 136, Loss: 1.08636474609375, Accuracy: 0.654296875\n",
      "Batch: 137, Loss: 1.152982234954834, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.2578208446502686, Accuracy: 0.583984375\n",
      "Batch: 139, Loss: 1.2345733642578125, Accuracy: 0.6025390625\n",
      "Batch: 140, Loss: 1.2406926155090332, Accuracy: 0.615234375\n",
      "Batch: 141, Loss: 1.1802208423614502, Accuracy: 0.6103515625\n",
      "Batch: 142, Loss: 1.162703275680542, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.1500129699707031, Accuracy: 0.623046875\n",
      "Batch: 144, Loss: 1.2152233123779297, Accuracy: 0.607421875\n",
      "Batch: 145, Loss: 1.2321839332580566, Accuracy: 0.6025390625\n",
      "Batch: 146, Loss: 1.1728039979934692, Accuracy: 0.619140625\n",
      "Batch: 147, Loss: 1.1887221336364746, Accuracy: 0.6064453125\n",
      "Batch: 148, Loss: 1.1652765274047852, Accuracy: 0.6171875\n",
      "Batch: 149, Loss: 1.1721084117889404, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1182966232299805, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.1463954448699951, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.140610694885254, Accuracy: 0.6318359375\n",
      "Batch: 153, Loss: 1.1293251514434814, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1126415729522705, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 155, Loss: 1.0034334659576416, Accuracy: 0.6611328125\n",
      "Epoch 554/200\n",
      "Batch: 1, Loss: 1.1847935914993286, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 1.0273020267486572, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 0.9950699806213379, Accuracy: 0.6787109375\n",
      "Batch: 4, Loss: 1.0278279781341553, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0148067474365234, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 1.0258195400238037, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 1.0233404636383057, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.946475625038147, Accuracy: 0.6962890625\n",
      "Batch: 9, Loss: 0.9726806282997131, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9399393796920776, Accuracy: 0.69140625\n",
      "Batch: 11, Loss: 0.9298912286758423, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.9379282593727112, Accuracy: 0.69140625\n",
      "Batch: 13, Loss: 1.0020809173583984, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9597651958465576, Accuracy: 0.673828125\n",
      "Batch: 15, Loss: 0.981857419013977, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 0.9925700426101685, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 1.018145203590393, Accuracy: 0.66015625\n",
      "Batch: 18, Loss: 1.1237385272979736, Accuracy: 0.615234375\n",
      "Batch: 19, Loss: 1.1576063632965088, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 0.9881864786148071, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 1.0572404861450195, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.2075608968734741, Accuracy: 0.6259765625\n",
      "Batch: 23, Loss: 1.2390563488006592, Accuracy: 0.611328125\n",
      "Batch: 24, Loss: 1.1375749111175537, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.1164181232452393, Accuracy: 0.6357421875\n",
      "Batch: 26, Loss: 1.1713247299194336, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.080489993095398, Accuracy: 0.6435546875\n",
      "Batch: 28, Loss: 1.0415244102478027, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.0563321113586426, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.0986757278442383, Accuracy: 0.6416015625\n",
      "Batch: 31, Loss: 1.1665654182434082, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.0149316787719727, Accuracy: 0.67578125\n",
      "Batch: 33, Loss: 0.9803434014320374, Accuracy: 0.681640625\n",
      "Batch: 34, Loss: 1.077033281326294, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.100287675857544, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.1651966571807861, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.1311559677124023, Accuracy: 0.6181640625\n",
      "Batch: 38, Loss: 1.0900721549987793, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.066075325012207, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.087319016456604, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.1143579483032227, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.0447192192077637, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.0777164697647095, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.0052813291549683, Accuracy: 0.681640625\n",
      "Batch: 45, Loss: 1.0386676788330078, Accuracy: 0.6650390625\n",
      "Batch: 46, Loss: 1.1016180515289307, Accuracy: 0.6416015625\n",
      "Batch: 47, Loss: 1.046928882598877, Accuracy: 0.671875\n",
      "Batch: 48, Loss: 1.097281575202942, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.1608508825302124, Accuracy: 0.6328125\n",
      "Batch: 50, Loss: 1.0936272144317627, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.143751621246338, Accuracy: 0.6181640625\n",
      "Batch: 52, Loss: 1.219611406326294, Accuracy: 0.6005859375\n",
      "Batch: 53, Loss: 1.148248314857483, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.0861272811889648, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.1045910120010376, Accuracy: 0.642578125\n",
      "Batch: 56, Loss: 1.1202988624572754, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.1114318370819092, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.1062862873077393, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.0717363357543945, Accuracy: 0.646484375\n",
      "Batch: 60, Loss: 1.2139029502868652, Accuracy: 0.607421875\n",
      "Batch: 61, Loss: 1.1358630657196045, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.1957159042358398, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.1387563943862915, Accuracy: 0.634765625\n",
      "Batch: 64, Loss: 1.1660085916519165, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.1230449676513672, Accuracy: 0.6376953125\n",
      "Batch: 66, Loss: 1.19998037815094, Accuracy: 0.6162109375\n",
      "Batch: 67, Loss: 1.1073445081710815, Accuracy: 0.625\n",
      "Batch: 68, Loss: 1.0849419832229614, Accuracy: 0.6376953125\n",
      "Batch: 69, Loss: 1.182987928390503, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.168154001235962, Accuracy: 0.6279296875\n",
      "Batch: 71, Loss: 1.069779872894287, Accuracy: 0.6552734375\n",
      "Batch: 72, Loss: 1.1298428773880005, Accuracy: 0.6513671875\n",
      "Batch: 73, Loss: 1.1668555736541748, Accuracy: 0.6044921875\n",
      "Batch: 74, Loss: 1.1085636615753174, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.0889496803283691, Accuracy: 0.6328125\n",
      "Batch: 76, Loss: 1.0887978076934814, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 1.0560340881347656, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.041438341140747, Accuracy: 0.646484375\n",
      "Batch: 79, Loss: 1.0546914339065552, Accuracy: 0.66015625\n",
      "Batch: 80, Loss: 1.1998887062072754, Accuracy: 0.6220703125\n",
      "Batch: 81, Loss: 1.1274421215057373, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.1037497520446777, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 1.1627728939056396, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.1098188161849976, Accuracy: 0.6591796875\n",
      "Batch: 85, Loss: 1.147025227546692, Accuracy: 0.6484375\n",
      "Batch: 86, Loss: 1.1460634469985962, Accuracy: 0.6142578125\n",
      "Batch: 87, Loss: 1.1787902116775513, Accuracy: 0.603515625\n",
      "Batch: 88, Loss: 1.1390116214752197, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.13645601272583, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.1120598316192627, Accuracy: 0.646484375\n",
      "Batch: 91, Loss: 1.1180744171142578, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.1328554153442383, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.1166579723358154, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.1495262384414673, Accuracy: 0.6337890625\n",
      "Batch: 95, Loss: 1.150993824005127, Accuracy: 0.6328125\n",
      "Batch: 96, Loss: 1.1332106590270996, Accuracy: 0.630859375\n",
      "Batch: 97, Loss: 1.0939915180206299, Accuracy: 0.6552734375\n",
      "Batch: 98, Loss: 1.118120789527893, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.106123924255371, Accuracy: 0.642578125\n",
      "Batch: 100, Loss: 1.0146420001983643, Accuracy: 0.6796875\n",
      "Batch: 101, Loss: 1.0137557983398438, Accuracy: 0.6669921875\n",
      "Batch: 102, Loss: 1.1816567182540894, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.1540942192077637, Accuracy: 0.6513671875\n",
      "Batch: 104, Loss: 1.106010913848877, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.1229400634765625, Accuracy: 0.6318359375\n",
      "Batch: 106, Loss: 1.1201201677322388, Accuracy: 0.6376953125\n",
      "Batch: 107, Loss: 1.194991946220398, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.1191128492355347, Accuracy: 0.6142578125\n",
      "Batch: 109, Loss: 1.118168830871582, Accuracy: 0.6240234375\n",
      "Batch: 110, Loss: 1.1126385927200317, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.072288990020752, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.0867326259613037, Accuracy: 0.6435546875\n",
      "Batch: 113, Loss: 1.1620502471923828, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.1467081308364868, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.1749153137207031, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.189268708229065, Accuracy: 0.5947265625\n",
      "Batch: 117, Loss: 1.144842505455017, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.1730237007141113, Accuracy: 0.6142578125\n",
      "Batch: 119, Loss: 1.1852545738220215, Accuracy: 0.6259765625\n",
      "Batch: 120, Loss: 1.2367408275604248, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.1534624099731445, Accuracy: 0.6240234375\n",
      "Batch: 122, Loss: 1.141716718673706, Accuracy: 0.630859375\n",
      "Batch: 123, Loss: 1.182176113128662, Accuracy: 0.62890625\n",
      "Batch: 124, Loss: 1.215458869934082, Accuracy: 0.6025390625\n",
      "Batch: 125, Loss: 1.1435644626617432, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.1776535511016846, Accuracy: 0.62109375\n",
      "Batch: 127, Loss: 1.1276425123214722, Accuracy: 0.654296875\n",
      "Batch: 128, Loss: 1.1715344190597534, Accuracy: 0.6123046875\n",
      "Batch: 129, Loss: 1.1638014316558838, Accuracy: 0.6318359375\n",
      "Batch: 130, Loss: 1.117558479309082, Accuracy: 0.638671875\n",
      "Batch: 131, Loss: 1.1414943933486938, Accuracy: 0.6220703125\n",
      "Batch: 132, Loss: 1.0597628355026245, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.0946006774902344, Accuracy: 0.64453125\n",
      "Batch: 134, Loss: 1.085658311843872, Accuracy: 0.6640625\n",
      "Batch: 135, Loss: 1.0033891201019287, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.038864016532898, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 1.1237415075302124, Accuracy: 0.646484375\n",
      "Batch: 138, Loss: 1.2068567276000977, Accuracy: 0.583984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 1.186583399772644, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.1609458923339844, Accuracy: 0.6240234375\n",
      "Batch: 141, Loss: 1.128912329673767, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.115027666091919, Accuracy: 0.65234375\n",
      "Batch: 143, Loss: 1.1339303255081177, Accuracy: 0.6474609375\n",
      "Batch: 144, Loss: 1.2409793138504028, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.223073959350586, Accuracy: 0.6083984375\n",
      "Batch: 146, Loss: 1.1266388893127441, Accuracy: 0.6396484375\n",
      "Batch: 147, Loss: 1.161932349205017, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.102500081062317, Accuracy: 0.650390625\n",
      "Batch: 149, Loss: 1.136401891708374, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.136155128479004, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.0997910499572754, Accuracy: 0.6484375\n",
      "Batch: 152, Loss: 1.0912386178970337, Accuracy: 0.6455078125\n",
      "Batch: 153, Loss: 1.1201237440109253, Accuracy: 0.64453125\n",
      "Batch: 154, Loss: 1.1385506391525269, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0797131061553955, Accuracy: 0.6474609375\n",
      "Epoch 555/200\n",
      "Batch: 1, Loss: 1.1668586730957031, Accuracy: 0.6748046875\n",
      "Batch: 2, Loss: 1.04254150390625, Accuracy: 0.6689453125\n",
      "Batch: 3, Loss: 1.0291950702667236, Accuracy: 0.6591796875\n",
      "Batch: 4, Loss: 1.0737261772155762, Accuracy: 0.6533203125\n",
      "Batch: 5, Loss: 1.032169222831726, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.0093166828155518, Accuracy: 0.68359375\n",
      "Batch: 7, Loss: 0.9962688684463501, Accuracy: 0.67578125\n",
      "Batch: 8, Loss: 0.9707372784614563, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 0.9796736240386963, Accuracy: 0.6748046875\n",
      "Batch: 10, Loss: 0.936910092830658, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9759178161621094, Accuracy: 0.6728515625\n",
      "Batch: 12, Loss: 0.9640644788742065, Accuracy: 0.6962890625\n",
      "Batch: 13, Loss: 0.9910162687301636, Accuracy: 0.6708984375\n",
      "Batch: 14, Loss: 0.9665520191192627, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.9347320795059204, Accuracy: 0.69921875\n",
      "Batch: 16, Loss: 1.017547369003296, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 0.9927294254302979, Accuracy: 0.6796875\n",
      "Batch: 18, Loss: 1.1092143058776855, Accuracy: 0.6416015625\n",
      "Batch: 19, Loss: 1.1437926292419434, Accuracy: 0.6455078125\n",
      "Batch: 20, Loss: 1.0428357124328613, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.0454072952270508, Accuracy: 0.67578125\n",
      "Batch: 22, Loss: 1.1517319679260254, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.2199194431304932, Accuracy: 0.6025390625\n",
      "Batch: 24, Loss: 1.1052768230438232, Accuracy: 0.6611328125\n",
      "Batch: 25, Loss: 1.1298669576644897, Accuracy: 0.6240234375\n",
      "Batch: 26, Loss: 1.1201860904693604, Accuracy: 0.630859375\n",
      "Batch: 27, Loss: 1.094552993774414, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.06562340259552, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.028330683708191, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1080708503723145, Accuracy: 0.6318359375\n",
      "Batch: 31, Loss: 1.1691393852233887, Accuracy: 0.6123046875\n",
      "Batch: 32, Loss: 1.0237619876861572, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 0.9530512094497681, Accuracy: 0.7041015625\n",
      "Batch: 34, Loss: 1.0692813396453857, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 1.097183346748352, Accuracy: 0.6259765625\n",
      "Batch: 36, Loss: 1.1934926509857178, Accuracy: 0.6064453125\n",
      "Batch: 37, Loss: 1.1993378400802612, Accuracy: 0.5927734375\n",
      "Batch: 38, Loss: 1.1726486682891846, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0317692756652832, Accuracy: 0.6630859375\n",
      "Batch: 40, Loss: 1.0875933170318604, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.1652419567108154, Accuracy: 0.6298828125\n",
      "Batch: 42, Loss: 1.03196120262146, Accuracy: 0.6552734375\n",
      "Batch: 43, Loss: 1.0669126510620117, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.0424221754074097, Accuracy: 0.662109375\n",
      "Batch: 45, Loss: 1.0073200464248657, Accuracy: 0.658203125\n",
      "Batch: 46, Loss: 1.0937203168869019, Accuracy: 0.640625\n",
      "Batch: 47, Loss: 1.0786402225494385, Accuracy: 0.66015625\n",
      "Batch: 48, Loss: 1.1176143884658813, Accuracy: 0.634765625\n",
      "Batch: 49, Loss: 1.1366068124771118, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.0662903785705566, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.100611686706543, Accuracy: 0.6220703125\n",
      "Batch: 52, Loss: 1.1417021751403809, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 1.1280741691589355, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.1715295314788818, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.0990464687347412, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.1329437494277954, Accuracy: 0.6376953125\n",
      "Batch: 57, Loss: 1.0678956508636475, Accuracy: 0.6552734375\n",
      "Batch: 58, Loss: 1.0646023750305176, Accuracy: 0.666015625\n",
      "Batch: 59, Loss: 1.072407841682434, Accuracy: 0.642578125\n",
      "Batch: 60, Loss: 1.2449170351028442, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.110084891319275, Accuracy: 0.6435546875\n",
      "Batch: 62, Loss: 1.1249810457229614, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.1595537662506104, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.2161248922348022, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.212083339691162, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.1295735836029053, Accuracy: 0.640625\n",
      "Batch: 67, Loss: 1.1380696296691895, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.1164977550506592, Accuracy: 0.6240234375\n",
      "Batch: 69, Loss: 1.159919261932373, Accuracy: 0.6181640625\n",
      "Batch: 70, Loss: 1.060806393623352, Accuracy: 0.6650390625\n",
      "Batch: 71, Loss: 1.074925184249878, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.1905994415283203, Accuracy: 0.62890625\n",
      "Batch: 73, Loss: 1.138102650642395, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.0709831714630127, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.1001417636871338, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.1115883588790894, Accuracy: 0.625\n",
      "Batch: 77, Loss: 1.0455703735351562, Accuracy: 0.6611328125\n",
      "Batch: 78, Loss: 1.03793203830719, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.118563175201416, Accuracy: 0.623046875\n",
      "Batch: 80, Loss: 1.1611430644989014, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.0900150537490845, Accuracy: 0.6494140625\n",
      "Batch: 82, Loss: 1.1104722023010254, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.1677637100219727, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.088456392288208, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.1229444742202759, Accuracy: 0.6396484375\n",
      "Batch: 86, Loss: 1.1121513843536377, Accuracy: 0.650390625\n",
      "Batch: 87, Loss: 1.1133089065551758, Accuracy: 0.65234375\n",
      "Batch: 88, Loss: 1.1540151834487915, Accuracy: 0.623046875\n",
      "Batch: 89, Loss: 1.1041786670684814, Accuracy: 0.634765625\n",
      "Batch: 90, Loss: 1.0829533338546753, Accuracy: 0.6396484375\n",
      "Batch: 91, Loss: 1.1267904043197632, Accuracy: 0.634765625\n",
      "Batch: 92, Loss: 1.0648722648620605, Accuracy: 0.6318359375\n",
      "Batch: 93, Loss: 1.0726842880249023, Accuracy: 0.6357421875\n",
      "Batch: 94, Loss: 1.1496338844299316, Accuracy: 0.626953125\n",
      "Batch: 95, Loss: 1.174483299255371, Accuracy: 0.6328125\n",
      "Batch: 96, Loss: 1.1646000146865845, Accuracy: 0.6640625\n",
      "Batch: 97, Loss: 1.1741899251937866, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.0446901321411133, Accuracy: 0.6533203125\n",
      "Batch: 99, Loss: 1.1393702030181885, Accuracy: 0.638671875\n",
      "Batch: 100, Loss: 1.0383822917938232, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.0699527263641357, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.1328370571136475, Accuracy: 0.6396484375\n",
      "Batch: 103, Loss: 1.0451866388320923, Accuracy: 0.673828125\n",
      "Batch: 104, Loss: 1.1476848125457764, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.1474500894546509, Accuracy: 0.640625\n",
      "Batch: 106, Loss: 1.1570967435836792, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.2294538021087646, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.112115740776062, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.0902314186096191, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 1.0744075775146484, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.0668070316314697, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0538349151611328, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.0582993030548096, Accuracy: 0.6533203125\n",
      "Batch: 114, Loss: 1.1649473905563354, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.1479814052581787, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1587400436401367, Accuracy: 0.6220703125\n",
      "Batch: 117, Loss: 1.1634000539779663, Accuracy: 0.623046875\n",
      "Batch: 118, Loss: 1.1645032167434692, Accuracy: 0.6181640625\n",
      "Batch: 119, Loss: 1.2200407981872559, Accuracy: 0.6142578125\n",
      "Batch: 120, Loss: 1.240447998046875, Accuracy: 0.619140625\n",
      "Batch: 121, Loss: 1.1839029788970947, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.1745712757110596, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 123, Loss: 1.1585242748260498, Accuracy: 0.62109375\n",
      "Batch: 124, Loss: 1.1551851034164429, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1423791646957397, Accuracy: 0.65234375\n",
      "Batch: 126, Loss: 1.2455360889434814, Accuracy: 0.6162109375\n",
      "Batch: 127, Loss: 1.1690139770507812, Accuracy: 0.63671875\n",
      "Batch: 128, Loss: 1.1888482570648193, Accuracy: 0.609375\n",
      "Batch: 129, Loss: 1.1286864280700684, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.13454008102417, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.1263763904571533, Accuracy: 0.6328125\n",
      "Batch: 132, Loss: 1.08406400680542, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.1120777130126953, Accuracy: 0.654296875\n",
      "Batch: 134, Loss: 1.0863876342773438, Accuracy: 0.66796875\n",
      "Batch: 135, Loss: 1.0209925174713135, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.0617127418518066, Accuracy: 0.6689453125\n",
      "Batch: 137, Loss: 1.0785795450210571, Accuracy: 0.6455078125\n",
      "Batch: 138, Loss: 1.1666805744171143, Accuracy: 0.625\n",
      "Batch: 139, Loss: 1.147639274597168, Accuracy: 0.638671875\n",
      "Batch: 140, Loss: 1.200075626373291, Accuracy: 0.619140625\n",
      "Batch: 141, Loss: 1.1207683086395264, Accuracy: 0.64453125\n",
      "Batch: 142, Loss: 1.2188642024993896, Accuracy: 0.5908203125\n",
      "Batch: 143, Loss: 1.1868417263031006, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.183671236038208, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.251050353050232, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.1543512344360352, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.1465951204299927, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.1137341260910034, Accuracy: 0.6533203125\n",
      "Batch: 149, Loss: 1.156810998916626, Accuracy: 0.599609375\n",
      "Batch: 150, Loss: 1.1709942817687988, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.0872406959533691, Accuracy: 0.642578125\n",
      "Batch: 152, Loss: 1.097858190536499, Accuracy: 0.634765625\n",
      "Batch: 153, Loss: 1.1596877574920654, Accuracy: 0.6044921875\n",
      "Batch: 154, Loss: 1.0857239961624146, Accuracy: 0.634765625\n",
      "Batch: 155, Loss: 1.0799293518066406, Accuracy: 0.6513671875\n",
      "Epoch 556/200\n",
      "Batch: 1, Loss: 1.17806077003479, Accuracy: 0.6455078125\n",
      "Batch: 2, Loss: 1.0803333520889282, Accuracy: 0.634765625\n",
      "Batch: 3, Loss: 1.0429041385650635, Accuracy: 0.68359375\n",
      "Batch: 4, Loss: 1.1263082027435303, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 0.9764477014541626, Accuracy: 0.6806640625\n",
      "Batch: 6, Loss: 1.0322997570037842, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 0.9963030219078064, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9539680480957031, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 1.0108752250671387, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 0.9307633638381958, Accuracy: 0.7021484375\n",
      "Batch: 11, Loss: 0.9246809482574463, Accuracy: 0.697265625\n",
      "Batch: 12, Loss: 0.9855979084968567, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 0.9717873930931091, Accuracy: 0.6904296875\n",
      "Batch: 14, Loss: 0.9333994388580322, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.9490853548049927, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 0.9321497082710266, Accuracy: 0.7060546875\n",
      "Batch: 17, Loss: 1.0604572296142578, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1394158601760864, Accuracy: 0.603515625\n",
      "Batch: 19, Loss: 1.2060483694076538, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.0305016040802002, Accuracy: 0.6708984375\n",
      "Batch: 21, Loss: 1.0174920558929443, Accuracy: 0.6748046875\n",
      "Batch: 22, Loss: 1.2031959295272827, Accuracy: 0.6142578125\n",
      "Batch: 23, Loss: 1.2003201246261597, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.1067924499511719, Accuracy: 0.6484375\n",
      "Batch: 25, Loss: 1.156327486038208, Accuracy: 0.6396484375\n",
      "Batch: 26, Loss: 1.1310224533081055, Accuracy: 0.634765625\n",
      "Batch: 27, Loss: 1.0750837326049805, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 1.0783345699310303, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.0476651191711426, Accuracy: 0.6513671875\n",
      "Batch: 30, Loss: 1.1162174940109253, Accuracy: 0.630859375\n",
      "Batch: 31, Loss: 1.1794066429138184, Accuracy: 0.626953125\n",
      "Batch: 32, Loss: 1.0260577201843262, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 0.9843418002128601, Accuracy: 0.6767578125\n",
      "Batch: 34, Loss: 1.077160358428955, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.0756136178970337, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.2078534364700317, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.2341241836547852, Accuracy: 0.615234375\n",
      "Batch: 38, Loss: 1.1608613729476929, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.0181230306625366, Accuracy: 0.6591796875\n",
      "Batch: 40, Loss: 1.0638048648834229, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.072850227355957, Accuracy: 0.658203125\n",
      "Batch: 42, Loss: 1.0655691623687744, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.0432316064834595, Accuracy: 0.6728515625\n",
      "Batch: 44, Loss: 1.0428510904312134, Accuracy: 0.6640625\n",
      "Batch: 45, Loss: 1.06834077835083, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.156247615814209, Accuracy: 0.61328125\n",
      "Batch: 47, Loss: 1.09946870803833, Accuracy: 0.6640625\n",
      "Batch: 48, Loss: 1.0533218383789062, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.0982372760772705, Accuracy: 0.6494140625\n",
      "Batch: 50, Loss: 1.1061350107192993, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.103825330734253, Accuracy: 0.6337890625\n",
      "Batch: 52, Loss: 1.2035372257232666, Accuracy: 0.625\n",
      "Batch: 53, Loss: 1.1540560722351074, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1068522930145264, Accuracy: 0.63671875\n",
      "Batch: 55, Loss: 1.1250754594802856, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.0856956243515015, Accuracy: 0.666015625\n",
      "Batch: 57, Loss: 1.0706219673156738, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.0605580806732178, Accuracy: 0.646484375\n",
      "Batch: 59, Loss: 1.0994460582733154, Accuracy: 0.6455078125\n",
      "Batch: 60, Loss: 1.2427653074264526, Accuracy: 0.60546875\n",
      "Batch: 61, Loss: 1.1292212009429932, Accuracy: 0.634765625\n",
      "Batch: 62, Loss: 1.103271484375, Accuracy: 0.6435546875\n",
      "Batch: 63, Loss: 1.1361093521118164, Accuracy: 0.619140625\n",
      "Batch: 64, Loss: 1.223609447479248, Accuracy: 0.58984375\n",
      "Batch: 65, Loss: 1.1199333667755127, Accuracy: 0.6318359375\n",
      "Batch: 66, Loss: 1.164981484413147, Accuracy: 0.6142578125\n",
      "Batch: 67, Loss: 1.129461646080017, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.0558090209960938, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.1939587593078613, Accuracy: 0.609375\n",
      "Batch: 70, Loss: 1.1969895362854004, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.0619038343429565, Accuracy: 0.6669921875\n",
      "Batch: 72, Loss: 1.0947794914245605, Accuracy: 0.646484375\n",
      "Batch: 73, Loss: 1.141391396522522, Accuracy: 0.6318359375\n",
      "Batch: 74, Loss: 1.0536415576934814, Accuracy: 0.6552734375\n",
      "Batch: 75, Loss: 1.1127727031707764, Accuracy: 0.6435546875\n",
      "Batch: 76, Loss: 1.0552128553390503, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 1.0124046802520752, Accuracy: 0.671875\n",
      "Batch: 78, Loss: 1.0626742839813232, Accuracy: 0.6279296875\n",
      "Batch: 79, Loss: 1.1053651571273804, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1153067350387573, Accuracy: 0.6474609375\n",
      "Batch: 81, Loss: 1.092395305633545, Accuracy: 0.634765625\n",
      "Batch: 82, Loss: 1.1205871105194092, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.1115061044692993, Accuracy: 0.6279296875\n",
      "Batch: 84, Loss: 1.1108615398406982, Accuracy: 0.642578125\n",
      "Batch: 85, Loss: 1.1143933534622192, Accuracy: 0.6494140625\n",
      "Batch: 86, Loss: 1.1576248407363892, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 1.1303467750549316, Accuracy: 0.6201171875\n",
      "Batch: 88, Loss: 1.1457808017730713, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.11454439163208, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.1329573392868042, Accuracy: 0.6220703125\n",
      "Batch: 91, Loss: 1.0908465385437012, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.108641266822815, Accuracy: 0.6494140625\n",
      "Batch: 93, Loss: 1.0729141235351562, Accuracy: 0.6455078125\n",
      "Batch: 94, Loss: 1.1469324827194214, Accuracy: 0.6455078125\n",
      "Batch: 95, Loss: 1.1734873056411743, Accuracy: 0.630859375\n",
      "Batch: 96, Loss: 1.1760270595550537, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.1346745491027832, Accuracy: 0.6162109375\n",
      "Batch: 98, Loss: 1.0960556268692017, Accuracy: 0.6435546875\n",
      "Batch: 99, Loss: 1.099941611289978, Accuracy: 0.638671875\n",
      "Batch: 100, Loss: 1.0216014385223389, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 1.0249435901641846, Accuracy: 0.677734375\n",
      "Batch: 102, Loss: 1.1485235691070557, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.130896806716919, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1255972385406494, Accuracy: 0.6318359375\n",
      "Batch: 105, Loss: 1.1733720302581787, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.1975287199020386, Accuracy: 0.62109375\n",
      "Batch: 107, Loss: 1.221879005432129, Accuracy: 0.60546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 1.1239149570465088, Accuracy: 0.603515625\n",
      "Batch: 109, Loss: 1.181743860244751, Accuracy: 0.611328125\n",
      "Batch: 110, Loss: 1.1226061582565308, Accuracy: 0.63671875\n",
      "Batch: 111, Loss: 1.0382473468780518, Accuracy: 0.6552734375\n",
      "Batch: 112, Loss: 1.044834852218628, Accuracy: 0.6572265625\n",
      "Batch: 113, Loss: 1.0927495956420898, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.0967398881912231, Accuracy: 0.6455078125\n",
      "Batch: 115, Loss: 1.1415175199508667, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1600404977798462, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.1695277690887451, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.1892985105514526, Accuracy: 0.6201171875\n",
      "Batch: 119, Loss: 1.2101750373840332, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.260190725326538, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.1501829624176025, Accuracy: 0.6435546875\n",
      "Batch: 122, Loss: 1.1791455745697021, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.1527869701385498, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.2355796098709106, Accuracy: 0.607421875\n",
      "Batch: 125, Loss: 1.1136529445648193, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.240028977394104, Accuracy: 0.6201171875\n",
      "Batch: 127, Loss: 1.1909053325653076, Accuracy: 0.640625\n",
      "Batch: 128, Loss: 1.1604793071746826, Accuracy: 0.6181640625\n",
      "Batch: 129, Loss: 1.1424309015274048, Accuracy: 0.64453125\n",
      "Batch: 130, Loss: 1.0721595287322998, Accuracy: 0.6484375\n",
      "Batch: 131, Loss: 1.1389906406402588, Accuracy: 0.64453125\n",
      "Batch: 132, Loss: 1.0763862133026123, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 1.0489755868911743, Accuracy: 0.638671875\n",
      "Batch: 134, Loss: 1.112551212310791, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.035477876663208, Accuracy: 0.658203125\n",
      "Batch: 136, Loss: 1.0671136379241943, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 1.1246678829193115, Accuracy: 0.6474609375\n",
      "Batch: 138, Loss: 1.1881942749023438, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.17818284034729, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.225549578666687, Accuracy: 0.6142578125\n",
      "Batch: 141, Loss: 1.1009905338287354, Accuracy: 0.654296875\n",
      "Batch: 142, Loss: 1.1447107791900635, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2015786170959473, Accuracy: 0.6103515625\n",
      "Batch: 144, Loss: 1.2653868198394775, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.2058119773864746, Accuracy: 0.611328125\n",
      "Batch: 146, Loss: 1.1797412633895874, Accuracy: 0.6162109375\n",
      "Batch: 147, Loss: 1.123234748840332, Accuracy: 0.6162109375\n",
      "Batch: 148, Loss: 1.1357501745224, Accuracy: 0.6396484375\n",
      "Batch: 149, Loss: 1.110140323638916, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.069620132446289, Accuracy: 0.6396484375\n",
      "Batch: 151, Loss: 1.1553938388824463, Accuracy: 0.60546875\n",
      "Batch: 152, Loss: 1.1739810705184937, Accuracy: 0.6025390625\n",
      "Batch: 153, Loss: 1.1257665157318115, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.0834689140319824, Accuracy: 0.63671875\n",
      "Batch: 155, Loss: 1.080765724182129, Accuracy: 0.6455078125\n",
      "Epoch 557/200\n",
      "Batch: 1, Loss: 1.2244579792022705, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0772801637649536, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0458757877349854, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.0610876083374023, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.0373644828796387, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 0.958992600440979, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 0.9881299734115601, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 1.0163960456848145, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 1.0077308416366577, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 0.973629355430603, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9720292687416077, Accuracy: 0.6806640625\n",
      "Batch: 12, Loss: 0.9262056350708008, Accuracy: 0.6962890625\n",
      "Batch: 13, Loss: 0.9996577501296997, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 0.9724736213684082, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.960116982460022, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.9888405203819275, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 0.9841946363449097, Accuracy: 0.6748046875\n",
      "Batch: 18, Loss: 1.1102830171585083, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.1997931003570557, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.066908836364746, Accuracy: 0.6640625\n",
      "Batch: 21, Loss: 1.1046738624572754, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.2205591201782227, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.1777160167694092, Accuracy: 0.6064453125\n",
      "Batch: 24, Loss: 1.0722802877426147, Accuracy: 0.666015625\n",
      "Batch: 25, Loss: 1.1179094314575195, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.139758586883545, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.0982730388641357, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.0401356220245361, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.0317089557647705, Accuracy: 0.6640625\n",
      "Batch: 30, Loss: 1.1768234968185425, Accuracy: 0.607421875\n",
      "Batch: 31, Loss: 1.1484113931655884, Accuracy: 0.6064453125\n",
      "Batch: 32, Loss: 1.0154231786727905, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.010809063911438, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.0943129062652588, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.0780479907989502, Accuracy: 0.6279296875\n",
      "Batch: 36, Loss: 1.1700868606567383, Accuracy: 0.61328125\n",
      "Batch: 37, Loss: 1.1831188201904297, Accuracy: 0.6123046875\n",
      "Batch: 38, Loss: 1.1993474960327148, Accuracy: 0.6103515625\n",
      "Batch: 39, Loss: 1.0843160152435303, Accuracy: 0.6201171875\n",
      "Batch: 40, Loss: 1.065340518951416, Accuracy: 0.6455078125\n",
      "Batch: 41, Loss: 1.128064751625061, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 1.034229040145874, Accuracy: 0.6650390625\n",
      "Batch: 43, Loss: 1.0604705810546875, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0674617290496826, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 1.027860164642334, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.1375229358673096, Accuracy: 0.6201171875\n",
      "Batch: 47, Loss: 1.0929007530212402, Accuracy: 0.654296875\n",
      "Batch: 48, Loss: 1.108551025390625, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1066546440124512, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.130936622619629, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.1014717817306519, Accuracy: 0.638671875\n",
      "Batch: 52, Loss: 1.212408423423767, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.1098437309265137, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.148432731628418, Accuracy: 0.62109375\n",
      "Batch: 55, Loss: 1.0564680099487305, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.094801902770996, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.089123249053955, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.0582337379455566, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 1.0400947332382202, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.19635009765625, Accuracy: 0.6025390625\n",
      "Batch: 61, Loss: 1.092216968536377, Accuracy: 0.640625\n",
      "Batch: 62, Loss: 1.1499717235565186, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.1769554615020752, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.1687633991241455, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.164061427116394, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.0686638355255127, Accuracy: 0.66796875\n",
      "Batch: 67, Loss: 1.0972180366516113, Accuracy: 0.6357421875\n",
      "Batch: 68, Loss: 1.0444116592407227, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.1622939109802246, Accuracy: 0.61328125\n",
      "Batch: 70, Loss: 1.135161280632019, Accuracy: 0.6220703125\n",
      "Batch: 71, Loss: 1.1083531379699707, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.155730962753296, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.1951369047164917, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.0638628005981445, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.0749424695968628, Accuracy: 0.6494140625\n",
      "Batch: 76, Loss: 1.0640556812286377, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.0386009216308594, Accuracy: 0.6513671875\n",
      "Batch: 78, Loss: 1.0397664308547974, Accuracy: 0.662109375\n",
      "Batch: 79, Loss: 1.0408456325531006, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.1001471281051636, Accuracy: 0.63671875\n",
      "Batch: 81, Loss: 1.1059660911560059, Accuracy: 0.6328125\n",
      "Batch: 82, Loss: 1.1350445747375488, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.190566062927246, Accuracy: 0.61328125\n",
      "Batch: 84, Loss: 1.0924277305603027, Accuracy: 0.650390625\n",
      "Batch: 85, Loss: 1.1580395698547363, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.1103216409683228, Accuracy: 0.64453125\n",
      "Batch: 87, Loss: 1.1294407844543457, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.2434473037719727, Accuracy: 0.591796875\n",
      "Batch: 89, Loss: 1.072601079940796, Accuracy: 0.6572265625\n",
      "Batch: 90, Loss: 1.0322799682617188, Accuracy: 0.662109375\n",
      "Batch: 91, Loss: 1.1423113346099854, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.1371607780456543, Accuracy: 0.654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 93, Loss: 1.0999069213867188, Accuracy: 0.6591796875\n",
      "Batch: 94, Loss: 1.168790340423584, Accuracy: 0.6298828125\n",
      "Batch: 95, Loss: 1.161775827407837, Accuracy: 0.6279296875\n",
      "Batch: 96, Loss: 1.1183269023895264, Accuracy: 0.646484375\n",
      "Batch: 97, Loss: 1.1412055492401123, Accuracy: 0.62890625\n",
      "Batch: 98, Loss: 1.10061514377594, Accuracy: 0.6357421875\n",
      "Batch: 99, Loss: 1.1311630010604858, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.022446632385254, Accuracy: 0.6748046875\n",
      "Batch: 101, Loss: 1.0864115953445435, Accuracy: 0.642578125\n",
      "Batch: 102, Loss: 1.0906016826629639, Accuracy: 0.650390625\n",
      "Batch: 103, Loss: 1.2037005424499512, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.1232092380523682, Accuracy: 0.634765625\n",
      "Batch: 105, Loss: 1.1437413692474365, Accuracy: 0.638671875\n",
      "Batch: 106, Loss: 1.161372423171997, Accuracy: 0.6171875\n",
      "Batch: 107, Loss: 1.1772069931030273, Accuracy: 0.611328125\n",
      "Batch: 108, Loss: 1.1382310390472412, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.1187541484832764, Accuracy: 0.6494140625\n",
      "Batch: 110, Loss: 1.12273371219635, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.0773680210113525, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0478453636169434, Accuracy: 0.67578125\n",
      "Batch: 113, Loss: 1.0750186443328857, Accuracy: 0.6513671875\n",
      "Batch: 114, Loss: 1.081521987915039, Accuracy: 0.6474609375\n",
      "Batch: 115, Loss: 1.173614501953125, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.1547250747680664, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1607890129089355, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.223179578781128, Accuracy: 0.619140625\n",
      "Batch: 119, Loss: 1.1731892824172974, Accuracy: 0.59765625\n",
      "Batch: 120, Loss: 1.2318546772003174, Accuracy: 0.625\n",
      "Batch: 121, Loss: 1.1454517841339111, Accuracy: 0.634765625\n",
      "Batch: 122, Loss: 1.2051361799240112, Accuracy: 0.6337890625\n",
      "Batch: 123, Loss: 1.1071913242340088, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.1425615549087524, Accuracy: 0.6376953125\n",
      "Batch: 125, Loss: 1.1402580738067627, Accuracy: 0.646484375\n",
      "Batch: 126, Loss: 1.175117015838623, Accuracy: 0.62890625\n",
      "Batch: 127, Loss: 1.2272475957870483, Accuracy: 0.5869140625\n",
      "Batch: 128, Loss: 1.1918468475341797, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.1048635244369507, Accuracy: 0.642578125\n",
      "Batch: 130, Loss: 1.13007390499115, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.1815727949142456, Accuracy: 0.62109375\n",
      "Batch: 132, Loss: 0.9977697134017944, Accuracy: 0.681640625\n",
      "Batch: 133, Loss: 1.1318609714508057, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.0663752555847168, Accuracy: 0.662109375\n",
      "Batch: 135, Loss: 1.000983476638794, Accuracy: 0.6845703125\n",
      "Batch: 136, Loss: 1.0741924047470093, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.141008734703064, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.2257320880889893, Accuracy: 0.5947265625\n",
      "Batch: 139, Loss: 1.1763302087783813, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.2093636989593506, Accuracy: 0.6240234375\n",
      "Batch: 141, Loss: 1.119950294494629, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.0948282480239868, Accuracy: 0.6640625\n",
      "Batch: 143, Loss: 1.1829947233200073, Accuracy: 0.6181640625\n",
      "Batch: 144, Loss: 1.1873852014541626, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.2030986547470093, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.1389660835266113, Accuracy: 0.6142578125\n",
      "Batch: 147, Loss: 1.1723212003707886, Accuracy: 0.62890625\n",
      "Batch: 148, Loss: 1.199554204940796, Accuracy: 0.5986328125\n",
      "Batch: 149, Loss: 1.162251353263855, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.102830171585083, Accuracy: 0.64453125\n",
      "Batch: 151, Loss: 1.0810902118682861, Accuracy: 0.650390625\n",
      "Batch: 152, Loss: 1.1491464376449585, Accuracy: 0.6005859375\n",
      "Batch: 153, Loss: 1.072131872177124, Accuracy: 0.6572265625\n",
      "Batch: 154, Loss: 1.0881068706512451, Accuracy: 0.654296875\n",
      "Batch: 155, Loss: 1.085702896118164, Accuracy: 0.6240234375\n",
      "Epoch 558/200\n",
      "Batch: 1, Loss: 1.1926512718200684, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.0278594493865967, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 0.992139458656311, Accuracy: 0.6884765625\n",
      "Batch: 4, Loss: 1.1055231094360352, Accuracy: 0.6357421875\n",
      "Batch: 5, Loss: 0.9835723042488098, Accuracy: 0.66796875\n",
      "Batch: 6, Loss: 1.0394208431243896, Accuracy: 0.654296875\n",
      "Batch: 7, Loss: 0.9964502453804016, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 0.9539611339569092, Accuracy: 0.70703125\n",
      "Batch: 9, Loss: 0.9280762672424316, Accuracy: 0.689453125\n",
      "Batch: 10, Loss: 0.9428670406341553, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 0.8976758122444153, Accuracy: 0.6845703125\n",
      "Batch: 12, Loss: 1.0120056867599487, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 1.0551681518554688, Accuracy: 0.638671875\n",
      "Batch: 14, Loss: 0.9470778107643127, Accuracy: 0.6923828125\n",
      "Batch: 15, Loss: 0.925020158290863, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.0599286556243896, Accuracy: 0.6435546875\n",
      "Batch: 17, Loss: 1.0768651962280273, Accuracy: 0.6494140625\n",
      "Batch: 18, Loss: 1.0860543251037598, Accuracy: 0.654296875\n",
      "Batch: 19, Loss: 1.1872198581695557, Accuracy: 0.6201171875\n",
      "Batch: 20, Loss: 1.0929412841796875, Accuracy: 0.654296875\n",
      "Batch: 21, Loss: 1.065599799156189, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.179351806640625, Accuracy: 0.62890625\n",
      "Batch: 23, Loss: 1.1933257579803467, Accuracy: 0.6279296875\n",
      "Batch: 24, Loss: 1.106801152229309, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1310248374938965, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.1569745540618896, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.1700787544250488, Accuracy: 0.623046875\n",
      "Batch: 28, Loss: 1.064123272895813, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.0885332822799683, Accuracy: 0.6396484375\n",
      "Batch: 30, Loss: 1.13502836227417, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.1679913997650146, Accuracy: 0.591796875\n",
      "Batch: 32, Loss: 1.0298514366149902, Accuracy: 0.6484375\n",
      "Batch: 33, Loss: 0.9595963358879089, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.02716064453125, Accuracy: 0.669921875\n",
      "Batch: 35, Loss: 1.0987480878829956, Accuracy: 0.6513671875\n",
      "Batch: 36, Loss: 1.1588737964630127, Accuracy: 0.625\n",
      "Batch: 37, Loss: 1.2263842821121216, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.1870850324630737, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.061605453491211, Accuracy: 0.662109375\n",
      "Batch: 40, Loss: 1.0617177486419678, Accuracy: 0.646484375\n",
      "Batch: 41, Loss: 1.087117314338684, Accuracy: 0.623046875\n",
      "Batch: 42, Loss: 1.0796607732772827, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 0.9988536238670349, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0514302253723145, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 0.9988554120063782, Accuracy: 0.6796875\n",
      "Batch: 46, Loss: 1.0946487188339233, Accuracy: 0.6357421875\n",
      "Batch: 47, Loss: 1.0850093364715576, Accuracy: 0.6591796875\n",
      "Batch: 48, Loss: 1.088670253753662, Accuracy: 0.642578125\n",
      "Batch: 49, Loss: 1.1047348976135254, Accuracy: 0.6533203125\n",
      "Batch: 50, Loss: 1.0994735956192017, Accuracy: 0.63671875\n",
      "Batch: 51, Loss: 1.1296391487121582, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.2017250061035156, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.1755053997039795, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.137656807899475, Accuracy: 0.6201171875\n",
      "Batch: 55, Loss: 1.0952684879302979, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.085802435874939, Accuracy: 0.638671875\n",
      "Batch: 57, Loss: 1.0534087419509888, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.0999326705932617, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.1021323204040527, Accuracy: 0.6396484375\n",
      "Batch: 60, Loss: 1.2168411016464233, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1052746772766113, Accuracy: 0.6396484375\n",
      "Batch: 62, Loss: 1.1913642883300781, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.0763390064239502, Accuracy: 0.654296875\n",
      "Batch: 64, Loss: 1.1533957719802856, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1377646923065186, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.116207480430603, Accuracy: 0.63671875\n",
      "Batch: 67, Loss: 1.1499364376068115, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.0921989679336548, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.0934247970581055, Accuracy: 0.6435546875\n",
      "Batch: 70, Loss: 1.1643507480621338, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.1633683443069458, Accuracy: 0.62109375\n",
      "Batch: 72, Loss: 1.1693198680877686, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.1497681140899658, Accuracy: 0.625\n",
      "Batch: 74, Loss: 1.1013929843902588, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.0971734523773193, Accuracy: 0.6328125\n",
      "Batch: 76, Loss: 1.0589311122894287, Accuracy: 0.6474609375\n",
      "Batch: 77, Loss: 1.0071935653686523, Accuracy: 0.6943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 78, Loss: 1.0406835079193115, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.0991677045822144, Accuracy: 0.666015625\n",
      "Batch: 80, Loss: 1.1721305847167969, Accuracy: 0.626953125\n",
      "Batch: 81, Loss: 1.0818121433258057, Accuracy: 0.6533203125\n",
      "Batch: 82, Loss: 1.1123740673065186, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.1648155450820923, Accuracy: 0.6357421875\n",
      "Batch: 84, Loss: 1.1343547105789185, Accuracy: 0.6328125\n",
      "Batch: 85, Loss: 1.125028371810913, Accuracy: 0.6279296875\n",
      "Batch: 86, Loss: 1.1486165523529053, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.1473925113677979, Accuracy: 0.60546875\n",
      "Batch: 88, Loss: 1.1064186096191406, Accuracy: 0.64453125\n",
      "Batch: 89, Loss: 1.0551073551177979, Accuracy: 0.66015625\n",
      "Batch: 90, Loss: 1.056976318359375, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.1397454738616943, Accuracy: 0.6337890625\n",
      "Batch: 92, Loss: 1.049290657043457, Accuracy: 0.669921875\n",
      "Batch: 93, Loss: 1.0749187469482422, Accuracy: 0.642578125\n",
      "Batch: 94, Loss: 1.1513047218322754, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1378356218338013, Accuracy: 0.63671875\n",
      "Batch: 96, Loss: 1.1720131635665894, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.170668125152588, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.1522948741912842, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.0914673805236816, Accuracy: 0.654296875\n",
      "Batch: 100, Loss: 1.0697612762451172, Accuracy: 0.6474609375\n",
      "Batch: 101, Loss: 1.0554733276367188, Accuracy: 0.6337890625\n",
      "Batch: 102, Loss: 1.1342337131500244, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.1351773738861084, Accuracy: 0.63671875\n",
      "Batch: 104, Loss: 1.0750832557678223, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.2138365507125854, Accuracy: 0.6162109375\n",
      "Batch: 106, Loss: 1.148728370666504, Accuracy: 0.6220703125\n",
      "Batch: 107, Loss: 1.1933162212371826, Accuracy: 0.595703125\n",
      "Batch: 108, Loss: 1.1393723487854004, Accuracy: 0.6376953125\n",
      "Batch: 109, Loss: 1.156137228012085, Accuracy: 0.6328125\n",
      "Batch: 110, Loss: 1.0897443294525146, Accuracy: 0.6484375\n",
      "Batch: 111, Loss: 1.136735439300537, Accuracy: 0.6162109375\n",
      "Batch: 112, Loss: 1.081073522567749, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.0554791688919067, Accuracy: 0.642578125\n",
      "Batch: 114, Loss: 1.1176488399505615, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.1616690158843994, Accuracy: 0.6044921875\n",
      "Batch: 116, Loss: 1.1391514539718628, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1570162773132324, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.1824016571044922, Accuracy: 0.62890625\n",
      "Batch: 119, Loss: 1.2349704504013062, Accuracy: 0.611328125\n",
      "Batch: 120, Loss: 1.2554588317871094, Accuracy: 0.5986328125\n",
      "Batch: 121, Loss: 1.130181908607483, Accuracy: 0.6376953125\n",
      "Batch: 122, Loss: 1.2249155044555664, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1970813274383545, Accuracy: 0.6181640625\n",
      "Batch: 124, Loss: 1.1606122255325317, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1257275342941284, Accuracy: 0.642578125\n",
      "Batch: 126, Loss: 1.249199390411377, Accuracy: 0.607421875\n",
      "Batch: 127, Loss: 1.1871881484985352, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.1809346675872803, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.1377609968185425, Accuracy: 0.6396484375\n",
      "Batch: 130, Loss: 1.0576082468032837, Accuracy: 0.6396484375\n",
      "Batch: 131, Loss: 1.1709022521972656, Accuracy: 0.6201171875\n",
      "Batch: 132, Loss: 1.0668082237243652, Accuracy: 0.654296875\n",
      "Batch: 133, Loss: 1.1191251277923584, Accuracy: 0.623046875\n",
      "Batch: 134, Loss: 1.0788383483886719, Accuracy: 0.6708984375\n",
      "Batch: 135, Loss: 1.03291916847229, Accuracy: 0.671875\n",
      "Batch: 136, Loss: 1.0568163394927979, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.0955051183700562, Accuracy: 0.66015625\n",
      "Batch: 138, Loss: 1.2265114784240723, Accuracy: 0.6083984375\n",
      "Batch: 139, Loss: 1.1763995885849, Accuracy: 0.6142578125\n",
      "Batch: 140, Loss: 1.2221624851226807, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1161057949066162, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.147481918334961, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1917610168457031, Accuracy: 0.5888671875\n",
      "Batch: 144, Loss: 1.124860405921936, Accuracy: 0.6171875\n",
      "Batch: 145, Loss: 1.2004302740097046, Accuracy: 0.611328125\n",
      "Batch: 146, Loss: 1.1910494565963745, Accuracy: 0.60546875\n",
      "Batch: 147, Loss: 1.1533260345458984, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.171483039855957, Accuracy: 0.62109375\n",
      "Batch: 149, Loss: 1.1520801782608032, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.2171335220336914, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.1269330978393555, Accuracy: 0.626953125\n",
      "Batch: 152, Loss: 1.1288652420043945, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.0595552921295166, Accuracy: 0.666015625\n",
      "Batch: 154, Loss: 1.0836024284362793, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.0644786357879639, Accuracy: 0.6455078125\n",
      "Epoch 559/200\n",
      "Batch: 1, Loss: 1.1958732604980469, Accuracy: 0.65625\n",
      "Batch: 2, Loss: 1.0704708099365234, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 1.0200457572937012, Accuracy: 0.66796875\n",
      "Batch: 4, Loss: 1.0105347633361816, Accuracy: 0.671875\n",
      "Batch: 5, Loss: 0.9872405529022217, Accuracy: 0.6748046875\n",
      "Batch: 6, Loss: 1.0236629247665405, Accuracy: 0.6728515625\n",
      "Batch: 7, Loss: 1.0140461921691895, Accuracy: 0.673828125\n",
      "Batch: 8, Loss: 0.9570790529251099, Accuracy: 0.6865234375\n",
      "Batch: 9, Loss: 1.0233956575393677, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 0.984260082244873, Accuracy: 0.666015625\n",
      "Batch: 11, Loss: 0.9699690341949463, Accuracy: 0.67578125\n",
      "Batch: 12, Loss: 0.9746206998825073, Accuracy: 0.6884765625\n",
      "Batch: 13, Loss: 1.0118428468704224, Accuracy: 0.6552734375\n",
      "Batch: 14, Loss: 0.9679698944091797, Accuracy: 0.677734375\n",
      "Batch: 15, Loss: 0.9564887285232544, Accuracy: 0.6845703125\n",
      "Batch: 16, Loss: 0.9942781925201416, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 1.014067530632019, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.0638796091079712, Accuracy: 0.6611328125\n",
      "Batch: 19, Loss: 1.151073932647705, Accuracy: 0.623046875\n",
      "Batch: 20, Loss: 1.1032495498657227, Accuracy: 0.6416015625\n",
      "Batch: 21, Loss: 1.0490307807922363, Accuracy: 0.638671875\n",
      "Batch: 22, Loss: 1.2119523286819458, Accuracy: 0.61328125\n",
      "Batch: 23, Loss: 1.174787163734436, Accuracy: 0.623046875\n",
      "Batch: 24, Loss: 1.1137099266052246, Accuracy: 0.6337890625\n",
      "Batch: 25, Loss: 1.132979393005371, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1215388774871826, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.142808437347412, Accuracy: 0.646484375\n",
      "Batch: 28, Loss: 1.0832823514938354, Accuracy: 0.642578125\n",
      "Batch: 29, Loss: 1.0320583581924438, Accuracy: 0.6669921875\n",
      "Batch: 30, Loss: 1.1266696453094482, Accuracy: 0.6337890625\n",
      "Batch: 31, Loss: 1.172179937362671, Accuracy: 0.62109375\n",
      "Batch: 32, Loss: 1.0313172340393066, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 0.9929821491241455, Accuracy: 0.681640625\n",
      "Batch: 34, Loss: 1.0916880369186401, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.147709846496582, Accuracy: 0.6474609375\n",
      "Batch: 36, Loss: 1.173217535018921, Accuracy: 0.6103515625\n",
      "Batch: 37, Loss: 1.1734195947647095, Accuracy: 0.6181640625\n",
      "Batch: 38, Loss: 1.1478276252746582, Accuracy: 0.6103515625\n",
      "Batch: 39, Loss: 1.0205681324005127, Accuracy: 0.6591796875\n",
      "Batch: 40, Loss: 1.0369682312011719, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.071664571762085, Accuracy: 0.6396484375\n",
      "Batch: 42, Loss: 1.0076721906661987, Accuracy: 0.6884765625\n",
      "Batch: 43, Loss: 1.0477492809295654, Accuracy: 0.6484375\n",
      "Batch: 44, Loss: 0.9828423261642456, Accuracy: 0.6689453125\n",
      "Batch: 45, Loss: 1.0306353569030762, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.1453120708465576, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.0944880247116089, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1272377967834473, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.12559974193573, Accuracy: 0.6474609375\n",
      "Batch: 50, Loss: 1.0766785144805908, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.1378278732299805, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.1713652610778809, Accuracy: 0.6357421875\n",
      "Batch: 53, Loss: 1.1573443412780762, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.1655369997024536, Accuracy: 0.6162109375\n",
      "Batch: 55, Loss: 1.0891011953353882, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.1177489757537842, Accuracy: 0.630859375\n",
      "Batch: 57, Loss: 1.0570404529571533, Accuracy: 0.65625\n",
      "Batch: 58, Loss: 1.021125078201294, Accuracy: 0.66796875\n",
      "Batch: 59, Loss: 1.1190952062606812, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.1652131080627441, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1510632038116455, Accuracy: 0.623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 1.1325125694274902, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1384776830673218, Accuracy: 0.6572265625\n",
      "Batch: 64, Loss: 1.1489484310150146, Accuracy: 0.6279296875\n",
      "Batch: 65, Loss: 1.1766268014907837, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.130351185798645, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.1283036470413208, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.0807819366455078, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1954889297485352, Accuracy: 0.6142578125\n",
      "Batch: 70, Loss: 1.087782859802246, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.0786406993865967, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 1.1334587335586548, Accuracy: 0.642578125\n",
      "Batch: 73, Loss: 1.2113592624664307, Accuracy: 0.6123046875\n",
      "Batch: 74, Loss: 1.0667626857757568, Accuracy: 0.6494140625\n",
      "Batch: 75, Loss: 1.0888299942016602, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.0905604362487793, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0037531852722168, Accuracy: 0.6748046875\n",
      "Batch: 78, Loss: 1.0145721435546875, Accuracy: 0.6513671875\n",
      "Batch: 79, Loss: 1.1153359413146973, Accuracy: 0.6318359375\n",
      "Batch: 80, Loss: 1.120861291885376, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.07814621925354, Accuracy: 0.646484375\n",
      "Batch: 82, Loss: 1.0789341926574707, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 1.123387336730957, Accuracy: 0.6416015625\n",
      "Batch: 84, Loss: 1.1120288372039795, Accuracy: 0.6611328125\n",
      "Batch: 85, Loss: 1.0941853523254395, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1565346717834473, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.118696689605713, Accuracy: 0.6416015625\n",
      "Batch: 88, Loss: 1.1445231437683105, Accuracy: 0.642578125\n",
      "Batch: 89, Loss: 1.1124712228775024, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.0573914051055908, Accuracy: 0.64453125\n",
      "Batch: 91, Loss: 1.1233909130096436, Accuracy: 0.638671875\n",
      "Batch: 92, Loss: 1.1087726354599, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.1533589363098145, Accuracy: 0.6259765625\n",
      "Batch: 94, Loss: 1.181504726409912, Accuracy: 0.6435546875\n",
      "Batch: 95, Loss: 1.1173137426376343, Accuracy: 0.6416015625\n",
      "Batch: 96, Loss: 1.1937270164489746, Accuracy: 0.62109375\n",
      "Batch: 97, Loss: 1.0966089963912964, Accuracy: 0.6376953125\n",
      "Batch: 98, Loss: 1.120038390159607, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.0765403509140015, Accuracy: 0.638671875\n",
      "Batch: 100, Loss: 1.0263891220092773, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 1.072412133216858, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.1580373048782349, Accuracy: 0.6357421875\n",
      "Batch: 103, Loss: 1.139357089996338, Accuracy: 0.6357421875\n",
      "Batch: 104, Loss: 1.159501314163208, Accuracy: 0.6416015625\n",
      "Batch: 105, Loss: 1.1360422372817993, Accuracy: 0.634765625\n",
      "Batch: 106, Loss: 1.1532177925109863, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.1375164985656738, Accuracy: 0.6279296875\n",
      "Batch: 108, Loss: 1.1661672592163086, Accuracy: 0.599609375\n",
      "Batch: 109, Loss: 1.1294090747833252, Accuracy: 0.6474609375\n",
      "Batch: 110, Loss: 1.1146948337554932, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.1094937324523926, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.1026673316955566, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1169164180755615, Accuracy: 0.625\n",
      "Batch: 114, Loss: 1.1506602764129639, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.1077487468719482, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.1118831634521484, Accuracy: 0.6396484375\n",
      "Batch: 117, Loss: 1.0826791524887085, Accuracy: 0.6435546875\n",
      "Batch: 118, Loss: 1.1431523561477661, Accuracy: 0.6259765625\n",
      "Batch: 119, Loss: 1.210274338722229, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.2040152549743652, Accuracy: 0.6162109375\n",
      "Batch: 121, Loss: 1.132232666015625, Accuracy: 0.634765625\n",
      "Batch: 122, Loss: 1.1517729759216309, Accuracy: 0.6416015625\n",
      "Batch: 123, Loss: 1.1324248313903809, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.206620693206787, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.1547178030014038, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.1734294891357422, Accuracy: 0.638671875\n",
      "Batch: 127, Loss: 1.2235937118530273, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.2052370309829712, Accuracy: 0.607421875\n",
      "Batch: 129, Loss: 1.1730629205703735, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.1121644973754883, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.1971888542175293, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 1.061110496520996, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.0153086185455322, Accuracy: 0.6650390625\n",
      "Batch: 134, Loss: 1.0633238554000854, Accuracy: 0.6767578125\n",
      "Batch: 135, Loss: 0.9762293100357056, Accuracy: 0.677734375\n",
      "Batch: 136, Loss: 1.0388166904449463, Accuracy: 0.65625\n",
      "Batch: 137, Loss: 1.1146544218063354, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.1963505744934082, Accuracy: 0.57421875\n",
      "Batch: 139, Loss: 1.1533218622207642, Accuracy: 0.6357421875\n",
      "Batch: 140, Loss: 1.2628052234649658, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.1345417499542236, Accuracy: 0.6318359375\n",
      "Batch: 142, Loss: 1.1313786506652832, Accuracy: 0.6435546875\n",
      "Batch: 143, Loss: 1.1762982606887817, Accuracy: 0.626953125\n",
      "Batch: 144, Loss: 1.1973215341567993, Accuracy: 0.6181640625\n",
      "Batch: 145, Loss: 1.1916828155517578, Accuracy: 0.6103515625\n",
      "Batch: 146, Loss: 1.1442842483520508, Accuracy: 0.6259765625\n",
      "Batch: 147, Loss: 1.1763484477996826, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.1878705024719238, Accuracy: 0.6162109375\n",
      "Batch: 149, Loss: 1.1868829727172852, Accuracy: 0.59765625\n",
      "Batch: 150, Loss: 1.1450614929199219, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.0667378902435303, Accuracy: 0.6591796875\n",
      "Batch: 152, Loss: 1.0798487663269043, Accuracy: 0.662109375\n",
      "Batch: 153, Loss: 1.1037318706512451, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.0832067728042603, Accuracy: 0.65625\n",
      "Batch: 155, Loss: 1.0537593364715576, Accuracy: 0.6630859375\n",
      "Epoch 560/200\n",
      "Batch: 1, Loss: 1.158776044845581, Accuracy: 0.654296875\n",
      "Batch: 2, Loss: 1.0263110399246216, Accuracy: 0.669921875\n",
      "Batch: 3, Loss: 1.0006260871887207, Accuracy: 0.6708984375\n",
      "Batch: 4, Loss: 1.0228122472763062, Accuracy: 0.662109375\n",
      "Batch: 5, Loss: 0.9919571280479431, Accuracy: 0.6982421875\n",
      "Batch: 6, Loss: 1.0081201791763306, Accuracy: 0.6748046875\n",
      "Batch: 7, Loss: 0.972946286201477, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9605063199996948, Accuracy: 0.6806640625\n",
      "Batch: 9, Loss: 0.9683444499969482, Accuracy: 0.6904296875\n",
      "Batch: 10, Loss: 1.0183073282241821, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9256243705749512, Accuracy: 0.7080078125\n",
      "Batch: 12, Loss: 0.968705952167511, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 1.0090867280960083, Accuracy: 0.6708984375\n",
      "Batch: 14, Loss: 0.9532272815704346, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.9108825922012329, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 0.9976785182952881, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 1.0496768951416016, Accuracy: 0.6640625\n",
      "Batch: 18, Loss: 1.1223371028900146, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.1871912479400635, Accuracy: 0.630859375\n",
      "Batch: 20, Loss: 1.041764736175537, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.0750603675842285, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.189029574394226, Accuracy: 0.609375\n",
      "Batch: 23, Loss: 1.219446063041687, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.145085096359253, Accuracy: 0.646484375\n",
      "Batch: 25, Loss: 1.1567907333374023, Accuracy: 0.62109375\n",
      "Batch: 26, Loss: 1.143092393875122, Accuracy: 0.6171875\n",
      "Batch: 27, Loss: 1.0988366603851318, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.0251027345657349, Accuracy: 0.6572265625\n",
      "Batch: 29, Loss: 1.054020643234253, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1082243919372559, Accuracy: 0.6337890625\n",
      "Batch: 31, Loss: 1.1980961561203003, Accuracy: 0.59765625\n",
      "Batch: 32, Loss: 1.0733580589294434, Accuracy: 0.6396484375\n",
      "Batch: 33, Loss: 0.994538426399231, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0776793956756592, Accuracy: 0.6572265625\n",
      "Batch: 35, Loss: 1.1166822910308838, Accuracy: 0.6240234375\n",
      "Batch: 36, Loss: 1.1948215961456299, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.1888930797576904, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.183891773223877, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.0239328145980835, Accuracy: 0.6591796875\n",
      "Batch: 40, Loss: 1.0997955799102783, Accuracy: 0.6396484375\n",
      "Batch: 41, Loss: 1.1350595951080322, Accuracy: 0.6162109375\n",
      "Batch: 42, Loss: 1.0549018383026123, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.0377840995788574, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.0313524007797241, Accuracy: 0.6591796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 0.9929547905921936, Accuracy: 0.6748046875\n",
      "Batch: 46, Loss: 1.0647220611572266, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.171511173248291, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.1311088800430298, Accuracy: 0.626953125\n",
      "Batch: 49, Loss: 1.1167869567871094, Accuracy: 0.6376953125\n",
      "Batch: 50, Loss: 1.123311161994934, Accuracy: 0.6318359375\n",
      "Batch: 51, Loss: 1.137758493423462, Accuracy: 0.619140625\n",
      "Batch: 52, Loss: 1.2274727821350098, Accuracy: 0.6044921875\n",
      "Batch: 53, Loss: 1.1311979293823242, Accuracy: 0.62890625\n",
      "Batch: 54, Loss: 1.1865711212158203, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.0813945531845093, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.0842934846878052, Accuracy: 0.6552734375\n",
      "Batch: 57, Loss: 1.0846176147460938, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.0603575706481934, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.0830044746398926, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.204887866973877, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1845371723175049, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.2028627395629883, Accuracy: 0.6220703125\n",
      "Batch: 63, Loss: 1.181785225868225, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.136420488357544, Accuracy: 0.6357421875\n",
      "Batch: 65, Loss: 1.158088207244873, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.1472408771514893, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1532337665557861, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.0852689743041992, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.0921696424484253, Accuracy: 0.6572265625\n",
      "Batch: 70, Loss: 1.1767644882202148, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.095363974571228, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.1695127487182617, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.1470563411712646, Accuracy: 0.6279296875\n",
      "Batch: 74, Loss: 1.108008623123169, Accuracy: 0.6484375\n",
      "Batch: 75, Loss: 1.0786867141723633, Accuracy: 0.6455078125\n",
      "Batch: 76, Loss: 1.0774588584899902, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0323119163513184, Accuracy: 0.6640625\n",
      "Batch: 78, Loss: 1.053065538406372, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.1440006494522095, Accuracy: 0.6259765625\n",
      "Batch: 80, Loss: 1.0806033611297607, Accuracy: 0.6484375\n",
      "Batch: 81, Loss: 1.125741720199585, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.130248785018921, Accuracy: 0.6513671875\n",
      "Batch: 83, Loss: 1.1401770114898682, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.1138935089111328, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.18133544921875, Accuracy: 0.6259765625\n",
      "Batch: 86, Loss: 1.1139633655548096, Accuracy: 0.634765625\n",
      "Batch: 87, Loss: 1.1748117208480835, Accuracy: 0.6298828125\n",
      "Batch: 88, Loss: 1.0916755199432373, Accuracy: 0.642578125\n",
      "Batch: 89, Loss: 1.1580430269241333, Accuracy: 0.6337890625\n",
      "Batch: 90, Loss: 1.0616315603256226, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.1500556468963623, Accuracy: 0.619140625\n",
      "Batch: 92, Loss: 1.1470824480056763, Accuracy: 0.640625\n",
      "Batch: 93, Loss: 1.1332104206085205, Accuracy: 0.64453125\n",
      "Batch: 94, Loss: 1.1480827331542969, Accuracy: 0.6328125\n",
      "Batch: 95, Loss: 1.187821865081787, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.0887608528137207, Accuracy: 0.6650390625\n",
      "Batch: 97, Loss: 1.1501574516296387, Accuracy: 0.630859375\n",
      "Batch: 98, Loss: 1.0751309394836426, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.1292455196380615, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.039616584777832, Accuracy: 0.65625\n",
      "Batch: 101, Loss: 1.0459250211715698, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.1633706092834473, Accuracy: 0.638671875\n",
      "Batch: 103, Loss: 1.19097900390625, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1196203231811523, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.173172950744629, Accuracy: 0.61328125\n",
      "Batch: 106, Loss: 1.104494571685791, Accuracy: 0.6240234375\n",
      "Batch: 107, Loss: 1.2543495893478394, Accuracy: 0.5888671875\n",
      "Batch: 108, Loss: 1.1229145526885986, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.1973235607147217, Accuracy: 0.619140625\n",
      "Batch: 110, Loss: 1.1028523445129395, Accuracy: 0.6533203125\n",
      "Batch: 111, Loss: 1.091526985168457, Accuracy: 0.646484375\n",
      "Batch: 112, Loss: 1.0147987604141235, Accuracy: 0.6591796875\n",
      "Batch: 113, Loss: 1.1459192037582397, Accuracy: 0.62890625\n",
      "Batch: 114, Loss: 1.1522363424301147, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.1438570022583008, Accuracy: 0.6318359375\n",
      "Batch: 116, Loss: 1.175384521484375, Accuracy: 0.6181640625\n",
      "Batch: 117, Loss: 1.1786458492279053, Accuracy: 0.6220703125\n",
      "Batch: 118, Loss: 1.1767381429672241, Accuracy: 0.6064453125\n",
      "Batch: 119, Loss: 1.1611789464950562, Accuracy: 0.6298828125\n",
      "Batch: 120, Loss: 1.2791575193405151, Accuracy: 0.5869140625\n",
      "Batch: 121, Loss: 1.1213324069976807, Accuracy: 0.626953125\n",
      "Batch: 122, Loss: 1.2307814359664917, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.1741901636123657, Accuracy: 0.6240234375\n",
      "Batch: 124, Loss: 1.200451374053955, Accuracy: 0.6171875\n",
      "Batch: 125, Loss: 1.1580950021743774, Accuracy: 0.638671875\n",
      "Batch: 126, Loss: 1.2129557132720947, Accuracy: 0.61328125\n",
      "Batch: 127, Loss: 1.2835416793823242, Accuracy: 0.6005859375\n",
      "Batch: 128, Loss: 1.1702055931091309, Accuracy: 0.625\n",
      "Batch: 129, Loss: 1.1144148111343384, Accuracy: 0.634765625\n",
      "Batch: 130, Loss: 1.11245596408844, Accuracy: 0.6240234375\n",
      "Batch: 131, Loss: 1.1741068363189697, Accuracy: 0.62109375\n",
      "Batch: 132, Loss: 1.0470749139785767, Accuracy: 0.6591796875\n",
      "Batch: 133, Loss: 1.1133490800857544, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.0744564533233643, Accuracy: 0.646484375\n",
      "Batch: 135, Loss: 0.9608007669448853, Accuracy: 0.6806640625\n",
      "Batch: 136, Loss: 1.0864930152893066, Accuracy: 0.6279296875\n",
      "Batch: 137, Loss: 1.154348611831665, Accuracy: 0.6162109375\n",
      "Batch: 138, Loss: 1.197867751121521, Accuracy: 0.625\n",
      "Batch: 139, Loss: 1.1785993576049805, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.2216603755950928, Accuracy: 0.6162109375\n",
      "Batch: 141, Loss: 1.140869140625, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.183114767074585, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.1896493434906006, Accuracy: 0.607421875\n",
      "Batch: 144, Loss: 1.2108356952667236, Accuracy: 0.607421875\n",
      "Batch: 145, Loss: 1.2126657962799072, Accuracy: 0.6220703125\n",
      "Batch: 146, Loss: 1.2032015323638916, Accuracy: 0.6259765625\n",
      "Batch: 147, Loss: 1.1861214637756348, Accuracy: 0.625\n",
      "Batch: 148, Loss: 1.209115982055664, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.1319328546524048, Accuracy: 0.6337890625\n",
      "Batch: 150, Loss: 1.143608808517456, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.1546308994293213, Accuracy: 0.6318359375\n",
      "Batch: 152, Loss: 1.1115624904632568, Accuracy: 0.6328125\n",
      "Batch: 153, Loss: 1.1043574810028076, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1213783025741577, Accuracy: 0.6337890625\n",
      "Batch: 155, Loss: 1.1485952138900757, Accuracy: 0.6240234375\n",
      "Saved Weights at epoch 560 to file Weights_560.h5\n",
      "Epoch 561/200\n",
      "Batch: 1, Loss: 1.1662620306015015, Accuracy: 0.671875\n",
      "Batch: 2, Loss: 1.0713069438934326, Accuracy: 0.6513671875\n",
      "Batch: 3, Loss: 0.9862509965896606, Accuracy: 0.6767578125\n",
      "Batch: 4, Loss: 1.0584437847137451, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 1.0344200134277344, Accuracy: 0.6494140625\n",
      "Batch: 6, Loss: 1.0032739639282227, Accuracy: 0.6708984375\n",
      "Batch: 7, Loss: 0.9898722767829895, Accuracy: 0.66796875\n",
      "Batch: 8, Loss: 0.9791913628578186, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 0.9708247184753418, Accuracy: 0.6787109375\n",
      "Batch: 10, Loss: 1.005305528640747, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 0.9376417994499207, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9823052883148193, Accuracy: 0.689453125\n",
      "Batch: 13, Loss: 1.002685308456421, Accuracy: 0.6748046875\n",
      "Batch: 14, Loss: 0.947199821472168, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.9149343967437744, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.015432596206665, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 0.9875516295433044, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.077262282371521, Accuracy: 0.64453125\n",
      "Batch: 19, Loss: 1.1697663068771362, Accuracy: 0.62109375\n",
      "Batch: 20, Loss: 1.045259714126587, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0704060792922974, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.202469825744629, Accuracy: 0.6171875\n",
      "Batch: 23, Loss: 1.2319176197052002, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.0925582647323608, Accuracy: 0.6357421875\n",
      "Batch: 25, Loss: 1.1427451372146606, Accuracy: 0.642578125\n",
      "Batch: 26, Loss: 1.149393081665039, Accuracy: 0.623046875\n",
      "Batch: 27, Loss: 1.0769540071487427, Accuracy: 0.6474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28, Loss: 1.0468957424163818, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.1223523616790771, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.150667667388916, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.1581504344940186, Accuracy: 0.6337890625\n",
      "Batch: 32, Loss: 1.0639832019805908, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 0.979119062423706, Accuracy: 0.677734375\n",
      "Batch: 34, Loss: 1.0670949220657349, Accuracy: 0.6630859375\n",
      "Batch: 35, Loss: 1.1199042797088623, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.1191880702972412, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.2202706336975098, Accuracy: 0.595703125\n",
      "Batch: 38, Loss: 1.1049623489379883, Accuracy: 0.6416015625\n",
      "Batch: 39, Loss: 1.0545592308044434, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.0761451721191406, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.1013495922088623, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 1.048020601272583, Accuracy: 0.64453125\n",
      "Batch: 43, Loss: 1.0287009477615356, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.0252819061279297, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.0105526447296143, Accuracy: 0.671875\n",
      "Batch: 46, Loss: 1.152604579925537, Accuracy: 0.6103515625\n",
      "Batch: 47, Loss: 1.1020814180374146, Accuracy: 0.6357421875\n",
      "Batch: 48, Loss: 1.079332709312439, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.1342897415161133, Accuracy: 0.6396484375\n",
      "Batch: 50, Loss: 1.1324057579040527, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.1473631858825684, Accuracy: 0.611328125\n",
      "Batch: 52, Loss: 1.2503583431243896, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.090092658996582, Accuracy: 0.64453125\n",
      "Batch: 54, Loss: 1.1601042747497559, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.0349516868591309, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.116925597190857, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.0877916812896729, Accuracy: 0.66796875\n",
      "Batch: 58, Loss: 1.0736198425292969, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.0954556465148926, Accuracy: 0.66015625\n",
      "Batch: 60, Loss: 1.2244164943695068, Accuracy: 0.599609375\n",
      "Batch: 61, Loss: 1.0973764657974243, Accuracy: 0.646484375\n",
      "Batch: 62, Loss: 1.1393928527832031, Accuracy: 0.6318359375\n",
      "Batch: 63, Loss: 1.164476990699768, Accuracy: 0.63671875\n",
      "Batch: 64, Loss: 1.1503233909606934, Accuracy: 0.611328125\n",
      "Batch: 65, Loss: 1.1145565509796143, Accuracy: 0.638671875\n",
      "Batch: 66, Loss: 1.1400588750839233, Accuracy: 0.6494140625\n",
      "Batch: 67, Loss: 1.150001049041748, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.0631643533706665, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.125654935836792, Accuracy: 0.6328125\n",
      "Batch: 70, Loss: 1.1131713390350342, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.0954967737197876, Accuracy: 0.6318359375\n",
      "Batch: 72, Loss: 1.1747119426727295, Accuracy: 0.6181640625\n",
      "Batch: 73, Loss: 1.1955782175064087, Accuracy: 0.6376953125\n",
      "Batch: 74, Loss: 1.1010856628417969, Accuracy: 0.626953125\n",
      "Batch: 75, Loss: 1.079351544380188, Accuracy: 0.6484375\n",
      "Batch: 76, Loss: 1.0519291162490845, Accuracy: 0.646484375\n",
      "Batch: 77, Loss: 1.0740121603012085, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0338592529296875, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.0980640649795532, Accuracy: 0.65234375\n",
      "Batch: 80, Loss: 1.1184535026550293, Accuracy: 0.6181640625\n",
      "Batch: 81, Loss: 1.0860615968704224, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.0855954885482788, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 1.128894567489624, Accuracy: 0.6357421875\n",
      "Batch: 84, Loss: 1.1051266193389893, Accuracy: 0.64453125\n",
      "Batch: 85, Loss: 1.1283420324325562, Accuracy: 0.6474609375\n",
      "Batch: 86, Loss: 1.1294560432434082, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.0834304094314575, Accuracy: 0.6533203125\n",
      "Batch: 88, Loss: 1.1861889362335205, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.0576136112213135, Accuracy: 0.66796875\n",
      "Batch: 90, Loss: 1.04054856300354, Accuracy: 0.66015625\n",
      "Batch: 91, Loss: 1.1076961755752563, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.125117301940918, Accuracy: 0.6513671875\n",
      "Batch: 93, Loss: 1.0953123569488525, Accuracy: 0.642578125\n",
      "Batch: 94, Loss: 1.1430482864379883, Accuracy: 0.6298828125\n",
      "Batch: 95, Loss: 1.138207197189331, Accuracy: 0.634765625\n",
      "Batch: 96, Loss: 1.19404935836792, Accuracy: 0.6298828125\n",
      "Batch: 97, Loss: 1.1441282033920288, Accuracy: 0.6259765625\n",
      "Batch: 98, Loss: 1.0835899114608765, Accuracy: 0.6611328125\n",
      "Batch: 99, Loss: 1.1067044734954834, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.0356905460357666, Accuracy: 0.6611328125\n",
      "Batch: 101, Loss: 1.0697333812713623, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 1.0982780456542969, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1087372303009033, Accuracy: 0.6455078125\n",
      "Batch: 104, Loss: 1.093024492263794, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.1690765619277954, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.132659912109375, Accuracy: 0.638671875\n",
      "Batch: 107, Loss: 1.1894810199737549, Accuracy: 0.623046875\n",
      "Batch: 108, Loss: 1.1319153308868408, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.1717817783355713, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.0905654430389404, Accuracy: 0.6513671875\n",
      "Batch: 111, Loss: 1.1043708324432373, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.0072557926177979, Accuracy: 0.66796875\n",
      "Batch: 113, Loss: 1.1035348176956177, Accuracy: 0.6494140625\n",
      "Batch: 114, Loss: 1.1224111318588257, Accuracy: 0.625\n",
      "Batch: 115, Loss: 1.1914571523666382, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.1600139141082764, Accuracy: 0.6181640625\n",
      "Batch: 117, Loss: 1.1926169395446777, Accuracy: 0.6015625\n",
      "Batch: 118, Loss: 1.194370150566101, Accuracy: 0.60546875\n",
      "Batch: 119, Loss: 1.173128604888916, Accuracy: 0.642578125\n",
      "Batch: 120, Loss: 1.2168983221054077, Accuracy: 0.61328125\n",
      "Batch: 121, Loss: 1.1894147396087646, Accuracy: 0.6328125\n",
      "Batch: 122, Loss: 1.1752358675003052, Accuracy: 0.6025390625\n",
      "Batch: 123, Loss: 1.1300616264343262, Accuracy: 0.6591796875\n",
      "Batch: 124, Loss: 1.1875059604644775, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1821649074554443, Accuracy: 0.638671875\n",
      "Batch: 126, Loss: 1.1914751529693604, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.2298589944839478, Accuracy: 0.59765625\n",
      "Batch: 128, Loss: 1.1589736938476562, Accuracy: 0.642578125\n",
      "Batch: 129, Loss: 1.1496100425720215, Accuracy: 0.6328125\n",
      "Batch: 130, Loss: 1.0945428609848022, Accuracy: 0.6435546875\n",
      "Batch: 131, Loss: 1.1384589672088623, Accuracy: 0.65234375\n",
      "Batch: 132, Loss: 1.0731573104858398, Accuracy: 0.6318359375\n",
      "Batch: 133, Loss: 1.1051075458526611, Accuracy: 0.6416015625\n",
      "Batch: 134, Loss: 1.1008448600769043, Accuracy: 0.6376953125\n",
      "Batch: 135, Loss: 1.0494788885116577, Accuracy: 0.650390625\n",
      "Batch: 136, Loss: 1.0573173761367798, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1462528705596924, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.203311562538147, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.1554075479507446, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.2301414012908936, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1697651147842407, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.1276838779449463, Accuracy: 0.6220703125\n",
      "Batch: 143, Loss: 1.1518731117248535, Accuracy: 0.626953125\n",
      "Batch: 144, Loss: 1.2057602405548096, Accuracy: 0.6123046875\n",
      "Batch: 145, Loss: 1.2145835161209106, Accuracy: 0.6064453125\n",
      "Batch: 146, Loss: 1.2124556303024292, Accuracy: 0.6103515625\n",
      "Batch: 147, Loss: 1.1700661182403564, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.194475531578064, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.1456151008605957, Accuracy: 0.6240234375\n",
      "Batch: 150, Loss: 1.098184585571289, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 1.1320359706878662, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.1489381790161133, Accuracy: 0.615234375\n",
      "Batch: 153, Loss: 1.054105281829834, Accuracy: 0.6689453125\n",
      "Batch: 154, Loss: 1.0957200527191162, Accuracy: 0.6416015625\n",
      "Batch: 155, Loss: 1.0776753425598145, Accuracy: 0.65234375\n",
      "Epoch 562/200\n",
      "Batch: 1, Loss: 1.1515781879425049, Accuracy: 0.66015625\n",
      "Batch: 2, Loss: 1.0435121059417725, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 0.9337332248687744, Accuracy: 0.701171875\n",
      "Batch: 4, Loss: 1.0699886083602905, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 0.9887821078300476, Accuracy: 0.68359375\n",
      "Batch: 6, Loss: 0.9835859537124634, Accuracy: 0.669921875\n",
      "Batch: 7, Loss: 0.9962407350540161, Accuracy: 0.6796875\n",
      "Batch: 8, Loss: 0.9485834240913391, Accuracy: 0.6806640625\n",
      "Batch: 9, Loss: 0.977434515953064, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9700651168823242, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9516074657440186, Accuracy: 0.66796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12, Loss: 0.9942147731781006, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.9730930328369141, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 0.9968185424804688, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9093376994132996, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 0.9852335453033447, Accuracy: 0.705078125\n",
      "Batch: 17, Loss: 1.0013575553894043, Accuracy: 0.6640625\n",
      "Batch: 18, Loss: 1.0955641269683838, Accuracy: 0.65625\n",
      "Batch: 19, Loss: 1.1829743385314941, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0669317245483398, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.0425565242767334, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.1832003593444824, Accuracy: 0.6328125\n",
      "Batch: 23, Loss: 1.232313871383667, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.1053364276885986, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 1.1106032133102417, Accuracy: 0.6396484375\n",
      "Batch: 26, Loss: 1.1583868265151978, Accuracy: 0.6240234375\n",
      "Batch: 27, Loss: 1.1092462539672852, Accuracy: 0.6376953125\n",
      "Batch: 28, Loss: 1.046077847480774, Accuracy: 0.6611328125\n",
      "Batch: 29, Loss: 1.0324428081512451, Accuracy: 0.65625\n",
      "Batch: 30, Loss: 1.1487200260162354, Accuracy: 0.6318359375\n",
      "Batch: 31, Loss: 1.2141051292419434, Accuracy: 0.6005859375\n",
      "Batch: 32, Loss: 0.9967308044433594, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 0.9739025831222534, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.056458592414856, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.1353964805603027, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.135624885559082, Accuracy: 0.630859375\n",
      "Batch: 37, Loss: 1.1755602359771729, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.1496145725250244, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.0213427543640137, Accuracy: 0.67578125\n",
      "Batch: 40, Loss: 1.0968327522277832, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.0964939594268799, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 1.0333764553070068, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.0709953308105469, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 0.9983170628547668, Accuracy: 0.6484375\n",
      "Batch: 45, Loss: 0.9786773920059204, Accuracy: 0.6923828125\n",
      "Batch: 46, Loss: 1.109877586364746, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.0175197124481201, Accuracy: 0.685546875\n",
      "Batch: 48, Loss: 1.122328519821167, Accuracy: 0.6259765625\n",
      "Batch: 49, Loss: 1.1231434345245361, Accuracy: 0.638671875\n",
      "Batch: 50, Loss: 1.1062326431274414, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.1351408958435059, Accuracy: 0.6279296875\n",
      "Batch: 52, Loss: 1.2105486392974854, Accuracy: 0.6064453125\n",
      "Batch: 53, Loss: 1.1353747844696045, Accuracy: 0.6318359375\n",
      "Batch: 54, Loss: 1.1458139419555664, Accuracy: 0.6201171875\n",
      "Batch: 55, Loss: 1.124424934387207, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.091902732849121, Accuracy: 0.642578125\n",
      "Batch: 57, Loss: 1.0399847030639648, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.109816551208496, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 1.0882271528244019, Accuracy: 0.64453125\n",
      "Batch: 60, Loss: 1.1759452819824219, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1032999753952026, Accuracy: 0.6328125\n",
      "Batch: 62, Loss: 1.1432170867919922, Accuracy: 0.6220703125\n",
      "Batch: 63, Loss: 1.1634080410003662, Accuracy: 0.6064453125\n",
      "Batch: 64, Loss: 1.1320542097091675, Accuracy: 0.6279296875\n",
      "Batch: 65, Loss: 1.1509416103363037, Accuracy: 0.63671875\n",
      "Batch: 66, Loss: 1.1353455781936646, Accuracy: 0.6220703125\n",
      "Batch: 67, Loss: 1.1430723667144775, Accuracy: 0.6103515625\n",
      "Batch: 68, Loss: 1.087551236152649, Accuracy: 0.646484375\n",
      "Batch: 69, Loss: 1.1423813104629517, Accuracy: 0.6298828125\n",
      "Batch: 70, Loss: 1.110032320022583, Accuracy: 0.6357421875\n",
      "Batch: 71, Loss: 1.1105046272277832, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.1735315322875977, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.1335725784301758, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.0830318927764893, Accuracy: 0.646484375\n",
      "Batch: 75, Loss: 1.075075387954712, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.0681416988372803, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.0238932371139526, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.0412250757217407, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.1542484760284424, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.1226186752319336, Accuracy: 0.6416015625\n",
      "Batch: 81, Loss: 1.0994536876678467, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.1254764795303345, Accuracy: 0.6552734375\n",
      "Batch: 83, Loss: 1.1342495679855347, Accuracy: 0.62890625\n",
      "Batch: 84, Loss: 1.0992090702056885, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.1482219696044922, Accuracy: 0.625\n",
      "Batch: 86, Loss: 1.1018741130828857, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.1258153915405273, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.1192251443862915, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.103299617767334, Accuracy: 0.6240234375\n",
      "Batch: 90, Loss: 1.0443791151046753, Accuracy: 0.666015625\n",
      "Batch: 91, Loss: 1.136391520500183, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.0734035968780518, Accuracy: 0.66015625\n",
      "Batch: 93, Loss: 1.0320764780044556, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.1581963300704956, Accuracy: 0.638671875\n",
      "Batch: 95, Loss: 1.1301705837249756, Accuracy: 0.638671875\n",
      "Batch: 96, Loss: 1.185787320137024, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.1749677658081055, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.017993450164795, Accuracy: 0.666015625\n",
      "Batch: 99, Loss: 1.1096935272216797, Accuracy: 0.6572265625\n",
      "Batch: 100, Loss: 1.0260517597198486, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.0548670291900635, Accuracy: 0.6708984375\n",
      "Batch: 102, Loss: 1.1048592329025269, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.1017155647277832, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.0881842374801636, Accuracy: 0.623046875\n",
      "Batch: 105, Loss: 1.1489710807800293, Accuracy: 0.62890625\n",
      "Batch: 106, Loss: 1.0780267715454102, Accuracy: 0.65234375\n",
      "Batch: 107, Loss: 1.2475963830947876, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.1398048400878906, Accuracy: 0.623046875\n",
      "Batch: 109, Loss: 1.1528898477554321, Accuracy: 0.630859375\n",
      "Batch: 110, Loss: 1.1434791088104248, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.0827209949493408, Accuracy: 0.64453125\n",
      "Batch: 112, Loss: 1.0286142826080322, Accuracy: 0.6669921875\n",
      "Batch: 113, Loss: 1.1359097957611084, Accuracy: 0.630859375\n",
      "Batch: 114, Loss: 1.1744533777236938, Accuracy: 0.6123046875\n",
      "Batch: 115, Loss: 1.1245054006576538, Accuracy: 0.625\n",
      "Batch: 116, Loss: 1.1425509452819824, Accuracy: 0.6337890625\n",
      "Batch: 117, Loss: 1.0824873447418213, Accuracy: 0.646484375\n",
      "Batch: 118, Loss: 1.1613458395004272, Accuracy: 0.625\n",
      "Batch: 119, Loss: 1.216505527496338, Accuracy: 0.5869140625\n",
      "Batch: 120, Loss: 1.2580076456069946, Accuracy: 0.6123046875\n",
      "Batch: 121, Loss: 1.1852521896362305, Accuracy: 0.61328125\n",
      "Batch: 122, Loss: 1.1688045263290405, Accuracy: 0.6171875\n",
      "Batch: 123, Loss: 1.12125825881958, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.1937090158462524, Accuracy: 0.62890625\n",
      "Batch: 125, Loss: 1.1510307788848877, Accuracy: 0.625\n",
      "Batch: 126, Loss: 1.1480090618133545, Accuracy: 0.6337890625\n",
      "Batch: 127, Loss: 1.224848747253418, Accuracy: 0.6162109375\n",
      "Batch: 128, Loss: 1.148951768875122, Accuracy: 0.626953125\n",
      "Batch: 129, Loss: 1.1217904090881348, Accuracy: 0.646484375\n",
      "Batch: 130, Loss: 1.1226410865783691, Accuracy: 0.6318359375\n",
      "Batch: 131, Loss: 1.1845626831054688, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.0399386882781982, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 1.079537272453308, Accuracy: 0.6572265625\n",
      "Batch: 134, Loss: 1.1231791973114014, Accuracy: 0.654296875\n",
      "Batch: 135, Loss: 0.9985107779502869, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.0422552824020386, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.1228947639465332, Accuracy: 0.6318359375\n",
      "Batch: 138, Loss: 1.1959762573242188, Accuracy: 0.607421875\n",
      "Batch: 139, Loss: 1.1736931800842285, Accuracy: 0.62890625\n",
      "Batch: 140, Loss: 1.2068586349487305, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.1331515312194824, Accuracy: 0.63671875\n",
      "Batch: 142, Loss: 1.1643980741500854, Accuracy: 0.638671875\n",
      "Batch: 143, Loss: 1.1613383293151855, Accuracy: 0.6318359375\n",
      "Batch: 144, Loss: 1.193830132484436, Accuracy: 0.6142578125\n",
      "Batch: 145, Loss: 1.1597330570220947, Accuracy: 0.6044921875\n",
      "Batch: 146, Loss: 1.1427184343338013, Accuracy: 0.6318359375\n",
      "Batch: 147, Loss: 1.2116498947143555, Accuracy: 0.6083984375\n",
      "Batch: 148, Loss: 1.205653190612793, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.2017250061035156, Accuracy: 0.609375\n",
      "Batch: 150, Loss: 1.125533938407898, Accuracy: 0.6298828125\n",
      "Batch: 151, Loss: 1.1415035724639893, Accuracy: 0.6318359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 152, Loss: 1.1729857921600342, Accuracy: 0.6005859375\n",
      "Batch: 153, Loss: 1.120520830154419, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.0529685020446777, Accuracy: 0.671875\n",
      "Batch: 155, Loss: 1.1212477684020996, Accuracy: 0.62890625\n",
      "Epoch 563/200\n",
      "Batch: 1, Loss: 1.2080196142196655, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0875186920166016, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 0.9986375570297241, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.0537631511688232, Accuracy: 0.64453125\n",
      "Batch: 5, Loss: 0.9784884452819824, Accuracy: 0.6748046875\n",
      "Batch: 6, Loss: 1.0056467056274414, Accuracy: 0.6806640625\n",
      "Batch: 7, Loss: 1.0048763751983643, Accuracy: 0.67578125\n",
      "Batch: 8, Loss: 0.9692065119743347, Accuracy: 0.6953125\n",
      "Batch: 9, Loss: 0.9672292470932007, Accuracy: 0.7001953125\n",
      "Batch: 10, Loss: 0.95076584815979, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.952123761177063, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.9613325595855713, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 0.9735661745071411, Accuracy: 0.6767578125\n",
      "Batch: 14, Loss: 0.9742242097854614, Accuracy: 0.6611328125\n",
      "Batch: 15, Loss: 0.9274214506149292, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 1.0384148359298706, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.0205926895141602, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 1.1450371742248535, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.2244954109191895, Accuracy: 0.60546875\n",
      "Batch: 20, Loss: 1.0659210681915283, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.0688831806182861, Accuracy: 0.6494140625\n",
      "Batch: 22, Loss: 1.1949598789215088, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.2012388706207275, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.0673093795776367, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.0984593629837036, Accuracy: 0.6552734375\n",
      "Batch: 26, Loss: 1.1298784017562866, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.0607024431228638, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 1.053873896598816, Accuracy: 0.65625\n",
      "Batch: 29, Loss: 1.0232583284378052, Accuracy: 0.6533203125\n",
      "Batch: 30, Loss: 1.1689252853393555, Accuracy: 0.5986328125\n",
      "Batch: 31, Loss: 1.1854323148727417, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.050856590270996, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 0.9861149787902832, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.109602928161621, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.0617836713790894, Accuracy: 0.671875\n",
      "Batch: 36, Loss: 1.149580717086792, Accuracy: 0.6005859375\n",
      "Batch: 37, Loss: 1.159959316253662, Accuracy: 0.626953125\n",
      "Batch: 38, Loss: 1.1668280363082886, Accuracy: 0.6181640625\n",
      "Batch: 39, Loss: 1.0201315879821777, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.11589777469635, Accuracy: 0.6318359375\n",
      "Batch: 41, Loss: 1.109851360321045, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.013791799545288, Accuracy: 0.6611328125\n",
      "Batch: 43, Loss: 1.0455961227416992, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0300636291503906, Accuracy: 0.6650390625\n",
      "Batch: 45, Loss: 1.0615441799163818, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.1227335929870605, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.0747008323669434, Accuracy: 0.6376953125\n",
      "Batch: 48, Loss: 1.1192443370819092, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.1363229751586914, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.1162939071655273, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.1499991416931152, Accuracy: 0.6064453125\n",
      "Batch: 52, Loss: 1.1869292259216309, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.1372548341751099, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1782355308532715, Accuracy: 0.6220703125\n",
      "Batch: 55, Loss: 1.0541744232177734, Accuracy: 0.65625\n",
      "Batch: 56, Loss: 1.0016710758209229, Accuracy: 0.671875\n",
      "Batch: 57, Loss: 1.1057164669036865, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.104874849319458, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 1.1023857593536377, Accuracy: 0.630859375\n",
      "Batch: 60, Loss: 1.1628650426864624, Accuracy: 0.62890625\n",
      "Batch: 61, Loss: 1.1526693105697632, Accuracy: 0.63671875\n",
      "Batch: 62, Loss: 1.097486972808838, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1484956741333008, Accuracy: 0.62890625\n",
      "Batch: 64, Loss: 1.233783483505249, Accuracy: 0.5986328125\n",
      "Batch: 65, Loss: 1.1881580352783203, Accuracy: 0.6298828125\n",
      "Batch: 66, Loss: 1.1290827989578247, Accuracy: 0.646484375\n",
      "Batch: 67, Loss: 1.1208207607269287, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0520747900009155, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.07599675655365, Accuracy: 0.646484375\n",
      "Batch: 70, Loss: 1.099619746208191, Accuracy: 0.6435546875\n",
      "Batch: 71, Loss: 1.1323573589324951, Accuracy: 0.6318359375\n",
      "Batch: 72, Loss: 1.1673099994659424, Accuracy: 0.6142578125\n",
      "Batch: 73, Loss: 1.2000105381011963, Accuracy: 0.6279296875\n",
      "Batch: 74, Loss: 1.0153733491897583, Accuracy: 0.6640625\n",
      "Batch: 75, Loss: 1.0957392454147339, Accuracy: 0.642578125\n",
      "Batch: 76, Loss: 1.0664403438568115, Accuracy: 0.63671875\n",
      "Batch: 77, Loss: 1.0692758560180664, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.082216501235962, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.078174352645874, Accuracy: 0.650390625\n",
      "Batch: 80, Loss: 1.1264586448669434, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.0821588039398193, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 1.0918502807617188, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.2107264995574951, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.088388442993164, Accuracy: 0.6455078125\n",
      "Batch: 85, Loss: 1.1174867153167725, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.0963654518127441, Accuracy: 0.6484375\n",
      "Batch: 87, Loss: 1.1009416580200195, Accuracy: 0.6455078125\n",
      "Batch: 88, Loss: 1.1102699041366577, Accuracy: 0.6318359375\n",
      "Batch: 89, Loss: 1.0822913646697998, Accuracy: 0.6435546875\n",
      "Batch: 90, Loss: 1.121172547340393, Accuracy: 0.626953125\n",
      "Batch: 91, Loss: 1.1252065896987915, Accuracy: 0.6337890625\n",
      "Batch: 92, Loss: 1.0975955724716187, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.1089670658111572, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.1625745296478271, Accuracy: 0.626953125\n",
      "Batch: 95, Loss: 1.1488523483276367, Accuracy: 0.6298828125\n",
      "Batch: 96, Loss: 1.1702746152877808, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.0889074802398682, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.0827791690826416, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.1249489784240723, Accuracy: 0.6435546875\n",
      "Batch: 100, Loss: 1.022925615310669, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0912971496582031, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 1.0925261974334717, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.1427630186080933, Accuracy: 0.640625\n",
      "Batch: 104, Loss: 1.0755836963653564, Accuracy: 0.6474609375\n",
      "Batch: 105, Loss: 1.2106668949127197, Accuracy: 0.6044921875\n",
      "Batch: 106, Loss: 1.1284382343292236, Accuracy: 0.64453125\n",
      "Batch: 107, Loss: 1.176651954650879, Accuracy: 0.6181640625\n",
      "Batch: 108, Loss: 1.085385799407959, Accuracy: 0.6357421875\n",
      "Batch: 109, Loss: 1.1596685647964478, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.1438469886779785, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.0711359977722168, Accuracy: 0.6513671875\n",
      "Batch: 112, Loss: 1.0869163274765015, Accuracy: 0.6416015625\n",
      "Batch: 113, Loss: 1.108664631843567, Accuracy: 0.6328125\n",
      "Batch: 114, Loss: 1.1220093965530396, Accuracy: 0.6259765625\n",
      "Batch: 115, Loss: 1.1360045671463013, Accuracy: 0.638671875\n",
      "Batch: 116, Loss: 1.2033960819244385, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.1356608867645264, Accuracy: 0.625\n",
      "Batch: 118, Loss: 1.2198996543884277, Accuracy: 0.599609375\n",
      "Batch: 119, Loss: 1.2249650955200195, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.2857719659805298, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.1511224508285522, Accuracy: 0.6279296875\n",
      "Batch: 122, Loss: 1.1767693758010864, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.142942190170288, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.2024314403533936, Accuracy: 0.615234375\n",
      "Batch: 125, Loss: 1.121105432510376, Accuracy: 0.6533203125\n",
      "Batch: 126, Loss: 1.1883620023727417, Accuracy: 0.62890625\n",
      "Batch: 127, Loss: 1.285631775856018, Accuracy: 0.603515625\n",
      "Batch: 128, Loss: 1.1629198789596558, Accuracy: 0.6416015625\n",
      "Batch: 129, Loss: 1.1289345026016235, Accuracy: 0.6435546875\n",
      "Batch: 130, Loss: 1.1396359205245972, Accuracy: 0.6435546875\n",
      "Batch: 131, Loss: 1.1708970069885254, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.0467978715896606, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.1088404655456543, Accuracy: 0.6494140625\n",
      "Batch: 134, Loss: 1.0824694633483887, Accuracy: 0.6767578125\n",
      "Batch: 135, Loss: 1.0171438455581665, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.0283374786376953, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.1281764507293701, Accuracy: 0.6435546875\n",
      "Batch: 138, Loss: 1.169480323791504, Accuracy: 0.6171875\n",
      "Batch: 139, Loss: 1.1837061643600464, Accuracy: 0.6240234375\n",
      "Batch: 140, Loss: 1.2180120944976807, Accuracy: 0.6123046875\n",
      "Batch: 141, Loss: 1.1479657888412476, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.130568027496338, Accuracy: 0.6474609375\n",
      "Batch: 143, Loss: 1.1594383716583252, Accuracy: 0.6083984375\n",
      "Batch: 144, Loss: 1.201351284980774, Accuracy: 0.611328125\n",
      "Batch: 145, Loss: 1.2563111782073975, Accuracy: 0.59765625\n",
      "Batch: 146, Loss: 1.178139328956604, Accuracy: 0.599609375\n",
      "Batch: 147, Loss: 1.1970422267913818, Accuracy: 0.591796875\n",
      "Batch: 148, Loss: 1.2103939056396484, Accuracy: 0.607421875\n",
      "Batch: 149, Loss: 1.120901107788086, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1164777278900146, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.1570463180541992, Accuracy: 0.6201171875\n",
      "Batch: 152, Loss: 1.1759639978408813, Accuracy: 0.6005859375\n",
      "Batch: 153, Loss: 1.0951664447784424, Accuracy: 0.650390625\n",
      "Batch: 154, Loss: 1.06272292137146, Accuracy: 0.6474609375\n",
      "Batch: 155, Loss: 1.0554955005645752, Accuracy: 0.66015625\n",
      "Epoch 564/200\n",
      "Batch: 1, Loss: 1.275438666343689, Accuracy: 0.625\n",
      "Batch: 2, Loss: 1.0297954082489014, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 0.9969395399093628, Accuracy: 0.6533203125\n",
      "Batch: 4, Loss: 1.0783246755599976, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 1.012672781944275, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 0.9857393503189087, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 0.9877524971961975, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9861186742782593, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9330984354019165, Accuracy: 0.69921875\n",
      "Batch: 10, Loss: 0.9672755599021912, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.959510087966919, Accuracy: 0.6923828125\n",
      "Batch: 12, Loss: 1.0342761278152466, Accuracy: 0.6455078125\n",
      "Batch: 13, Loss: 1.0043463706970215, Accuracy: 0.6689453125\n",
      "Batch: 14, Loss: 0.9463726282119751, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 1.0229151248931885, Accuracy: 0.6591796875\n",
      "Batch: 16, Loss: 1.0562512874603271, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.0673651695251465, Accuracy: 0.650390625\n",
      "Batch: 18, Loss: 1.0792617797851562, Accuracy: 0.646484375\n",
      "Batch: 19, Loss: 1.1932023763656616, Accuracy: 0.615234375\n",
      "Batch: 20, Loss: 1.093947410583496, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.0426400899887085, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.1928603649139404, Accuracy: 0.6015625\n",
      "Batch: 23, Loss: 1.2034997940063477, Accuracy: 0.6083984375\n",
      "Batch: 24, Loss: 1.1073663234710693, Accuracy: 0.6484375\n",
      "Batch: 25, Loss: 1.114459753036499, Accuracy: 0.6396484375\n",
      "Batch: 26, Loss: 1.1568458080291748, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.0838649272918701, Accuracy: 0.6552734375\n",
      "Batch: 28, Loss: 1.067715048789978, Accuracy: 0.6396484375\n",
      "Batch: 29, Loss: 1.0136570930480957, Accuracy: 0.6826171875\n",
      "Batch: 30, Loss: 1.165820598602295, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.1395511627197266, Accuracy: 0.634765625\n",
      "Batch: 32, Loss: 1.0425066947937012, Accuracy: 0.6513671875\n",
      "Batch: 33, Loss: 0.9754345417022705, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.0650396347045898, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 1.1457847356796265, Accuracy: 0.62890625\n",
      "Batch: 36, Loss: 1.1590197086334229, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.2017183303833008, Accuracy: 0.58984375\n",
      "Batch: 38, Loss: 1.1522572040557861, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0786457061767578, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.0422561168670654, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1421902179718018, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 1.041048288345337, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.0278654098510742, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.0181641578674316, Accuracy: 0.6728515625\n",
      "Batch: 45, Loss: 0.9845718145370483, Accuracy: 0.66796875\n",
      "Batch: 46, Loss: 1.1371982097625732, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.0754303932189941, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1037535667419434, Accuracy: 0.625\n",
      "Batch: 49, Loss: 1.1079846620559692, Accuracy: 0.6494140625\n",
      "Batch: 50, Loss: 1.1018316745758057, Accuracy: 0.6513671875\n",
      "Batch: 51, Loss: 1.106255054473877, Accuracy: 0.6259765625\n",
      "Batch: 52, Loss: 1.2015526294708252, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.1474554538726807, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.1691747903823853, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.1322658061981201, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.0844160318374634, Accuracy: 0.671875\n",
      "Batch: 57, Loss: 1.0833407640457153, Accuracy: 0.65234375\n",
      "Batch: 58, Loss: 1.0818371772766113, Accuracy: 0.658203125\n",
      "Batch: 59, Loss: 1.056197166442871, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.2095668315887451, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.1005911827087402, Accuracy: 0.6318359375\n",
      "Batch: 62, Loss: 1.147703766822815, Accuracy: 0.625\n",
      "Batch: 63, Loss: 1.13680100440979, Accuracy: 0.6318359375\n",
      "Batch: 64, Loss: 1.1365888118743896, Accuracy: 0.6220703125\n",
      "Batch: 65, Loss: 1.1858630180358887, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.088377833366394, Accuracy: 0.6435546875\n",
      "Batch: 67, Loss: 1.1528129577636719, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.0542289018630981, Accuracy: 0.6787109375\n",
      "Batch: 69, Loss: 1.1195868253707886, Accuracy: 0.6337890625\n",
      "Batch: 70, Loss: 1.1296120882034302, Accuracy: 0.64453125\n",
      "Batch: 71, Loss: 1.1026690006256104, Accuracy: 0.6455078125\n",
      "Batch: 72, Loss: 1.1500611305236816, Accuracy: 0.6318359375\n",
      "Batch: 73, Loss: 1.1830096244812012, Accuracy: 0.603515625\n",
      "Batch: 74, Loss: 1.0758858919143677, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.0863804817199707, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.0651497840881348, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0891293287277222, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0332845449447632, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.114216923713684, Accuracy: 0.626953125\n",
      "Batch: 80, Loss: 1.1370971202850342, Accuracy: 0.6240234375\n",
      "Batch: 81, Loss: 1.0952547788619995, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.059412956237793, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.142687201499939, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.1339640617370605, Accuracy: 0.6474609375\n",
      "Batch: 85, Loss: 1.219130277633667, Accuracy: 0.609375\n",
      "Batch: 86, Loss: 1.1169625520706177, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 1.1764994859695435, Accuracy: 0.6181640625\n",
      "Batch: 88, Loss: 1.1459510326385498, Accuracy: 0.640625\n",
      "Batch: 89, Loss: 1.1293412446975708, Accuracy: 0.654296875\n",
      "Batch: 90, Loss: 1.0506680011749268, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.0541348457336426, Accuracy: 0.6484375\n",
      "Batch: 92, Loss: 1.1116694211959839, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.1023083925247192, Accuracy: 0.65234375\n",
      "Batch: 94, Loss: 1.1302932500839233, Accuracy: 0.6298828125\n",
      "Batch: 95, Loss: 1.1302592754364014, Accuracy: 0.6494140625\n",
      "Batch: 96, Loss: 1.1049060821533203, Accuracy: 0.662109375\n",
      "Batch: 97, Loss: 1.1694767475128174, Accuracy: 0.607421875\n",
      "Batch: 98, Loss: 1.1156458854675293, Accuracy: 0.630859375\n",
      "Batch: 99, Loss: 1.1430366039276123, Accuracy: 0.6318359375\n",
      "Batch: 100, Loss: 1.0741291046142578, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.062019944190979, Accuracy: 0.6611328125\n",
      "Batch: 102, Loss: 1.1082779169082642, Accuracy: 0.6572265625\n",
      "Batch: 103, Loss: 1.102174997329712, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.0872459411621094, Accuracy: 0.640625\n",
      "Batch: 105, Loss: 1.1886613368988037, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.1208577156066895, Accuracy: 0.646484375\n",
      "Batch: 107, Loss: 1.1997096538543701, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.1343262195587158, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.1098123788833618, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.1033172607421875, Accuracy: 0.6171875\n",
      "Batch: 111, Loss: 1.093447208404541, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.0500390529632568, Accuracy: 0.6630859375\n",
      "Batch: 113, Loss: 1.1175538301467896, Accuracy: 0.63671875\n",
      "Batch: 114, Loss: 1.1097877025604248, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.2168241739273071, Accuracy: 0.6083984375\n",
      "Batch: 116, Loss: 1.1166305541992188, Accuracy: 0.63671875\n",
      "Batch: 117, Loss: 1.1888961791992188, Accuracy: 0.6201171875\n",
      "Batch: 118, Loss: 1.197033405303955, Accuracy: 0.591796875\n",
      "Batch: 119, Loss: 1.2011604309082031, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.228154182434082, Accuracy: 0.61328125\n",
      "Batch: 121, Loss: 1.2127797603607178, Accuracy: 0.61328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 1.1436665058135986, Accuracy: 0.6455078125\n",
      "Batch: 123, Loss: 1.1357227563858032, Accuracy: 0.6435546875\n",
      "Batch: 124, Loss: 1.173243522644043, Accuracy: 0.6298828125\n",
      "Batch: 125, Loss: 1.1592202186584473, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.2090528011322021, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.1909806728363037, Accuracy: 0.61328125\n",
      "Batch: 128, Loss: 1.1576735973358154, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1324970722198486, Accuracy: 0.6298828125\n",
      "Batch: 130, Loss: 1.1153950691223145, Accuracy: 0.650390625\n",
      "Batch: 131, Loss: 1.1748826503753662, Accuracy: 0.6171875\n",
      "Batch: 132, Loss: 0.9877808094024658, Accuracy: 0.693359375\n",
      "Batch: 133, Loss: 1.078852891921997, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.130630373954773, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 1.0308606624603271, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.1074552536010742, Accuracy: 0.6416015625\n",
      "Batch: 137, Loss: 1.0852599143981934, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.1973270177841187, Accuracy: 0.599609375\n",
      "Batch: 139, Loss: 1.1882928609848022, Accuracy: 0.6181640625\n",
      "Batch: 140, Loss: 1.2101539373397827, Accuracy: 0.6318359375\n",
      "Batch: 141, Loss: 1.1396825313568115, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.135129690170288, Accuracy: 0.64453125\n",
      "Batch: 143, Loss: 1.1818214654922485, Accuracy: 0.62109375\n",
      "Batch: 144, Loss: 1.2682693004608154, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.2127678394317627, Accuracy: 0.5908203125\n",
      "Batch: 146, Loss: 1.0788295269012451, Accuracy: 0.634765625\n",
      "Batch: 147, Loss: 1.1925454139709473, Accuracy: 0.615234375\n",
      "Batch: 148, Loss: 1.1639357805252075, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.1821153163909912, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.1039299964904785, Accuracy: 0.646484375\n",
      "Batch: 151, Loss: 1.1318583488464355, Accuracy: 0.6396484375\n",
      "Batch: 152, Loss: 1.0910372734069824, Accuracy: 0.666015625\n",
      "Batch: 153, Loss: 1.0478854179382324, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.0742204189300537, Accuracy: 0.6513671875\n",
      "Batch: 155, Loss: 1.0495833158493042, Accuracy: 0.658203125\n",
      "Epoch 565/200\n",
      "Batch: 1, Loss: 1.145946741104126, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 1.0416823625564575, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 1.0045157670974731, Accuracy: 0.6708984375\n",
      "Batch: 4, Loss: 1.0287874937057495, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 0.9885175824165344, Accuracy: 0.681640625\n",
      "Batch: 6, Loss: 1.0169833898544312, Accuracy: 0.666015625\n",
      "Batch: 7, Loss: 1.0063472986221313, Accuracy: 0.6689453125\n",
      "Batch: 8, Loss: 0.9494926929473877, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9501317739486694, Accuracy: 0.69921875\n",
      "Batch: 10, Loss: 0.9546645283699036, Accuracy: 0.705078125\n",
      "Batch: 11, Loss: 0.9534299373626709, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 1.010364294052124, Accuracy: 0.6767578125\n",
      "Batch: 13, Loss: 0.9842507243156433, Accuracy: 0.673828125\n",
      "Batch: 14, Loss: 0.9540543556213379, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 0.9134843349456787, Accuracy: 0.69140625\n",
      "Batch: 16, Loss: 0.9766453504562378, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.0323619842529297, Accuracy: 0.671875\n",
      "Batch: 18, Loss: 1.13547945022583, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.1447744369506836, Accuracy: 0.6328125\n",
      "Batch: 20, Loss: 1.0829241275787354, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.0465505123138428, Accuracy: 0.6669921875\n",
      "Batch: 22, Loss: 1.196056604385376, Accuracy: 0.6279296875\n",
      "Batch: 23, Loss: 1.151379108428955, Accuracy: 0.607421875\n",
      "Batch: 24, Loss: 1.0463132858276367, Accuracy: 0.65625\n",
      "Batch: 25, Loss: 1.1141239404678345, Accuracy: 0.6669921875\n",
      "Batch: 26, Loss: 1.1853406429290771, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.0888755321502686, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0372873544692993, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 0.9884185791015625, Accuracy: 0.677734375\n",
      "Batch: 30, Loss: 1.0662182569503784, Accuracy: 0.642578125\n",
      "Batch: 31, Loss: 1.140258550643921, Accuracy: 0.6337890625\n",
      "Batch: 32, Loss: 1.0206496715545654, Accuracy: 0.6708984375\n",
      "Batch: 33, Loss: 0.9454324245452881, Accuracy: 0.685546875\n",
      "Batch: 34, Loss: 1.0581167936325073, Accuracy: 0.65625\n",
      "Batch: 35, Loss: 1.0960564613342285, Accuracy: 0.646484375\n",
      "Batch: 36, Loss: 1.161265254020691, Accuracy: 0.62890625\n",
      "Batch: 37, Loss: 1.189273476600647, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.1624367237091064, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0695388317108154, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.0719399452209473, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.1218997240066528, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.0824798345565796, Accuracy: 0.646484375\n",
      "Batch: 43, Loss: 1.0277738571166992, Accuracy: 0.64453125\n",
      "Batch: 44, Loss: 0.9288403987884521, Accuracy: 0.693359375\n",
      "Batch: 45, Loss: 1.0005767345428467, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.1441452503204346, Accuracy: 0.619140625\n",
      "Batch: 47, Loss: 1.052278995513916, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.127439260482788, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.165891170501709, Accuracy: 0.61328125\n",
      "Batch: 50, Loss: 1.1206399202346802, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.1692270040512085, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.2043850421905518, Accuracy: 0.63671875\n",
      "Batch: 53, Loss: 1.1658861637115479, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.1739699840545654, Accuracy: 0.611328125\n",
      "Batch: 55, Loss: 1.1181085109710693, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.092454433441162, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.078498125076294, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.0737838745117188, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.0747456550598145, Accuracy: 0.6611328125\n",
      "Batch: 60, Loss: 1.2368671894073486, Accuracy: 0.6103515625\n",
      "Batch: 61, Loss: 1.1095318794250488, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1193842887878418, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1288654804229736, Accuracy: 0.642578125\n",
      "Batch: 64, Loss: 1.219363808631897, Accuracy: 0.611328125\n",
      "Batch: 65, Loss: 1.1744580268859863, Accuracy: 0.615234375\n",
      "Batch: 66, Loss: 1.0725712776184082, Accuracy: 0.65234375\n",
      "Batch: 67, Loss: 1.165451169013977, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.0802364349365234, Accuracy: 0.65234375\n",
      "Batch: 69, Loss: 1.1635587215423584, Accuracy: 0.65234375\n",
      "Batch: 70, Loss: 1.1572829484939575, Accuracy: 0.642578125\n",
      "Batch: 71, Loss: 1.1197693347930908, Accuracy: 0.640625\n",
      "Batch: 72, Loss: 1.1559991836547852, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.1725322008132935, Accuracy: 0.6279296875\n",
      "Batch: 74, Loss: 1.0797488689422607, Accuracy: 0.65625\n",
      "Batch: 75, Loss: 1.1152794361114502, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.0712627172470093, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0593132972717285, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.0312188863754272, Accuracy: 0.6650390625\n",
      "Batch: 79, Loss: 1.1016448736190796, Accuracy: 0.6357421875\n",
      "Batch: 80, Loss: 1.1649450063705444, Accuracy: 0.619140625\n",
      "Batch: 81, Loss: 1.1498146057128906, Accuracy: 0.6279296875\n",
      "Batch: 82, Loss: 1.1089584827423096, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.1632475852966309, Accuracy: 0.6298828125\n",
      "Batch: 84, Loss: 1.0975337028503418, Accuracy: 0.6396484375\n",
      "Batch: 85, Loss: 1.1577342748641968, Accuracy: 0.6455078125\n",
      "Batch: 86, Loss: 1.1225306987762451, Accuracy: 0.6201171875\n",
      "Batch: 87, Loss: 1.1793584823608398, Accuracy: 0.609375\n",
      "Batch: 88, Loss: 1.156714677810669, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1082907915115356, Accuracy: 0.642578125\n",
      "Batch: 90, Loss: 1.0640206336975098, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.0959596633911133, Accuracy: 0.64453125\n",
      "Batch: 92, Loss: 1.1380261182785034, Accuracy: 0.62890625\n",
      "Batch: 93, Loss: 1.1089364290237427, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.1175191402435303, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.1360907554626465, Accuracy: 0.638671875\n",
      "Batch: 96, Loss: 1.1208431720733643, Accuracy: 0.6298828125\n",
      "Batch: 97, Loss: 1.1559228897094727, Accuracy: 0.623046875\n",
      "Batch: 98, Loss: 1.0828180313110352, Accuracy: 0.6376953125\n",
      "Batch: 99, Loss: 1.1422138214111328, Accuracy: 0.6484375\n",
      "Batch: 100, Loss: 1.0696513652801514, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.0734225511550903, Accuracy: 0.662109375\n",
      "Batch: 102, Loss: 1.0943546295166016, Accuracy: 0.630859375\n",
      "Batch: 103, Loss: 1.114089012145996, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.1058484315872192, Accuracy: 0.650390625\n",
      "Batch: 105, Loss: 1.1425611972808838, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.1464025974273682, Accuracy: 0.6240234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 1.2109131813049316, Accuracy: 0.607421875\n",
      "Batch: 108, Loss: 1.1272130012512207, Accuracy: 0.62890625\n",
      "Batch: 109, Loss: 1.1553043127059937, Accuracy: 0.6201171875\n",
      "Batch: 110, Loss: 1.1241254806518555, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.078054428100586, Accuracy: 0.6533203125\n",
      "Batch: 112, Loss: 1.007821798324585, Accuracy: 0.66796875\n",
      "Batch: 113, Loss: 1.0904685258865356, Accuracy: 0.6494140625\n",
      "Batch: 114, Loss: 1.124652624130249, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.1415213346481323, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.1339199542999268, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.1391228437423706, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 1.1756962537765503, Accuracy: 0.6064453125\n",
      "Batch: 119, Loss: 1.1824097633361816, Accuracy: 0.62109375\n",
      "Batch: 120, Loss: 1.221142292022705, Accuracy: 0.6103515625\n",
      "Batch: 121, Loss: 1.1735929250717163, Accuracy: 0.62109375\n",
      "Batch: 122, Loss: 1.1629059314727783, Accuracy: 0.62890625\n",
      "Batch: 123, Loss: 1.08998441696167, Accuracy: 0.6474609375\n",
      "Batch: 124, Loss: 1.184320092201233, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.1252468824386597, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.166919469833374, Accuracy: 0.6259765625\n",
      "Batch: 127, Loss: 1.2108746767044067, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.2037773132324219, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.1130133867263794, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.1285756826400757, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.191378116607666, Accuracy: 0.630859375\n",
      "Batch: 132, Loss: 1.0143131017684937, Accuracy: 0.6806640625\n",
      "Batch: 133, Loss: 1.1062060594558716, Accuracy: 0.638671875\n",
      "Batch: 134, Loss: 1.038169026374817, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 1.0083093643188477, Accuracy: 0.662109375\n",
      "Batch: 136, Loss: 1.0005637407302856, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 1.1131916046142578, Accuracy: 0.62890625\n",
      "Batch: 138, Loss: 1.1391042470932007, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.124824047088623, Accuracy: 0.63671875\n",
      "Batch: 140, Loss: 1.177960991859436, Accuracy: 0.634765625\n",
      "Batch: 141, Loss: 1.1397989988327026, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.1883455514907837, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.2490181922912598, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.2491450309753418, Accuracy: 0.599609375\n",
      "Batch: 145, Loss: 1.1973015069961548, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.1738890409469604, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.1993038654327393, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.171449065208435, Accuracy: 0.6083984375\n",
      "Batch: 149, Loss: 1.1699268817901611, Accuracy: 0.6123046875\n",
      "Batch: 150, Loss: 1.1179587841033936, Accuracy: 0.640625\n",
      "Batch: 151, Loss: 1.113163709640503, Accuracy: 0.630859375\n",
      "Batch: 152, Loss: 1.141721487045288, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.0393941402435303, Accuracy: 0.6591796875\n",
      "Batch: 154, Loss: 1.1076545715332031, Accuracy: 0.6533203125\n",
      "Batch: 155, Loss: 1.0609813928604126, Accuracy: 0.6484375\n",
      "Epoch 566/200\n",
      "Batch: 1, Loss: 1.18882155418396, Accuracy: 0.638671875\n",
      "Batch: 2, Loss: 1.0792495012283325, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 1.0259435176849365, Accuracy: 0.6484375\n",
      "Batch: 4, Loss: 1.0625033378601074, Accuracy: 0.6513671875\n",
      "Batch: 5, Loss: 1.0433632135391235, Accuracy: 0.6494140625\n",
      "Batch: 6, Loss: 0.9886230826377869, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.9649437665939331, Accuracy: 0.6787109375\n",
      "Batch: 8, Loss: 0.9415709972381592, Accuracy: 0.6875\n",
      "Batch: 9, Loss: 0.9812038540840149, Accuracy: 0.6806640625\n",
      "Batch: 10, Loss: 0.9433714151382446, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9806147813796997, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 0.960055947303772, Accuracy: 0.6875\n",
      "Batch: 13, Loss: 1.0248615741729736, Accuracy: 0.65625\n",
      "Batch: 14, Loss: 0.9614180326461792, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.9267200827598572, Accuracy: 0.6962890625\n",
      "Batch: 16, Loss: 0.9461846351623535, Accuracy: 0.703125\n",
      "Batch: 17, Loss: 1.038032054901123, Accuracy: 0.6552734375\n",
      "Batch: 18, Loss: 1.0607385635375977, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.121648907661438, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.0820575952529907, Accuracy: 0.64453125\n",
      "Batch: 21, Loss: 1.0705931186676025, Accuracy: 0.642578125\n",
      "Batch: 22, Loss: 1.27323579788208, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.2851834297180176, Accuracy: 0.5546875\n",
      "Batch: 24, Loss: 1.0831685066223145, Accuracy: 0.6455078125\n",
      "Batch: 25, Loss: 1.1571269035339355, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.1854288578033447, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.1133666038513184, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.0531976222991943, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.0168719291687012, Accuracy: 0.6728515625\n",
      "Batch: 30, Loss: 1.1599040031433105, Accuracy: 0.619140625\n",
      "Batch: 31, Loss: 1.114489197731018, Accuracy: 0.623046875\n",
      "Batch: 32, Loss: 1.008383870124817, Accuracy: 0.65625\n",
      "Batch: 33, Loss: 0.9698969125747681, Accuracy: 0.6728515625\n",
      "Batch: 34, Loss: 1.09966242313385, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1027803421020508, Accuracy: 0.634765625\n",
      "Batch: 36, Loss: 1.130647897720337, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.1673150062561035, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.1124372482299805, Accuracy: 0.6328125\n",
      "Batch: 39, Loss: 1.0913708209991455, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.0993013381958008, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.1174919605255127, Accuracy: 0.6337890625\n",
      "Batch: 42, Loss: 1.023617148399353, Accuracy: 0.6708984375\n",
      "Batch: 43, Loss: 0.9952437281608582, Accuracy: 0.671875\n",
      "Batch: 44, Loss: 0.9757816791534424, Accuracy: 0.6689453125\n",
      "Batch: 45, Loss: 1.0105838775634766, Accuracy: 0.6708984375\n",
      "Batch: 46, Loss: 1.1127640008926392, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.0478248596191406, Accuracy: 0.6572265625\n",
      "Batch: 48, Loss: 1.1029069423675537, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.1003694534301758, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.0271625518798828, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.152873158454895, Accuracy: 0.6259765625\n",
      "Batch: 52, Loss: 1.2163772583007812, Accuracy: 0.6171875\n",
      "Batch: 53, Loss: 1.1001091003417969, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.1565420627593994, Accuracy: 0.6328125\n",
      "Batch: 55, Loss: 1.0925989151000977, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.0576622486114502, Accuracy: 0.671875\n",
      "Batch: 57, Loss: 1.1228687763214111, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.0610064268112183, Accuracy: 0.634765625\n",
      "Batch: 59, Loss: 1.0827560424804688, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.2301995754241943, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1492395401000977, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1200823783874512, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.135333776473999, Accuracy: 0.62109375\n",
      "Batch: 64, Loss: 1.11561918258667, Accuracy: 0.6318359375\n",
      "Batch: 65, Loss: 1.1609225273132324, Accuracy: 0.6142578125\n",
      "Batch: 66, Loss: 1.1077125072479248, Accuracy: 0.64453125\n",
      "Batch: 67, Loss: 1.0845884084701538, Accuracy: 0.6435546875\n",
      "Batch: 68, Loss: 1.0707074403762817, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.1431620121002197, Accuracy: 0.61328125\n",
      "Batch: 70, Loss: 1.125195026397705, Accuracy: 0.6396484375\n",
      "Batch: 71, Loss: 1.1012572050094604, Accuracy: 0.6298828125\n",
      "Batch: 72, Loss: 1.1868679523468018, Accuracy: 0.6015625\n",
      "Batch: 73, Loss: 1.185473918914795, Accuracy: 0.6083984375\n",
      "Batch: 74, Loss: 1.073759913444519, Accuracy: 0.640625\n",
      "Batch: 75, Loss: 1.0792497396469116, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.0518043041229248, Accuracy: 0.6748046875\n",
      "Batch: 77, Loss: 1.0272817611694336, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.0417191982269287, Accuracy: 0.6552734375\n",
      "Batch: 79, Loss: 1.066530466079712, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.1558380126953125, Accuracy: 0.62890625\n",
      "Batch: 81, Loss: 1.1078989505767822, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 1.101886510848999, Accuracy: 0.634765625\n",
      "Batch: 83, Loss: 1.1474707126617432, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.0706567764282227, Accuracy: 0.6611328125\n",
      "Batch: 85, Loss: 1.1122968196868896, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.172060251235962, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.1540546417236328, Accuracy: 0.626953125\n",
      "Batch: 88, Loss: 1.1164929866790771, Accuracy: 0.6396484375\n",
      "Batch: 89, Loss: 1.1106877326965332, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.0680148601531982, Accuracy: 0.6435546875\n",
      "Batch: 91, Loss: 1.0601801872253418, Accuracy: 0.6689453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 92, Loss: 1.0726168155670166, Accuracy: 0.6669921875\n",
      "Batch: 93, Loss: 1.046722412109375, Accuracy: 0.6484375\n",
      "Batch: 94, Loss: 1.1628186702728271, Accuracy: 0.6328125\n",
      "Batch: 95, Loss: 1.1163899898529053, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.1344811916351318, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.1619951725006104, Accuracy: 0.6142578125\n",
      "Batch: 98, Loss: 1.1116571426391602, Accuracy: 0.642578125\n",
      "Batch: 99, Loss: 1.081331491470337, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.0026763677597046, Accuracy: 0.671875\n",
      "Batch: 101, Loss: 1.0238380432128906, Accuracy: 0.671875\n",
      "Batch: 102, Loss: 1.16151762008667, Accuracy: 0.6220703125\n",
      "Batch: 103, Loss: 1.1213994026184082, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.1142385005950928, Accuracy: 0.646484375\n",
      "Batch: 105, Loss: 1.1706085205078125, Accuracy: 0.6201171875\n",
      "Batch: 106, Loss: 1.1747560501098633, Accuracy: 0.6171875\n",
      "Batch: 107, Loss: 1.1650794744491577, Accuracy: 0.62109375\n",
      "Batch: 108, Loss: 1.1070942878723145, Accuracy: 0.638671875\n",
      "Batch: 109, Loss: 1.1647003889083862, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.0830390453338623, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.061058759689331, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.0831220149993896, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.1249620914459229, Accuracy: 0.62890625\n",
      "Batch: 114, Loss: 1.2058773040771484, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.1982730627059937, Accuracy: 0.5986328125\n",
      "Batch: 116, Loss: 1.1418025493621826, Accuracy: 0.6376953125\n",
      "Batch: 117, Loss: 1.1308519840240479, Accuracy: 0.62890625\n",
      "Batch: 118, Loss: 1.1511955261230469, Accuracy: 0.626953125\n",
      "Batch: 119, Loss: 1.1916272640228271, Accuracy: 0.630859375\n",
      "Batch: 120, Loss: 1.2480113506317139, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.190943956375122, Accuracy: 0.626953125\n",
      "Batch: 122, Loss: 1.22236967086792, Accuracy: 0.6044921875\n",
      "Batch: 123, Loss: 1.1259479522705078, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.15980863571167, Accuracy: 0.6357421875\n",
      "Batch: 125, Loss: 1.1728718280792236, Accuracy: 0.63671875\n",
      "Batch: 126, Loss: 1.1869652271270752, Accuracy: 0.64453125\n",
      "Batch: 127, Loss: 1.173223853111267, Accuracy: 0.6220703125\n",
      "Batch: 128, Loss: 1.182725429534912, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.2293916940689087, Accuracy: 0.599609375\n",
      "Batch: 130, Loss: 1.0830504894256592, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 1.1917937994003296, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 1.0371168851852417, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.13823401927948, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.0885556936264038, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 0.9906949400901794, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.115229606628418, Accuracy: 0.6435546875\n",
      "Batch: 137, Loss: 1.1755326986312866, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 1.1851780414581299, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1744070053100586, Accuracy: 0.6259765625\n",
      "Batch: 140, Loss: 1.1568925380706787, Accuracy: 0.6357421875\n",
      "Batch: 141, Loss: 1.1540591716766357, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.1107664108276367, Accuracy: 0.650390625\n",
      "Batch: 143, Loss: 1.1943378448486328, Accuracy: 0.6123046875\n",
      "Batch: 144, Loss: 1.2361756563186646, Accuracy: 0.5966796875\n",
      "Batch: 145, Loss: 1.209650993347168, Accuracy: 0.6083984375\n",
      "Batch: 146, Loss: 1.1290218830108643, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.2016712427139282, Accuracy: 0.595703125\n",
      "Batch: 148, Loss: 1.1729624271392822, Accuracy: 0.62109375\n",
      "Batch: 149, Loss: 1.1529979705810547, Accuracy: 0.630859375\n",
      "Batch: 150, Loss: 1.1334421634674072, Accuracy: 0.6298828125\n",
      "Batch: 151, Loss: 1.1209759712219238, Accuracy: 0.6328125\n",
      "Batch: 152, Loss: 1.0885767936706543, Accuracy: 0.6337890625\n",
      "Batch: 153, Loss: 1.0789469480514526, Accuracy: 0.6552734375\n",
      "Batch: 154, Loss: 1.0852593183517456, Accuracy: 0.65234375\n",
      "Batch: 155, Loss: 1.0577521324157715, Accuracy: 0.6552734375\n",
      "Epoch 567/200\n",
      "Batch: 1, Loss: 1.1805869340896606, Accuracy: 0.658203125\n",
      "Batch: 2, Loss: 1.1053694486618042, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 0.9847607016563416, Accuracy: 0.6796875\n",
      "Batch: 4, Loss: 0.9925057888031006, Accuracy: 0.6845703125\n",
      "Batch: 5, Loss: 0.9701873660087585, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.033990502357483, Accuracy: 0.6484375\n",
      "Batch: 7, Loss: 1.0477505922317505, Accuracy: 0.6572265625\n",
      "Batch: 8, Loss: 0.9692693948745728, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 0.9921590685844421, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 0.9706336259841919, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 0.9467408657073975, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 0.98936927318573, Accuracy: 0.6689453125\n",
      "Batch: 13, Loss: 0.9745057821273804, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 0.9689570665359497, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.9283151626586914, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.00311279296875, Accuracy: 0.685546875\n",
      "Batch: 17, Loss: 1.0690550804138184, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.0924057960510254, Accuracy: 0.6513671875\n",
      "Batch: 19, Loss: 1.1510660648345947, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0759446620941162, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.087033748626709, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.225630283355713, Accuracy: 0.6240234375\n",
      "Batch: 23, Loss: 1.2241663932800293, Accuracy: 0.6103515625\n",
      "Batch: 24, Loss: 1.145226001739502, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.1207059621810913, Accuracy: 0.6220703125\n",
      "Batch: 26, Loss: 1.1347718238830566, Accuracy: 0.6435546875\n",
      "Batch: 27, Loss: 1.1061818599700928, Accuracy: 0.6376953125\n",
      "Batch: 28, Loss: 1.069868803024292, Accuracy: 0.646484375\n",
      "Batch: 29, Loss: 1.033599615097046, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 1.1544721126556396, Accuracy: 0.623046875\n",
      "Batch: 31, Loss: 1.185257077217102, Accuracy: 0.6064453125\n",
      "Batch: 32, Loss: 1.0439702272415161, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 0.9599075317382812, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.0498392581939697, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 1.1041572093963623, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.147587537765503, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.2104883193969727, Accuracy: 0.603515625\n",
      "Batch: 38, Loss: 1.12418532371521, Accuracy: 0.6123046875\n",
      "Batch: 39, Loss: 1.0725973844528198, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.118499517440796, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.0886292457580566, Accuracy: 0.642578125\n",
      "Batch: 42, Loss: 1.0194435119628906, Accuracy: 0.6669921875\n",
      "Batch: 43, Loss: 1.0024648904800415, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.0173218250274658, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0251253843307495, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.1112754344940186, Accuracy: 0.6328125\n",
      "Batch: 47, Loss: 1.0841041803359985, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.0808427333831787, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.1202473640441895, Accuracy: 0.640625\n",
      "Batch: 50, Loss: 1.1043580770492554, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.120579719543457, Accuracy: 0.64453125\n",
      "Batch: 52, Loss: 1.2303073406219482, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1367814540863037, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.1019084453582764, Accuracy: 0.6298828125\n",
      "Batch: 55, Loss: 1.0655912160873413, Accuracy: 0.65625\n",
      "Batch: 56, Loss: 1.0770212411880493, Accuracy: 0.6630859375\n",
      "Batch: 57, Loss: 1.0364248752593994, Accuracy: 0.673828125\n",
      "Batch: 58, Loss: 1.0705851316452026, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 1.0922715663909912, Accuracy: 0.6328125\n",
      "Batch: 60, Loss: 1.1718705892562866, Accuracy: 0.623046875\n",
      "Batch: 61, Loss: 1.1763625144958496, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.1035070419311523, Accuracy: 0.6181640625\n",
      "Batch: 63, Loss: 1.1285405158996582, Accuracy: 0.62890625\n",
      "Batch: 64, Loss: 1.1887128353118896, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.166960597038269, Accuracy: 0.6220703125\n",
      "Batch: 66, Loss: 1.1039412021636963, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.1305973529815674, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.0786653757095337, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 1.1385669708251953, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.1545283794403076, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.0788136720657349, Accuracy: 0.66015625\n",
      "Batch: 72, Loss: 1.2039176225662231, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.1553640365600586, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.127437949180603, Accuracy: 0.646484375\n",
      "Batch: 75, Loss: 1.0475552082061768, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.0816694498062134, Accuracy: 0.6474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 0.9856878519058228, Accuracy: 0.67578125\n",
      "Batch: 78, Loss: 1.0500630140304565, Accuracy: 0.6279296875\n",
      "Batch: 79, Loss: 1.055351972579956, Accuracy: 0.64453125\n",
      "Batch: 80, Loss: 1.1586687564849854, Accuracy: 0.640625\n",
      "Batch: 81, Loss: 1.0885814428329468, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 1.115365743637085, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.1528717279434204, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.066887617111206, Accuracy: 0.6357421875\n",
      "Batch: 85, Loss: 1.0716739892959595, Accuracy: 0.6591796875\n",
      "Batch: 86, Loss: 1.1039707660675049, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1362440586090088, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.1486759185791016, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.0798258781433105, Accuracy: 0.6328125\n",
      "Batch: 90, Loss: 1.0317742824554443, Accuracy: 0.6748046875\n",
      "Batch: 91, Loss: 1.081737995147705, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.10750150680542, Accuracy: 0.6484375\n",
      "Batch: 93, Loss: 1.1064410209655762, Accuracy: 0.6416015625\n",
      "Batch: 94, Loss: 1.198908805847168, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.1109988689422607, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.1213370561599731, Accuracy: 0.662109375\n",
      "Batch: 97, Loss: 1.1405386924743652, Accuracy: 0.6240234375\n",
      "Batch: 98, Loss: 1.0621285438537598, Accuracy: 0.6455078125\n",
      "Batch: 99, Loss: 1.1241344213485718, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.025972843170166, Accuracy: 0.6591796875\n",
      "Batch: 101, Loss: 1.0464959144592285, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.1331517696380615, Accuracy: 0.6298828125\n",
      "Batch: 103, Loss: 1.1961841583251953, Accuracy: 0.611328125\n",
      "Batch: 104, Loss: 1.1194753646850586, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.155646800994873, Accuracy: 0.6318359375\n",
      "Batch: 106, Loss: 1.139404296875, Accuracy: 0.6455078125\n",
      "Batch: 107, Loss: 1.1705102920532227, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.1523594856262207, Accuracy: 0.603515625\n",
      "Batch: 109, Loss: 1.1732780933380127, Accuracy: 0.6201171875\n",
      "Batch: 110, Loss: 1.0790839195251465, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.1687343120574951, Accuracy: 0.611328125\n",
      "Batch: 112, Loss: 1.0475010871887207, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1544535160064697, Accuracy: 0.6337890625\n",
      "Batch: 114, Loss: 1.1665095090866089, Accuracy: 0.6025390625\n",
      "Batch: 115, Loss: 1.1224305629730225, Accuracy: 0.6298828125\n",
      "Batch: 116, Loss: 1.159078598022461, Accuracy: 0.6162109375\n",
      "Batch: 117, Loss: 1.1826919317245483, Accuracy: 0.6201171875\n",
      "Batch: 118, Loss: 1.123936414718628, Accuracy: 0.62890625\n",
      "Batch: 119, Loss: 1.211787223815918, Accuracy: 0.619140625\n",
      "Batch: 120, Loss: 1.2534534931182861, Accuracy: 0.5986328125\n",
      "Batch: 121, Loss: 1.1450947523117065, Accuracy: 0.6298828125\n",
      "Batch: 122, Loss: 1.1541481018066406, Accuracy: 0.6201171875\n",
      "Batch: 123, Loss: 1.1684303283691406, Accuracy: 0.6416015625\n",
      "Batch: 124, Loss: 1.2187371253967285, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.1528823375701904, Accuracy: 0.62109375\n",
      "Batch: 126, Loss: 1.2148419618606567, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.2095189094543457, Accuracy: 0.615234375\n",
      "Batch: 128, Loss: 1.1950438022613525, Accuracy: 0.6142578125\n",
      "Batch: 129, Loss: 1.127267599105835, Accuracy: 0.634765625\n",
      "Batch: 130, Loss: 1.140215516090393, Accuracy: 0.638671875\n",
      "Batch: 131, Loss: 1.1466972827911377, Accuracy: 0.623046875\n",
      "Batch: 132, Loss: 1.0321359634399414, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 1.106510043144226, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.0530149936676025, Accuracy: 0.6689453125\n",
      "Batch: 135, Loss: 0.9761624932289124, Accuracy: 0.6689453125\n",
      "Batch: 136, Loss: 1.060655951499939, Accuracy: 0.671875\n",
      "Batch: 137, Loss: 1.1018612384796143, Accuracy: 0.6630859375\n",
      "Batch: 138, Loss: 1.2014358043670654, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.1570202112197876, Accuracy: 0.62890625\n",
      "Batch: 140, Loss: 1.1921788454055786, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.1051833629608154, Accuracy: 0.65625\n",
      "Batch: 142, Loss: 1.133644938468933, Accuracy: 0.6259765625\n",
      "Batch: 143, Loss: 1.1444411277770996, Accuracy: 0.625\n",
      "Batch: 144, Loss: 1.190865159034729, Accuracy: 0.615234375\n",
      "Batch: 145, Loss: 1.2144547700881958, Accuracy: 0.6259765625\n",
      "Batch: 146, Loss: 1.188821792602539, Accuracy: 0.6259765625\n",
      "Batch: 147, Loss: 1.153075933456421, Accuracy: 0.607421875\n",
      "Batch: 148, Loss: 1.1880061626434326, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.0671977996826172, Accuracy: 0.64453125\n",
      "Batch: 150, Loss: 1.1522644758224487, Accuracy: 0.6357421875\n",
      "Batch: 151, Loss: 1.079338550567627, Accuracy: 0.669921875\n",
      "Batch: 152, Loss: 1.1040517091751099, Accuracy: 0.6357421875\n",
      "Batch: 153, Loss: 1.0959539413452148, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.1258478164672852, Accuracy: 0.619140625\n",
      "Batch: 155, Loss: 1.0430103540420532, Accuracy: 0.669921875\n",
      "Epoch 568/200\n",
      "Batch: 1, Loss: 1.17110013961792, Accuracy: 0.65234375\n",
      "Batch: 2, Loss: 1.021108627319336, Accuracy: 0.677734375\n",
      "Batch: 3, Loss: 1.0282180309295654, Accuracy: 0.650390625\n",
      "Batch: 4, Loss: 0.9972870945930481, Accuracy: 0.6689453125\n",
      "Batch: 5, Loss: 1.0037163496017456, Accuracy: 0.666015625\n",
      "Batch: 6, Loss: 0.9953200817108154, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 0.9942243695259094, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 0.9933137893676758, Accuracy: 0.6748046875\n",
      "Batch: 9, Loss: 0.9949656128883362, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9875684380531311, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 0.9162333011627197, Accuracy: 0.703125\n",
      "Batch: 12, Loss: 1.0042455196380615, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 1.0089216232299805, Accuracy: 0.677734375\n",
      "Batch: 14, Loss: 0.8947203159332275, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.9639374017715454, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 0.9852152466773987, Accuracy: 0.673828125\n",
      "Batch: 17, Loss: 1.0134934186935425, Accuracy: 0.6611328125\n",
      "Batch: 18, Loss: 1.0535300970077515, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.1077027320861816, Accuracy: 0.6357421875\n",
      "Batch: 20, Loss: 1.087181568145752, Accuracy: 0.6611328125\n",
      "Batch: 21, Loss: 1.072310209274292, Accuracy: 0.65234375\n",
      "Batch: 22, Loss: 1.1979618072509766, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2353103160858154, Accuracy: 0.6005859375\n",
      "Batch: 24, Loss: 1.093672275543213, Accuracy: 0.6640625\n",
      "Batch: 25, Loss: 1.100239634513855, Accuracy: 0.6435546875\n",
      "Batch: 26, Loss: 1.1796858310699463, Accuracy: 0.60546875\n",
      "Batch: 27, Loss: 1.1210514307022095, Accuracy: 0.6240234375\n",
      "Batch: 28, Loss: 1.0340242385864258, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.0241589546203613, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.117915391921997, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.164534330368042, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.0017157793045044, Accuracy: 0.6396484375\n",
      "Batch: 33, Loss: 1.0206902027130127, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.0482451915740967, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 1.125819206237793, Accuracy: 0.6181640625\n",
      "Batch: 36, Loss: 1.166568398475647, Accuracy: 0.5859375\n",
      "Batch: 37, Loss: 1.1462759971618652, Accuracy: 0.6259765625\n",
      "Batch: 38, Loss: 1.1435215473175049, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.045238733291626, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.0783805847167969, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.093484878540039, Accuracy: 0.6396484375\n",
      "Batch: 42, Loss: 1.0538746118545532, Accuracy: 0.6669921875\n",
      "Batch: 43, Loss: 1.0207442045211792, Accuracy: 0.6552734375\n",
      "Batch: 44, Loss: 1.0225359201431274, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0050995349884033, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.1173943281173706, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.0339504480361938, Accuracy: 0.6650390625\n",
      "Batch: 48, Loss: 1.055409550666809, Accuracy: 0.650390625\n",
      "Batch: 49, Loss: 1.1040375232696533, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.0655694007873535, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.1658198833465576, Accuracy: 0.603515625\n",
      "Batch: 52, Loss: 1.198020339012146, Accuracy: 0.62109375\n",
      "Batch: 53, Loss: 1.127419352531433, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.14253568649292, Accuracy: 0.6376953125\n",
      "Batch: 55, Loss: 1.1492469310760498, Accuracy: 0.62890625\n",
      "Batch: 56, Loss: 1.126227855682373, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.0702197551727295, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.1041909456253052, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 1.0506293773651123, Accuracy: 0.642578125\n",
      "Batch: 60, Loss: 1.1640121936798096, Accuracy: 0.6337890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 61, Loss: 1.1433939933776855, Accuracy: 0.6162109375\n",
      "Batch: 62, Loss: 1.0525119304656982, Accuracy: 0.6591796875\n",
      "Batch: 63, Loss: 1.2090132236480713, Accuracy: 0.6005859375\n",
      "Batch: 64, Loss: 1.1939382553100586, Accuracy: 0.6083984375\n",
      "Batch: 65, Loss: 1.0980868339538574, Accuracy: 0.64453125\n",
      "Batch: 66, Loss: 1.1151838302612305, Accuracy: 0.66015625\n",
      "Batch: 67, Loss: 1.1103299856185913, Accuracy: 0.6357421875\n",
      "Batch: 68, Loss: 1.0948882102966309, Accuracy: 0.6611328125\n",
      "Batch: 69, Loss: 1.1333339214324951, Accuracy: 0.63671875\n",
      "Batch: 70, Loss: 1.1619963645935059, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.0841915607452393, Accuracy: 0.6474609375\n",
      "Batch: 72, Loss: 1.1434564590454102, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.1345407962799072, Accuracy: 0.6181640625\n",
      "Batch: 74, Loss: 1.1412699222564697, Accuracy: 0.6220703125\n",
      "Batch: 75, Loss: 1.0564534664154053, Accuracy: 0.650390625\n",
      "Batch: 76, Loss: 1.0536646842956543, Accuracy: 0.6572265625\n",
      "Batch: 77, Loss: 0.9907922744750977, Accuracy: 0.6728515625\n",
      "Batch: 78, Loss: 1.020794153213501, Accuracy: 0.65625\n",
      "Batch: 79, Loss: 1.1208412647247314, Accuracy: 0.6298828125\n",
      "Batch: 80, Loss: 1.1620879173278809, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.110148310661316, Accuracy: 0.63671875\n",
      "Batch: 82, Loss: 1.0807527303695679, Accuracy: 0.6513671875\n",
      "Batch: 83, Loss: 1.0950112342834473, Accuracy: 0.64453125\n",
      "Batch: 84, Loss: 1.0741113424301147, Accuracy: 0.6455078125\n",
      "Batch: 85, Loss: 1.133775234222412, Accuracy: 0.6416015625\n",
      "Batch: 86, Loss: 1.1338307857513428, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1306861639022827, Accuracy: 0.63671875\n",
      "Batch: 88, Loss: 1.114008903503418, Accuracy: 0.650390625\n",
      "Batch: 89, Loss: 1.122921109199524, Accuracy: 0.6435546875\n",
      "Batch: 90, Loss: 1.0709969997406006, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.1553250551223755, Accuracy: 0.62109375\n",
      "Batch: 92, Loss: 1.1269474029541016, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.0791373252868652, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.1453815698623657, Accuracy: 0.6533203125\n",
      "Batch: 95, Loss: 1.1215269565582275, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.1353776454925537, Accuracy: 0.65234375\n",
      "Batch: 97, Loss: 1.1417620182037354, Accuracy: 0.60546875\n",
      "Batch: 98, Loss: 1.052621841430664, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.0978111028671265, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.0277817249298096, Accuracy: 0.6650390625\n",
      "Batch: 101, Loss: 1.1307131052017212, Accuracy: 0.654296875\n",
      "Batch: 102, Loss: 1.1068451404571533, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.1304497718811035, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.0888803005218506, Accuracy: 0.6650390625\n",
      "Batch: 105, Loss: 1.1564993858337402, Accuracy: 0.6376953125\n",
      "Batch: 106, Loss: 1.1789190769195557, Accuracy: 0.6044921875\n",
      "Batch: 107, Loss: 1.2013274431228638, Accuracy: 0.615234375\n",
      "Batch: 108, Loss: 1.1263234615325928, Accuracy: 0.6357421875\n",
      "Batch: 109, Loss: 1.1689629554748535, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 1.0708091259002686, Accuracy: 0.6474609375\n",
      "Batch: 111, Loss: 1.091567039489746, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.0448148250579834, Accuracy: 0.66796875\n",
      "Batch: 113, Loss: 1.164130687713623, Accuracy: 0.640625\n",
      "Batch: 114, Loss: 1.0722240209579468, Accuracy: 0.63671875\n",
      "Batch: 115, Loss: 1.1298341751098633, Accuracy: 0.6396484375\n",
      "Batch: 116, Loss: 1.1603796482086182, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.122382640838623, Accuracy: 0.6259765625\n",
      "Batch: 118, Loss: 1.1372883319854736, Accuracy: 0.642578125\n",
      "Batch: 119, Loss: 1.17814302444458, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.2709956169128418, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.1624937057495117, Accuracy: 0.619140625\n",
      "Batch: 122, Loss: 1.194589614868164, Accuracy: 0.61328125\n",
      "Batch: 123, Loss: 1.1147527694702148, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.1796660423278809, Accuracy: 0.6357421875\n",
      "Batch: 125, Loss: 1.120262622833252, Accuracy: 0.62890625\n",
      "Batch: 126, Loss: 1.1561437845230103, Accuracy: 0.6455078125\n",
      "Batch: 127, Loss: 1.2135279178619385, Accuracy: 0.603515625\n",
      "Batch: 128, Loss: 1.1812777519226074, Accuracy: 0.6279296875\n",
      "Batch: 129, Loss: 1.1388598680496216, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.084104061126709, Accuracy: 0.6494140625\n",
      "Batch: 131, Loss: 1.1721556186676025, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.0538480281829834, Accuracy: 0.640625\n",
      "Batch: 133, Loss: 1.0916879177093506, Accuracy: 0.66015625\n",
      "Batch: 134, Loss: 1.1190632581710815, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.0373046398162842, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.0530816316604614, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.0743860006332397, Accuracy: 0.6494140625\n",
      "Batch: 138, Loss: 1.1693050861358643, Accuracy: 0.6044921875\n",
      "Batch: 139, Loss: 1.160218358039856, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.2022669315338135, Accuracy: 0.6240234375\n",
      "Batch: 141, Loss: 1.0508216619491577, Accuracy: 0.6484375\n",
      "Batch: 142, Loss: 1.1664555072784424, Accuracy: 0.603515625\n",
      "Batch: 143, Loss: 1.189802885055542, Accuracy: 0.6162109375\n",
      "Batch: 144, Loss: 1.2497360706329346, Accuracy: 0.58984375\n",
      "Batch: 145, Loss: 1.2198803424835205, Accuracy: 0.6240234375\n",
      "Batch: 146, Loss: 1.1990662813186646, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.1506459712982178, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.179874300956726, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.157111406326294, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.0803959369659424, Accuracy: 0.62890625\n",
      "Batch: 151, Loss: 1.1255006790161133, Accuracy: 0.6396484375\n",
      "Batch: 152, Loss: 1.132594347000122, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.1234910488128662, Accuracy: 0.634765625\n",
      "Batch: 154, Loss: 1.1081931591033936, Accuracy: 0.6357421875\n",
      "Batch: 155, Loss: 1.0510542392730713, Accuracy: 0.6591796875\n",
      "Epoch 569/200\n",
      "Batch: 1, Loss: 1.1880708932876587, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 1.0351803302764893, Accuracy: 0.6533203125\n",
      "Batch: 3, Loss: 0.9763321876525879, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 1.0886626243591309, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0248512029647827, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.0289690494537354, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 1.0055197477340698, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 0.9364603757858276, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 0.9823468923568726, Accuracy: 0.677734375\n",
      "Batch: 10, Loss: 1.0033855438232422, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9172793626785278, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.9746095538139343, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 0.9802460670471191, Accuracy: 0.6728515625\n",
      "Batch: 14, Loss: 0.9632433652877808, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.9405069947242737, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 0.9702054262161255, Accuracy: 0.703125\n",
      "Batch: 17, Loss: 1.009719729423523, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.0962803363800049, Accuracy: 0.6328125\n",
      "Batch: 19, Loss: 1.2064182758331299, Accuracy: 0.6396484375\n",
      "Batch: 20, Loss: 0.9971848130226135, Accuracy: 0.6884765625\n",
      "Batch: 21, Loss: 1.0263102054595947, Accuracy: 0.658203125\n",
      "Batch: 22, Loss: 1.218947172164917, Accuracy: 0.619140625\n",
      "Batch: 23, Loss: 1.237141728401184, Accuracy: 0.5927734375\n",
      "Batch: 24, Loss: 1.1115062236785889, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.0900142192840576, Accuracy: 0.6455078125\n",
      "Batch: 26, Loss: 1.0967210531234741, Accuracy: 0.6376953125\n",
      "Batch: 27, Loss: 1.1236166954040527, Accuracy: 0.6328125\n",
      "Batch: 28, Loss: 1.0385730266571045, Accuracy: 0.64453125\n",
      "Batch: 29, Loss: 1.0203971862792969, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1776022911071777, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.1969486474990845, Accuracy: 0.62109375\n",
      "Batch: 32, Loss: 1.0046954154968262, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 1.0244046449661255, Accuracy: 0.67578125\n",
      "Batch: 34, Loss: 1.1053447723388672, Accuracy: 0.6396484375\n",
      "Batch: 35, Loss: 1.1065096855163574, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.1605308055877686, Accuracy: 0.625\n",
      "Batch: 37, Loss: 1.1369969844818115, Accuracy: 0.626953125\n",
      "Batch: 38, Loss: 1.1487395763397217, Accuracy: 0.626953125\n",
      "Batch: 39, Loss: 1.029512643814087, Accuracy: 0.671875\n",
      "Batch: 40, Loss: 1.0313831567764282, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.1123833656311035, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.063422679901123, Accuracy: 0.642578125\n",
      "Batch: 43, Loss: 1.0428466796875, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 1.0559760332107544, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 0.9848113059997559, Accuracy: 0.654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 1.0643867254257202, Accuracy: 0.6640625\n",
      "Batch: 47, Loss: 1.111520528793335, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.0386101007461548, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.1462788581848145, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.0904288291931152, Accuracy: 0.662109375\n",
      "Batch: 51, Loss: 1.111971139907837, Accuracy: 0.6259765625\n",
      "Batch: 52, Loss: 1.1837007999420166, Accuracy: 0.6025390625\n",
      "Batch: 53, Loss: 1.1460946798324585, Accuracy: 0.615234375\n",
      "Batch: 54, Loss: 1.1512115001678467, Accuracy: 0.6259765625\n",
      "Batch: 55, Loss: 1.068002462387085, Accuracy: 0.66015625\n",
      "Batch: 56, Loss: 1.0480594635009766, Accuracy: 0.6630859375\n",
      "Batch: 57, Loss: 1.058995246887207, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.1151301860809326, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.0492351055145264, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.1750297546386719, Accuracy: 0.6328125\n",
      "Batch: 61, Loss: 1.1114387512207031, Accuracy: 0.63671875\n",
      "Batch: 62, Loss: 1.0895216464996338, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.1405363082885742, Accuracy: 0.6474609375\n",
      "Batch: 64, Loss: 1.1828911304473877, Accuracy: 0.607421875\n",
      "Batch: 65, Loss: 1.1596859693527222, Accuracy: 0.640625\n",
      "Batch: 66, Loss: 1.0892747640609741, Accuracy: 0.6572265625\n",
      "Batch: 67, Loss: 1.1729459762573242, Accuracy: 0.6123046875\n",
      "Batch: 68, Loss: 1.0872689485549927, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1754488945007324, Accuracy: 0.6337890625\n",
      "Batch: 70, Loss: 1.1441445350646973, Accuracy: 0.6435546875\n",
      "Batch: 71, Loss: 1.1190075874328613, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.1837263107299805, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.1102213859558105, Accuracy: 0.6513671875\n",
      "Batch: 74, Loss: 1.0736687183380127, Accuracy: 0.6376953125\n",
      "Batch: 75, Loss: 1.0674846172332764, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.1277761459350586, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.0189383029937744, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 1.0854542255401611, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.0728719234466553, Accuracy: 0.6533203125\n",
      "Batch: 80, Loss: 1.0990508794784546, Accuracy: 0.634765625\n",
      "Batch: 81, Loss: 1.0669639110565186, Accuracy: 0.6650390625\n",
      "Batch: 82, Loss: 1.0589344501495361, Accuracy: 0.65625\n",
      "Batch: 83, Loss: 1.1375935077667236, Accuracy: 0.638671875\n",
      "Batch: 84, Loss: 1.1055712699890137, Accuracy: 0.65234375\n",
      "Batch: 85, Loss: 1.1267162561416626, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.131752848625183, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.0772817134857178, Accuracy: 0.642578125\n",
      "Batch: 88, Loss: 1.135087013244629, Accuracy: 0.625\n",
      "Batch: 89, Loss: 1.131953477859497, Accuracy: 0.6513671875\n",
      "Batch: 90, Loss: 1.0581376552581787, Accuracy: 0.650390625\n",
      "Batch: 91, Loss: 1.0975587368011475, Accuracy: 0.6533203125\n",
      "Batch: 92, Loss: 1.1786160469055176, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.1264570951461792, Accuracy: 0.640625\n",
      "Batch: 94, Loss: 1.1279352903366089, Accuracy: 0.638671875\n",
      "Batch: 95, Loss: 1.1257082223892212, Accuracy: 0.6328125\n",
      "Batch: 96, Loss: 1.1394776105880737, Accuracy: 0.6376953125\n",
      "Batch: 97, Loss: 1.0583109855651855, Accuracy: 0.6474609375\n",
      "Batch: 98, Loss: 1.1345956325531006, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.0942332744598389, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 1.0204919576644897, Accuracy: 0.6669921875\n",
      "Batch: 101, Loss: 1.0833213329315186, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1472728252410889, Accuracy: 0.6162109375\n",
      "Batch: 103, Loss: 1.1533417701721191, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.0274322032928467, Accuracy: 0.6572265625\n",
      "Batch: 105, Loss: 1.1274735927581787, Accuracy: 0.638671875\n",
      "Batch: 106, Loss: 1.1130948066711426, Accuracy: 0.640625\n",
      "Batch: 107, Loss: 1.1870741844177246, Accuracy: 0.6162109375\n",
      "Batch: 108, Loss: 1.0793176889419556, Accuracy: 0.6376953125\n",
      "Batch: 109, Loss: 1.2077687978744507, Accuracy: 0.591796875\n",
      "Batch: 110, Loss: 1.165738582611084, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.1042070388793945, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0271658897399902, Accuracy: 0.669921875\n",
      "Batch: 113, Loss: 1.1028062105178833, Accuracy: 0.638671875\n",
      "Batch: 114, Loss: 1.0881458520889282, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.138821005821228, Accuracy: 0.615234375\n",
      "Batch: 116, Loss: 1.12900972366333, Accuracy: 0.634765625\n",
      "Batch: 117, Loss: 1.0967497825622559, Accuracy: 0.63671875\n",
      "Batch: 118, Loss: 1.1472585201263428, Accuracy: 0.6201171875\n",
      "Batch: 119, Loss: 1.2450544834136963, Accuracy: 0.6083984375\n",
      "Batch: 120, Loss: 1.216737985610962, Accuracy: 0.619140625\n",
      "Batch: 121, Loss: 1.1994385719299316, Accuracy: 0.60546875\n",
      "Batch: 122, Loss: 1.1923243999481201, Accuracy: 0.6083984375\n",
      "Batch: 123, Loss: 1.1539969444274902, Accuracy: 0.6279296875\n",
      "Batch: 124, Loss: 1.1683173179626465, Accuracy: 0.626953125\n",
      "Batch: 125, Loss: 1.1070235967636108, Accuracy: 0.6455078125\n",
      "Batch: 126, Loss: 1.2272040843963623, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.1856439113616943, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.1506736278533936, Accuracy: 0.640625\n",
      "Batch: 129, Loss: 1.1202399730682373, Accuracy: 0.6357421875\n",
      "Batch: 130, Loss: 1.129443883895874, Accuracy: 0.64453125\n",
      "Batch: 131, Loss: 1.148921251296997, Accuracy: 0.603515625\n",
      "Batch: 132, Loss: 0.979952335357666, Accuracy: 0.6904296875\n",
      "Batch: 133, Loss: 1.1979366540908813, Accuracy: 0.611328125\n",
      "Batch: 134, Loss: 1.104101300239563, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.024957299232483, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.0618197917938232, Accuracy: 0.658203125\n",
      "Batch: 137, Loss: 1.150565266609192, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.2422645092010498, Accuracy: 0.5869140625\n",
      "Batch: 139, Loss: 1.2431340217590332, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.227163314819336, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.1404962539672852, Accuracy: 0.62109375\n",
      "Batch: 142, Loss: 1.1491698026657104, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.151266098022461, Accuracy: 0.634765625\n",
      "Batch: 144, Loss: 1.2315411567687988, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.1942198276519775, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.126885175704956, Accuracy: 0.6357421875\n",
      "Batch: 147, Loss: 1.1672346591949463, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.1293011903762817, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.2010129690170288, Accuracy: 0.591796875\n",
      "Batch: 150, Loss: 1.026764988899231, Accuracy: 0.6630859375\n",
      "Batch: 151, Loss: 1.1442670822143555, Accuracy: 0.62890625\n",
      "Batch: 152, Loss: 1.1774406433105469, Accuracy: 0.60546875\n",
      "Batch: 153, Loss: 1.088279128074646, Accuracy: 0.6435546875\n",
      "Batch: 154, Loss: 1.1037222146987915, Accuracy: 0.65234375\n",
      "Batch: 155, Loss: 1.068556308746338, Accuracy: 0.6533203125\n",
      "Epoch 570/200\n",
      "Batch: 1, Loss: 1.1562774181365967, Accuracy: 0.658203125\n",
      "Batch: 2, Loss: 1.0927793979644775, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0194398164749146, Accuracy: 0.65625\n",
      "Batch: 4, Loss: 1.0544397830963135, Accuracy: 0.65625\n",
      "Batch: 5, Loss: 1.0463709831237793, Accuracy: 0.6533203125\n",
      "Batch: 6, Loss: 1.0291001796722412, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 0.9894132018089294, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 1.0088472366333008, Accuracy: 0.6875\n",
      "Batch: 9, Loss: 1.0288225412368774, Accuracy: 0.6767578125\n",
      "Batch: 10, Loss: 0.9691305160522461, Accuracy: 0.6708984375\n",
      "Batch: 11, Loss: 0.9226987361907959, Accuracy: 0.703125\n",
      "Batch: 12, Loss: 1.0073717832565308, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 1.0290725231170654, Accuracy: 0.6728515625\n",
      "Batch: 14, Loss: 0.9632204174995422, Accuracy: 0.6943359375\n",
      "Batch: 15, Loss: 0.9198369979858398, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 1.0682735443115234, Accuracy: 0.6513671875\n",
      "Batch: 17, Loss: 1.0435123443603516, Accuracy: 0.6318359375\n",
      "Batch: 18, Loss: 1.0803159475326538, Accuracy: 0.6416015625\n",
      "Batch: 19, Loss: 1.1680656671524048, Accuracy: 0.6162109375\n",
      "Batch: 20, Loss: 1.0851500034332275, Accuracy: 0.654296875\n",
      "Batch: 21, Loss: 1.009185791015625, Accuracy: 0.669921875\n",
      "Batch: 22, Loss: 1.206573247909546, Accuracy: 0.6220703125\n",
      "Batch: 23, Loss: 1.184340238571167, Accuracy: 0.6201171875\n",
      "Batch: 24, Loss: 1.0988688468933105, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1949368715286255, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1667051315307617, Accuracy: 0.5986328125\n",
      "Batch: 27, Loss: 1.128470540046692, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.0367993116378784, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.033306360244751, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.1357691287994385, Accuracy: 0.634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31, Loss: 1.1762009859085083, Accuracy: 0.623046875\n",
      "Batch: 32, Loss: 1.0611624717712402, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.0089582204818726, Accuracy: 0.66015625\n",
      "Batch: 34, Loss: 1.0835316181182861, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.1082582473754883, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.178985357284546, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1868256330490112, Accuracy: 0.6318359375\n",
      "Batch: 38, Loss: 1.1920325756072998, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.0783615112304688, Accuracy: 0.6640625\n",
      "Batch: 40, Loss: 1.105769157409668, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.0046782493591309, Accuracy: 0.6611328125\n",
      "Batch: 42, Loss: 1.058158278465271, Accuracy: 0.6474609375\n",
      "Batch: 43, Loss: 1.1201046705245972, Accuracy: 0.6328125\n",
      "Batch: 44, Loss: 1.018813133239746, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.0610172748565674, Accuracy: 0.634765625\n",
      "Batch: 46, Loss: 1.093159794807434, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.0389491319656372, Accuracy: 0.662109375\n",
      "Batch: 48, Loss: 1.0852251052856445, Accuracy: 0.6416015625\n",
      "Batch: 49, Loss: 1.0988863706588745, Accuracy: 0.6494140625\n",
      "Batch: 50, Loss: 1.12993586063385, Accuracy: 0.6318359375\n",
      "Batch: 51, Loss: 1.0994727611541748, Accuracy: 0.6357421875\n",
      "Batch: 52, Loss: 1.2141749858856201, Accuracy: 0.619140625\n",
      "Batch: 53, Loss: 1.087785243988037, Accuracy: 0.654296875\n",
      "Batch: 54, Loss: 1.1870920658111572, Accuracy: 0.603515625\n",
      "Batch: 55, Loss: 1.0816195011138916, Accuracy: 0.6416015625\n",
      "Batch: 56, Loss: 1.072119116783142, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.0479799509048462, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.1003124713897705, Accuracy: 0.6484375\n",
      "Batch: 59, Loss: 1.0933592319488525, Accuracy: 0.658203125\n",
      "Batch: 60, Loss: 1.1682785749435425, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1523394584655762, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.1582117080688477, Accuracy: 0.6318359375\n",
      "Batch: 63, Loss: 1.1007088422775269, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.1152424812316895, Accuracy: 0.6240234375\n",
      "Batch: 65, Loss: 1.1278631687164307, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.1157331466674805, Accuracy: 0.6435546875\n",
      "Batch: 67, Loss: 1.1735714673995972, Accuracy: 0.591796875\n",
      "Batch: 68, Loss: 1.060199499130249, Accuracy: 0.67578125\n",
      "Batch: 69, Loss: 1.1480929851531982, Accuracy: 0.626953125\n",
      "Batch: 70, Loss: 1.1162505149841309, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.1531565189361572, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.163001537322998, Accuracy: 0.62109375\n",
      "Batch: 73, Loss: 1.1367833614349365, Accuracy: 0.6259765625\n",
      "Batch: 74, Loss: 1.0206421613693237, Accuracy: 0.6650390625\n",
      "Batch: 75, Loss: 1.0864505767822266, Accuracy: 0.6435546875\n",
      "Batch: 76, Loss: 1.0952401161193848, Accuracy: 0.6376953125\n",
      "Batch: 77, Loss: 1.0675994157791138, Accuracy: 0.6640625\n",
      "Batch: 78, Loss: 1.1181230545043945, Accuracy: 0.6318359375\n",
      "Batch: 79, Loss: 1.1510815620422363, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.102994441986084, Accuracy: 0.640625\n",
      "Batch: 81, Loss: 1.1203877925872803, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.099313497543335, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.229928731918335, Accuracy: 0.59765625\n",
      "Batch: 84, Loss: 1.1122221946716309, Accuracy: 0.6513671875\n",
      "Batch: 85, Loss: 1.1504991054534912, Accuracy: 0.62890625\n",
      "Batch: 86, Loss: 1.154582142829895, Accuracy: 0.6396484375\n",
      "Batch: 87, Loss: 1.1690869331359863, Accuracy: 0.62890625\n",
      "Batch: 88, Loss: 1.102149486541748, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.1652569770812988, Accuracy: 0.619140625\n",
      "Batch: 90, Loss: 1.0733118057250977, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.1144630908966064, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.0822176933288574, Accuracy: 0.662109375\n",
      "Batch: 93, Loss: 1.083820104598999, Accuracy: 0.6474609375\n",
      "Batch: 94, Loss: 1.2117081880569458, Accuracy: 0.59375\n",
      "Batch: 95, Loss: 1.1453893184661865, Accuracy: 0.6318359375\n",
      "Batch: 96, Loss: 1.1867705583572388, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.133237600326538, Accuracy: 0.62890625\n",
      "Batch: 98, Loss: 1.0712515115737915, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1314858198165894, Accuracy: 0.6416015625\n",
      "Batch: 100, Loss: 1.0382293462753296, Accuracy: 0.669921875\n",
      "Batch: 101, Loss: 1.0846928358078003, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1807104349136353, Accuracy: 0.607421875\n",
      "Batch: 103, Loss: 1.1478826999664307, Accuracy: 0.63671875\n",
      "Batch: 104, Loss: 1.1291954517364502, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.0904308557510376, Accuracy: 0.64453125\n",
      "Batch: 106, Loss: 1.1415374279022217, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.2151261568069458, Accuracy: 0.6171875\n",
      "Batch: 108, Loss: 1.117060661315918, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1420671939849854, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 1.1096683740615845, Accuracy: 0.654296875\n",
      "Batch: 111, Loss: 1.1202019453048706, Accuracy: 0.6240234375\n",
      "Batch: 112, Loss: 1.0464626550674438, Accuracy: 0.662109375\n",
      "Batch: 113, Loss: 1.1049468517303467, Accuracy: 0.6533203125\n",
      "Batch: 114, Loss: 1.0949733257293701, Accuracy: 0.634765625\n",
      "Batch: 115, Loss: 1.1780591011047363, Accuracy: 0.607421875\n",
      "Batch: 116, Loss: 1.157947063446045, Accuracy: 0.6396484375\n",
      "Batch: 117, Loss: 1.1335232257843018, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 1.1998127698898315, Accuracy: 0.61328125\n",
      "Batch: 119, Loss: 1.2105071544647217, Accuracy: 0.611328125\n",
      "Batch: 120, Loss: 1.2622979879379272, Accuracy: 0.580078125\n",
      "Batch: 121, Loss: 1.1194570064544678, Accuracy: 0.6484375\n",
      "Batch: 122, Loss: 1.1990840435028076, Accuracy: 0.615234375\n",
      "Batch: 123, Loss: 1.1250901222229004, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.1639363765716553, Accuracy: 0.62890625\n",
      "Batch: 125, Loss: 1.138884425163269, Accuracy: 0.64453125\n",
      "Batch: 126, Loss: 1.2143702507019043, Accuracy: 0.626953125\n",
      "Batch: 127, Loss: 1.2145966291427612, Accuracy: 0.6181640625\n",
      "Batch: 128, Loss: 1.1791043281555176, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.1937263011932373, Accuracy: 0.619140625\n",
      "Batch: 130, Loss: 1.1120600700378418, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.180834174156189, Accuracy: 0.603515625\n",
      "Batch: 132, Loss: 1.0359046459197998, Accuracy: 0.658203125\n",
      "Batch: 133, Loss: 1.120293378829956, Accuracy: 0.650390625\n",
      "Batch: 134, Loss: 1.1305339336395264, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 1.025047779083252, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.0875351428985596, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.1256680488586426, Accuracy: 0.6396484375\n",
      "Batch: 138, Loss: 1.1588823795318604, Accuracy: 0.6240234375\n",
      "Batch: 139, Loss: 1.1665146350860596, Accuracy: 0.634765625\n",
      "Batch: 140, Loss: 1.2518516778945923, Accuracy: 0.61328125\n",
      "Batch: 141, Loss: 1.1301991939544678, Accuracy: 0.646484375\n",
      "Batch: 142, Loss: 1.1049442291259766, Accuracy: 0.64453125\n",
      "Batch: 143, Loss: 1.1455988883972168, Accuracy: 0.6259765625\n",
      "Batch: 144, Loss: 1.2690269947052002, Accuracy: 0.5966796875\n",
      "Batch: 145, Loss: 1.244359016418457, Accuracy: 0.595703125\n",
      "Batch: 146, Loss: 1.185227632522583, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.1687817573547363, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.1796901226043701, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.1890848875045776, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.1659386157989502, Accuracy: 0.615234375\n",
      "Batch: 151, Loss: 1.1944270133972168, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.1600664854049683, Accuracy: 0.6201171875\n",
      "Batch: 153, Loss: 1.1027008295059204, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.0475547313690186, Accuracy: 0.662109375\n",
      "Batch: 155, Loss: 1.0691707134246826, Accuracy: 0.65234375\n",
      "Saved Weights at epoch 570 to file Weights_570.h5\n",
      "Epoch 571/200\n",
      "Batch: 1, Loss: 1.2337802648544312, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 1.0649056434631348, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 0.9920550584793091, Accuracy: 0.66015625\n",
      "Batch: 4, Loss: 1.03068208694458, Accuracy: 0.640625\n",
      "Batch: 5, Loss: 1.0430517196655273, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.0308252573013306, Accuracy: 0.654296875\n",
      "Batch: 7, Loss: 1.026881456375122, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 0.9446020126342773, Accuracy: 0.6953125\n",
      "Batch: 9, Loss: 0.9815409183502197, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 0.9536952972412109, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 0.9804938435554504, Accuracy: 0.677734375\n",
      "Batch: 12, Loss: 0.9927208423614502, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 0.9906753301620483, Accuracy: 0.671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.9617718458175659, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.9235488176345825, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 1.0393873453140259, Accuracy: 0.6591796875\n",
      "Batch: 17, Loss: 1.0547740459442139, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 1.0630433559417725, Accuracy: 0.6484375\n",
      "Batch: 19, Loss: 1.213326334953308, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0909266471862793, Accuracy: 0.6572265625\n",
      "Batch: 21, Loss: 1.022139072418213, Accuracy: 0.6708984375\n",
      "Batch: 22, Loss: 1.243457317352295, Accuracy: 0.6162109375\n",
      "Batch: 23, Loss: 1.22877836227417, Accuracy: 0.5888671875\n",
      "Batch: 24, Loss: 1.1051390171051025, Accuracy: 0.6240234375\n",
      "Batch: 25, Loss: 1.1793973445892334, Accuracy: 0.611328125\n",
      "Batch: 26, Loss: 1.1213589906692505, Accuracy: 0.6064453125\n",
      "Batch: 27, Loss: 1.1124372482299805, Accuracy: 0.640625\n",
      "Batch: 28, Loss: 1.0614476203918457, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.0352215766906738, Accuracy: 0.642578125\n",
      "Batch: 30, Loss: 1.1477501392364502, Accuracy: 0.5986328125\n",
      "Batch: 31, Loss: 1.1939784288406372, Accuracy: 0.6171875\n",
      "Batch: 32, Loss: 1.0335367918014526, Accuracy: 0.6630859375\n",
      "Batch: 33, Loss: 1.0005205869674683, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.0997729301452637, Accuracy: 0.646484375\n",
      "Batch: 35, Loss: 1.1067306995391846, Accuracy: 0.61328125\n",
      "Batch: 36, Loss: 1.181115984916687, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.1999852657318115, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.1069875955581665, Accuracy: 0.6337890625\n",
      "Batch: 39, Loss: 1.0392968654632568, Accuracy: 0.66796875\n",
      "Batch: 40, Loss: 1.0895570516586304, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.1552907228469849, Accuracy: 0.6220703125\n",
      "Batch: 42, Loss: 1.0661158561706543, Accuracy: 0.6533203125\n",
      "Batch: 43, Loss: 1.0531182289123535, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 0.9923489689826965, Accuracy: 0.66015625\n",
      "Batch: 45, Loss: 1.0588915348052979, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.0793471336364746, Accuracy: 0.6416015625\n",
      "Batch: 47, Loss: 1.1004527807235718, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.1209460496902466, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.1833570003509521, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.0944617986679077, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1666107177734375, Accuracy: 0.6181640625\n",
      "Batch: 52, Loss: 1.1923441886901855, Accuracy: 0.595703125\n",
      "Batch: 53, Loss: 1.1527738571166992, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.1283303499221802, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.0847053527832031, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.088419795036316, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 1.0609636306762695, Accuracy: 0.65234375\n",
      "Batch: 58, Loss: 1.0240483283996582, Accuracy: 0.6650390625\n",
      "Batch: 59, Loss: 1.047258973121643, Accuracy: 0.662109375\n",
      "Batch: 60, Loss: 1.2139358520507812, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1444767713546753, Accuracy: 0.623046875\n",
      "Batch: 62, Loss: 1.1398499011993408, Accuracy: 0.6337890625\n",
      "Batch: 63, Loss: 1.1490033864974976, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.1577162742614746, Accuracy: 0.6337890625\n",
      "Batch: 65, Loss: 1.1844583749771118, Accuracy: 0.6171875\n",
      "Batch: 66, Loss: 1.1483113765716553, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1435800790786743, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0967252254486084, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.165540099143982, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.1080758571624756, Accuracy: 0.6396484375\n",
      "Batch: 71, Loss: 1.083491563796997, Accuracy: 0.6474609375\n",
      "Batch: 72, Loss: 1.1669412851333618, Accuracy: 0.6357421875\n",
      "Batch: 73, Loss: 1.1203858852386475, Accuracy: 0.6396484375\n",
      "Batch: 74, Loss: 1.0827083587646484, Accuracy: 0.6396484375\n",
      "Batch: 75, Loss: 1.1224002838134766, Accuracy: 0.6494140625\n",
      "Batch: 76, Loss: 1.0700045824050903, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 1.0548609495162964, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.0562753677368164, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.0835540294647217, Accuracy: 0.6484375\n",
      "Batch: 80, Loss: 1.1250920295715332, Accuracy: 0.6201171875\n",
      "Batch: 81, Loss: 1.066351056098938, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.1046851873397827, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.157738208770752, Accuracy: 0.642578125\n",
      "Batch: 84, Loss: 1.0845506191253662, Accuracy: 0.6572265625\n",
      "Batch: 85, Loss: 1.1254351139068604, Accuracy: 0.65234375\n",
      "Batch: 86, Loss: 1.1548035144805908, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 1.1674096584320068, Accuracy: 0.6357421875\n",
      "Batch: 88, Loss: 1.1261812448501587, Accuracy: 0.615234375\n",
      "Batch: 89, Loss: 1.1365711688995361, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.044082760810852, Accuracy: 0.671875\n",
      "Batch: 91, Loss: 1.0384953022003174, Accuracy: 0.666015625\n",
      "Batch: 92, Loss: 1.077141523361206, Accuracy: 0.654296875\n",
      "Batch: 93, Loss: 1.077357292175293, Accuracy: 0.64453125\n",
      "Batch: 94, Loss: 1.163309097290039, Accuracy: 0.626953125\n",
      "Batch: 95, Loss: 1.1423701047897339, Accuracy: 0.654296875\n",
      "Batch: 96, Loss: 1.137880563735962, Accuracy: 0.6494140625\n",
      "Batch: 97, Loss: 1.143343210220337, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.0676145553588867, Accuracy: 0.658203125\n",
      "Batch: 99, Loss: 1.1702382564544678, Accuracy: 0.623046875\n",
      "Batch: 100, Loss: 1.0937831401824951, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.0580077171325684, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 1.1145498752593994, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1385221481323242, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.1231669187545776, Accuracy: 0.6298828125\n",
      "Batch: 105, Loss: 1.1800150871276855, Accuracy: 0.626953125\n",
      "Batch: 106, Loss: 1.1888208389282227, Accuracy: 0.615234375\n",
      "Batch: 107, Loss: 1.2132441997528076, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.1496613025665283, Accuracy: 0.6171875\n",
      "Batch: 109, Loss: 1.111565113067627, Accuracy: 0.6337890625\n",
      "Batch: 110, Loss: 1.1147844791412354, Accuracy: 0.6494140625\n",
      "Batch: 111, Loss: 1.0761650800704956, Accuracy: 0.658203125\n",
      "Batch: 112, Loss: 1.0809218883514404, Accuracy: 0.640625\n",
      "Batch: 113, Loss: 1.1054260730743408, Accuracy: 0.638671875\n",
      "Batch: 114, Loss: 1.1683707237243652, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.1533915996551514, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.208209753036499, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.1475412845611572, Accuracy: 0.6298828125\n",
      "Batch: 118, Loss: 1.207161545753479, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.1516244411468506, Accuracy: 0.630859375\n",
      "Batch: 120, Loss: 1.2331807613372803, Accuracy: 0.6357421875\n",
      "Batch: 121, Loss: 1.1188594102859497, Accuracy: 0.6416015625\n",
      "Batch: 122, Loss: 1.2105207443237305, Accuracy: 0.6015625\n",
      "Batch: 123, Loss: 1.104186773300171, Accuracy: 0.658203125\n",
      "Batch: 124, Loss: 1.1499994993209839, Accuracy: 0.6455078125\n",
      "Batch: 125, Loss: 1.1169428825378418, Accuracy: 0.642578125\n",
      "Batch: 126, Loss: 1.1810084581375122, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.1980003118515015, Accuracy: 0.6279296875\n",
      "Batch: 128, Loss: 1.1670939922332764, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.1290562152862549, Accuracy: 0.638671875\n",
      "Batch: 130, Loss: 1.0818214416503906, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 1.188335657119751, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 1.0768237113952637, Accuracy: 0.6650390625\n",
      "Batch: 133, Loss: 1.0740082263946533, Accuracy: 0.6494140625\n",
      "Batch: 134, Loss: 1.0678044557571411, Accuracy: 0.681640625\n",
      "Batch: 135, Loss: 1.0038063526153564, Accuracy: 0.67578125\n",
      "Batch: 136, Loss: 1.0613652467727661, Accuracy: 0.666015625\n",
      "Batch: 137, Loss: 1.151968240737915, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.246628999710083, Accuracy: 0.5927734375\n",
      "Batch: 139, Loss: 1.1787974834442139, Accuracy: 0.6298828125\n",
      "Batch: 140, Loss: 1.252098560333252, Accuracy: 0.6083984375\n",
      "Batch: 141, Loss: 1.0905735492706299, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.1252975463867188, Accuracy: 0.6298828125\n",
      "Batch: 143, Loss: 1.2178055047988892, Accuracy: 0.6044921875\n",
      "Batch: 144, Loss: 1.2004364728927612, Accuracy: 0.6298828125\n",
      "Batch: 145, Loss: 1.1713474988937378, Accuracy: 0.599609375\n",
      "Batch: 146, Loss: 1.1596708297729492, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.1763570308685303, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.1640229225158691, Accuracy: 0.626953125\n",
      "Batch: 149, Loss: 1.1163597106933594, Accuracy: 0.626953125\n",
      "Batch: 150, Loss: 1.108995795249939, Accuracy: 0.6240234375\n",
      "Batch: 151, Loss: 1.1352843046188354, Accuracy: 0.6455078125\n",
      "Batch: 152, Loss: 1.149918556213379, Accuracy: 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 153, Loss: 1.1171026229858398, Accuracy: 0.6533203125\n",
      "Batch: 154, Loss: 1.0917810201644897, Accuracy: 0.6494140625\n",
      "Batch: 155, Loss: 1.051121473312378, Accuracy: 0.6552734375\n",
      "Epoch 572/200\n",
      "Batch: 1, Loss: 1.2035739421844482, Accuracy: 0.6572265625\n",
      "Batch: 2, Loss: 1.0685621500015259, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 1.0539265871047974, Accuracy: 0.6455078125\n",
      "Batch: 4, Loss: 1.025116205215454, Accuracy: 0.6552734375\n",
      "Batch: 5, Loss: 1.0087841749191284, Accuracy: 0.6689453125\n",
      "Batch: 6, Loss: 1.0332391262054443, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 1.025651216506958, Accuracy: 0.64453125\n",
      "Batch: 8, Loss: 0.9619305729866028, Accuracy: 0.6865234375\n",
      "Batch: 9, Loss: 0.9863568544387817, Accuracy: 0.6904296875\n",
      "Batch: 10, Loss: 1.0217924118041992, Accuracy: 0.6669921875\n",
      "Batch: 11, Loss: 0.9386144876480103, Accuracy: 0.7021484375\n",
      "Batch: 12, Loss: 0.9783802032470703, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 1.0072336196899414, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 0.9364926815032959, Accuracy: 0.6953125\n",
      "Batch: 15, Loss: 0.9981957674026489, Accuracy: 0.6689453125\n",
      "Batch: 16, Loss: 0.985642671585083, Accuracy: 0.662109375\n",
      "Batch: 17, Loss: 1.0309748649597168, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.0727550983428955, Accuracy: 0.65625\n",
      "Batch: 19, Loss: 1.1760294437408447, Accuracy: 0.6318359375\n",
      "Batch: 20, Loss: 1.0759170055389404, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.0338656902313232, Accuracy: 0.67578125\n",
      "Batch: 22, Loss: 1.2571945190429688, Accuracy: 0.5849609375\n",
      "Batch: 23, Loss: 1.1813099384307861, Accuracy: 0.6240234375\n",
      "Batch: 24, Loss: 1.0684254169464111, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.09926176071167, Accuracy: 0.642578125\n",
      "Batch: 26, Loss: 1.2028943300247192, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.098095178604126, Accuracy: 0.658203125\n",
      "Batch: 28, Loss: 1.0005266666412354, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 1.043487548828125, Accuracy: 0.6630859375\n",
      "Batch: 30, Loss: 1.153143048286438, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.1462979316711426, Accuracy: 0.6298828125\n",
      "Batch: 32, Loss: 1.0973871946334839, Accuracy: 0.64453125\n",
      "Batch: 33, Loss: 0.9996984004974365, Accuracy: 0.6640625\n",
      "Batch: 34, Loss: 1.130586862564087, Accuracy: 0.640625\n",
      "Batch: 35, Loss: 1.183239459991455, Accuracy: 0.6240234375\n",
      "Batch: 36, Loss: 1.225605845451355, Accuracy: 0.599609375\n",
      "Batch: 37, Loss: 1.1608688831329346, Accuracy: 0.6259765625\n",
      "Batch: 38, Loss: 1.1863290071487427, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.0454978942871094, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0537376403808594, Accuracy: 0.6611328125\n",
      "Batch: 41, Loss: 1.0596153736114502, Accuracy: 0.6484375\n",
      "Batch: 42, Loss: 1.056004524230957, Accuracy: 0.6494140625\n",
      "Batch: 43, Loss: 0.9861757159233093, Accuracy: 0.6796875\n",
      "Batch: 44, Loss: 1.0157043933868408, Accuracy: 0.662109375\n",
      "Batch: 45, Loss: 0.9847484827041626, Accuracy: 0.6787109375\n",
      "Batch: 46, Loss: 1.1245551109313965, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.0450718402862549, Accuracy: 0.6669921875\n",
      "Batch: 48, Loss: 1.1008296012878418, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.135646939277649, Accuracy: 0.6279296875\n",
      "Batch: 50, Loss: 1.0917508602142334, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.1134083271026611, Accuracy: 0.626953125\n",
      "Batch: 52, Loss: 1.236790418624878, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.1125900745391846, Accuracy: 0.6328125\n",
      "Batch: 54, Loss: 1.1446609497070312, Accuracy: 0.640625\n",
      "Batch: 55, Loss: 1.1322827339172363, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.0922703742980957, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.041168451309204, Accuracy: 0.6650390625\n",
      "Batch: 58, Loss: 1.1060870885849, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.0812251567840576, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.1852233409881592, Accuracy: 0.6181640625\n",
      "Batch: 61, Loss: 1.1187490224838257, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.117203950881958, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.182546854019165, Accuracy: 0.595703125\n",
      "Batch: 64, Loss: 1.1614291667938232, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.1816134452819824, Accuracy: 0.615234375\n",
      "Batch: 66, Loss: 1.1003577709197998, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.0368702411651611, Accuracy: 0.6484375\n",
      "Batch: 68, Loss: 1.0237159729003906, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 1.1264910697937012, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.1336671113967896, Accuracy: 0.6533203125\n",
      "Batch: 71, Loss: 1.1049665212631226, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.1377558708190918, Accuracy: 0.634765625\n",
      "Batch: 73, Loss: 1.137004017829895, Accuracy: 0.640625\n",
      "Batch: 74, Loss: 1.0701141357421875, Accuracy: 0.6630859375\n",
      "Batch: 75, Loss: 1.0691986083984375, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.0567682981491089, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.037933349609375, Accuracy: 0.654296875\n",
      "Batch: 78, Loss: 1.0226942300796509, Accuracy: 0.666015625\n",
      "Batch: 79, Loss: 1.139885425567627, Accuracy: 0.619140625\n",
      "Batch: 80, Loss: 1.1412591934204102, Accuracy: 0.63671875\n",
      "Batch: 81, Loss: 1.0121588706970215, Accuracy: 0.6650390625\n",
      "Batch: 82, Loss: 1.0581068992614746, Accuracy: 0.666015625\n",
      "Batch: 83, Loss: 1.172905683517456, Accuracy: 0.6201171875\n",
      "Batch: 84, Loss: 1.1009881496429443, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.121872901916504, Accuracy: 0.638671875\n",
      "Batch: 86, Loss: 1.1416807174682617, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 1.129151701927185, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.1084403991699219, Accuracy: 0.6337890625\n",
      "Batch: 89, Loss: 1.1063395738601685, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.042588710784912, Accuracy: 0.66015625\n",
      "Batch: 91, Loss: 1.1210516691207886, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.1408193111419678, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.118696928024292, Accuracy: 0.650390625\n",
      "Batch: 94, Loss: 1.1771011352539062, Accuracy: 0.625\n",
      "Batch: 95, Loss: 1.1501479148864746, Accuracy: 0.62890625\n",
      "Batch: 96, Loss: 1.159469485282898, Accuracy: 0.630859375\n",
      "Batch: 97, Loss: 1.114241600036621, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.0780993700027466, Accuracy: 0.65234375\n",
      "Batch: 99, Loss: 1.0911110639572144, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.0683867931365967, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.061996340751648, Accuracy: 0.6630859375\n",
      "Batch: 102, Loss: 1.0467922687530518, Accuracy: 0.658203125\n",
      "Batch: 103, Loss: 1.1636968851089478, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.0715596675872803, Accuracy: 0.6494140625\n",
      "Batch: 105, Loss: 1.1774623394012451, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.1284162998199463, Accuracy: 0.646484375\n",
      "Batch: 107, Loss: 1.2123353481292725, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.1385743618011475, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1731700897216797, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.0641496181488037, Accuracy: 0.654296875\n",
      "Batch: 111, Loss: 1.0990474224090576, Accuracy: 0.640625\n",
      "Batch: 112, Loss: 1.029118537902832, Accuracy: 0.6689453125\n",
      "Batch: 113, Loss: 1.0556366443634033, Accuracy: 0.6640625\n",
      "Batch: 114, Loss: 1.118819236755371, Accuracy: 0.62109375\n",
      "Batch: 115, Loss: 1.1720105409622192, Accuracy: 0.634765625\n",
      "Batch: 116, Loss: 1.1653813123703003, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.1519641876220703, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 1.1736576557159424, Accuracy: 0.6201171875\n",
      "Batch: 119, Loss: 1.1845283508300781, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.182803750038147, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.1665441989898682, Accuracy: 0.6416015625\n",
      "Batch: 122, Loss: 1.2010974884033203, Accuracy: 0.6025390625\n",
      "Batch: 123, Loss: 1.155759334564209, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.1801414489746094, Accuracy: 0.6240234375\n",
      "Batch: 125, Loss: 1.1230279207229614, Accuracy: 0.6455078125\n",
      "Batch: 126, Loss: 1.1963510513305664, Accuracy: 0.638671875\n",
      "Batch: 127, Loss: 1.1942148208618164, Accuracy: 0.62109375\n",
      "Batch: 128, Loss: 1.1441309452056885, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1140060424804688, Accuracy: 0.64453125\n",
      "Batch: 130, Loss: 1.1196351051330566, Accuracy: 0.6201171875\n",
      "Batch: 131, Loss: 1.1648231744766235, Accuracy: 0.626953125\n",
      "Batch: 132, Loss: 1.022019386291504, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 1.0813078880310059, Accuracy: 0.6474609375\n",
      "Batch: 134, Loss: 1.1279959678649902, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 0.989033579826355, Accuracy: 0.6669921875\n",
      "Batch: 136, Loss: 1.0827564001083374, Accuracy: 0.65234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.1538829803466797, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.2426056861877441, Accuracy: 0.6025390625\n",
      "Batch: 139, Loss: 1.1664446592330933, Accuracy: 0.61328125\n",
      "Batch: 140, Loss: 1.2017247676849365, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.112828016281128, Accuracy: 0.6240234375\n",
      "Batch: 142, Loss: 1.159658432006836, Accuracy: 0.6396484375\n",
      "Batch: 143, Loss: 1.1768945455551147, Accuracy: 0.6220703125\n",
      "Batch: 144, Loss: 1.197868824005127, Accuracy: 0.6025390625\n",
      "Batch: 145, Loss: 1.2431107759475708, Accuracy: 0.6015625\n",
      "Batch: 146, Loss: 1.1736376285552979, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.1530301570892334, Accuracy: 0.6044921875\n",
      "Batch: 148, Loss: 1.1297502517700195, Accuracy: 0.6171875\n",
      "Batch: 149, Loss: 1.151145100593567, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.0683979988098145, Accuracy: 0.6484375\n",
      "Batch: 151, Loss: 1.1298896074295044, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.0942633152008057, Accuracy: 0.6259765625\n",
      "Batch: 153, Loss: 1.0532808303833008, Accuracy: 0.6630859375\n",
      "Batch: 154, Loss: 1.0841920375823975, Accuracy: 0.638671875\n",
      "Batch: 155, Loss: 1.0666040182113647, Accuracy: 0.6513671875\n",
      "Epoch 573/200\n",
      "Batch: 1, Loss: 1.2476248741149902, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.068047046661377, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 1.0540878772735596, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.058431625366211, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 0.9477320909500122, Accuracy: 0.69140625\n",
      "Batch: 6, Loss: 1.027285099029541, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 0.9481854438781738, Accuracy: 0.6884765625\n",
      "Batch: 8, Loss: 1.0152630805969238, Accuracy: 0.666015625\n",
      "Batch: 9, Loss: 0.9647199511528015, Accuracy: 0.6962890625\n",
      "Batch: 10, Loss: 0.9766243696212769, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 0.9120377898216248, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.9526376128196716, Accuracy: 0.6884765625\n",
      "Batch: 13, Loss: 1.0044480562210083, Accuracy: 0.67578125\n",
      "Batch: 14, Loss: 0.9657415151596069, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.9328916072845459, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 0.9749995470046997, Accuracy: 0.66796875\n",
      "Batch: 17, Loss: 0.9647922515869141, Accuracy: 0.6806640625\n",
      "Batch: 18, Loss: 1.1054940223693848, Accuracy: 0.6220703125\n",
      "Batch: 19, Loss: 1.1636147499084473, Accuracy: 0.6318359375\n",
      "Batch: 20, Loss: 1.038469910621643, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 1.0253667831420898, Accuracy: 0.671875\n",
      "Batch: 22, Loss: 1.1979475021362305, Accuracy: 0.6259765625\n",
      "Batch: 23, Loss: 1.205965280532837, Accuracy: 0.619140625\n",
      "Batch: 24, Loss: 1.1137291193008423, Accuracy: 0.6416015625\n",
      "Batch: 25, Loss: 1.095102310180664, Accuracy: 0.634765625\n",
      "Batch: 26, Loss: 1.144958734512329, Accuracy: 0.626953125\n",
      "Batch: 27, Loss: 1.1475160121917725, Accuracy: 0.623046875\n",
      "Batch: 28, Loss: 1.0252060890197754, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.0489606857299805, Accuracy: 0.65625\n",
      "Batch: 30, Loss: 1.1254217624664307, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.1818628311157227, Accuracy: 0.59765625\n",
      "Batch: 32, Loss: 1.0043327808380127, Accuracy: 0.6630859375\n",
      "Batch: 33, Loss: 0.9664779901504517, Accuracy: 0.6904296875\n",
      "Batch: 34, Loss: 1.054157018661499, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.093489408493042, Accuracy: 0.6396484375\n",
      "Batch: 36, Loss: 1.1644552946090698, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.1524591445922852, Accuracy: 0.6298828125\n",
      "Batch: 38, Loss: 1.1269536018371582, Accuracy: 0.625\n",
      "Batch: 39, Loss: 1.0860155820846558, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.1095612049102783, Accuracy: 0.6328125\n",
      "Batch: 41, Loss: 1.1072418689727783, Accuracy: 0.640625\n",
      "Batch: 42, Loss: 1.0359481573104858, Accuracy: 0.6708984375\n",
      "Batch: 43, Loss: 1.0584721565246582, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.0677977800369263, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 0.9957113265991211, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.1165772676467896, Accuracy: 0.6279296875\n",
      "Batch: 47, Loss: 1.011839747428894, Accuracy: 0.68359375\n",
      "Batch: 48, Loss: 1.0480161905288696, Accuracy: 0.64453125\n",
      "Batch: 49, Loss: 1.1461403369903564, Accuracy: 0.6416015625\n",
      "Batch: 50, Loss: 1.1151249408721924, Accuracy: 0.634765625\n",
      "Batch: 51, Loss: 1.1183347702026367, Accuracy: 0.6279296875\n",
      "Batch: 52, Loss: 1.1984930038452148, Accuracy: 0.6201171875\n",
      "Batch: 53, Loss: 1.1277036666870117, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.1149086952209473, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.0964325666427612, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.027819037437439, Accuracy: 0.6708984375\n",
      "Batch: 57, Loss: 1.1262269020080566, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.0743536949157715, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.0994293689727783, Accuracy: 0.6435546875\n",
      "Batch: 60, Loss: 1.2224140167236328, Accuracy: 0.5986328125\n",
      "Batch: 61, Loss: 1.127445936203003, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1014140844345093, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1028082370758057, Accuracy: 0.6435546875\n",
      "Batch: 64, Loss: 1.1217892169952393, Accuracy: 0.6142578125\n",
      "Batch: 65, Loss: 1.0772422552108765, Accuracy: 0.6591796875\n",
      "Batch: 66, Loss: 1.0789597034454346, Accuracy: 0.646484375\n",
      "Batch: 67, Loss: 1.1243157386779785, Accuracy: 0.6591796875\n",
      "Batch: 68, Loss: 0.9920437335968018, Accuracy: 0.6875\n",
      "Batch: 69, Loss: 1.1521258354187012, Accuracy: 0.638671875\n",
      "Batch: 70, Loss: 1.146921157836914, Accuracy: 0.640625\n",
      "Batch: 71, Loss: 1.09193754196167, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.1592779159545898, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.1128621101379395, Accuracy: 0.6484375\n",
      "Batch: 74, Loss: 1.0711214542388916, Accuracy: 0.6611328125\n",
      "Batch: 75, Loss: 1.065325140953064, Accuracy: 0.6474609375\n",
      "Batch: 76, Loss: 1.0948328971862793, Accuracy: 0.62109375\n",
      "Batch: 77, Loss: 1.040698766708374, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.087899923324585, Accuracy: 0.6337890625\n",
      "Batch: 79, Loss: 1.0883774757385254, Accuracy: 0.64453125\n",
      "Batch: 80, Loss: 1.1408226490020752, Accuracy: 0.6416015625\n",
      "Batch: 81, Loss: 1.0656962394714355, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.1123019456863403, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.1477566957473755, Accuracy: 0.6171875\n",
      "Batch: 84, Loss: 1.1077388525009155, Accuracy: 0.65625\n",
      "Batch: 85, Loss: 1.142743706703186, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.1474781036376953, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1243946552276611, Accuracy: 0.6552734375\n",
      "Batch: 88, Loss: 1.075761079788208, Accuracy: 0.650390625\n",
      "Batch: 89, Loss: 1.1056861877441406, Accuracy: 0.6396484375\n",
      "Batch: 90, Loss: 1.0383212566375732, Accuracy: 0.6669921875\n",
      "Batch: 91, Loss: 1.0766154527664185, Accuracy: 0.654296875\n",
      "Batch: 92, Loss: 1.044831395149231, Accuracy: 0.66796875\n",
      "Batch: 93, Loss: 1.105879306793213, Accuracy: 0.65625\n",
      "Batch: 94, Loss: 1.1746885776519775, Accuracy: 0.62109375\n",
      "Batch: 95, Loss: 1.088932991027832, Accuracy: 0.6533203125\n",
      "Batch: 96, Loss: 1.105614185333252, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.1064666509628296, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.0838171243667603, Accuracy: 0.6318359375\n",
      "Batch: 99, Loss: 1.0540629625320435, Accuracy: 0.6669921875\n",
      "Batch: 100, Loss: 1.052740216255188, Accuracy: 0.6806640625\n",
      "Batch: 101, Loss: 1.056028127670288, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 1.1172893047332764, Accuracy: 0.62890625\n",
      "Batch: 103, Loss: 1.1232280731201172, Accuracy: 0.6318359375\n",
      "Batch: 104, Loss: 1.0314996242523193, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.165526270866394, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.2014315128326416, Accuracy: 0.6142578125\n",
      "Batch: 107, Loss: 1.1968733072280884, Accuracy: 0.611328125\n",
      "Batch: 108, Loss: 1.1508402824401855, Accuracy: 0.6044921875\n",
      "Batch: 109, Loss: 1.1442031860351562, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.110830307006836, Accuracy: 0.619140625\n",
      "Batch: 111, Loss: 1.0942800045013428, Accuracy: 0.64453125\n",
      "Batch: 112, Loss: 1.039294719696045, Accuracy: 0.6611328125\n",
      "Batch: 113, Loss: 1.157831072807312, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.1201560497283936, Accuracy: 0.6328125\n",
      "Batch: 115, Loss: 1.161959171295166, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.1155295372009277, Accuracy: 0.6376953125\n",
      "Batch: 117, Loss: 1.123049259185791, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.1943182945251465, Accuracy: 0.599609375\n",
      "Batch: 119, Loss: 1.2106437683105469, Accuracy: 0.623046875\n",
      "Batch: 120, Loss: 1.2725049257278442, Accuracy: 0.5908203125\n",
      "Batch: 121, Loss: 1.1343491077423096, Accuracy: 0.6572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 1.1945979595184326, Accuracy: 0.6357421875\n",
      "Batch: 123, Loss: 1.2016887664794922, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.1679186820983887, Accuracy: 0.6455078125\n",
      "Batch: 125, Loss: 1.130164623260498, Accuracy: 0.64453125\n",
      "Batch: 126, Loss: 1.2241359949111938, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.177687644958496, Accuracy: 0.6220703125\n",
      "Batch: 128, Loss: 1.1032421588897705, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.1259692907333374, Accuracy: 0.63671875\n",
      "Batch: 130, Loss: 1.1178734302520752, Accuracy: 0.6533203125\n",
      "Batch: 131, Loss: 1.1760448217391968, Accuracy: 0.6181640625\n",
      "Batch: 132, Loss: 1.0415529012680054, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.123498558998108, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.082855463027954, Accuracy: 0.6474609375\n",
      "Batch: 135, Loss: 1.0108698606491089, Accuracy: 0.671875\n",
      "Batch: 136, Loss: 1.0554132461547852, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.143633246421814, Accuracy: 0.634765625\n",
      "Batch: 138, Loss: 1.1967811584472656, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.1443980932235718, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.2146621942520142, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.1056227684020996, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1364021301269531, Accuracy: 0.6396484375\n",
      "Batch: 143, Loss: 1.153273105621338, Accuracy: 0.625\n",
      "Batch: 144, Loss: 1.2342450618743896, Accuracy: 0.615234375\n",
      "Batch: 145, Loss: 1.188014268875122, Accuracy: 0.6171875\n",
      "Batch: 146, Loss: 1.1561498641967773, Accuracy: 0.63671875\n",
      "Batch: 147, Loss: 1.144700527191162, Accuracy: 0.634765625\n",
      "Batch: 148, Loss: 1.164365530014038, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.1250312328338623, Accuracy: 0.61328125\n",
      "Batch: 150, Loss: 1.0872182846069336, Accuracy: 0.658203125\n",
      "Batch: 151, Loss: 1.0996986627578735, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.0933356285095215, Accuracy: 0.6435546875\n",
      "Batch: 153, Loss: 1.0889508724212646, Accuracy: 0.6455078125\n",
      "Batch: 154, Loss: 1.084568977355957, Accuracy: 0.6533203125\n",
      "Batch: 155, Loss: 1.0539193153381348, Accuracy: 0.6513671875\n",
      "Epoch 574/200\n",
      "Batch: 1, Loss: 1.1678011417388916, Accuracy: 0.6630859375\n",
      "Batch: 2, Loss: 1.004751205444336, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 1.021963119506836, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 1.0329785346984863, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 0.9928452968597412, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 0.9940483570098877, Accuracy: 0.6669921875\n",
      "Batch: 7, Loss: 0.9945776462554932, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 0.9999961853027344, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9731523990631104, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9060589671134949, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 0.910329282283783, Accuracy: 0.705078125\n",
      "Batch: 12, Loss: 0.9873202443122864, Accuracy: 0.6650390625\n",
      "Batch: 13, Loss: 0.9685845971107483, Accuracy: 0.6875\n",
      "Batch: 14, Loss: 0.9477100372314453, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9465050101280212, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 0.9722561836242676, Accuracy: 0.6787109375\n",
      "Batch: 17, Loss: 1.0006608963012695, Accuracy: 0.6552734375\n",
      "Batch: 18, Loss: 1.0885838270187378, Accuracy: 0.65625\n",
      "Batch: 19, Loss: 1.1767537593841553, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.0461764335632324, Accuracy: 0.669921875\n",
      "Batch: 21, Loss: 1.071338415145874, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.212292194366455, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.2228636741638184, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.0887749195098877, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.1074128150939941, Accuracy: 0.630859375\n",
      "Batch: 26, Loss: 1.1877602338790894, Accuracy: 0.609375\n",
      "Batch: 27, Loss: 1.0589375495910645, Accuracy: 0.6552734375\n",
      "Batch: 28, Loss: 1.0327467918395996, Accuracy: 0.654296875\n",
      "Batch: 29, Loss: 1.0429091453552246, Accuracy: 0.6494140625\n",
      "Batch: 30, Loss: 1.1210527420043945, Accuracy: 0.6328125\n",
      "Batch: 31, Loss: 1.17138671875, Accuracy: 0.623046875\n",
      "Batch: 32, Loss: 1.0306718349456787, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 0.9645613431930542, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.0945723056793213, Accuracy: 0.6455078125\n",
      "Batch: 35, Loss: 1.1390819549560547, Accuracy: 0.6318359375\n",
      "Batch: 36, Loss: 1.1783998012542725, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.172023892402649, Accuracy: 0.6201171875\n",
      "Batch: 38, Loss: 1.1064871549606323, Accuracy: 0.634765625\n",
      "Batch: 39, Loss: 1.028156042098999, Accuracy: 0.6611328125\n",
      "Batch: 40, Loss: 1.1005847454071045, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.0620331764221191, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.0018771886825562, Accuracy: 0.67578125\n",
      "Batch: 43, Loss: 1.0471733808517456, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 1.0118192434310913, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.046785593032837, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.12064790725708, Accuracy: 0.619140625\n",
      "Batch: 47, Loss: 1.024135947227478, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0990257263183594, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.1156935691833496, Accuracy: 0.640625\n",
      "Batch: 50, Loss: 1.0924348831176758, Accuracy: 0.6455078125\n",
      "Batch: 51, Loss: 1.1176759004592896, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.2069355249404907, Accuracy: 0.6337890625\n",
      "Batch: 53, Loss: 1.1251933574676514, Accuracy: 0.611328125\n",
      "Batch: 54, Loss: 1.0771911144256592, Accuracy: 0.640625\n",
      "Batch: 55, Loss: 1.0495036840438843, Accuracy: 0.6591796875\n",
      "Batch: 56, Loss: 1.0289908647537231, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 1.0948275327682495, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.0670320987701416, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 1.1278305053710938, Accuracy: 0.6298828125\n",
      "Batch: 60, Loss: 1.20731782913208, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.1407384872436523, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.1044321060180664, Accuracy: 0.6572265625\n",
      "Batch: 63, Loss: 1.0640432834625244, Accuracy: 0.6591796875\n",
      "Batch: 64, Loss: 1.1422785520553589, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1650242805480957, Accuracy: 0.60546875\n",
      "Batch: 66, Loss: 1.0972766876220703, Accuracy: 0.6552734375\n",
      "Batch: 67, Loss: 1.1143510341644287, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.062798023223877, Accuracy: 0.63671875\n",
      "Batch: 69, Loss: 1.120246171951294, Accuracy: 0.6416015625\n",
      "Batch: 70, Loss: 1.1383720636367798, Accuracy: 0.6162109375\n",
      "Batch: 71, Loss: 1.1205779314041138, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.144955039024353, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.129435420036316, Accuracy: 0.625\n",
      "Batch: 74, Loss: 1.0980446338653564, Accuracy: 0.62890625\n",
      "Batch: 75, Loss: 1.0430394411087036, Accuracy: 0.6328125\n",
      "Batch: 76, Loss: 1.0885206460952759, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 0.9959787726402283, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.1109734773635864, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.094313621520996, Accuracy: 0.6396484375\n",
      "Batch: 80, Loss: 1.1312206983566284, Accuracy: 0.64453125\n",
      "Batch: 81, Loss: 1.0938618183135986, Accuracy: 0.6484375\n",
      "Batch: 82, Loss: 1.1106927394866943, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.1816115379333496, Accuracy: 0.6376953125\n",
      "Batch: 84, Loss: 1.0748896598815918, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1779799461364746, Accuracy: 0.619140625\n",
      "Batch: 86, Loss: 1.146589756011963, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.078193187713623, Accuracy: 0.64453125\n",
      "Batch: 88, Loss: 1.1109013557434082, Accuracy: 0.6357421875\n",
      "Batch: 89, Loss: 1.0584990978240967, Accuracy: 0.6669921875\n",
      "Batch: 90, Loss: 1.0546627044677734, Accuracy: 0.6640625\n",
      "Batch: 91, Loss: 1.1019972562789917, Accuracy: 0.6259765625\n",
      "Batch: 92, Loss: 1.0779401063919067, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.1201167106628418, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.1770318746566772, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.1405627727508545, Accuracy: 0.6376953125\n",
      "Batch: 96, Loss: 1.167773962020874, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.1063427925109863, Accuracy: 0.634765625\n",
      "Batch: 98, Loss: 1.050150752067566, Accuracy: 0.662109375\n",
      "Batch: 99, Loss: 1.0467917919158936, Accuracy: 0.662109375\n",
      "Batch: 100, Loss: 1.0003080368041992, Accuracy: 0.6787109375\n",
      "Batch: 101, Loss: 1.052021861076355, Accuracy: 0.658203125\n",
      "Batch: 102, Loss: 1.135257601737976, Accuracy: 0.63671875\n",
      "Batch: 103, Loss: 1.0439647436141968, Accuracy: 0.67578125\n",
      "Batch: 104, Loss: 1.0773653984069824, Accuracy: 0.65625\n",
      "Batch: 105, Loss: 1.1489412784576416, Accuracy: 0.6396484375\n",
      "Batch: 106, Loss: 1.1413638591766357, Accuracy: 0.6318359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 1.1938486099243164, Accuracy: 0.6064453125\n",
      "Batch: 108, Loss: 1.1503396034240723, Accuracy: 0.6201171875\n",
      "Batch: 109, Loss: 1.15952730178833, Accuracy: 0.6044921875\n",
      "Batch: 110, Loss: 1.1100645065307617, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.0947738885879517, Accuracy: 0.6640625\n",
      "Batch: 112, Loss: 1.0455546379089355, Accuracy: 0.6640625\n",
      "Batch: 113, Loss: 1.1021182537078857, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.164720892906189, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.1688745021820068, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.1191232204437256, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.1339117288589478, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.199374794960022, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.1705193519592285, Accuracy: 0.630859375\n",
      "Batch: 120, Loss: 1.1318953037261963, Accuracy: 0.6396484375\n",
      "Batch: 121, Loss: 1.1878020763397217, Accuracy: 0.6181640625\n",
      "Batch: 122, Loss: 1.1493706703186035, Accuracy: 0.6396484375\n",
      "Batch: 123, Loss: 1.1244683265686035, Accuracy: 0.6318359375\n",
      "Batch: 124, Loss: 1.1152114868164062, Accuracy: 0.630859375\n",
      "Batch: 125, Loss: 1.1115522384643555, Accuracy: 0.6455078125\n",
      "Batch: 126, Loss: 1.199493169784546, Accuracy: 0.6279296875\n",
      "Batch: 127, Loss: 1.1499512195587158, Accuracy: 0.6376953125\n",
      "Batch: 128, Loss: 1.1592483520507812, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.1593316793441772, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.1446698904037476, Accuracy: 0.6044921875\n",
      "Batch: 131, Loss: 1.1561402082443237, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 0.9960914850234985, Accuracy: 0.681640625\n",
      "Batch: 133, Loss: 1.1241774559020996, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.0795178413391113, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.017346978187561, Accuracy: 0.666015625\n",
      "Batch: 136, Loss: 1.0333421230316162, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.081040620803833, Accuracy: 0.6328125\n",
      "Batch: 138, Loss: 1.1982102394104004, Accuracy: 0.615234375\n",
      "Batch: 139, Loss: 1.1265861988067627, Accuracy: 0.6376953125\n",
      "Batch: 140, Loss: 1.2447059154510498, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.1432803869247437, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.1683050394058228, Accuracy: 0.63671875\n",
      "Batch: 143, Loss: 1.1358447074890137, Accuracy: 0.642578125\n",
      "Batch: 144, Loss: 1.2450238466262817, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.1734293699264526, Accuracy: 0.6064453125\n",
      "Batch: 146, Loss: 1.2464768886566162, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.145229458808899, Accuracy: 0.6298828125\n",
      "Batch: 148, Loss: 1.167454719543457, Accuracy: 0.623046875\n",
      "Batch: 149, Loss: 1.095028281211853, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.1120498180389404, Accuracy: 0.6435546875\n",
      "Batch: 151, Loss: 1.1172089576721191, Accuracy: 0.6455078125\n",
      "Batch: 152, Loss: 1.1336586475372314, Accuracy: 0.6162109375\n",
      "Batch: 153, Loss: 1.0846121311187744, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.0374996662139893, Accuracy: 0.6630859375\n",
      "Batch: 155, Loss: 1.0675331354141235, Accuracy: 0.64453125\n",
      "Epoch 575/200\n",
      "Batch: 1, Loss: 1.1589908599853516, Accuracy: 0.6611328125\n",
      "Batch: 2, Loss: 1.0214849710464478, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.9934225082397461, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0743310451507568, Accuracy: 0.638671875\n",
      "Batch: 5, Loss: 1.0453605651855469, Accuracy: 0.6513671875\n",
      "Batch: 6, Loss: 0.9848676323890686, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 0.9733396768569946, Accuracy: 0.6806640625\n",
      "Batch: 8, Loss: 0.9175066947937012, Accuracy: 0.68359375\n",
      "Batch: 9, Loss: 0.9592479467391968, Accuracy: 0.7041015625\n",
      "Batch: 10, Loss: 0.9475784301757812, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 0.9588326215744019, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 1.0152461528778076, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 1.0373499393463135, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 0.9953821301460266, Accuracy: 0.6767578125\n",
      "Batch: 15, Loss: 0.9540458917617798, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.007370948791504, Accuracy: 0.669921875\n",
      "Batch: 17, Loss: 0.9865565896034241, Accuracy: 0.650390625\n",
      "Batch: 18, Loss: 1.1317416429519653, Accuracy: 0.6240234375\n",
      "Batch: 19, Loss: 1.131489634513855, Accuracy: 0.6376953125\n",
      "Batch: 20, Loss: 1.0254266262054443, Accuracy: 0.685546875\n",
      "Batch: 21, Loss: 1.0608021020889282, Accuracy: 0.64453125\n",
      "Batch: 22, Loss: 1.197891354560852, Accuracy: 0.6181640625\n",
      "Batch: 23, Loss: 1.1918859481811523, Accuracy: 0.615234375\n",
      "Batch: 24, Loss: 1.0882039070129395, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.134238839149475, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1988794803619385, Accuracy: 0.6064453125\n",
      "Batch: 27, Loss: 1.155687689781189, Accuracy: 0.6181640625\n",
      "Batch: 28, Loss: 1.0359441041946411, Accuracy: 0.66015625\n",
      "Batch: 29, Loss: 1.0409178733825684, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.1530853509902954, Accuracy: 0.6171875\n",
      "Batch: 31, Loss: 1.1315346956253052, Accuracy: 0.6220703125\n",
      "Batch: 32, Loss: 1.035520076751709, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 0.9492359161376953, Accuracy: 0.6953125\n",
      "Batch: 34, Loss: 1.0599215030670166, Accuracy: 0.671875\n",
      "Batch: 35, Loss: 1.1334373950958252, Accuracy: 0.642578125\n",
      "Batch: 36, Loss: 1.131827473640442, Accuracy: 0.6376953125\n",
      "Batch: 37, Loss: 1.1942660808563232, Accuracy: 0.603515625\n",
      "Batch: 38, Loss: 1.1634762287139893, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.0624611377716064, Accuracy: 0.646484375\n",
      "Batch: 40, Loss: 1.0039911270141602, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.0749567747116089, Accuracy: 0.634765625\n",
      "Batch: 42, Loss: 1.042318344116211, Accuracy: 0.6630859375\n",
      "Batch: 43, Loss: 1.0621874332427979, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.0199271440505981, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 1.0103241205215454, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 1.0714333057403564, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.0603642463684082, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1278716325759888, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.1669790744781494, Accuracy: 0.623046875\n",
      "Batch: 50, Loss: 1.0854089260101318, Accuracy: 0.6455078125\n",
      "Batch: 51, Loss: 1.0994162559509277, Accuracy: 0.630859375\n",
      "Batch: 52, Loss: 1.2033915519714355, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1190950870513916, Accuracy: 0.6298828125\n",
      "Batch: 54, Loss: 1.164780616760254, Accuracy: 0.6279296875\n",
      "Batch: 55, Loss: 1.0612865686416626, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.070028305053711, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.1051338911056519, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.0195764303207397, Accuracy: 0.6552734375\n",
      "Batch: 59, Loss: 1.067399501800537, Accuracy: 0.646484375\n",
      "Batch: 60, Loss: 1.1999917030334473, Accuracy: 0.6318359375\n",
      "Batch: 61, Loss: 1.0675837993621826, Accuracy: 0.634765625\n",
      "Batch: 62, Loss: 1.0963289737701416, Accuracy: 0.64453125\n",
      "Batch: 63, Loss: 1.1533808708190918, Accuracy: 0.6201171875\n",
      "Batch: 64, Loss: 1.131593942642212, Accuracy: 0.642578125\n",
      "Batch: 65, Loss: 1.1242196559906006, Accuracy: 0.615234375\n",
      "Batch: 66, Loss: 1.1214237213134766, Accuracy: 0.6357421875\n",
      "Batch: 67, Loss: 1.0869213342666626, Accuracy: 0.650390625\n",
      "Batch: 68, Loss: 1.0792582035064697, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.1399457454681396, Accuracy: 0.634765625\n",
      "Batch: 70, Loss: 1.0763566493988037, Accuracy: 0.6484375\n",
      "Batch: 71, Loss: 1.1369684934616089, Accuracy: 0.6171875\n",
      "Batch: 72, Loss: 1.146519660949707, Accuracy: 0.6337890625\n",
      "Batch: 73, Loss: 1.1246546506881714, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1654514074325562, Accuracy: 0.6025390625\n",
      "Batch: 75, Loss: 1.0913177728652954, Accuracy: 0.6357421875\n",
      "Batch: 76, Loss: 1.0685020685195923, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.0071682929992676, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.05275559425354, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.0830235481262207, Accuracy: 0.66015625\n",
      "Batch: 80, Loss: 1.1112990379333496, Accuracy: 0.634765625\n",
      "Batch: 81, Loss: 1.0585987567901611, Accuracy: 0.6572265625\n",
      "Batch: 82, Loss: 1.0991783142089844, Accuracy: 0.6533203125\n",
      "Batch: 83, Loss: 1.1770539283752441, Accuracy: 0.6240234375\n",
      "Batch: 84, Loss: 1.0792598724365234, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.1104567050933838, Accuracy: 0.6494140625\n",
      "Batch: 86, Loss: 1.0830360651016235, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 1.0815067291259766, Accuracy: 0.6513671875\n",
      "Batch: 88, Loss: 1.1133265495300293, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.0700079202651978, Accuracy: 0.646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 1.0533231496810913, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.0566946268081665, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.0977816581726074, Accuracy: 0.65625\n",
      "Batch: 93, Loss: 1.0947221517562866, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.20643949508667, Accuracy: 0.6279296875\n",
      "Batch: 95, Loss: 1.136000394821167, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.131284236907959, Accuracy: 0.6455078125\n",
      "Batch: 97, Loss: 1.1197876930236816, Accuracy: 0.6259765625\n",
      "Batch: 98, Loss: 1.092187762260437, Accuracy: 0.6533203125\n",
      "Batch: 99, Loss: 1.1315360069274902, Accuracy: 0.650390625\n",
      "Batch: 100, Loss: 1.0437196493148804, Accuracy: 0.662109375\n",
      "Batch: 101, Loss: 1.1131500005722046, Accuracy: 0.640625\n",
      "Batch: 102, Loss: 1.1203722953796387, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.080735683441162, Accuracy: 0.6474609375\n",
      "Batch: 104, Loss: 1.121212124824524, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.1607708930969238, Accuracy: 0.6376953125\n",
      "Batch: 106, Loss: 1.067158818244934, Accuracy: 0.6455078125\n",
      "Batch: 107, Loss: 1.1564452648162842, Accuracy: 0.626953125\n",
      "Batch: 108, Loss: 1.1690967082977295, Accuracy: 0.5849609375\n",
      "Batch: 109, Loss: 1.0991857051849365, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 1.1256579160690308, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.0917415618896484, Accuracy: 0.64453125\n",
      "Batch: 112, Loss: 0.9908219575881958, Accuracy: 0.6708984375\n",
      "Batch: 113, Loss: 1.1294996738433838, Accuracy: 0.640625\n",
      "Batch: 114, Loss: 1.1479637622833252, Accuracy: 0.6181640625\n",
      "Batch: 115, Loss: 1.1692581176757812, Accuracy: 0.61328125\n",
      "Batch: 116, Loss: 1.11968195438385, Accuracy: 0.6240234375\n",
      "Batch: 117, Loss: 1.1373968124389648, Accuracy: 0.642578125\n",
      "Batch: 118, Loss: 1.164433479309082, Accuracy: 0.615234375\n",
      "Batch: 119, Loss: 1.2142484188079834, Accuracy: 0.611328125\n",
      "Batch: 120, Loss: 1.2249106168746948, Accuracy: 0.6318359375\n",
      "Batch: 121, Loss: 1.1455559730529785, Accuracy: 0.6298828125\n",
      "Batch: 122, Loss: 1.2433326244354248, Accuracy: 0.59375\n",
      "Batch: 123, Loss: 1.182295560836792, Accuracy: 0.6396484375\n",
      "Batch: 124, Loss: 1.2015924453735352, Accuracy: 0.615234375\n",
      "Batch: 125, Loss: 1.153885006904602, Accuracy: 0.6474609375\n",
      "Batch: 126, Loss: 1.256208896636963, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.2312037944793701, Accuracy: 0.61328125\n",
      "Batch: 128, Loss: 1.1705479621887207, Accuracy: 0.6171875\n",
      "Batch: 129, Loss: 1.1345345973968506, Accuracy: 0.646484375\n",
      "Batch: 130, Loss: 1.0941731929779053, Accuracy: 0.6435546875\n",
      "Batch: 131, Loss: 1.165651798248291, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.0340825319290161, Accuracy: 0.6845703125\n",
      "Batch: 133, Loss: 1.1269049644470215, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.0961016416549683, Accuracy: 0.6494140625\n",
      "Batch: 135, Loss: 1.0247026681900024, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.0699290037155151, Accuracy: 0.666015625\n",
      "Batch: 137, Loss: 1.0673484802246094, Accuracy: 0.646484375\n",
      "Batch: 138, Loss: 1.1781319379806519, Accuracy: 0.5947265625\n",
      "Batch: 139, Loss: 1.1534030437469482, Accuracy: 0.6298828125\n",
      "Batch: 140, Loss: 1.192152976989746, Accuracy: 0.642578125\n",
      "Batch: 141, Loss: 1.101754903793335, Accuracy: 0.646484375\n",
      "Batch: 142, Loss: 1.08695387840271, Accuracy: 0.658203125\n",
      "Batch: 143, Loss: 1.1730289459228516, Accuracy: 0.6337890625\n",
      "Batch: 144, Loss: 1.2378406524658203, Accuracy: 0.59765625\n",
      "Batch: 145, Loss: 1.2523024082183838, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.1267588138580322, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.1950761079788208, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.1607301235198975, Accuracy: 0.623046875\n",
      "Batch: 149, Loss: 1.1083426475524902, Accuracy: 0.6279296875\n",
      "Batch: 150, Loss: 1.0886833667755127, Accuracy: 0.646484375\n",
      "Batch: 151, Loss: 1.0547714233398438, Accuracy: 0.65234375\n",
      "Batch: 152, Loss: 1.0817979574203491, Accuracy: 0.6396484375\n",
      "Batch: 153, Loss: 1.1075750589370728, Accuracy: 0.6328125\n",
      "Batch: 154, Loss: 1.0909727811813354, Accuracy: 0.662109375\n",
      "Batch: 155, Loss: 1.091786503791809, Accuracy: 0.6337890625\n",
      "Epoch 576/200\n",
      "Batch: 1, Loss: 1.204128623008728, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 0.9763918519020081, Accuracy: 0.685546875\n",
      "Batch: 3, Loss: 0.996467113494873, Accuracy: 0.6650390625\n",
      "Batch: 4, Loss: 1.0459182262420654, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 0.9761676788330078, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.025281310081482, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0087342262268066, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.9547867178916931, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9450548887252808, Accuracy: 0.7099609375\n",
      "Batch: 10, Loss: 0.9608360528945923, Accuracy: 0.689453125\n",
      "Batch: 11, Loss: 0.9578120112419128, Accuracy: 0.6787109375\n",
      "Batch: 12, Loss: 0.9476260542869568, Accuracy: 0.6875\n",
      "Batch: 13, Loss: 1.0371249914169312, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 0.8912570476531982, Accuracy: 0.72265625\n",
      "Batch: 15, Loss: 0.9482291340827942, Accuracy: 0.6865234375\n",
      "Batch: 16, Loss: 1.0095069408416748, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.0457751750946045, Accuracy: 0.662109375\n",
      "Batch: 18, Loss: 1.0877971649169922, Accuracy: 0.6484375\n",
      "Batch: 19, Loss: 1.269270896911621, Accuracy: 0.58984375\n",
      "Batch: 20, Loss: 1.0735108852386475, Accuracy: 0.654296875\n",
      "Batch: 21, Loss: 1.0636584758758545, Accuracy: 0.6376953125\n",
      "Batch: 22, Loss: 1.1442410945892334, Accuracy: 0.6484375\n",
      "Batch: 23, Loss: 1.1998822689056396, Accuracy: 0.59765625\n",
      "Batch: 24, Loss: 1.1104776859283447, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.1247916221618652, Accuracy: 0.64453125\n",
      "Batch: 26, Loss: 1.1643810272216797, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.133668065071106, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.0591765642166138, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.0538216829299927, Accuracy: 0.64453125\n",
      "Batch: 30, Loss: 1.154834270477295, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.1444718837738037, Accuracy: 0.61328125\n",
      "Batch: 32, Loss: 0.9870747327804565, Accuracy: 0.6689453125\n",
      "Batch: 33, Loss: 0.9498109817504883, Accuracy: 0.6875\n",
      "Batch: 34, Loss: 1.134200096130371, Accuracy: 0.625\n",
      "Batch: 35, Loss: 1.1118066310882568, Accuracy: 0.6298828125\n",
      "Batch: 36, Loss: 1.1947588920593262, Accuracy: 0.6083984375\n",
      "Batch: 37, Loss: 1.1487908363342285, Accuracy: 0.62109375\n",
      "Batch: 38, Loss: 1.179686188697815, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.0235356092453003, Accuracy: 0.642578125\n",
      "Batch: 40, Loss: 0.985501766204834, Accuracy: 0.677734375\n",
      "Batch: 41, Loss: 1.062558650970459, Accuracy: 0.6513671875\n",
      "Batch: 42, Loss: 1.0154564380645752, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 0.9940198063850403, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.0464838743209839, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 1.0100854635238647, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.115673542022705, Accuracy: 0.6328125\n",
      "Batch: 47, Loss: 1.075383186340332, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1073482036590576, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.1529436111450195, Accuracy: 0.6435546875\n",
      "Batch: 50, Loss: 1.0787485837936401, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.120779037475586, Accuracy: 0.6298828125\n",
      "Batch: 52, Loss: 1.1894993782043457, Accuracy: 0.623046875\n",
      "Batch: 53, Loss: 1.133540153503418, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.139275312423706, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.0443507432937622, Accuracy: 0.6728515625\n",
      "Batch: 56, Loss: 1.1560232639312744, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.0484535694122314, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.0829271078109741, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 1.0472700595855713, Accuracy: 0.6630859375\n",
      "Batch: 60, Loss: 1.2207911014556885, Accuracy: 0.6064453125\n",
      "Batch: 61, Loss: 1.1611403226852417, Accuracy: 0.6181640625\n",
      "Batch: 62, Loss: 1.1345057487487793, Accuracy: 0.6435546875\n",
      "Batch: 63, Loss: 1.1343135833740234, Accuracy: 0.6337890625\n",
      "Batch: 64, Loss: 1.13631010055542, Accuracy: 0.64453125\n",
      "Batch: 65, Loss: 1.1573094129562378, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.1116478443145752, Accuracy: 0.638671875\n",
      "Batch: 67, Loss: 1.1753839254379272, Accuracy: 0.6201171875\n",
      "Batch: 68, Loss: 1.0678101778030396, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.1417635679244995, Accuracy: 0.634765625\n",
      "Batch: 70, Loss: 1.1558250188827515, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.104721188545227, Accuracy: 0.6337890625\n",
      "Batch: 72, Loss: 1.178932785987854, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.1206011772155762, Accuracy: 0.640625\n",
      "Batch: 74, Loss: 1.0944852828979492, Accuracy: 0.654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 75, Loss: 1.0765748023986816, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.0591329336166382, Accuracy: 0.64453125\n",
      "Batch: 77, Loss: 0.9887758493423462, Accuracy: 0.6728515625\n",
      "Batch: 78, Loss: 1.020254135131836, Accuracy: 0.6630859375\n",
      "Batch: 79, Loss: 1.1396652460098267, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1413593292236328, Accuracy: 0.6455078125\n",
      "Batch: 81, Loss: 1.0697160959243774, Accuracy: 0.6396484375\n",
      "Batch: 82, Loss: 1.089752197265625, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 1.1516380310058594, Accuracy: 0.61328125\n",
      "Batch: 84, Loss: 1.082783579826355, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.0892798900604248, Accuracy: 0.6533203125\n",
      "Batch: 86, Loss: 1.1017321348190308, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.120820164680481, Accuracy: 0.64453125\n",
      "Batch: 88, Loss: 1.11013662815094, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.118175983428955, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0991313457489014, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.042070746421814, Accuracy: 0.640625\n",
      "Batch: 92, Loss: 1.064706563949585, Accuracy: 0.6591796875\n",
      "Batch: 93, Loss: 1.1470859050750732, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.1584421396255493, Accuracy: 0.62890625\n",
      "Batch: 95, Loss: 1.0923519134521484, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.1365563869476318, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.1345930099487305, Accuracy: 0.6357421875\n",
      "Batch: 98, Loss: 1.0842283964157104, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.1047829389572144, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 0.9761331081390381, Accuracy: 0.6845703125\n",
      "Batch: 101, Loss: 1.0871529579162598, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.1341379880905151, Accuracy: 0.638671875\n",
      "Batch: 103, Loss: 1.1121084690093994, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.1170926094055176, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.1711819171905518, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.1116454601287842, Accuracy: 0.6474609375\n",
      "Batch: 107, Loss: 1.1402769088745117, Accuracy: 0.6240234375\n",
      "Batch: 108, Loss: 1.1177966594696045, Accuracy: 0.63671875\n",
      "Batch: 109, Loss: 1.146364450454712, Accuracy: 0.615234375\n",
      "Batch: 110, Loss: 1.1183784008026123, Accuracy: 0.630859375\n",
      "Batch: 111, Loss: 1.0649495124816895, Accuracy: 0.6630859375\n",
      "Batch: 112, Loss: 1.0357000827789307, Accuracy: 0.6494140625\n",
      "Batch: 113, Loss: 1.061992883682251, Accuracy: 0.6357421875\n",
      "Batch: 114, Loss: 1.163480520248413, Accuracy: 0.6171875\n",
      "Batch: 115, Loss: 1.14003586769104, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.1426053047180176, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1402623653411865, Accuracy: 0.6201171875\n",
      "Batch: 118, Loss: 1.1642372608184814, Accuracy: 0.599609375\n",
      "Batch: 119, Loss: 1.2095328569412231, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.2397805452346802, Accuracy: 0.6103515625\n",
      "Batch: 121, Loss: 1.1455841064453125, Accuracy: 0.623046875\n",
      "Batch: 122, Loss: 1.138378620147705, Accuracy: 0.625\n",
      "Batch: 123, Loss: 1.095177173614502, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.1860442161560059, Accuracy: 0.611328125\n",
      "Batch: 125, Loss: 1.1139883995056152, Accuracy: 0.6337890625\n",
      "Batch: 126, Loss: 1.2195491790771484, Accuracy: 0.6181640625\n",
      "Batch: 127, Loss: 1.1823220252990723, Accuracy: 0.630859375\n",
      "Batch: 128, Loss: 1.1623656749725342, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.1974358558654785, Accuracy: 0.6064453125\n",
      "Batch: 130, Loss: 1.0645414590835571, Accuracy: 0.65234375\n",
      "Batch: 131, Loss: 1.1586681604385376, Accuracy: 0.625\n",
      "Batch: 132, Loss: 1.0740323066711426, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 1.1492732763290405, Accuracy: 0.6015625\n",
      "Batch: 134, Loss: 1.0522946119308472, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 1.0124398469924927, Accuracy: 0.65234375\n",
      "Batch: 136, Loss: 1.0613081455230713, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.1708736419677734, Accuracy: 0.615234375\n",
      "Batch: 138, Loss: 1.1985750198364258, Accuracy: 0.61328125\n",
      "Batch: 139, Loss: 1.1532665491104126, Accuracy: 0.6298828125\n",
      "Batch: 140, Loss: 1.204263687133789, Accuracy: 0.6181640625\n",
      "Batch: 141, Loss: 1.108431100845337, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1552324295043945, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.1208853721618652, Accuracy: 0.6474609375\n",
      "Batch: 144, Loss: 1.2439675331115723, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.1976678371429443, Accuracy: 0.625\n",
      "Batch: 146, Loss: 1.1813169717788696, Accuracy: 0.6181640625\n",
      "Batch: 147, Loss: 1.1827054023742676, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.1480660438537598, Accuracy: 0.6044921875\n",
      "Batch: 149, Loss: 1.1182994842529297, Accuracy: 0.6328125\n",
      "Batch: 150, Loss: 1.148025393486023, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.148195505142212, Accuracy: 0.6220703125\n",
      "Batch: 152, Loss: 1.1134226322174072, Accuracy: 0.63671875\n",
      "Batch: 153, Loss: 1.0915560722351074, Accuracy: 0.6328125\n",
      "Batch: 154, Loss: 1.1162256002426147, Accuracy: 0.634765625\n",
      "Batch: 155, Loss: 1.081905722618103, Accuracy: 0.650390625\n",
      "Epoch 577/200\n",
      "Batch: 1, Loss: 1.2401158809661865, Accuracy: 0.62890625\n",
      "Batch: 2, Loss: 1.0284206867218018, Accuracy: 0.650390625\n",
      "Batch: 3, Loss: 1.0325497388839722, Accuracy: 0.662109375\n",
      "Batch: 4, Loss: 1.0729141235351562, Accuracy: 0.6318359375\n",
      "Batch: 5, Loss: 0.9848388433456421, Accuracy: 0.6826171875\n",
      "Batch: 6, Loss: 1.0323905944824219, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 1.0213779211044312, Accuracy: 0.6640625\n",
      "Batch: 8, Loss: 0.9486647844314575, Accuracy: 0.697265625\n",
      "Batch: 9, Loss: 1.024885892868042, Accuracy: 0.66015625\n",
      "Batch: 10, Loss: 0.9097640514373779, Accuracy: 0.7099609375\n",
      "Batch: 11, Loss: 0.9267911911010742, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 1.0309909582138062, Accuracy: 0.646484375\n",
      "Batch: 13, Loss: 0.9587916135787964, Accuracy: 0.6748046875\n",
      "Batch: 14, Loss: 0.9127745032310486, Accuracy: 0.6982421875\n",
      "Batch: 15, Loss: 0.9470677375793457, Accuracy: 0.6806640625\n",
      "Batch: 16, Loss: 0.9805353879928589, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 1.0233280658721924, Accuracy: 0.6533203125\n",
      "Batch: 18, Loss: 1.0664646625518799, Accuracy: 0.65234375\n",
      "Batch: 19, Loss: 1.1752299070358276, Accuracy: 0.623046875\n",
      "Batch: 20, Loss: 1.075295090675354, Accuracy: 0.6708984375\n",
      "Batch: 21, Loss: 1.0198571681976318, Accuracy: 0.6669921875\n",
      "Batch: 22, Loss: 1.2183964252471924, Accuracy: 0.5888671875\n",
      "Batch: 23, Loss: 1.1401857137680054, Accuracy: 0.630859375\n",
      "Batch: 24, Loss: 1.0523386001586914, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.1125421524047852, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.1791799068450928, Accuracy: 0.61328125\n",
      "Batch: 27, Loss: 1.0661306381225586, Accuracy: 0.6396484375\n",
      "Batch: 28, Loss: 1.010083556175232, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.0500943660736084, Accuracy: 0.6640625\n",
      "Batch: 30, Loss: 1.0817490816116333, Accuracy: 0.6376953125\n",
      "Batch: 31, Loss: 1.1600722074508667, Accuracy: 0.6142578125\n",
      "Batch: 32, Loss: 1.0084421634674072, Accuracy: 0.6767578125\n",
      "Batch: 33, Loss: 0.9788333177566528, Accuracy: 0.673828125\n",
      "Batch: 34, Loss: 1.0179526805877686, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 1.0810831785202026, Accuracy: 0.646484375\n",
      "Batch: 36, Loss: 1.1730146408081055, Accuracy: 0.6015625\n",
      "Batch: 37, Loss: 1.1958205699920654, Accuracy: 0.5947265625\n",
      "Batch: 38, Loss: 1.1320936679840088, Accuracy: 0.654296875\n",
      "Batch: 39, Loss: 1.015381097793579, Accuracy: 0.6748046875\n",
      "Batch: 40, Loss: 1.0833609104156494, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.1073150634765625, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0472464561462402, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 0.9936174154281616, Accuracy: 0.6640625\n",
      "Batch: 44, Loss: 0.9730421304702759, Accuracy: 0.6923828125\n",
      "Batch: 45, Loss: 0.9880239367485046, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.1111242771148682, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.038006067276001, Accuracy: 0.677734375\n",
      "Batch: 48, Loss: 1.10516357421875, Accuracy: 0.646484375\n",
      "Batch: 49, Loss: 1.1740460395812988, Accuracy: 0.630859375\n",
      "Batch: 50, Loss: 1.0984275341033936, Accuracy: 0.6396484375\n",
      "Batch: 51, Loss: 1.1343101263046265, Accuracy: 0.640625\n",
      "Batch: 52, Loss: 1.2086243629455566, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1714876890182495, Accuracy: 0.611328125\n",
      "Batch: 54, Loss: 1.1503534317016602, Accuracy: 0.6474609375\n",
      "Batch: 55, Loss: 1.0549798011779785, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.065192699432373, Accuracy: 0.662109375\n",
      "Batch: 57, Loss: 1.1006238460540771, Accuracy: 0.6572265625\n",
      "Batch: 58, Loss: 1.0431770086288452, Accuracy: 0.6689453125\n",
      "Batch: 59, Loss: 1.0818796157836914, Accuracy: 0.6630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 1.182604193687439, Accuracy: 0.6181640625\n",
      "Batch: 61, Loss: 1.0603692531585693, Accuracy: 0.646484375\n",
      "Batch: 62, Loss: 1.1382226943969727, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.1388881206512451, Accuracy: 0.6279296875\n",
      "Batch: 64, Loss: 1.1888580322265625, Accuracy: 0.5966796875\n",
      "Batch: 65, Loss: 1.1541166305541992, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.1006946563720703, Accuracy: 0.6484375\n",
      "Batch: 67, Loss: 1.1517974138259888, Accuracy: 0.640625\n",
      "Batch: 68, Loss: 1.0426146984100342, Accuracy: 0.6650390625\n",
      "Batch: 69, Loss: 1.146905779838562, Accuracy: 0.607421875\n",
      "Batch: 70, Loss: 1.0968084335327148, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.0880893468856812, Accuracy: 0.6533203125\n",
      "Batch: 72, Loss: 1.2139201164245605, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.1192001104354858, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.062333106994629, Accuracy: 0.654296875\n",
      "Batch: 75, Loss: 1.0768392086029053, Accuracy: 0.6591796875\n",
      "Batch: 76, Loss: 1.029078722000122, Accuracy: 0.6669921875\n",
      "Batch: 77, Loss: 1.025969386100769, Accuracy: 0.6748046875\n",
      "Batch: 78, Loss: 1.0499639511108398, Accuracy: 0.658203125\n",
      "Batch: 79, Loss: 1.090085744857788, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.1195552349090576, Accuracy: 0.6533203125\n",
      "Batch: 81, Loss: 1.1007635593414307, Accuracy: 0.6298828125\n",
      "Batch: 82, Loss: 1.102782130241394, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.1023237705230713, Accuracy: 0.6484375\n",
      "Batch: 84, Loss: 1.0576363801956177, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.141758680343628, Accuracy: 0.6435546875\n",
      "Batch: 86, Loss: 1.11762273311615, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 1.121342420578003, Accuracy: 0.6357421875\n",
      "Batch: 88, Loss: 1.102843165397644, Accuracy: 0.6513671875\n",
      "Batch: 89, Loss: 1.0919618606567383, Accuracy: 0.6611328125\n",
      "Batch: 90, Loss: 1.001702070236206, Accuracy: 0.66015625\n",
      "Batch: 91, Loss: 1.1218576431274414, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1011877059936523, Accuracy: 0.63671875\n",
      "Batch: 93, Loss: 1.1489019393920898, Accuracy: 0.6220703125\n",
      "Batch: 94, Loss: 1.1867561340332031, Accuracy: 0.619140625\n",
      "Batch: 95, Loss: 1.1285107135772705, Accuracy: 0.640625\n",
      "Batch: 96, Loss: 1.1181364059448242, Accuracy: 0.6376953125\n",
      "Batch: 97, Loss: 1.1319844722747803, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.0775730609893799, Accuracy: 0.6591796875\n",
      "Batch: 99, Loss: 1.1001263856887817, Accuracy: 0.6484375\n",
      "Batch: 100, Loss: 1.0238996744155884, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 1.0138286352157593, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 1.1485509872436523, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.129835605621338, Accuracy: 0.6298828125\n",
      "Batch: 104, Loss: 1.0899975299835205, Accuracy: 0.6640625\n",
      "Batch: 105, Loss: 1.1956908702850342, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1203227043151855, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.159930944442749, Accuracy: 0.6201171875\n",
      "Batch: 108, Loss: 1.074631690979004, Accuracy: 0.662109375\n",
      "Batch: 109, Loss: 1.1849396228790283, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 1.1220258474349976, Accuracy: 0.6298828125\n",
      "Batch: 111, Loss: 1.087010145187378, Accuracy: 0.642578125\n",
      "Batch: 112, Loss: 1.0641638040542603, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.112511396408081, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.1345980167388916, Accuracy: 0.625\n",
      "Batch: 115, Loss: 1.1794179677963257, Accuracy: 0.60546875\n",
      "Batch: 116, Loss: 1.164949655532837, Accuracy: 0.6171875\n",
      "Batch: 117, Loss: 1.1743773221969604, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 1.1958329677581787, Accuracy: 0.6220703125\n",
      "Batch: 119, Loss: 1.1783092021942139, Accuracy: 0.626953125\n",
      "Batch: 120, Loss: 1.2225955724716187, Accuracy: 0.630859375\n",
      "Batch: 121, Loss: 1.1403834819793701, Accuracy: 0.6259765625\n",
      "Batch: 122, Loss: 1.1856286525726318, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.1556079387664795, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.2346491813659668, Accuracy: 0.595703125\n",
      "Batch: 125, Loss: 1.092306137084961, Accuracy: 0.6259765625\n",
      "Batch: 126, Loss: 1.1259006261825562, Accuracy: 0.63671875\n",
      "Batch: 127, Loss: 1.1765342950820923, Accuracy: 0.603515625\n",
      "Batch: 128, Loss: 1.1532567739486694, Accuracy: 0.6357421875\n",
      "Batch: 129, Loss: 1.1126387119293213, Accuracy: 0.6455078125\n",
      "Batch: 130, Loss: 1.1197950839996338, Accuracy: 0.6328125\n",
      "Batch: 131, Loss: 1.1686997413635254, Accuracy: 0.6162109375\n",
      "Batch: 132, Loss: 1.015420913696289, Accuracy: 0.68359375\n",
      "Batch: 133, Loss: 1.1085002422332764, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.043205976486206, Accuracy: 0.6669921875\n",
      "Batch: 135, Loss: 1.0085549354553223, Accuracy: 0.6787109375\n",
      "Batch: 136, Loss: 1.051241397857666, Accuracy: 0.66015625\n",
      "Batch: 137, Loss: 1.094020962715149, Accuracy: 0.6513671875\n",
      "Batch: 138, Loss: 1.208630919456482, Accuracy: 0.619140625\n",
      "Batch: 139, Loss: 1.1037099361419678, Accuracy: 0.638671875\n",
      "Batch: 140, Loss: 1.1918456554412842, Accuracy: 0.6201171875\n",
      "Batch: 141, Loss: 1.1507771015167236, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.136651873588562, Accuracy: 0.630859375\n",
      "Batch: 143, Loss: 1.1432877779006958, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.216220736503601, Accuracy: 0.6005859375\n",
      "Batch: 145, Loss: 1.1711854934692383, Accuracy: 0.60546875\n",
      "Batch: 146, Loss: 1.1160390377044678, Accuracy: 0.6376953125\n",
      "Batch: 147, Loss: 1.1606037616729736, Accuracy: 0.6318359375\n",
      "Batch: 148, Loss: 1.1423888206481934, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.1719943284988403, Accuracy: 0.603515625\n",
      "Batch: 150, Loss: 1.1212291717529297, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.0953593254089355, Accuracy: 0.6484375\n",
      "Batch: 152, Loss: 1.061449408531189, Accuracy: 0.6494140625\n",
      "Batch: 153, Loss: 1.0923268795013428, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.0993411540985107, Accuracy: 0.6298828125\n",
      "Batch: 155, Loss: 1.091315507888794, Accuracy: 0.64453125\n",
      "Epoch 578/200\n",
      "Batch: 1, Loss: 1.1570091247558594, Accuracy: 0.6728515625\n",
      "Batch: 2, Loss: 1.0584038496017456, Accuracy: 0.6533203125\n",
      "Batch: 3, Loss: 1.0065414905548096, Accuracy: 0.685546875\n",
      "Batch: 4, Loss: 1.0523648262023926, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 0.9649502038955688, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 0.981332004070282, Accuracy: 0.68359375\n",
      "Batch: 7, Loss: 0.9973710775375366, Accuracy: 0.65625\n",
      "Batch: 8, Loss: 1.0047638416290283, Accuracy: 0.6826171875\n",
      "Batch: 9, Loss: 1.004512071609497, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 0.9698355197906494, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 0.9494001269340515, Accuracy: 0.677734375\n",
      "Batch: 12, Loss: 0.9677923321723938, Accuracy: 0.6826171875\n",
      "Batch: 13, Loss: 1.0101940631866455, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9131574034690857, Accuracy: 0.6962890625\n",
      "Batch: 15, Loss: 0.9187544584274292, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 1.0130046606063843, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.0039284229278564, Accuracy: 0.6591796875\n",
      "Batch: 18, Loss: 1.0781323909759521, Accuracy: 0.650390625\n",
      "Batch: 19, Loss: 1.1611034870147705, Accuracy: 0.6220703125\n",
      "Batch: 20, Loss: 1.0903799533843994, Accuracy: 0.6640625\n",
      "Batch: 21, Loss: 1.0443466901779175, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1743478775024414, Accuracy: 0.62109375\n",
      "Batch: 23, Loss: 1.2164772748947144, Accuracy: 0.5908203125\n",
      "Batch: 24, Loss: 1.0794994831085205, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.1138337850570679, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.1118437051773071, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.0238571166992188, Accuracy: 0.6591796875\n",
      "Batch: 28, Loss: 1.0704233646392822, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 1.0563695430755615, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 1.1883430480957031, Accuracy: 0.609375\n",
      "Batch: 31, Loss: 1.2043606042861938, Accuracy: 0.611328125\n",
      "Batch: 32, Loss: 1.0076169967651367, Accuracy: 0.662109375\n",
      "Batch: 33, Loss: 1.0046157836914062, Accuracy: 0.66796875\n",
      "Batch: 34, Loss: 1.054476022720337, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.1075835227966309, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.2175977230072021, Accuracy: 0.5849609375\n",
      "Batch: 37, Loss: 1.1467485427856445, Accuracy: 0.630859375\n",
      "Batch: 38, Loss: 1.1503746509552002, Accuracy: 0.630859375\n",
      "Batch: 39, Loss: 1.0856785774230957, Accuracy: 0.65234375\n",
      "Batch: 40, Loss: 1.0510060787200928, Accuracy: 0.66015625\n",
      "Batch: 41, Loss: 1.1125435829162598, Accuracy: 0.6484375\n",
      "Batch: 42, Loss: 1.0744520425796509, Accuracy: 0.66015625\n",
      "Batch: 43, Loss: 1.0309641361236572, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 1.0153567790985107, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 1.0153601169586182, Accuracy: 0.673828125\n",
      "Batch: 46, Loss: 1.0424422025680542, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.034513235092163, Accuracy: 0.6591796875\n",
      "Batch: 48, Loss: 1.104529857635498, Accuracy: 0.634765625\n",
      "Batch: 49, Loss: 1.1466865539550781, Accuracy: 0.60546875\n",
      "Batch: 50, Loss: 1.1297717094421387, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.1237064599990845, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.1835839748382568, Accuracy: 0.61328125\n",
      "Batch: 53, Loss: 1.1531178951263428, Accuracy: 0.6083984375\n",
      "Batch: 54, Loss: 1.0874159336090088, Accuracy: 0.642578125\n",
      "Batch: 55, Loss: 1.101905107498169, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.093432903289795, Accuracy: 0.646484375\n",
      "Batch: 57, Loss: 1.1019275188446045, Accuracy: 0.6533203125\n",
      "Batch: 58, Loss: 1.0810154676437378, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.0657047033309937, Accuracy: 0.6474609375\n",
      "Batch: 60, Loss: 1.1408172845840454, Accuracy: 0.6376953125\n",
      "Batch: 61, Loss: 1.1066434383392334, Accuracy: 0.6298828125\n",
      "Batch: 62, Loss: 1.1334679126739502, Accuracy: 0.6416015625\n",
      "Batch: 63, Loss: 1.122326374053955, Accuracy: 0.65234375\n",
      "Batch: 64, Loss: 1.191856861114502, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1062712669372559, Accuracy: 0.638671875\n",
      "Batch: 66, Loss: 1.0846922397613525, Accuracy: 0.6435546875\n",
      "Batch: 67, Loss: 1.1276092529296875, Accuracy: 0.6435546875\n",
      "Batch: 68, Loss: 1.0727884769439697, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.138452410697937, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.1312991380691528, Accuracy: 0.6279296875\n",
      "Batch: 71, Loss: 1.1084253787994385, Accuracy: 0.6474609375\n",
      "Batch: 72, Loss: 1.174426555633545, Accuracy: 0.623046875\n",
      "Batch: 73, Loss: 1.1351191997528076, Accuracy: 0.6259765625\n",
      "Batch: 74, Loss: 1.1127288341522217, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.1124173402786255, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.0428086519241333, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 1.048750638961792, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.08268141746521, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.0570201873779297, Accuracy: 0.662109375\n",
      "Batch: 80, Loss: 1.104846477508545, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.035361409187317, Accuracy: 0.6669921875\n",
      "Batch: 82, Loss: 1.0992717742919922, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 1.1356146335601807, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.0738255977630615, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.1469610929489136, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1662609577178955, Accuracy: 0.6220703125\n",
      "Batch: 87, Loss: 1.0999627113342285, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.0938234329223633, Accuracy: 0.654296875\n",
      "Batch: 89, Loss: 1.0919723510742188, Accuracy: 0.66796875\n",
      "Batch: 90, Loss: 1.0715363025665283, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.1952259540557861, Accuracy: 0.5986328125\n",
      "Batch: 92, Loss: 1.130544662475586, Accuracy: 0.6396484375\n",
      "Batch: 93, Loss: 1.0769283771514893, Accuracy: 0.650390625\n",
      "Batch: 94, Loss: 1.16299307346344, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.092343807220459, Accuracy: 0.6337890625\n",
      "Batch: 96, Loss: 1.187510371208191, Accuracy: 0.6357421875\n",
      "Batch: 97, Loss: 1.1556179523468018, Accuracy: 0.609375\n",
      "Batch: 98, Loss: 1.0949220657348633, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1237118244171143, Accuracy: 0.630859375\n",
      "Batch: 100, Loss: 1.0963685512542725, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.0744001865386963, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 1.0792474746704102, Accuracy: 0.63671875\n",
      "Batch: 103, Loss: 1.162392258644104, Accuracy: 0.6396484375\n",
      "Batch: 104, Loss: 1.1583878993988037, Accuracy: 0.6259765625\n",
      "Batch: 105, Loss: 1.1744099855422974, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.1582269668579102, Accuracy: 0.630859375\n",
      "Batch: 107, Loss: 1.2975670099258423, Accuracy: 0.564453125\n",
      "Batch: 108, Loss: 1.1561954021453857, Accuracy: 0.6220703125\n",
      "Batch: 109, Loss: 1.1514382362365723, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1081569194793701, Accuracy: 0.6376953125\n",
      "Batch: 111, Loss: 1.0892488956451416, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.0904819965362549, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.1389662027359009, Accuracy: 0.640625\n",
      "Batch: 114, Loss: 1.1351768970489502, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.181794285774231, Accuracy: 0.6171875\n",
      "Batch: 116, Loss: 1.149909496307373, Accuracy: 0.6103515625\n",
      "Batch: 117, Loss: 1.1312448978424072, Accuracy: 0.6220703125\n",
      "Batch: 118, Loss: 1.1185322999954224, Accuracy: 0.6220703125\n",
      "Batch: 119, Loss: 1.2258098125457764, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.2736214399337769, Accuracy: 0.5908203125\n",
      "Batch: 121, Loss: 1.152190923690796, Accuracy: 0.626953125\n",
      "Batch: 122, Loss: 1.187580943107605, Accuracy: 0.61328125\n",
      "Batch: 123, Loss: 1.1000862121582031, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.2177293300628662, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1441082954406738, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.1974278688430786, Accuracy: 0.6025390625\n",
      "Batch: 127, Loss: 1.2409899234771729, Accuracy: 0.58984375\n",
      "Batch: 128, Loss: 1.1515130996704102, Accuracy: 0.6201171875\n",
      "Batch: 129, Loss: 1.1687560081481934, Accuracy: 0.6396484375\n",
      "Batch: 130, Loss: 1.1762752532958984, Accuracy: 0.6181640625\n",
      "Batch: 131, Loss: 1.2165098190307617, Accuracy: 0.61328125\n",
      "Batch: 132, Loss: 1.103027582168579, Accuracy: 0.6455078125\n",
      "Batch: 133, Loss: 1.123390793800354, Accuracy: 0.65234375\n",
      "Batch: 134, Loss: 1.088808536529541, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 0.9780842065811157, Accuracy: 0.6826171875\n",
      "Batch: 136, Loss: 1.0687229633331299, Accuracy: 0.6611328125\n",
      "Batch: 137, Loss: 1.1011821031570435, Accuracy: 0.6455078125\n",
      "Batch: 138, Loss: 1.1887972354888916, Accuracy: 0.5986328125\n",
      "Batch: 139, Loss: 1.1939940452575684, Accuracy: 0.6259765625\n",
      "Batch: 140, Loss: 1.1676077842712402, Accuracy: 0.630859375\n",
      "Batch: 141, Loss: 1.0938034057617188, Accuracy: 0.6259765625\n",
      "Batch: 142, Loss: 1.2006330490112305, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.1597213745117188, Accuracy: 0.625\n",
      "Batch: 144, Loss: 1.2025353908538818, Accuracy: 0.6220703125\n",
      "Batch: 145, Loss: 1.1764185428619385, Accuracy: 0.619140625\n",
      "Batch: 146, Loss: 1.1661462783813477, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.1618229150772095, Accuracy: 0.62890625\n",
      "Batch: 148, Loss: 1.217353343963623, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.167229175567627, Accuracy: 0.6064453125\n",
      "Batch: 150, Loss: 1.110372543334961, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.1274691820144653, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1523772478103638, Accuracy: 0.6220703125\n",
      "Batch: 153, Loss: 1.0825423002243042, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.1072008609771729, Accuracy: 0.6494140625\n",
      "Batch: 155, Loss: 1.052141547203064, Accuracy: 0.658203125\n",
      "Epoch 579/200\n",
      "Batch: 1, Loss: 1.1147483587265015, Accuracy: 0.6728515625\n",
      "Batch: 2, Loss: 1.0397950410842896, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 0.9821022748947144, Accuracy: 0.6796875\n",
      "Batch: 4, Loss: 1.0723235607147217, Accuracy: 0.630859375\n",
      "Batch: 5, Loss: 0.9941400289535522, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0090502500534058, Accuracy: 0.669921875\n",
      "Batch: 7, Loss: 0.9954589605331421, Accuracy: 0.6806640625\n",
      "Batch: 8, Loss: 0.9471602439880371, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 1.0028917789459229, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 0.9164578318595886, Accuracy: 0.7119140625\n",
      "Batch: 11, Loss: 0.9283306002616882, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.9712990522384644, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 0.9896465539932251, Accuracy: 0.6962890625\n",
      "Batch: 14, Loss: 0.9654228687286377, Accuracy: 0.68359375\n",
      "Batch: 15, Loss: 0.934222936630249, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0520610809326172, Accuracy: 0.650390625\n",
      "Batch: 17, Loss: 1.014174461364746, Accuracy: 0.681640625\n",
      "Batch: 18, Loss: 1.0980618000030518, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.177945852279663, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.0683228969573975, Accuracy: 0.6728515625\n",
      "Batch: 21, Loss: 1.0810739994049072, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.228865385055542, Accuracy: 0.6220703125\n",
      "Batch: 23, Loss: 1.1850180625915527, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.0766626596450806, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.0912408828735352, Accuracy: 0.6533203125\n",
      "Batch: 26, Loss: 1.1534299850463867, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.0975205898284912, Accuracy: 0.6474609375\n",
      "Batch: 28, Loss: 1.0777994394302368, Accuracy: 0.6298828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 1.0736877918243408, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.1359525918960571, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.2175602912902832, Accuracy: 0.5947265625\n",
      "Batch: 32, Loss: 1.0115327835083008, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 1.0057108402252197, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.0707988739013672, Accuracy: 0.6494140625\n",
      "Batch: 35, Loss: 1.1216580867767334, Accuracy: 0.6162109375\n",
      "Batch: 36, Loss: 1.145999789237976, Accuracy: 0.6162109375\n",
      "Batch: 37, Loss: 1.1587722301483154, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.1367714405059814, Accuracy: 0.625\n",
      "Batch: 39, Loss: 1.0585616827011108, Accuracy: 0.65234375\n",
      "Batch: 40, Loss: 1.046245813369751, Accuracy: 0.6611328125\n",
      "Batch: 41, Loss: 1.105078935623169, Accuracy: 0.6376953125\n",
      "Batch: 42, Loss: 1.0205070972442627, Accuracy: 0.658203125\n",
      "Batch: 43, Loss: 1.0729401111602783, Accuracy: 0.6513671875\n",
      "Batch: 44, Loss: 1.045553207397461, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0757572650909424, Accuracy: 0.6328125\n",
      "Batch: 46, Loss: 1.0892143249511719, Accuracy: 0.6396484375\n",
      "Batch: 47, Loss: 1.0228179693222046, Accuracy: 0.6767578125\n",
      "Batch: 48, Loss: 1.109747290611267, Accuracy: 0.642578125\n",
      "Batch: 49, Loss: 1.1609541177749634, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.1299793720245361, Accuracy: 0.6298828125\n",
      "Batch: 51, Loss: 1.1172407865524292, Accuracy: 0.6201171875\n",
      "Batch: 52, Loss: 1.217215895652771, Accuracy: 0.59375\n",
      "Batch: 53, Loss: 1.1009225845336914, Accuracy: 0.6552734375\n",
      "Batch: 54, Loss: 1.1865177154541016, Accuracy: 0.5966796875\n",
      "Batch: 55, Loss: 1.061779260635376, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.095144510269165, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.1011927127838135, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.0434482097625732, Accuracy: 0.6513671875\n",
      "Batch: 59, Loss: 1.0836241245269775, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.199042797088623, Accuracy: 0.6435546875\n",
      "Batch: 61, Loss: 1.135561227798462, Accuracy: 0.638671875\n",
      "Batch: 62, Loss: 1.1095443964004517, Accuracy: 0.6318359375\n",
      "Batch: 63, Loss: 1.1757621765136719, Accuracy: 0.6279296875\n",
      "Batch: 64, Loss: 1.18743896484375, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1722959280014038, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.0797815322875977, Accuracy: 0.650390625\n",
      "Batch: 67, Loss: 1.1408735513687134, Accuracy: 0.6474609375\n",
      "Batch: 68, Loss: 1.0803337097167969, Accuracy: 0.634765625\n",
      "Batch: 69, Loss: 1.1357098817825317, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.159057378768921, Accuracy: 0.6142578125\n",
      "Batch: 71, Loss: 1.038294792175293, Accuracy: 0.6640625\n",
      "Batch: 72, Loss: 1.1800694465637207, Accuracy: 0.6171875\n",
      "Batch: 73, Loss: 1.129178524017334, Accuracy: 0.64453125\n",
      "Batch: 74, Loss: 1.1079212427139282, Accuracy: 0.654296875\n",
      "Batch: 75, Loss: 1.064079761505127, Accuracy: 0.6689453125\n",
      "Batch: 76, Loss: 1.0268059968948364, Accuracy: 0.66015625\n",
      "Batch: 77, Loss: 1.0413339138031006, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.0726172924041748, Accuracy: 0.6533203125\n",
      "Batch: 79, Loss: 1.0957450866699219, Accuracy: 0.642578125\n",
      "Batch: 80, Loss: 1.1291372776031494, Accuracy: 0.6455078125\n",
      "Batch: 81, Loss: 1.0639315843582153, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.1007622480392456, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.2032248973846436, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.0394620895385742, Accuracy: 0.673828125\n",
      "Batch: 85, Loss: 1.0958088636398315, Accuracy: 0.6455078125\n",
      "Batch: 86, Loss: 1.1289702653884888, Accuracy: 0.625\n",
      "Batch: 87, Loss: 1.1322541236877441, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.120529055595398, Accuracy: 0.6474609375\n",
      "Batch: 89, Loss: 1.093573808670044, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0659291744232178, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.0767203569412231, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.0444695949554443, Accuracy: 0.65234375\n",
      "Batch: 93, Loss: 1.1113325357437134, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.189467191696167, Accuracy: 0.6103515625\n",
      "Batch: 95, Loss: 1.1752502918243408, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.1654032468795776, Accuracy: 0.6318359375\n",
      "Batch: 97, Loss: 1.1594665050506592, Accuracy: 0.615234375\n",
      "Batch: 98, Loss: 1.132643222808838, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.135122537612915, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.0212194919586182, Accuracy: 0.66796875\n",
      "Batch: 101, Loss: 1.0843651294708252, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.155996322631836, Accuracy: 0.630859375\n",
      "Batch: 103, Loss: 1.171670913696289, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.1259899139404297, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.1811282634735107, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.1587797403335571, Accuracy: 0.6357421875\n",
      "Batch: 107, Loss: 1.2219963073730469, Accuracy: 0.60546875\n",
      "Batch: 108, Loss: 1.1519365310668945, Accuracy: 0.6259765625\n",
      "Batch: 109, Loss: 1.159576177597046, Accuracy: 0.619140625\n",
      "Batch: 110, Loss: 1.1247062683105469, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.106473445892334, Accuracy: 0.6552734375\n",
      "Batch: 112, Loss: 1.0199387073516846, Accuracy: 0.6767578125\n",
      "Batch: 113, Loss: 1.0570499897003174, Accuracy: 0.6640625\n",
      "Batch: 114, Loss: 1.1029937267303467, Accuracy: 0.6259765625\n",
      "Batch: 115, Loss: 1.1382739543914795, Accuracy: 0.6318359375\n",
      "Batch: 116, Loss: 1.1375782489776611, Accuracy: 0.63671875\n",
      "Batch: 117, Loss: 1.1544568538665771, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 1.179900884628296, Accuracy: 0.6025390625\n",
      "Batch: 119, Loss: 1.1895170211791992, Accuracy: 0.6123046875\n",
      "Batch: 120, Loss: 1.2909117937088013, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.212605595588684, Accuracy: 0.6044921875\n",
      "Batch: 122, Loss: 1.1461939811706543, Accuracy: 0.640625\n",
      "Batch: 123, Loss: 1.077543020248413, Accuracy: 0.650390625\n",
      "Batch: 124, Loss: 1.1922760009765625, Accuracy: 0.615234375\n",
      "Batch: 125, Loss: 1.1364307403564453, Accuracy: 0.6533203125\n",
      "Batch: 126, Loss: 1.208085298538208, Accuracy: 0.615234375\n",
      "Batch: 127, Loss: 1.1622123718261719, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.1859400272369385, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.143906593322754, Accuracy: 0.6328125\n",
      "Batch: 130, Loss: 1.1456623077392578, Accuracy: 0.634765625\n",
      "Batch: 131, Loss: 1.205527901649475, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.0511517524719238, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.0615512132644653, Accuracy: 0.6513671875\n",
      "Batch: 134, Loss: 1.0239094495773315, Accuracy: 0.6796875\n",
      "Batch: 135, Loss: 1.0025486946105957, Accuracy: 0.6826171875\n",
      "Batch: 136, Loss: 1.0333106517791748, Accuracy: 0.671875\n",
      "Batch: 137, Loss: 1.1345415115356445, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.1901004314422607, Accuracy: 0.61328125\n",
      "Batch: 139, Loss: 1.1014704704284668, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.1770193576812744, Accuracy: 0.619140625\n",
      "Batch: 141, Loss: 1.1161746978759766, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 1.1155675649642944, Accuracy: 0.6328125\n",
      "Batch: 143, Loss: 1.1198558807373047, Accuracy: 0.640625\n",
      "Batch: 144, Loss: 1.2428200244903564, Accuracy: 0.5927734375\n",
      "Batch: 145, Loss: 1.2274246215820312, Accuracy: 0.5908203125\n",
      "Batch: 146, Loss: 1.168515682220459, Accuracy: 0.62109375\n",
      "Batch: 147, Loss: 1.1840341091156006, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.1820766925811768, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.1241402626037598, Accuracy: 0.6298828125\n",
      "Batch: 150, Loss: 1.091644048690796, Accuracy: 0.634765625\n",
      "Batch: 151, Loss: 1.1077587604522705, Accuracy: 0.6298828125\n",
      "Batch: 152, Loss: 1.1155014038085938, Accuracy: 0.646484375\n",
      "Batch: 153, Loss: 1.1734554767608643, Accuracy: 0.6318359375\n",
      "Batch: 154, Loss: 1.1255109310150146, Accuracy: 0.6318359375\n",
      "Batch: 155, Loss: 1.0774986743927002, Accuracy: 0.6552734375\n",
      "Epoch 580/200\n",
      "Batch: 1, Loss: 1.239037036895752, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.0419669151306152, Accuracy: 0.6689453125\n",
      "Batch: 3, Loss: 1.0053489208221436, Accuracy: 0.6875\n",
      "Batch: 4, Loss: 1.0285614728927612, Accuracy: 0.646484375\n",
      "Batch: 5, Loss: 0.9488401412963867, Accuracy: 0.6943359375\n",
      "Batch: 6, Loss: 0.978757917881012, Accuracy: 0.7001953125\n",
      "Batch: 7, Loss: 1.0098978281021118, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9604358673095703, Accuracy: 0.68359375\n",
      "Batch: 9, Loss: 0.9525523781776428, Accuracy: 0.6962890625\n",
      "Batch: 10, Loss: 0.8891801834106445, Accuracy: 0.7021484375\n",
      "Batch: 11, Loss: 0.9441429376602173, Accuracy: 0.6845703125\n",
      "Batch: 12, Loss: 0.9893076419830322, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 0.9359054565429688, Accuracy: 0.6845703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.9800134897232056, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.9182292222976685, Accuracy: 0.6943359375\n",
      "Batch: 16, Loss: 1.0451298952102661, Accuracy: 0.67578125\n",
      "Batch: 17, Loss: 0.9490424394607544, Accuracy: 0.6845703125\n",
      "Batch: 18, Loss: 1.1634840965270996, Accuracy: 0.6142578125\n",
      "Batch: 19, Loss: 1.1933220624923706, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.05597984790802, Accuracy: 0.654296875\n",
      "Batch: 21, Loss: 1.049670696258545, Accuracy: 0.658203125\n",
      "Batch: 22, Loss: 1.153625249862671, Accuracy: 0.623046875\n",
      "Batch: 23, Loss: 1.20820951461792, Accuracy: 0.6064453125\n",
      "Batch: 24, Loss: 1.0714448690414429, Accuracy: 0.6591796875\n",
      "Batch: 25, Loss: 1.073318362236023, Accuracy: 0.63671875\n",
      "Batch: 26, Loss: 1.1420780420303345, Accuracy: 0.6123046875\n",
      "Batch: 27, Loss: 1.0272938013076782, Accuracy: 0.6640625\n",
      "Batch: 28, Loss: 1.056745171546936, Accuracy: 0.6669921875\n",
      "Batch: 29, Loss: 1.0354371070861816, Accuracy: 0.6591796875\n",
      "Batch: 30, Loss: 1.0771945714950562, Accuracy: 0.6396484375\n",
      "Batch: 31, Loss: 1.145521879196167, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.072336196899414, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 0.9777508974075317, Accuracy: 0.681640625\n",
      "Batch: 34, Loss: 1.0568366050720215, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.1560478210449219, Accuracy: 0.6171875\n",
      "Batch: 36, Loss: 1.153343915939331, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.1945286989212036, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.184607982635498, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.0323469638824463, Accuracy: 0.666015625\n",
      "Batch: 40, Loss: 1.085843563079834, Accuracy: 0.6279296875\n",
      "Batch: 41, Loss: 1.1343755722045898, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 1.054322600364685, Accuracy: 0.640625\n",
      "Batch: 43, Loss: 1.0341781377792358, Accuracy: 0.6728515625\n",
      "Batch: 44, Loss: 1.013901948928833, Accuracy: 0.666015625\n",
      "Batch: 45, Loss: 0.9860861301422119, Accuracy: 0.67578125\n",
      "Batch: 46, Loss: 1.0624690055847168, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.0541892051696777, Accuracy: 0.67578125\n",
      "Batch: 48, Loss: 1.129594326019287, Accuracy: 0.6337890625\n",
      "Batch: 49, Loss: 1.1669034957885742, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.1229722499847412, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.1097197532653809, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.1920533180236816, Accuracy: 0.591796875\n",
      "Batch: 53, Loss: 1.1449182033538818, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.1043418645858765, Accuracy: 0.646484375\n",
      "Batch: 55, Loss: 1.0525093078613281, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.1015173196792603, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.07257080078125, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.0980546474456787, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 1.088397741317749, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.1112143993377686, Accuracy: 0.658203125\n",
      "Batch: 61, Loss: 1.138419508934021, Accuracy: 0.625\n",
      "Batch: 62, Loss: 1.1270629167556763, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.1201281547546387, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.1828835010528564, Accuracy: 0.6201171875\n",
      "Batch: 65, Loss: 1.1454370021820068, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.0487017631530762, Accuracy: 0.6513671875\n",
      "Batch: 67, Loss: 1.0754470825195312, Accuracy: 0.6474609375\n",
      "Batch: 68, Loss: 1.0732922554016113, Accuracy: 0.6474609375\n",
      "Batch: 69, Loss: 1.1977176666259766, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.0930938720703125, Accuracy: 0.65234375\n",
      "Batch: 71, Loss: 1.0688884258270264, Accuracy: 0.66015625\n",
      "Batch: 72, Loss: 1.1453301906585693, Accuracy: 0.634765625\n",
      "Batch: 73, Loss: 1.1683895587921143, Accuracy: 0.625\n",
      "Batch: 74, Loss: 1.1062103509902954, Accuracy: 0.6298828125\n",
      "Batch: 75, Loss: 1.0482444763183594, Accuracy: 0.6591796875\n",
      "Batch: 76, Loss: 1.0787239074707031, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 0.956833004951477, Accuracy: 0.6923828125\n",
      "Batch: 78, Loss: 1.0630464553833008, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.0790364742279053, Accuracy: 0.6484375\n",
      "Batch: 80, Loss: 1.112558364868164, Accuracy: 0.6396484375\n",
      "Batch: 81, Loss: 1.1123296022415161, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.1148772239685059, Accuracy: 0.6552734375\n",
      "Batch: 83, Loss: 1.1253838539123535, Accuracy: 0.6376953125\n",
      "Batch: 84, Loss: 1.1088401079177856, Accuracy: 0.6318359375\n",
      "Batch: 85, Loss: 1.1236450672149658, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.101195216178894, Accuracy: 0.638671875\n",
      "Batch: 87, Loss: 1.135850191116333, Accuracy: 0.6357421875\n",
      "Batch: 88, Loss: 1.133378267288208, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1109542846679688, Accuracy: 0.6455078125\n",
      "Batch: 90, Loss: 1.0451580286026, Accuracy: 0.658203125\n",
      "Batch: 91, Loss: 1.0870335102081299, Accuracy: 0.6376953125\n",
      "Batch: 92, Loss: 1.0759929418563843, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.0846011638641357, Accuracy: 0.6396484375\n",
      "Batch: 94, Loss: 1.1467217206954956, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.1213313341140747, Accuracy: 0.62890625\n",
      "Batch: 96, Loss: 1.1335513591766357, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.0849405527114868, Accuracy: 0.6572265625\n",
      "Batch: 98, Loss: 1.0964051485061646, Accuracy: 0.650390625\n",
      "Batch: 99, Loss: 1.0610026121139526, Accuracy: 0.6708984375\n",
      "Batch: 100, Loss: 1.024444580078125, Accuracy: 0.6728515625\n",
      "Batch: 101, Loss: 1.0825002193450928, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.0914947986602783, Accuracy: 0.654296875\n",
      "Batch: 103, Loss: 1.1310316324234009, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.052817463874817, Accuracy: 0.6474609375\n",
      "Batch: 105, Loss: 1.1372919082641602, Accuracy: 0.634765625\n",
      "Batch: 106, Loss: 1.1210472583770752, Accuracy: 0.646484375\n",
      "Batch: 107, Loss: 1.189298391342163, Accuracy: 0.626953125\n",
      "Batch: 108, Loss: 1.1874995231628418, Accuracy: 0.6259765625\n",
      "Batch: 109, Loss: 1.1667903661727905, Accuracy: 0.60546875\n",
      "Batch: 110, Loss: 1.1179686784744263, Accuracy: 0.611328125\n",
      "Batch: 111, Loss: 1.087807536125183, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0439419746398926, Accuracy: 0.6494140625\n",
      "Batch: 113, Loss: 1.0764813423156738, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.1377661228179932, Accuracy: 0.6083984375\n",
      "Batch: 115, Loss: 1.1111133098602295, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.1961498260498047, Accuracy: 0.591796875\n",
      "Batch: 117, Loss: 1.0739409923553467, Accuracy: 0.6416015625\n",
      "Batch: 118, Loss: 1.1966440677642822, Accuracy: 0.6123046875\n",
      "Batch: 119, Loss: 1.1684367656707764, Accuracy: 0.623046875\n",
      "Batch: 120, Loss: 1.1844795942306519, Accuracy: 0.615234375\n",
      "Batch: 121, Loss: 1.1951818466186523, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.2025294303894043, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.099498987197876, Accuracy: 0.6533203125\n",
      "Batch: 124, Loss: 1.1821115016937256, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.170474648475647, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.154327154159546, Accuracy: 0.6123046875\n",
      "Batch: 127, Loss: 1.1538617610931396, Accuracy: 0.6357421875\n",
      "Batch: 128, Loss: 1.2229281663894653, Accuracy: 0.61328125\n",
      "Batch: 129, Loss: 1.1422162055969238, Accuracy: 0.626953125\n",
      "Batch: 130, Loss: 1.1113905906677246, Accuracy: 0.646484375\n",
      "Batch: 131, Loss: 1.1630704402923584, Accuracy: 0.619140625\n",
      "Batch: 132, Loss: 1.0303980112075806, Accuracy: 0.6669921875\n",
      "Batch: 133, Loss: 1.0613775253295898, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.0682252645492554, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 1.0026663541793823, Accuracy: 0.6708984375\n",
      "Batch: 136, Loss: 1.0178310871124268, Accuracy: 0.65625\n",
      "Batch: 137, Loss: 1.1257188320159912, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 1.2194138765335083, Accuracy: 0.5986328125\n",
      "Batch: 139, Loss: 1.1244001388549805, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.1516896486282349, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.1590908765792847, Accuracy: 0.630859375\n",
      "Batch: 142, Loss: 1.105469822883606, Accuracy: 0.65625\n",
      "Batch: 143, Loss: 1.1757519245147705, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.1685702800750732, Accuracy: 0.6328125\n",
      "Batch: 145, Loss: 1.2410292625427246, Accuracy: 0.6123046875\n",
      "Batch: 146, Loss: 1.181535243988037, Accuracy: 0.609375\n",
      "Batch: 147, Loss: 1.2019879817962646, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.1731271743774414, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.1178873777389526, Accuracy: 0.6181640625\n",
      "Batch: 150, Loss: 1.1102268695831299, Accuracy: 0.6240234375\n",
      "Batch: 151, Loss: 1.127096176147461, Accuracy: 0.642578125\n",
      "Batch: 152, Loss: 1.1001157760620117, Accuracy: 0.6513671875\n",
      "Batch: 153, Loss: 1.10924232006073, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 154, Loss: 1.116706132888794, Accuracy: 0.650390625\n",
      "Batch: 155, Loss: 1.1123287677764893, Accuracy: 0.6455078125\n",
      "Saved Weights at epoch 580 to file Weights_580.h5\n",
      "Epoch 581/200\n",
      "Batch: 1, Loss: 1.1593759059906006, Accuracy: 0.6611328125\n",
      "Batch: 2, Loss: 1.0378117561340332, Accuracy: 0.654296875\n",
      "Batch: 3, Loss: 0.988567590713501, Accuracy: 0.677734375\n",
      "Batch: 4, Loss: 1.0561416149139404, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 0.979610025882721, Accuracy: 0.6826171875\n",
      "Batch: 6, Loss: 1.0161635875701904, Accuracy: 0.6708984375\n",
      "Batch: 7, Loss: 0.9662419557571411, Accuracy: 0.666015625\n",
      "Batch: 8, Loss: 0.9491105079650879, Accuracy: 0.6982421875\n",
      "Batch: 9, Loss: 1.007974624633789, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 0.87176513671875, Accuracy: 0.6953125\n",
      "Batch: 11, Loss: 0.9810677170753479, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 1.0496066808700562, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 1.0099143981933594, Accuracy: 0.6689453125\n",
      "Batch: 14, Loss: 0.9738675355911255, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.928951621055603, Accuracy: 0.6962890625\n",
      "Batch: 16, Loss: 1.0147874355316162, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.021308183670044, Accuracy: 0.662109375\n",
      "Batch: 18, Loss: 1.0714030265808105, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.2436879873275757, Accuracy: 0.60546875\n",
      "Batch: 20, Loss: 1.059186577796936, Accuracy: 0.6689453125\n",
      "Batch: 21, Loss: 1.0647950172424316, Accuracy: 0.6435546875\n",
      "Batch: 22, Loss: 1.1643829345703125, Accuracy: 0.6015625\n",
      "Batch: 23, Loss: 1.213245153427124, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.103071689605713, Accuracy: 0.64453125\n",
      "Batch: 25, Loss: 1.0918571949005127, Accuracy: 0.654296875\n",
      "Batch: 26, Loss: 1.1517424583435059, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.0848184823989868, Accuracy: 0.6552734375\n",
      "Batch: 28, Loss: 1.0587913990020752, Accuracy: 0.6416015625\n",
      "Batch: 29, Loss: 1.0236213207244873, Accuracy: 0.6884765625\n",
      "Batch: 30, Loss: 1.1876881122589111, Accuracy: 0.6083984375\n",
      "Batch: 31, Loss: 1.1989611387252808, Accuracy: 0.60546875\n",
      "Batch: 32, Loss: 1.0333307981491089, Accuracy: 0.65625\n",
      "Batch: 33, Loss: 0.9890029430389404, Accuracy: 0.6767578125\n",
      "Batch: 34, Loss: 1.024497389793396, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 1.1390340328216553, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.1025564670562744, Accuracy: 0.6376953125\n",
      "Batch: 37, Loss: 1.1720612049102783, Accuracy: 0.62109375\n",
      "Batch: 38, Loss: 1.1155641078948975, Accuracy: 0.634765625\n",
      "Batch: 39, Loss: 1.0758211612701416, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0560863018035889, Accuracy: 0.6572265625\n",
      "Batch: 41, Loss: 1.1065179109573364, Accuracy: 0.640625\n",
      "Batch: 42, Loss: 1.055307149887085, Accuracy: 0.6611328125\n",
      "Batch: 43, Loss: 1.0781121253967285, Accuracy: 0.63671875\n",
      "Batch: 44, Loss: 1.0190837383270264, Accuracy: 0.67578125\n",
      "Batch: 45, Loss: 0.9877570271492004, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.0992677211761475, Accuracy: 0.625\n",
      "Batch: 47, Loss: 1.0880155563354492, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.1055375337600708, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.1506550312042236, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.0727753639221191, Accuracy: 0.6650390625\n",
      "Batch: 51, Loss: 1.13560152053833, Accuracy: 0.62109375\n",
      "Batch: 52, Loss: 1.2084505558013916, Accuracy: 0.6015625\n",
      "Batch: 53, Loss: 1.1393463611602783, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.0858232975006104, Accuracy: 0.6455078125\n",
      "Batch: 55, Loss: 1.0586967468261719, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.0326573848724365, Accuracy: 0.65234375\n",
      "Batch: 57, Loss: 1.0741565227508545, Accuracy: 0.66015625\n",
      "Batch: 58, Loss: 1.0417351722717285, Accuracy: 0.6513671875\n",
      "Batch: 59, Loss: 1.0899323225021362, Accuracy: 0.6396484375\n",
      "Batch: 60, Loss: 1.1884362697601318, Accuracy: 0.6279296875\n",
      "Batch: 61, Loss: 1.0813064575195312, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.068292260169983, Accuracy: 0.654296875\n",
      "Batch: 63, Loss: 1.1432366371154785, Accuracy: 0.6259765625\n",
      "Batch: 64, Loss: 1.1717777252197266, Accuracy: 0.607421875\n",
      "Batch: 65, Loss: 1.1709564924240112, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.13161301612854, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.09541916847229, Accuracy: 0.646484375\n",
      "Batch: 68, Loss: 1.0464012622833252, Accuracy: 0.6689453125\n",
      "Batch: 69, Loss: 1.1221940517425537, Accuracy: 0.6171875\n",
      "Batch: 70, Loss: 1.138425588607788, Accuracy: 0.62109375\n",
      "Batch: 71, Loss: 1.0880892276763916, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.114537000656128, Accuracy: 0.6298828125\n",
      "Batch: 73, Loss: 1.1091625690460205, Accuracy: 0.6416015625\n",
      "Batch: 74, Loss: 1.127486228942871, Accuracy: 0.634765625\n",
      "Batch: 75, Loss: 1.068021535873413, Accuracy: 0.6689453125\n",
      "Batch: 76, Loss: 1.068225622177124, Accuracy: 0.658203125\n",
      "Batch: 77, Loss: 0.9790893793106079, Accuracy: 0.6884765625\n",
      "Batch: 78, Loss: 1.0250211954116821, Accuracy: 0.6611328125\n",
      "Batch: 79, Loss: 1.0723514556884766, Accuracy: 0.6611328125\n",
      "Batch: 80, Loss: 1.1336146593093872, Accuracy: 0.62890625\n",
      "Batch: 81, Loss: 1.1138463020324707, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.0770622491836548, Accuracy: 0.6591796875\n",
      "Batch: 83, Loss: 1.1281869411468506, Accuracy: 0.6513671875\n",
      "Batch: 84, Loss: 1.064208984375, Accuracy: 0.654296875\n",
      "Batch: 85, Loss: 1.1110836267471313, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.1039032936096191, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.1010584831237793, Accuracy: 0.6572265625\n",
      "Batch: 88, Loss: 1.075383186340332, Accuracy: 0.6416015625\n",
      "Batch: 89, Loss: 1.1017978191375732, Accuracy: 0.66015625\n",
      "Batch: 90, Loss: 1.0262826681137085, Accuracy: 0.6591796875\n",
      "Batch: 91, Loss: 1.0513193607330322, Accuracy: 0.66015625\n",
      "Batch: 92, Loss: 1.0514545440673828, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 1.077591896057129, Accuracy: 0.65625\n",
      "Batch: 94, Loss: 1.1665000915527344, Accuracy: 0.6201171875\n",
      "Batch: 95, Loss: 1.079096794128418, Accuracy: 0.64453125\n",
      "Batch: 96, Loss: 1.1348071098327637, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.1075369119644165, Accuracy: 0.6416015625\n",
      "Batch: 98, Loss: 1.1119561195373535, Accuracy: 0.642578125\n",
      "Batch: 99, Loss: 1.051068663597107, Accuracy: 0.66015625\n",
      "Batch: 100, Loss: 1.003474235534668, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.062190055847168, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 1.213796615600586, Accuracy: 0.62109375\n",
      "Batch: 103, Loss: 1.161973476409912, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.1033838987350464, Accuracy: 0.6494140625\n",
      "Batch: 105, Loss: 1.1244699954986572, Accuracy: 0.6416015625\n",
      "Batch: 106, Loss: 1.133955717086792, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.1953316926956177, Accuracy: 0.6025390625\n",
      "Batch: 108, Loss: 1.1541087627410889, Accuracy: 0.615234375\n",
      "Batch: 109, Loss: 1.1428594589233398, Accuracy: 0.626953125\n",
      "Batch: 110, Loss: 1.115689754486084, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.116439938545227, Accuracy: 0.6259765625\n",
      "Batch: 112, Loss: 1.0368452072143555, Accuracy: 0.671875\n",
      "Batch: 113, Loss: 1.1359643936157227, Accuracy: 0.642578125\n",
      "Batch: 114, Loss: 1.1584820747375488, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.1720494031906128, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.1412125825881958, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.188759207725525, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.1954152584075928, Accuracy: 0.611328125\n",
      "Batch: 119, Loss: 1.1629972457885742, Accuracy: 0.6298828125\n",
      "Batch: 120, Loss: 1.253596544265747, Accuracy: 0.5869140625\n",
      "Batch: 121, Loss: 1.1541187763214111, Accuracy: 0.6376953125\n",
      "Batch: 122, Loss: 1.192631483078003, Accuracy: 0.6259765625\n",
      "Batch: 123, Loss: 1.1520287990570068, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.175089716911316, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.10948646068573, Accuracy: 0.6533203125\n",
      "Batch: 126, Loss: 1.211889386177063, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.1703976392745972, Accuracy: 0.6328125\n",
      "Batch: 128, Loss: 1.1184966564178467, Accuracy: 0.646484375\n",
      "Batch: 129, Loss: 1.1618549823760986, Accuracy: 0.615234375\n",
      "Batch: 130, Loss: 1.104478120803833, Accuracy: 0.6435546875\n",
      "Batch: 131, Loss: 1.1732789278030396, Accuracy: 0.6279296875\n",
      "Batch: 132, Loss: 1.0869140625, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.0719705820083618, Accuracy: 0.66796875\n",
      "Batch: 134, Loss: 1.0846854448318481, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 1.0187108516693115, Accuracy: 0.6630859375\n",
      "Batch: 136, Loss: 1.05405855178833, Accuracy: 0.642578125\n",
      "Batch: 137, Loss: 1.1584110260009766, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.2459707260131836, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 1.173082709312439, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.2301831245422363, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.1703182458877563, Accuracy: 0.6357421875\n",
      "Batch: 142, Loss: 1.1977289915084839, Accuracy: 0.634765625\n",
      "Batch: 143, Loss: 1.1255227327346802, Accuracy: 0.6396484375\n",
      "Batch: 144, Loss: 1.2731316089630127, Accuracy: 0.591796875\n",
      "Batch: 145, Loss: 1.2423685789108276, Accuracy: 0.6123046875\n",
      "Batch: 146, Loss: 1.1571919918060303, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.2076983451843262, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.1884546279907227, Accuracy: 0.6220703125\n",
      "Batch: 149, Loss: 1.1499159336090088, Accuracy: 0.615234375\n",
      "Batch: 150, Loss: 1.091874361038208, Accuracy: 0.6484375\n",
      "Batch: 151, Loss: 1.1267988681793213, Accuracy: 0.6259765625\n",
      "Batch: 152, Loss: 1.1196215152740479, Accuracy: 0.6298828125\n",
      "Batch: 153, Loss: 1.0602267980575562, Accuracy: 0.6484375\n",
      "Batch: 154, Loss: 1.1295533180236816, Accuracy: 0.6357421875\n",
      "Batch: 155, Loss: 1.0665888786315918, Accuracy: 0.6552734375\n",
      "Epoch 582/200\n",
      "Batch: 1, Loss: 1.1764172315597534, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.0583570003509521, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 0.9453739523887634, Accuracy: 0.671875\n",
      "Batch: 4, Loss: 1.009020209312439, Accuracy: 0.6591796875\n",
      "Batch: 5, Loss: 1.0067861080169678, Accuracy: 0.68359375\n",
      "Batch: 6, Loss: 1.068068027496338, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.0174360275268555, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.8955376148223877, Accuracy: 0.70703125\n",
      "Batch: 9, Loss: 0.9470357298851013, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9242992997169495, Accuracy: 0.693359375\n",
      "Batch: 11, Loss: 0.9144171476364136, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.992319643497467, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 0.9806391596794128, Accuracy: 0.6796875\n",
      "Batch: 14, Loss: 0.9283783435821533, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.9328714609146118, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 0.9845288395881653, Accuracy: 0.6884765625\n",
      "Batch: 17, Loss: 1.0516579151153564, Accuracy: 0.66796875\n",
      "Batch: 18, Loss: 1.1095994710922241, Accuracy: 0.6533203125\n",
      "Batch: 19, Loss: 1.1748995780944824, Accuracy: 0.6259765625\n",
      "Batch: 20, Loss: 1.0139789581298828, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 1.1278293132781982, Accuracy: 0.6484375\n",
      "Batch: 22, Loss: 1.1886181831359863, Accuracy: 0.6298828125\n",
      "Batch: 23, Loss: 1.1966619491577148, Accuracy: 0.6025390625\n",
      "Batch: 24, Loss: 1.0625046491622925, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.0907282829284668, Accuracy: 0.6376953125\n",
      "Batch: 26, Loss: 1.1414716243743896, Accuracy: 0.6318359375\n",
      "Batch: 27, Loss: 1.1032546758651733, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.0879273414611816, Accuracy: 0.6416015625\n",
      "Batch: 29, Loss: 1.0618877410888672, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 1.1427814960479736, Accuracy: 0.6123046875\n",
      "Batch: 31, Loss: 1.170809030532837, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.0348149538040161, Accuracy: 0.646484375\n",
      "Batch: 33, Loss: 0.9544987678527832, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.0651781558990479, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 1.1133620738983154, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.1963804960250854, Accuracy: 0.6162109375\n",
      "Batch: 37, Loss: 1.1772077083587646, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.1298614740371704, Accuracy: 0.615234375\n",
      "Batch: 39, Loss: 1.0163750648498535, Accuracy: 0.6826171875\n",
      "Batch: 40, Loss: 1.0410603284835815, Accuracy: 0.63671875\n",
      "Batch: 41, Loss: 1.176436424255371, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0362014770507812, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 1.0218615531921387, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.024161458015442, Accuracy: 0.6650390625\n",
      "Batch: 45, Loss: 1.0238229036331177, Accuracy: 0.666015625\n",
      "Batch: 46, Loss: 1.1332590579986572, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.1177093982696533, Accuracy: 0.658203125\n",
      "Batch: 48, Loss: 1.0864711999893188, Accuracy: 0.6513671875\n",
      "Batch: 49, Loss: 1.1553516387939453, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.125232458114624, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.171398639678955, Accuracy: 0.60546875\n",
      "Batch: 52, Loss: 1.229524850845337, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1388009786605835, Accuracy: 0.6298828125\n",
      "Batch: 54, Loss: 1.1841611862182617, Accuracy: 0.62890625\n",
      "Batch: 55, Loss: 1.0842020511627197, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.0799154043197632, Accuracy: 0.6591796875\n",
      "Batch: 57, Loss: 1.088341236114502, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.1023517847061157, Accuracy: 0.638671875\n",
      "Batch: 59, Loss: 1.0517494678497314, Accuracy: 0.66015625\n",
      "Batch: 60, Loss: 1.1709144115447998, Accuracy: 0.6171875\n",
      "Batch: 61, Loss: 1.1483676433563232, Accuracy: 0.625\n",
      "Batch: 62, Loss: 1.1205182075500488, Accuracy: 0.6318359375\n",
      "Batch: 63, Loss: 1.1242328882217407, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.185051441192627, Accuracy: 0.6123046875\n",
      "Batch: 65, Loss: 1.1137373447418213, Accuracy: 0.6455078125\n",
      "Batch: 66, Loss: 1.0554230213165283, Accuracy: 0.65234375\n",
      "Batch: 67, Loss: 1.1124035120010376, Accuracy: 0.615234375\n",
      "Batch: 68, Loss: 1.086069107055664, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 1.1848193407058716, Accuracy: 0.6123046875\n",
      "Batch: 70, Loss: 1.167726993560791, Accuracy: 0.6240234375\n",
      "Batch: 71, Loss: 1.1286389827728271, Accuracy: 0.64453125\n",
      "Batch: 72, Loss: 1.1975113153457642, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.157497763633728, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.0898470878601074, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.1064503192901611, Accuracy: 0.646484375\n",
      "Batch: 76, Loss: 1.0654094219207764, Accuracy: 0.6630859375\n",
      "Batch: 77, Loss: 1.0432655811309814, Accuracy: 0.666015625\n",
      "Batch: 78, Loss: 1.104805588722229, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.0931236743927002, Accuracy: 0.65234375\n",
      "Batch: 80, Loss: 1.1712414026260376, Accuracy: 0.6103515625\n",
      "Batch: 81, Loss: 1.0986647605895996, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.0617778301239014, Accuracy: 0.6572265625\n",
      "Batch: 83, Loss: 1.1789164543151855, Accuracy: 0.6240234375\n",
      "Batch: 84, Loss: 1.0760658979415894, Accuracy: 0.6513671875\n",
      "Batch: 85, Loss: 1.157651424407959, Accuracy: 0.634765625\n",
      "Batch: 86, Loss: 1.1088008880615234, Accuracy: 0.64453125\n",
      "Batch: 87, Loss: 1.110007643699646, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.0973927974700928, Accuracy: 0.6435546875\n",
      "Batch: 89, Loss: 1.1364392042160034, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.1092772483825684, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.1072616577148438, Accuracy: 0.6396484375\n",
      "Batch: 92, Loss: 1.1272094249725342, Accuracy: 0.6396484375\n",
      "Batch: 93, Loss: 1.110189437866211, Accuracy: 0.61328125\n",
      "Batch: 94, Loss: 1.2469582557678223, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.1563336849212646, Accuracy: 0.6357421875\n",
      "Batch: 96, Loss: 1.1741821765899658, Accuracy: 0.6298828125\n",
      "Batch: 97, Loss: 1.1290638446807861, Accuracy: 0.62109375\n",
      "Batch: 98, Loss: 1.1153364181518555, Accuracy: 0.62890625\n",
      "Batch: 99, Loss: 1.1083126068115234, Accuracy: 0.6591796875\n",
      "Batch: 100, Loss: 1.0364621877670288, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.0512595176696777, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 1.1007063388824463, Accuracy: 0.6298828125\n",
      "Batch: 103, Loss: 1.1391894817352295, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.1423242092132568, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.0670417547225952, Accuracy: 0.6533203125\n",
      "Batch: 106, Loss: 1.2128826379776, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.205554485321045, Accuracy: 0.611328125\n",
      "Batch: 108, Loss: 1.1444551944732666, Accuracy: 0.6201171875\n",
      "Batch: 109, Loss: 1.1724344491958618, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.1778225898742676, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.1002635955810547, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.0519230365753174, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.0936756134033203, Accuracy: 0.6435546875\n",
      "Batch: 114, Loss: 1.1596455574035645, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.1483887434005737, Accuracy: 0.6298828125\n",
      "Batch: 116, Loss: 1.2149336338043213, Accuracy: 0.607421875\n",
      "Batch: 117, Loss: 1.1638157367706299, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.1558963060379028, Accuracy: 0.6162109375\n",
      "Batch: 119, Loss: 1.2113926410675049, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.316652774810791, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.1425683498382568, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 1.1730189323425293, Accuracy: 0.62109375\n",
      "Batch: 123, Loss: 1.1586339473724365, Accuracy: 0.6328125\n",
      "Batch: 124, Loss: 1.1570440530776978, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.1579862833023071, Accuracy: 0.6455078125\n",
      "Batch: 126, Loss: 1.1791189908981323, Accuracy: 0.630859375\n",
      "Batch: 127, Loss: 1.1632732152938843, Accuracy: 0.615234375\n",
      "Batch: 128, Loss: 1.1678498983383179, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.1565512418746948, Accuracy: 0.6435546875\n",
      "Batch: 130, Loss: 1.1421589851379395, Accuracy: 0.630859375\n",
      "Batch: 131, Loss: 1.1295019388198853, Accuracy: 0.6416015625\n",
      "Batch: 132, Loss: 1.0744659900665283, Accuracy: 0.6533203125\n",
      "Batch: 133, Loss: 1.120379090309143, Accuracy: 0.646484375\n",
      "Batch: 134, Loss: 1.1019006967544556, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 0.9980317950248718, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.039373755455017, Accuracy: 0.658203125\n",
      "Batch: 137, Loss: 1.0838664770126343, Accuracy: 0.654296875\n",
      "Batch: 138, Loss: 1.2114750146865845, Accuracy: 0.58984375\n",
      "Batch: 139, Loss: 1.1069694757461548, Accuracy: 0.642578125\n",
      "Batch: 140, Loss: 1.1719839572906494, Accuracy: 0.6328125\n",
      "Batch: 141, Loss: 1.1355581283569336, Accuracy: 0.6298828125\n",
      "Batch: 142, Loss: 1.2090606689453125, Accuracy: 0.61328125\n",
      "Batch: 143, Loss: 1.134279489517212, Accuracy: 0.646484375\n",
      "Batch: 144, Loss: 1.157848596572876, Accuracy: 0.6142578125\n",
      "Batch: 145, Loss: 1.2251362800598145, Accuracy: 0.6103515625\n",
      "Batch: 146, Loss: 1.1770563125610352, Accuracy: 0.6259765625\n",
      "Batch: 147, Loss: 1.1699841022491455, Accuracy: 0.60546875\n",
      "Batch: 148, Loss: 1.114507794380188, Accuracy: 0.65625\n",
      "Batch: 149, Loss: 1.133152723312378, Accuracy: 0.6240234375\n",
      "Batch: 150, Loss: 1.1212234497070312, Accuracy: 0.625\n",
      "Batch: 151, Loss: 1.1165053844451904, Accuracy: 0.6171875\n",
      "Batch: 152, Loss: 1.1511962413787842, Accuracy: 0.6142578125\n",
      "Batch: 153, Loss: 1.0600210428237915, Accuracy: 0.6416015625\n",
      "Batch: 154, Loss: 1.0583961009979248, Accuracy: 0.658203125\n",
      "Batch: 155, Loss: 1.121760368347168, Accuracy: 0.640625\n",
      "Epoch 583/200\n",
      "Batch: 1, Loss: 1.1739258766174316, Accuracy: 0.6552734375\n",
      "Batch: 2, Loss: 1.0357654094696045, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 0.9661778211593628, Accuracy: 0.6884765625\n",
      "Batch: 4, Loss: 1.102614164352417, Accuracy: 0.6416015625\n",
      "Batch: 5, Loss: 0.9900609254837036, Accuracy: 0.68359375\n",
      "Batch: 6, Loss: 1.0679926872253418, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 0.9676690697669983, Accuracy: 0.6923828125\n",
      "Batch: 8, Loss: 0.9332865476608276, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9779753684997559, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9693988561630249, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.8759344816207886, Accuracy: 0.70703125\n",
      "Batch: 12, Loss: 0.9425206184387207, Accuracy: 0.6923828125\n",
      "Batch: 13, Loss: 1.0533957481384277, Accuracy: 0.6455078125\n",
      "Batch: 14, Loss: 0.9094514846801758, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9324216842651367, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 0.9829180240631104, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 0.9883064031600952, Accuracy: 0.6787109375\n",
      "Batch: 18, Loss: 1.0802116394042969, Accuracy: 0.658203125\n",
      "Batch: 19, Loss: 1.169910192489624, Accuracy: 0.619140625\n",
      "Batch: 20, Loss: 1.0771113634109497, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.030693531036377, Accuracy: 0.6826171875\n",
      "Batch: 22, Loss: 1.2081329822540283, Accuracy: 0.609375\n",
      "Batch: 23, Loss: 1.223282814025879, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.0977346897125244, Accuracy: 0.6484375\n",
      "Batch: 25, Loss: 1.1837542057037354, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1196963787078857, Accuracy: 0.6201171875\n",
      "Batch: 27, Loss: 1.146436333656311, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.0436952114105225, Accuracy: 0.646484375\n",
      "Batch: 29, Loss: 1.070730209350586, Accuracy: 0.658203125\n",
      "Batch: 30, Loss: 1.137112021446228, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.1732313632965088, Accuracy: 0.6298828125\n",
      "Batch: 32, Loss: 0.9789831042289734, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 0.9199577569961548, Accuracy: 0.693359375\n",
      "Batch: 34, Loss: 1.0474395751953125, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 1.0674636363983154, Accuracy: 0.654296875\n",
      "Batch: 36, Loss: 1.1435351371765137, Accuracy: 0.62890625\n",
      "Batch: 37, Loss: 1.176443099975586, Accuracy: 0.61328125\n",
      "Batch: 38, Loss: 1.1638423204421997, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.0637586116790771, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.0343706607818604, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.0715429782867432, Accuracy: 0.6513671875\n",
      "Batch: 42, Loss: 1.051408290863037, Accuracy: 0.65625\n",
      "Batch: 43, Loss: 1.0258350372314453, Accuracy: 0.6767578125\n",
      "Batch: 44, Loss: 0.9952479600906372, Accuracy: 0.6708984375\n",
      "Batch: 45, Loss: 1.009974479675293, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 1.1349663734436035, Accuracy: 0.6376953125\n",
      "Batch: 47, Loss: 1.0921533107757568, Accuracy: 0.6611328125\n",
      "Batch: 48, Loss: 1.108170509338379, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.1239540576934814, Accuracy: 0.6416015625\n",
      "Batch: 50, Loss: 1.0943212509155273, Accuracy: 0.6337890625\n",
      "Batch: 51, Loss: 1.1219193935394287, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.1827247142791748, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.149906039237976, Accuracy: 0.62109375\n",
      "Batch: 54, Loss: 1.1423358917236328, Accuracy: 0.6318359375\n",
      "Batch: 55, Loss: 1.0894185304641724, Accuracy: 0.658203125\n",
      "Batch: 56, Loss: 1.1033381223678589, Accuracy: 0.630859375\n",
      "Batch: 57, Loss: 1.1058579683303833, Accuracy: 0.6416015625\n",
      "Batch: 58, Loss: 1.139066219329834, Accuracy: 0.634765625\n",
      "Batch: 59, Loss: 1.142338514328003, Accuracy: 0.630859375\n",
      "Batch: 60, Loss: 1.1906764507293701, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.1445281505584717, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.1139025688171387, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.1439228057861328, Accuracy: 0.6357421875\n",
      "Batch: 64, Loss: 1.2098369598388672, Accuracy: 0.611328125\n",
      "Batch: 65, Loss: 1.1489911079406738, Accuracy: 0.6298828125\n",
      "Batch: 66, Loss: 1.124488353729248, Accuracy: 0.642578125\n",
      "Batch: 67, Loss: 1.0856117010116577, Accuracy: 0.650390625\n",
      "Batch: 68, Loss: 1.0624674558639526, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.193774700164795, Accuracy: 0.61328125\n",
      "Batch: 70, Loss: 1.2070770263671875, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1688848733901978, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.162139892578125, Accuracy: 0.6142578125\n",
      "Batch: 73, Loss: 1.1315258741378784, Accuracy: 0.6484375\n",
      "Batch: 74, Loss: 1.0978412628173828, Accuracy: 0.638671875\n",
      "Batch: 75, Loss: 1.0396060943603516, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.048081398010254, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 0.9757908582687378, Accuracy: 0.6689453125\n",
      "Batch: 78, Loss: 1.1014485359191895, Accuracy: 0.638671875\n",
      "Batch: 79, Loss: 1.1018574237823486, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.1495492458343506, Accuracy: 0.6181640625\n",
      "Batch: 81, Loss: 1.0918612480163574, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.0881800651550293, Accuracy: 0.6484375\n",
      "Batch: 83, Loss: 1.1744714975357056, Accuracy: 0.62890625\n",
      "Batch: 84, Loss: 1.0813426971435547, Accuracy: 0.65625\n",
      "Batch: 85, Loss: 1.162398338317871, Accuracy: 0.6328125\n",
      "Batch: 86, Loss: 1.0927283763885498, Accuracy: 0.630859375\n",
      "Batch: 87, Loss: 1.1609971523284912, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.182452917098999, Accuracy: 0.619140625\n",
      "Batch: 89, Loss: 1.1167526245117188, Accuracy: 0.642578125\n",
      "Batch: 90, Loss: 1.023210048675537, Accuracy: 0.6630859375\n",
      "Batch: 91, Loss: 1.0478074550628662, Accuracy: 0.6640625\n",
      "Batch: 92, Loss: 1.0882481336593628, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.0978116989135742, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.151504397392273, Accuracy: 0.642578125\n",
      "Batch: 95, Loss: 1.1690630912780762, Accuracy: 0.623046875\n",
      "Batch: 96, Loss: 1.2003931999206543, Accuracy: 0.6220703125\n",
      "Batch: 97, Loss: 1.125740885734558, Accuracy: 0.6376953125\n",
      "Batch: 98, Loss: 1.1287827491760254, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.0686116218566895, Accuracy: 0.6494140625\n",
      "Batch: 100, Loss: 1.0516986846923828, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.0933036804199219, Accuracy: 0.6318359375\n",
      "Batch: 102, Loss: 1.1232531070709229, Accuracy: 0.6484375\n",
      "Batch: 103, Loss: 1.1533300876617432, Accuracy: 0.638671875\n",
      "Batch: 104, Loss: 1.1194126605987549, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.134000539779663, Accuracy: 0.64453125\n",
      "Batch: 106, Loss: 1.1033635139465332, Accuracy: 0.6396484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 1.1363165378570557, Accuracy: 0.6298828125\n",
      "Batch: 108, Loss: 1.108270525932312, Accuracy: 0.6494140625\n",
      "Batch: 109, Loss: 1.2217952013015747, Accuracy: 0.5986328125\n",
      "Batch: 110, Loss: 1.1128020286560059, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.1064614057540894, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.0263712406158447, Accuracy: 0.669921875\n",
      "Batch: 113, Loss: 1.093218445777893, Accuracy: 0.626953125\n",
      "Batch: 114, Loss: 1.0989413261413574, Accuracy: 0.62890625\n",
      "Batch: 115, Loss: 1.1504342555999756, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1457797288894653, Accuracy: 0.6328125\n",
      "Batch: 117, Loss: 1.103142261505127, Accuracy: 0.63671875\n",
      "Batch: 118, Loss: 1.201110601425171, Accuracy: 0.6064453125\n",
      "Batch: 119, Loss: 1.1656887531280518, Accuracy: 0.6201171875\n",
      "Batch: 120, Loss: 1.2543251514434814, Accuracy: 0.6083984375\n",
      "Batch: 121, Loss: 1.138230562210083, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.1904047727584839, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.1744568347930908, Accuracy: 0.615234375\n",
      "Batch: 124, Loss: 1.184401035308838, Accuracy: 0.607421875\n",
      "Batch: 125, Loss: 1.0908308029174805, Accuracy: 0.65625\n",
      "Batch: 126, Loss: 1.2242493629455566, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.1527702808380127, Accuracy: 0.626953125\n",
      "Batch: 128, Loss: 1.1574214696884155, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.117401361465454, Accuracy: 0.6376953125\n",
      "Batch: 130, Loss: 1.1389137506484985, Accuracy: 0.6298828125\n",
      "Batch: 131, Loss: 1.2081588506698608, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.1078547239303589, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.074730634689331, Accuracy: 0.642578125\n",
      "Batch: 134, Loss: 1.0751304626464844, Accuracy: 0.6708984375\n",
      "Batch: 135, Loss: 1.0084686279296875, Accuracy: 0.673828125\n",
      "Batch: 136, Loss: 1.0729008913040161, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.1320703029632568, Accuracy: 0.6357421875\n",
      "Batch: 138, Loss: 1.202061653137207, Accuracy: 0.615234375\n",
      "Batch: 139, Loss: 1.1325066089630127, Accuracy: 0.64453125\n",
      "Batch: 140, Loss: 1.2485121488571167, Accuracy: 0.6201171875\n",
      "Batch: 141, Loss: 1.110020399093628, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1678318977355957, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.128063440322876, Accuracy: 0.63671875\n",
      "Batch: 144, Loss: 1.1729567050933838, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.2187062501907349, Accuracy: 0.623046875\n",
      "Batch: 146, Loss: 1.1872284412384033, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1315007209777832, Accuracy: 0.6279296875\n",
      "Batch: 148, Loss: 1.141453504562378, Accuracy: 0.63671875\n",
      "Batch: 149, Loss: 1.138918399810791, Accuracy: 0.6201171875\n",
      "Batch: 150, Loss: 1.0777071714401245, Accuracy: 0.642578125\n",
      "Batch: 151, Loss: 1.1875687837600708, Accuracy: 0.6240234375\n",
      "Batch: 152, Loss: 1.1234647035598755, Accuracy: 0.630859375\n",
      "Batch: 153, Loss: 1.0708482265472412, Accuracy: 0.65625\n",
      "Batch: 154, Loss: 1.1046321392059326, Accuracy: 0.642578125\n",
      "Batch: 155, Loss: 1.0292960405349731, Accuracy: 0.666015625\n",
      "Epoch 584/200\n",
      "Batch: 1, Loss: 1.216347575187683, Accuracy: 0.626953125\n",
      "Batch: 2, Loss: 1.0210992097854614, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.9837211966514587, Accuracy: 0.66015625\n",
      "Batch: 4, Loss: 1.0562975406646729, Accuracy: 0.6455078125\n",
      "Batch: 5, Loss: 0.9417928457260132, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 0.9456408619880676, Accuracy: 0.6943359375\n",
      "Batch: 7, Loss: 0.9775069952011108, Accuracy: 0.673828125\n",
      "Batch: 8, Loss: 0.9227405786514282, Accuracy: 0.71484375\n",
      "Batch: 9, Loss: 0.9562575817108154, Accuracy: 0.6767578125\n",
      "Batch: 10, Loss: 0.9579006433486938, Accuracy: 0.6748046875\n",
      "Batch: 11, Loss: 0.9471602439880371, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9793368577957153, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 0.958782434463501, Accuracy: 0.6904296875\n",
      "Batch: 14, Loss: 0.9695490598678589, Accuracy: 0.689453125\n",
      "Batch: 15, Loss: 0.9492553472518921, Accuracy: 0.6923828125\n",
      "Batch: 16, Loss: 0.9889143705368042, Accuracy: 0.6845703125\n",
      "Batch: 17, Loss: 1.0389450788497925, Accuracy: 0.6591796875\n",
      "Batch: 18, Loss: 1.0876104831695557, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1356472969055176, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0270445346832275, Accuracy: 0.677734375\n",
      "Batch: 21, Loss: 1.023351788520813, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.190191626548767, Accuracy: 0.6396484375\n",
      "Batch: 23, Loss: 1.2431960105895996, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.0941195487976074, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.1584587097167969, Accuracy: 0.62890625\n",
      "Batch: 26, Loss: 1.155027151107788, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.1319081783294678, Accuracy: 0.6220703125\n",
      "Batch: 28, Loss: 1.0085173845291138, Accuracy: 0.6650390625\n",
      "Batch: 29, Loss: 1.0444116592407227, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1410104036331177, Accuracy: 0.6337890625\n",
      "Batch: 31, Loss: 1.184053659439087, Accuracy: 0.62109375\n",
      "Batch: 32, Loss: 1.017381191253662, Accuracy: 0.6796875\n",
      "Batch: 33, Loss: 0.95561683177948, Accuracy: 0.693359375\n",
      "Batch: 34, Loss: 1.0630384683609009, Accuracy: 0.654296875\n",
      "Batch: 35, Loss: 1.104430913925171, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.0874388217926025, Accuracy: 0.6376953125\n",
      "Batch: 37, Loss: 1.1645622253417969, Accuracy: 0.6142578125\n",
      "Batch: 38, Loss: 1.1582839488983154, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.020767331123352, Accuracy: 0.6611328125\n",
      "Batch: 40, Loss: 1.1114190816879272, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.036564588546753, Accuracy: 0.6611328125\n",
      "Batch: 42, Loss: 1.049269437789917, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.054922103881836, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 0.9619763493537903, Accuracy: 0.69921875\n",
      "Batch: 45, Loss: 1.0660395622253418, Accuracy: 0.6376953125\n",
      "Batch: 46, Loss: 1.084742784500122, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.0655903816223145, Accuracy: 0.6513671875\n",
      "Batch: 48, Loss: 1.1084797382354736, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1113289594650269, Accuracy: 0.65234375\n",
      "Batch: 50, Loss: 1.0839300155639648, Accuracy: 0.6533203125\n",
      "Batch: 51, Loss: 1.0938907861709595, Accuracy: 0.6337890625\n",
      "Batch: 52, Loss: 1.1823621988296509, Accuracy: 0.6220703125\n",
      "Batch: 53, Loss: 1.1242477893829346, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.117795705795288, Accuracy: 0.6435546875\n",
      "Batch: 55, Loss: 1.0715030431747437, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.0964059829711914, Accuracy: 0.654296875\n",
      "Batch: 57, Loss: 1.0970306396484375, Accuracy: 0.6513671875\n",
      "Batch: 58, Loss: 1.0969147682189941, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.097906470298767, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.1795876026153564, Accuracy: 0.6083984375\n",
      "Batch: 61, Loss: 1.1629586219787598, Accuracy: 0.630859375\n",
      "Batch: 62, Loss: 1.1007051467895508, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.1277692317962646, Accuracy: 0.65234375\n",
      "Batch: 64, Loss: 1.1745120286941528, Accuracy: 0.615234375\n",
      "Batch: 65, Loss: 1.1071372032165527, Accuracy: 0.6328125\n",
      "Batch: 66, Loss: 1.1049485206604004, Accuracy: 0.662109375\n",
      "Batch: 67, Loss: 1.1379259824752808, Accuracy: 0.638671875\n",
      "Batch: 68, Loss: 1.0939120054244995, Accuracy: 0.6611328125\n",
      "Batch: 69, Loss: 1.1336278915405273, Accuracy: 0.63671875\n",
      "Batch: 70, Loss: 1.1420488357543945, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.1034431457519531, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.1135532855987549, Accuracy: 0.63671875\n",
      "Batch: 73, Loss: 1.0874944925308228, Accuracy: 0.630859375\n",
      "Batch: 74, Loss: 1.0499796867370605, Accuracy: 0.6650390625\n",
      "Batch: 75, Loss: 1.07319974899292, Accuracy: 0.658203125\n",
      "Batch: 76, Loss: 1.0188604593276978, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 1.0031096935272217, Accuracy: 0.671875\n",
      "Batch: 78, Loss: 1.037013053894043, Accuracy: 0.65234375\n",
      "Batch: 79, Loss: 1.0862215757369995, Accuracy: 0.6318359375\n",
      "Batch: 80, Loss: 1.113193392753601, Accuracy: 0.63671875\n",
      "Batch: 81, Loss: 1.1007094383239746, Accuracy: 0.630859375\n",
      "Batch: 82, Loss: 1.076270580291748, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.209053635597229, Accuracy: 0.6083984375\n",
      "Batch: 84, Loss: 1.0429133176803589, Accuracy: 0.6572265625\n",
      "Batch: 85, Loss: 1.0983076095581055, Accuracy: 0.650390625\n",
      "Batch: 86, Loss: 1.1018946170806885, Accuracy: 0.646484375\n",
      "Batch: 87, Loss: 1.119707465171814, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.1131590604782104, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.0386121273040771, Accuracy: 0.6845703125\n",
      "Batch: 90, Loss: 1.0809967517852783, Accuracy: 0.6435546875\n",
      "Batch: 91, Loss: 1.057887315750122, Accuracy: 0.65234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 92, Loss: 1.0670597553253174, Accuracy: 0.6591796875\n",
      "Batch: 93, Loss: 1.1109939813613892, Accuracy: 0.640625\n",
      "Batch: 94, Loss: 1.164013147354126, Accuracy: 0.6171875\n",
      "Batch: 95, Loss: 1.0961275100708008, Accuracy: 0.63671875\n",
      "Batch: 96, Loss: 1.1548997163772583, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.1520981788635254, Accuracy: 0.6240234375\n",
      "Batch: 98, Loss: 1.0782346725463867, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.1401623487472534, Accuracy: 0.642578125\n",
      "Batch: 100, Loss: 0.9761101007461548, Accuracy: 0.6923828125\n",
      "Batch: 101, Loss: 1.0838416814804077, Accuracy: 0.646484375\n",
      "Batch: 102, Loss: 1.120977520942688, Accuracy: 0.634765625\n",
      "Batch: 103, Loss: 1.0876576900482178, Accuracy: 0.6435546875\n",
      "Batch: 104, Loss: 1.1422157287597656, Accuracy: 0.6162109375\n",
      "Batch: 105, Loss: 1.16046142578125, Accuracy: 0.6181640625\n",
      "Batch: 106, Loss: 1.1465959548950195, Accuracy: 0.6298828125\n",
      "Batch: 107, Loss: 1.2054691314697266, Accuracy: 0.6083984375\n",
      "Batch: 108, Loss: 1.1077165603637695, Accuracy: 0.6396484375\n",
      "Batch: 109, Loss: 1.1491726636886597, Accuracy: 0.6435546875\n",
      "Batch: 110, Loss: 1.1303436756134033, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.1182798147201538, Accuracy: 0.6259765625\n",
      "Batch: 112, Loss: 1.0825016498565674, Accuracy: 0.6572265625\n",
      "Batch: 113, Loss: 1.0897021293640137, Accuracy: 0.654296875\n",
      "Batch: 114, Loss: 1.1554492712020874, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.1145944595336914, Accuracy: 0.65234375\n",
      "Batch: 116, Loss: 1.1062664985656738, Accuracy: 0.638671875\n",
      "Batch: 117, Loss: 1.1189864873886108, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.154025673866272, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.160804033279419, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.2519941329956055, Accuracy: 0.623046875\n",
      "Batch: 121, Loss: 1.160642385482788, Accuracy: 0.62890625\n",
      "Batch: 122, Loss: 1.1410210132598877, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.167085886001587, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.1919231414794922, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.0886437892913818, Accuracy: 0.658203125\n",
      "Batch: 126, Loss: 1.1533825397491455, Accuracy: 0.6328125\n",
      "Batch: 127, Loss: 1.1365699768066406, Accuracy: 0.6416015625\n",
      "Batch: 128, Loss: 1.0653572082519531, Accuracy: 0.6474609375\n",
      "Batch: 129, Loss: 1.1085084676742554, Accuracy: 0.6396484375\n",
      "Batch: 130, Loss: 1.0276234149932861, Accuracy: 0.6611328125\n",
      "Batch: 131, Loss: 1.1346904039382935, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0083571672439575, Accuracy: 0.673828125\n",
      "Batch: 133, Loss: 1.0883915424346924, Accuracy: 0.640625\n",
      "Batch: 134, Loss: 1.105440616607666, Accuracy: 0.65625\n",
      "Batch: 135, Loss: 1.0049479007720947, Accuracy: 0.6748046875\n",
      "Batch: 136, Loss: 1.0958654880523682, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.1090774536132812, Accuracy: 0.630859375\n",
      "Batch: 138, Loss: 1.1906615495681763, Accuracy: 0.6142578125\n",
      "Batch: 139, Loss: 1.1321492195129395, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.1544002294540405, Accuracy: 0.6318359375\n",
      "Batch: 141, Loss: 1.190664529800415, Accuracy: 0.6279296875\n",
      "Batch: 142, Loss: 1.147961139678955, Accuracy: 0.6494140625\n",
      "Batch: 143, Loss: 1.174712896347046, Accuracy: 0.611328125\n",
      "Batch: 144, Loss: 1.2126408815383911, Accuracy: 0.615234375\n",
      "Batch: 145, Loss: 1.2001731395721436, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.1635785102844238, Accuracy: 0.62109375\n",
      "Batch: 147, Loss: 1.217268705368042, Accuracy: 0.611328125\n",
      "Batch: 148, Loss: 1.220564842224121, Accuracy: 0.591796875\n",
      "Batch: 149, Loss: 1.1639513969421387, Accuracy: 0.6279296875\n",
      "Batch: 150, Loss: 1.1062016487121582, Accuracy: 0.6357421875\n",
      "Batch: 151, Loss: 1.0868823528289795, Accuracy: 0.6357421875\n",
      "Batch: 152, Loss: 1.1461162567138672, Accuracy: 0.62109375\n",
      "Batch: 153, Loss: 1.0853840112686157, Accuracy: 0.6298828125\n",
      "Batch: 154, Loss: 1.0800808668136597, Accuracy: 0.6591796875\n",
      "Batch: 155, Loss: 0.9993423223495483, Accuracy: 0.669921875\n",
      "Epoch 585/200\n",
      "Batch: 1, Loss: 1.2413257360458374, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 1.0462641716003418, Accuracy: 0.65234375\n",
      "Batch: 3, Loss: 1.0215845108032227, Accuracy: 0.6484375\n",
      "Batch: 4, Loss: 1.0187402963638306, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 0.9735850095748901, Accuracy: 0.662109375\n",
      "Batch: 6, Loss: 1.0013664960861206, Accuracy: 0.666015625\n",
      "Batch: 7, Loss: 0.9619171619415283, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 0.9101632833480835, Accuracy: 0.7099609375\n",
      "Batch: 9, Loss: 0.969048023223877, Accuracy: 0.6796875\n",
      "Batch: 10, Loss: 0.9857348203659058, Accuracy: 0.673828125\n",
      "Batch: 11, Loss: 0.9429358243942261, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9839217662811279, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 0.9914074540138245, Accuracy: 0.6748046875\n",
      "Batch: 14, Loss: 0.9888603687286377, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9241416454315186, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 0.9514038562774658, Accuracy: 0.69921875\n",
      "Batch: 17, Loss: 1.0438343286514282, Accuracy: 0.654296875\n",
      "Batch: 18, Loss: 1.1094017028808594, Accuracy: 0.6279296875\n",
      "Batch: 19, Loss: 1.1883704662322998, Accuracy: 0.6123046875\n",
      "Batch: 20, Loss: 1.09140944480896, Accuracy: 0.6748046875\n",
      "Batch: 21, Loss: 1.0590964555740356, Accuracy: 0.66796875\n",
      "Batch: 22, Loss: 1.194347858428955, Accuracy: 0.58984375\n",
      "Batch: 23, Loss: 1.210111379623413, Accuracy: 0.6025390625\n",
      "Batch: 24, Loss: 1.0732090473175049, Accuracy: 0.66015625\n",
      "Batch: 25, Loss: 1.1158015727996826, Accuracy: 0.6474609375\n",
      "Batch: 26, Loss: 1.1768957376480103, Accuracy: 0.595703125\n",
      "Batch: 27, Loss: 1.1059939861297607, Accuracy: 0.640625\n",
      "Batch: 28, Loss: 1.0428295135498047, Accuracy: 0.6513671875\n",
      "Batch: 29, Loss: 1.0679285526275635, Accuracy: 0.640625\n",
      "Batch: 30, Loss: 1.1023612022399902, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.165719985961914, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 0.9833245873451233, Accuracy: 0.66796875\n",
      "Batch: 33, Loss: 0.9614059925079346, Accuracy: 0.6630859375\n",
      "Batch: 34, Loss: 1.102668285369873, Accuracy: 0.64453125\n",
      "Batch: 35, Loss: 1.1421996355056763, Accuracy: 0.638671875\n",
      "Batch: 36, Loss: 1.1469357013702393, Accuracy: 0.6162109375\n",
      "Batch: 37, Loss: 1.2011399269104004, Accuracy: 0.62890625\n",
      "Batch: 38, Loss: 1.1383225917816162, Accuracy: 0.630859375\n",
      "Batch: 39, Loss: 1.0298632383346558, Accuracy: 0.6650390625\n",
      "Batch: 40, Loss: 1.0793086290359497, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.1096057891845703, Accuracy: 0.640625\n",
      "Batch: 42, Loss: 1.03128981590271, Accuracy: 0.6650390625\n",
      "Batch: 43, Loss: 1.0758869647979736, Accuracy: 0.642578125\n",
      "Batch: 44, Loss: 0.9763785600662231, Accuracy: 0.669921875\n",
      "Batch: 45, Loss: 1.0113037824630737, Accuracy: 0.669921875\n",
      "Batch: 46, Loss: 1.086625099182129, Accuracy: 0.626953125\n",
      "Batch: 47, Loss: 1.1251074075698853, Accuracy: 0.642578125\n",
      "Batch: 48, Loss: 1.0469117164611816, Accuracy: 0.6513671875\n",
      "Batch: 49, Loss: 1.1467339992523193, Accuracy: 0.6328125\n",
      "Batch: 50, Loss: 1.0909770727157593, Accuracy: 0.658203125\n",
      "Batch: 51, Loss: 1.124282956123352, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.2288916110992432, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.1428050994873047, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.1736233234405518, Accuracy: 0.611328125\n",
      "Batch: 55, Loss: 1.1028060913085938, Accuracy: 0.63671875\n",
      "Batch: 56, Loss: 1.058840036392212, Accuracy: 0.681640625\n",
      "Batch: 57, Loss: 1.0901954174041748, Accuracy: 0.65234375\n",
      "Batch: 58, Loss: 1.0419342517852783, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.077399492263794, Accuracy: 0.6611328125\n",
      "Batch: 60, Loss: 1.1956300735473633, Accuracy: 0.619140625\n",
      "Batch: 61, Loss: 1.1265246868133545, Accuracy: 0.6376953125\n",
      "Batch: 62, Loss: 1.1428290605545044, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.1454477310180664, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.1553258895874023, Accuracy: 0.6259765625\n",
      "Batch: 65, Loss: 1.1409953832626343, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.1101346015930176, Accuracy: 0.6318359375\n",
      "Batch: 67, Loss: 1.0824036598205566, Accuracy: 0.6640625\n",
      "Batch: 68, Loss: 1.0408737659454346, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 1.0964503288269043, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.185232162475586, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.1230820417404175, Accuracy: 0.646484375\n",
      "Batch: 72, Loss: 1.13016939163208, Accuracy: 0.6240234375\n",
      "Batch: 73, Loss: 1.1267666816711426, Accuracy: 0.630859375\n",
      "Batch: 74, Loss: 1.0815454721450806, Accuracy: 0.65625\n",
      "Batch: 75, Loss: 1.0989739894866943, Accuracy: 0.65234375\n",
      "Batch: 76, Loss: 1.0946033000946045, Accuracy: 0.6533203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 1.008017897605896, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 1.0825982093811035, Accuracy: 0.6259765625\n",
      "Batch: 79, Loss: 1.033426284790039, Accuracy: 0.650390625\n",
      "Batch: 80, Loss: 1.0915857553482056, Accuracy: 0.6376953125\n",
      "Batch: 81, Loss: 1.0981674194335938, Accuracy: 0.63671875\n",
      "Batch: 82, Loss: 1.072702407836914, Accuracy: 0.6572265625\n",
      "Batch: 83, Loss: 1.174199104309082, Accuracy: 0.615234375\n",
      "Batch: 84, Loss: 1.0817489624023438, Accuracy: 0.654296875\n",
      "Batch: 85, Loss: 1.1050145626068115, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.09913969039917, Accuracy: 0.638671875\n",
      "Batch: 87, Loss: 1.1030021905899048, Accuracy: 0.6572265625\n",
      "Batch: 88, Loss: 1.15614914894104, Accuracy: 0.6171875\n",
      "Batch: 89, Loss: 1.1018797159194946, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.0841846466064453, Accuracy: 0.6396484375\n",
      "Batch: 91, Loss: 1.080038070678711, Accuracy: 0.6455078125\n",
      "Batch: 92, Loss: 1.136461853981018, Accuracy: 0.6298828125\n",
      "Batch: 93, Loss: 1.08671236038208, Accuracy: 0.6552734375\n",
      "Batch: 94, Loss: 1.1864771842956543, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.1380219459533691, Accuracy: 0.630859375\n",
      "Batch: 96, Loss: 1.1969534158706665, Accuracy: 0.6083984375\n",
      "Batch: 97, Loss: 1.147047519683838, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.085398554801941, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.083296298980713, Accuracy: 0.6533203125\n",
      "Batch: 100, Loss: 1.0837925672531128, Accuracy: 0.6435546875\n",
      "Batch: 101, Loss: 1.0912554264068604, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.1286356449127197, Accuracy: 0.6240234375\n",
      "Batch: 103, Loss: 1.1006073951721191, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.088192343711853, Accuracy: 0.640625\n",
      "Batch: 105, Loss: 1.1731466054916382, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.1397267580032349, Accuracy: 0.6396484375\n",
      "Batch: 107, Loss: 1.1840262413024902, Accuracy: 0.6240234375\n",
      "Batch: 108, Loss: 1.1211355924606323, Accuracy: 0.640625\n",
      "Batch: 109, Loss: 1.1646634340286255, Accuracy: 0.626953125\n",
      "Batch: 110, Loss: 1.0817664861679077, Accuracy: 0.634765625\n",
      "Batch: 111, Loss: 1.049173355102539, Accuracy: 0.6591796875\n",
      "Batch: 112, Loss: 1.020141363143921, Accuracy: 0.671875\n",
      "Batch: 113, Loss: 1.1259607076644897, Accuracy: 0.638671875\n",
      "Batch: 114, Loss: 1.150808572769165, Accuracy: 0.6123046875\n",
      "Batch: 115, Loss: 1.1821887493133545, Accuracy: 0.6064453125\n",
      "Batch: 116, Loss: 1.1214721202850342, Accuracy: 0.6357421875\n",
      "Batch: 117, Loss: 1.1501562595367432, Accuracy: 0.626953125\n",
      "Batch: 118, Loss: 1.166078805923462, Accuracy: 0.626953125\n",
      "Batch: 119, Loss: 1.195202112197876, Accuracy: 0.61328125\n",
      "Batch: 120, Loss: 1.2177890539169312, Accuracy: 0.6181640625\n",
      "Batch: 121, Loss: 1.1958898305892944, Accuracy: 0.6240234375\n",
      "Batch: 122, Loss: 1.1694035530090332, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.171196460723877, Accuracy: 0.6357421875\n",
      "Batch: 124, Loss: 1.1878273487091064, Accuracy: 0.634765625\n",
      "Batch: 125, Loss: 1.1552557945251465, Accuracy: 0.658203125\n",
      "Batch: 126, Loss: 1.2199046611785889, Accuracy: 0.607421875\n",
      "Batch: 127, Loss: 1.1964243650436401, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.1129764318466187, Accuracy: 0.6318359375\n",
      "Batch: 129, Loss: 1.1335275173187256, Accuracy: 0.6611328125\n",
      "Batch: 130, Loss: 1.144812822341919, Accuracy: 0.609375\n",
      "Batch: 131, Loss: 1.168140172958374, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.0845962762832642, Accuracy: 0.640625\n",
      "Batch: 133, Loss: 1.1144899129867554, Accuracy: 0.6259765625\n",
      "Batch: 134, Loss: 1.0516810417175293, Accuracy: 0.6767578125\n",
      "Batch: 135, Loss: 0.9772526025772095, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.0938198566436768, Accuracy: 0.666015625\n",
      "Batch: 137, Loss: 1.1194466352462769, Accuracy: 0.65625\n",
      "Batch: 138, Loss: 1.17422354221344, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1122608184814453, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.183652400970459, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.1125551462173462, Accuracy: 0.6337890625\n",
      "Batch: 142, Loss: 1.1044955253601074, Accuracy: 0.6533203125\n",
      "Batch: 143, Loss: 1.1478564739227295, Accuracy: 0.61328125\n",
      "Batch: 144, Loss: 1.1710671186447144, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.1738287210464478, Accuracy: 0.609375\n",
      "Batch: 146, Loss: 1.1541309356689453, Accuracy: 0.62890625\n",
      "Batch: 147, Loss: 1.1627460718154907, Accuracy: 0.6328125\n",
      "Batch: 148, Loss: 1.1642603874206543, Accuracy: 0.625\n",
      "Batch: 149, Loss: 1.169596552848816, Accuracy: 0.626953125\n",
      "Batch: 150, Loss: 1.1053659915924072, Accuracy: 0.6494140625\n",
      "Batch: 151, Loss: 1.0879242420196533, Accuracy: 0.6533203125\n",
      "Batch: 152, Loss: 1.0995633602142334, Accuracy: 0.6240234375\n",
      "Batch: 153, Loss: 1.1173701286315918, Accuracy: 0.658203125\n",
      "Batch: 154, Loss: 1.0406107902526855, Accuracy: 0.666015625\n",
      "Batch: 155, Loss: 1.0595431327819824, Accuracy: 0.6474609375\n",
      "Epoch 586/200\n",
      "Batch: 1, Loss: 1.1471543312072754, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.021475911140442, Accuracy: 0.6630859375\n",
      "Batch: 3, Loss: 1.0255450010299683, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 0.9874846935272217, Accuracy: 0.67578125\n",
      "Batch: 5, Loss: 0.9844486117362976, Accuracy: 0.673828125\n",
      "Batch: 6, Loss: 1.0413484573364258, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 0.976471483707428, Accuracy: 0.6748046875\n",
      "Batch: 8, Loss: 0.9063711166381836, Accuracy: 0.6953125\n",
      "Batch: 9, Loss: 0.9610433578491211, Accuracy: 0.693359375\n",
      "Batch: 10, Loss: 1.0009751319885254, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 0.9492294788360596, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.9384678602218628, Accuracy: 0.68359375\n",
      "Batch: 13, Loss: 1.0184133052825928, Accuracy: 0.6748046875\n",
      "Batch: 14, Loss: 0.9330308437347412, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9452999830245972, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 0.9529076814651489, Accuracy: 0.703125\n",
      "Batch: 17, Loss: 1.0306026935577393, Accuracy: 0.65234375\n",
      "Batch: 18, Loss: 1.0662153959274292, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.122088074684143, Accuracy: 0.6376953125\n",
      "Batch: 20, Loss: 1.02625572681427, Accuracy: 0.6943359375\n",
      "Batch: 21, Loss: 1.0101115703582764, Accuracy: 0.68359375\n",
      "Batch: 22, Loss: 1.237562656402588, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.2002999782562256, Accuracy: 0.6259765625\n",
      "Batch: 24, Loss: 1.0618672370910645, Accuracy: 0.6650390625\n",
      "Batch: 25, Loss: 1.1043206453323364, Accuracy: 0.64453125\n",
      "Batch: 26, Loss: 1.162298321723938, Accuracy: 0.6044921875\n",
      "Batch: 27, Loss: 1.1228828430175781, Accuracy: 0.62109375\n",
      "Batch: 28, Loss: 1.0355713367462158, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.043210744857788, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.1615517139434814, Accuracy: 0.607421875\n",
      "Batch: 31, Loss: 1.1580967903137207, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.0219711065292358, Accuracy: 0.6787109375\n",
      "Batch: 33, Loss: 0.8890736699104309, Accuracy: 0.7021484375\n",
      "Batch: 34, Loss: 1.075727939605713, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.1214957237243652, Accuracy: 0.62109375\n",
      "Batch: 36, Loss: 1.1781401634216309, Accuracy: 0.60546875\n",
      "Batch: 37, Loss: 1.2141928672790527, Accuracy: 0.609375\n",
      "Batch: 38, Loss: 1.1029905080795288, Accuracy: 0.6142578125\n",
      "Batch: 39, Loss: 1.0161166191101074, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.0398766994476318, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.030442714691162, Accuracy: 0.65625\n",
      "Batch: 42, Loss: 1.0422682762145996, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.0447664260864258, Accuracy: 0.6650390625\n",
      "Batch: 44, Loss: 0.9832909107208252, Accuracy: 0.662109375\n",
      "Batch: 45, Loss: 0.9978681206703186, Accuracy: 0.662109375\n",
      "Batch: 46, Loss: 1.0652289390563965, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.058024287223816, Accuracy: 0.6728515625\n",
      "Batch: 48, Loss: 1.082156777381897, Accuracy: 0.6513671875\n",
      "Batch: 49, Loss: 1.1664307117462158, Accuracy: 0.630859375\n",
      "Batch: 50, Loss: 1.0878045558929443, Accuracy: 0.64453125\n",
      "Batch: 51, Loss: 1.0822765827178955, Accuracy: 0.6376953125\n",
      "Batch: 52, Loss: 1.2322190999984741, Accuracy: 0.611328125\n",
      "Batch: 53, Loss: 1.1062952280044556, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.1749107837677002, Accuracy: 0.6103515625\n",
      "Batch: 55, Loss: 1.0593950748443604, Accuracy: 0.6669921875\n",
      "Batch: 56, Loss: 1.0596238374710083, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.0929160118103027, Accuracy: 0.6494140625\n",
      "Batch: 58, Loss: 1.0540270805358887, Accuracy: 0.654296875\n",
      "Batch: 59, Loss: 1.0915827751159668, Accuracy: 0.658203125\n",
      "Batch: 60, Loss: 1.187641978263855, Accuracy: 0.619140625\n",
      "Batch: 61, Loss: 1.04646897315979, Accuracy: 0.6435546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 1.1328779458999634, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.1478271484375, Accuracy: 0.625\n",
      "Batch: 64, Loss: 1.1783367395401, Accuracy: 0.6123046875\n",
      "Batch: 65, Loss: 1.1669809818267822, Accuracy: 0.6083984375\n",
      "Batch: 66, Loss: 1.0591456890106201, Accuracy: 0.6533203125\n",
      "Batch: 67, Loss: 1.1432538032531738, Accuracy: 0.6318359375\n",
      "Batch: 68, Loss: 1.0694072246551514, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.1171826124191284, Accuracy: 0.642578125\n",
      "Batch: 70, Loss: 1.1061897277832031, Accuracy: 0.64453125\n",
      "Batch: 71, Loss: 1.129943609237671, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.1094050407409668, Accuracy: 0.63671875\n",
      "Batch: 73, Loss: 1.1175215244293213, Accuracy: 0.6611328125\n",
      "Batch: 74, Loss: 1.05433189868927, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.0535705089569092, Accuracy: 0.6572265625\n",
      "Batch: 76, Loss: 1.0037074089050293, Accuracy: 0.662109375\n",
      "Batch: 77, Loss: 1.0205628871917725, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.0329856872558594, Accuracy: 0.6484375\n",
      "Batch: 79, Loss: 1.104756474494934, Accuracy: 0.6474609375\n",
      "Batch: 80, Loss: 1.1273525953292847, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.1224584579467773, Accuracy: 0.642578125\n",
      "Batch: 82, Loss: 1.0606602430343628, Accuracy: 0.662109375\n",
      "Batch: 83, Loss: 1.146437644958496, Accuracy: 0.625\n",
      "Batch: 84, Loss: 1.108551025390625, Accuracy: 0.6279296875\n",
      "Batch: 85, Loss: 1.1451491117477417, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.0849533081054688, Accuracy: 0.646484375\n",
      "Batch: 87, Loss: 1.1036961078643799, Accuracy: 0.63671875\n",
      "Batch: 88, Loss: 1.1072518825531006, Accuracy: 0.6396484375\n",
      "Batch: 89, Loss: 1.0627810955047607, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.0769795179367065, Accuracy: 0.6611328125\n",
      "Batch: 91, Loss: 1.0508697032928467, Accuracy: 0.6494140625\n",
      "Batch: 92, Loss: 1.087162971496582, Accuracy: 0.65234375\n",
      "Batch: 93, Loss: 1.0871330499649048, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.1831549406051636, Accuracy: 0.642578125\n",
      "Batch: 95, Loss: 1.1649858951568604, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.1391774415969849, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.113368034362793, Accuracy: 0.6220703125\n",
      "Batch: 98, Loss: 1.0834391117095947, Accuracy: 0.6376953125\n",
      "Batch: 99, Loss: 1.1102797985076904, Accuracy: 0.6337890625\n",
      "Batch: 100, Loss: 0.9905587434768677, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0954554080963135, Accuracy: 0.64453125\n",
      "Batch: 102, Loss: 1.137393593788147, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.091966986656189, Accuracy: 0.64453125\n",
      "Batch: 104, Loss: 1.147643804550171, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.1761457920074463, Accuracy: 0.6201171875\n",
      "Batch: 106, Loss: 1.1573708057403564, Accuracy: 0.6201171875\n",
      "Batch: 107, Loss: 1.1450726985931396, Accuracy: 0.626953125\n",
      "Batch: 108, Loss: 1.0565495491027832, Accuracy: 0.642578125\n",
      "Batch: 109, Loss: 1.1190178394317627, Accuracy: 0.630859375\n",
      "Batch: 110, Loss: 1.032080888748169, Accuracy: 0.6630859375\n",
      "Batch: 111, Loss: 1.085566759109497, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0224860906600952, Accuracy: 0.67578125\n",
      "Batch: 113, Loss: 1.0576887130737305, Accuracy: 0.658203125\n",
      "Batch: 114, Loss: 1.1541427373886108, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.1509265899658203, Accuracy: 0.6259765625\n",
      "Batch: 116, Loss: 1.1734405755996704, Accuracy: 0.619140625\n",
      "Batch: 117, Loss: 1.096021056175232, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 1.174811601638794, Accuracy: 0.626953125\n",
      "Batch: 119, Loss: 1.2304514646530151, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.2504198551177979, Accuracy: 0.60546875\n",
      "Batch: 121, Loss: 1.1364606618881226, Accuracy: 0.6328125\n",
      "Batch: 122, Loss: 1.162077784538269, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.1849212646484375, Accuracy: 0.6337890625\n",
      "Batch: 124, Loss: 1.1655579805374146, Accuracy: 0.634765625\n",
      "Batch: 125, Loss: 1.0872881412506104, Accuracy: 0.65234375\n",
      "Batch: 126, Loss: 1.1622920036315918, Accuracy: 0.6484375\n",
      "Batch: 127, Loss: 1.234734296798706, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.163443922996521, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.1893976926803589, Accuracy: 0.6025390625\n",
      "Batch: 130, Loss: 1.0753753185272217, Accuracy: 0.6611328125\n",
      "Batch: 131, Loss: 1.1751291751861572, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.0537457466125488, Accuracy: 0.666015625\n",
      "Batch: 133, Loss: 1.1543846130371094, Accuracy: 0.625\n",
      "Batch: 134, Loss: 1.0421924591064453, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 0.9983338713645935, Accuracy: 0.6748046875\n",
      "Batch: 136, Loss: 1.047013521194458, Accuracy: 0.6513671875\n",
      "Batch: 137, Loss: 1.1311171054840088, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.1858322620391846, Accuracy: 0.6162109375\n",
      "Batch: 139, Loss: 1.1290786266326904, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.243582010269165, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.1250317096710205, Accuracy: 0.6279296875\n",
      "Batch: 142, Loss: 1.1233564615249634, Accuracy: 0.638671875\n",
      "Batch: 143, Loss: 1.133347511291504, Accuracy: 0.6220703125\n",
      "Batch: 144, Loss: 1.1967920064926147, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.2292052507400513, Accuracy: 0.5908203125\n",
      "Batch: 146, Loss: 1.153112769126892, Accuracy: 0.623046875\n",
      "Batch: 147, Loss: 1.139535903930664, Accuracy: 0.638671875\n",
      "Batch: 148, Loss: 1.1788063049316406, Accuracy: 0.619140625\n",
      "Batch: 149, Loss: 1.1316845417022705, Accuracy: 0.640625\n",
      "Batch: 150, Loss: 1.0875606536865234, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1389050483703613, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.1092560291290283, Accuracy: 0.62890625\n",
      "Batch: 153, Loss: 1.118882417678833, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.1191928386688232, Accuracy: 0.626953125\n",
      "Batch: 155, Loss: 1.08527672290802, Accuracy: 0.64453125\n",
      "Epoch 587/200\n",
      "Batch: 1, Loss: 1.1628518104553223, Accuracy: 0.6572265625\n",
      "Batch: 2, Loss: 1.0402123928070068, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.9988833069801331, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 1.0882872343063354, Accuracy: 0.6328125\n",
      "Batch: 5, Loss: 1.0370228290557861, Accuracy: 0.6787109375\n",
      "Batch: 6, Loss: 0.9952129125595093, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 0.9892794489860535, Accuracy: 0.6640625\n",
      "Batch: 8, Loss: 0.9470170140266418, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9766701459884644, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 0.9394996166229248, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 0.9182921648025513, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 1.0375558137893677, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.9945008158683777, Accuracy: 0.6943359375\n",
      "Batch: 14, Loss: 0.9418904781341553, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 1.0019681453704834, Accuracy: 0.669921875\n",
      "Batch: 16, Loss: 0.9930835962295532, Accuracy: 0.677734375\n",
      "Batch: 17, Loss: 0.9893213510513306, Accuracy: 0.693359375\n",
      "Batch: 18, Loss: 1.0761228799819946, Accuracy: 0.6513671875\n",
      "Batch: 19, Loss: 1.1777865886688232, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.0795583724975586, Accuracy: 0.671875\n",
      "Batch: 21, Loss: 1.0752249956130981, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2533087730407715, Accuracy: 0.6064453125\n",
      "Batch: 23, Loss: 1.2215560674667358, Accuracy: 0.603515625\n",
      "Batch: 24, Loss: 1.0992531776428223, Accuracy: 0.6455078125\n",
      "Batch: 25, Loss: 1.1378082036972046, Accuracy: 0.625\n",
      "Batch: 26, Loss: 1.1637202501296997, Accuracy: 0.6318359375\n",
      "Batch: 27, Loss: 1.0668666362762451, Accuracy: 0.638671875\n",
      "Batch: 28, Loss: 1.059668779373169, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.020256757736206, Accuracy: 0.6533203125\n",
      "Batch: 30, Loss: 1.1123976707458496, Accuracy: 0.6357421875\n",
      "Batch: 31, Loss: 1.2118644714355469, Accuracy: 0.6025390625\n",
      "Batch: 32, Loss: 1.0355548858642578, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 1.0177075862884521, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.0756276845932007, Accuracy: 0.6572265625\n",
      "Batch: 35, Loss: 1.1092300415039062, Accuracy: 0.6259765625\n",
      "Batch: 36, Loss: 1.177180528640747, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.1860477924346924, Accuracy: 0.6103515625\n",
      "Batch: 38, Loss: 1.1904296875, Accuracy: 0.6142578125\n",
      "Batch: 39, Loss: 1.0219261646270752, Accuracy: 0.6591796875\n",
      "Batch: 40, Loss: 1.108701229095459, Accuracy: 0.619140625\n",
      "Batch: 41, Loss: 1.1240031719207764, Accuracy: 0.6103515625\n",
      "Batch: 42, Loss: 1.0946075916290283, Accuracy: 0.634765625\n",
      "Batch: 43, Loss: 1.0363616943359375, Accuracy: 0.650390625\n",
      "Batch: 44, Loss: 1.0036067962646484, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 1.0329924821853638, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.0753247737884521, Accuracy: 0.6357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 47, Loss: 1.0387964248657227, Accuracy: 0.6669921875\n",
      "Batch: 48, Loss: 1.1166763305664062, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.1851263046264648, Accuracy: 0.62109375\n",
      "Batch: 50, Loss: 1.0870888233184814, Accuracy: 0.6240234375\n",
      "Batch: 51, Loss: 1.1265945434570312, Accuracy: 0.6337890625\n",
      "Batch: 52, Loss: 1.2188267707824707, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1059514284133911, Accuracy: 0.6328125\n",
      "Batch: 54, Loss: 1.0851523876190186, Accuracy: 0.630859375\n",
      "Batch: 55, Loss: 1.0696309804916382, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.0756936073303223, Accuracy: 0.6376953125\n",
      "Batch: 57, Loss: 1.0657007694244385, Accuracy: 0.669921875\n",
      "Batch: 58, Loss: 1.0863008499145508, Accuracy: 0.642578125\n",
      "Batch: 59, Loss: 1.0674114227294922, Accuracy: 0.65625\n",
      "Batch: 60, Loss: 1.1932475566864014, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.0820739269256592, Accuracy: 0.6552734375\n",
      "Batch: 62, Loss: 1.1169655323028564, Accuracy: 0.64453125\n",
      "Batch: 63, Loss: 1.1377500295639038, Accuracy: 0.6337890625\n",
      "Batch: 64, Loss: 1.0968940258026123, Accuracy: 0.6484375\n",
      "Batch: 65, Loss: 1.1490057706832886, Accuracy: 0.619140625\n",
      "Batch: 66, Loss: 1.0724155902862549, Accuracy: 0.65625\n",
      "Batch: 67, Loss: 1.0852060317993164, Accuracy: 0.6357421875\n",
      "Batch: 68, Loss: 1.1069726943969727, Accuracy: 0.6376953125\n",
      "Batch: 69, Loss: 1.1495282649993896, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.1432383060455322, Accuracy: 0.619140625\n",
      "Batch: 71, Loss: 1.0759024620056152, Accuracy: 0.6240234375\n",
      "Batch: 72, Loss: 1.1500153541564941, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.1312068700790405, Accuracy: 0.6376953125\n",
      "Batch: 74, Loss: 1.0970890522003174, Accuracy: 0.634765625\n",
      "Batch: 75, Loss: 1.039147138595581, Accuracy: 0.650390625\n",
      "Batch: 76, Loss: 1.0106875896453857, Accuracy: 0.66015625\n",
      "Batch: 77, Loss: 1.021144151687622, Accuracy: 0.6591796875\n",
      "Batch: 78, Loss: 1.0729436874389648, Accuracy: 0.66015625\n",
      "Batch: 79, Loss: 1.0684795379638672, Accuracy: 0.6591796875\n",
      "Batch: 80, Loss: 1.2057576179504395, Accuracy: 0.60546875\n",
      "Batch: 81, Loss: 1.0739747285842896, Accuracy: 0.6494140625\n",
      "Batch: 82, Loss: 1.0115143060684204, Accuracy: 0.6630859375\n",
      "Batch: 83, Loss: 1.1329666376113892, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.0866262912750244, Accuracy: 0.6630859375\n",
      "Batch: 85, Loss: 1.0937095880508423, Accuracy: 0.6572265625\n",
      "Batch: 86, Loss: 1.0982744693756104, Accuracy: 0.634765625\n",
      "Batch: 87, Loss: 1.1433762311935425, Accuracy: 0.6171875\n",
      "Batch: 88, Loss: 1.1191720962524414, Accuracy: 0.6376953125\n",
      "Batch: 89, Loss: 1.0836384296417236, Accuracy: 0.6650390625\n",
      "Batch: 90, Loss: 1.05704927444458, Accuracy: 0.6640625\n",
      "Batch: 91, Loss: 1.0847723484039307, Accuracy: 0.6416015625\n",
      "Batch: 92, Loss: 1.1059733629226685, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.1421257257461548, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.125793695449829, Accuracy: 0.638671875\n",
      "Batch: 95, Loss: 1.1168556213378906, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.1293461322784424, Accuracy: 0.642578125\n",
      "Batch: 97, Loss: 1.1464426517486572, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.0531831979751587, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.1026818752288818, Accuracy: 0.6357421875\n",
      "Batch: 100, Loss: 1.0380728244781494, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 1.0730693340301514, Accuracy: 0.662109375\n",
      "Batch: 102, Loss: 1.104677438735962, Accuracy: 0.6484375\n",
      "Batch: 103, Loss: 1.1020851135253906, Accuracy: 0.6484375\n",
      "Batch: 104, Loss: 1.1109087467193604, Accuracy: 0.6591796875\n",
      "Batch: 105, Loss: 1.1936185359954834, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.0931490659713745, Accuracy: 0.6376953125\n",
      "Batch: 107, Loss: 1.1819020509719849, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.0955305099487305, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1283526420593262, Accuracy: 0.625\n",
      "Batch: 110, Loss: 1.0998098850250244, Accuracy: 0.6298828125\n",
      "Batch: 111, Loss: 1.0782971382141113, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.0434952974319458, Accuracy: 0.6552734375\n",
      "Batch: 113, Loss: 1.060683012008667, Accuracy: 0.662109375\n",
      "Batch: 114, Loss: 1.1576725244522095, Accuracy: 0.6259765625\n",
      "Batch: 115, Loss: 1.1464505195617676, Accuracy: 0.6396484375\n",
      "Batch: 116, Loss: 1.1811587810516357, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.149936556816101, Accuracy: 0.6396484375\n",
      "Batch: 118, Loss: 1.1560215950012207, Accuracy: 0.62109375\n",
      "Batch: 119, Loss: 1.1771897077560425, Accuracy: 0.61328125\n",
      "Batch: 120, Loss: 1.2397148609161377, Accuracy: 0.6181640625\n",
      "Batch: 121, Loss: 1.142690658569336, Accuracy: 0.638671875\n",
      "Batch: 122, Loss: 1.1319828033447266, Accuracy: 0.6416015625\n",
      "Batch: 123, Loss: 1.0788531303405762, Accuracy: 0.6640625\n",
      "Batch: 124, Loss: 1.1780781745910645, Accuracy: 0.611328125\n",
      "Batch: 125, Loss: 1.143455982208252, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.1783473491668701, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.219710111618042, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.118651270866394, Accuracy: 0.6435546875\n",
      "Batch: 129, Loss: 1.1442229747772217, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.0779364109039307, Accuracy: 0.6513671875\n",
      "Batch: 131, Loss: 1.162493109703064, Accuracy: 0.6044921875\n",
      "Batch: 132, Loss: 1.024104118347168, Accuracy: 0.6630859375\n",
      "Batch: 133, Loss: 1.0998969078063965, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.1091630458831787, Accuracy: 0.6533203125\n",
      "Batch: 135, Loss: 0.9578721523284912, Accuracy: 0.6875\n",
      "Batch: 136, Loss: 1.0857899188995361, Accuracy: 0.6279296875\n",
      "Batch: 137, Loss: 1.122495412826538, Accuracy: 0.6318359375\n",
      "Batch: 138, Loss: 1.1342743635177612, Accuracy: 0.6298828125\n",
      "Batch: 139, Loss: 1.2200647592544556, Accuracy: 0.615234375\n",
      "Batch: 140, Loss: 1.1762323379516602, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.097646713256836, Accuracy: 0.65625\n",
      "Batch: 142, Loss: 1.1461279392242432, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.1030616760253906, Accuracy: 0.6435546875\n",
      "Batch: 144, Loss: 1.180643916130066, Accuracy: 0.6171875\n",
      "Batch: 145, Loss: 1.2439963817596436, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.1698631048202515, Accuracy: 0.607421875\n",
      "Batch: 147, Loss: 1.1620738506317139, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.1528429985046387, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.129286527633667, Accuracy: 0.625\n",
      "Batch: 150, Loss: 1.1234722137451172, Accuracy: 0.6279296875\n",
      "Batch: 151, Loss: 1.1089974641799927, Accuracy: 0.6337890625\n",
      "Batch: 152, Loss: 1.0939034223556519, Accuracy: 0.626953125\n",
      "Batch: 153, Loss: 1.1374093294143677, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.0781199932098389, Accuracy: 0.6533203125\n",
      "Batch: 155, Loss: 1.0057318210601807, Accuracy: 0.66796875\n",
      "Epoch 588/200\n",
      "Batch: 1, Loss: 1.164475440979004, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 1.0391913652420044, Accuracy: 0.6572265625\n",
      "Batch: 3, Loss: 0.9935821294784546, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 1.0910087823867798, Accuracy: 0.650390625\n",
      "Batch: 5, Loss: 0.9836024641990662, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 0.9568700790405273, Accuracy: 0.69921875\n",
      "Batch: 7, Loss: 1.031256914138794, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 0.88734370470047, Accuracy: 0.724609375\n",
      "Batch: 9, Loss: 1.0300246477127075, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 1.0022227764129639, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 0.9157687425613403, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 1.0049560070037842, Accuracy: 0.6611328125\n",
      "Batch: 13, Loss: 0.979845404624939, Accuracy: 0.6728515625\n",
      "Batch: 14, Loss: 0.9133484363555908, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.9204744100570679, Accuracy: 0.6884765625\n",
      "Batch: 16, Loss: 0.9972901940345764, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 0.9936896562576294, Accuracy: 0.6875\n",
      "Batch: 18, Loss: 1.005091667175293, Accuracy: 0.6748046875\n",
      "Batch: 19, Loss: 1.1173992156982422, Accuracy: 0.6357421875\n",
      "Batch: 20, Loss: 1.0546255111694336, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.022188425064087, Accuracy: 0.677734375\n",
      "Batch: 22, Loss: 1.2561721801757812, Accuracy: 0.5947265625\n",
      "Batch: 23, Loss: 1.1643625497817993, Accuracy: 0.626953125\n",
      "Batch: 24, Loss: 1.0564379692077637, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.0909945964813232, Accuracy: 0.638671875\n",
      "Batch: 26, Loss: 1.1763482093811035, Accuracy: 0.6240234375\n",
      "Batch: 27, Loss: 1.0852513313293457, Accuracy: 0.640625\n",
      "Batch: 28, Loss: 1.0362861156463623, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 0.9899352192878723, Accuracy: 0.6669921875\n",
      "Batch: 30, Loss: 1.1073355674743652, Accuracy: 0.65625\n",
      "Batch: 31, Loss: 1.176365852355957, Accuracy: 0.6103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 1.0164272785186768, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 0.9564841985702515, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1279181241989136, Accuracy: 0.6376953125\n",
      "Batch: 35, Loss: 1.0357367992401123, Accuracy: 0.650390625\n",
      "Batch: 36, Loss: 1.1589635610580444, Accuracy: 0.6123046875\n",
      "Batch: 37, Loss: 1.2218592166900635, Accuracy: 0.5966796875\n",
      "Batch: 38, Loss: 1.1212711334228516, Accuracy: 0.646484375\n",
      "Batch: 39, Loss: 1.033534288406372, Accuracy: 0.6572265625\n",
      "Batch: 40, Loss: 1.0715560913085938, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.096972942352295, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0440999269485474, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.0120691061019897, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 0.984175443649292, Accuracy: 0.67578125\n",
      "Batch: 45, Loss: 0.9641366004943848, Accuracy: 0.6826171875\n",
      "Batch: 46, Loss: 1.0579571723937988, Accuracy: 0.6435546875\n",
      "Batch: 47, Loss: 1.0310564041137695, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0968852043151855, Accuracy: 0.6416015625\n",
      "Batch: 49, Loss: 1.1196558475494385, Accuracy: 0.6494140625\n",
      "Batch: 50, Loss: 1.080726146697998, Accuracy: 0.6611328125\n",
      "Batch: 51, Loss: 1.1139991283416748, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.220736026763916, Accuracy: 0.6025390625\n",
      "Batch: 53, Loss: 1.1150332689285278, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.156006097793579, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.0724234580993652, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.0809682607650757, Accuracy: 0.6298828125\n",
      "Batch: 57, Loss: 1.1038410663604736, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.0898425579071045, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.0952262878417969, Accuracy: 0.63671875\n",
      "Batch: 60, Loss: 1.1453754901885986, Accuracy: 0.630859375\n",
      "Batch: 61, Loss: 1.1375932693481445, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.1293892860412598, Accuracy: 0.630859375\n",
      "Batch: 63, Loss: 1.126082181930542, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.1191105842590332, Accuracy: 0.62890625\n",
      "Batch: 65, Loss: 1.1682313680648804, Accuracy: 0.609375\n",
      "Batch: 66, Loss: 1.1076622009277344, Accuracy: 0.630859375\n",
      "Batch: 67, Loss: 1.0708727836608887, Accuracy: 0.658203125\n",
      "Batch: 68, Loss: 1.08943510055542, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.1431055068969727, Accuracy: 0.626953125\n",
      "Batch: 70, Loss: 1.0745227336883545, Accuracy: 0.6591796875\n",
      "Batch: 71, Loss: 1.174590826034546, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.1815087795257568, Accuracy: 0.6240234375\n",
      "Batch: 73, Loss: 1.1506710052490234, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.0721837282180786, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.0557940006256104, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.100005865097046, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0041658878326416, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 1.0573091506958008, Accuracy: 0.6552734375\n",
      "Batch: 79, Loss: 1.1272858381271362, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.1516268253326416, Accuracy: 0.6318359375\n",
      "Batch: 81, Loss: 1.0951485633850098, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.07735013961792, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.1501294374465942, Accuracy: 0.6298828125\n",
      "Batch: 84, Loss: 1.199916124343872, Accuracy: 0.6181640625\n",
      "Batch: 85, Loss: 1.157227635383606, Accuracy: 0.6396484375\n",
      "Batch: 86, Loss: 1.127995252609253, Accuracy: 0.619140625\n",
      "Batch: 87, Loss: 1.1195805072784424, Accuracy: 0.623046875\n",
      "Batch: 88, Loss: 1.1090879440307617, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1159889698028564, Accuracy: 0.630859375\n",
      "Batch: 90, Loss: 1.0532488822937012, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.0847922563552856, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.1168973445892334, Accuracy: 0.6484375\n",
      "Batch: 93, Loss: 1.08929443359375, Accuracy: 0.6513671875\n",
      "Batch: 94, Loss: 1.1464637517929077, Accuracy: 0.6455078125\n",
      "Batch: 95, Loss: 1.122875452041626, Accuracy: 0.6484375\n",
      "Batch: 96, Loss: 1.1417887210845947, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.1053097248077393, Accuracy: 0.6318359375\n",
      "Batch: 98, Loss: 1.0681068897247314, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.103480577468872, Accuracy: 0.6376953125\n",
      "Batch: 100, Loss: 1.0208723545074463, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.093395709991455, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 1.147193193435669, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.11546790599823, Accuracy: 0.6357421875\n",
      "Batch: 104, Loss: 1.062094807624817, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.184560775756836, Accuracy: 0.6201171875\n",
      "Batch: 106, Loss: 1.14314603805542, Accuracy: 0.6435546875\n",
      "Batch: 107, Loss: 1.1452693939208984, Accuracy: 0.6318359375\n",
      "Batch: 108, Loss: 1.1386656761169434, Accuracy: 0.6015625\n",
      "Batch: 109, Loss: 1.1834015846252441, Accuracy: 0.6123046875\n",
      "Batch: 110, Loss: 1.0788605213165283, Accuracy: 0.642578125\n",
      "Batch: 111, Loss: 1.112999677658081, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.0662319660186768, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1077090501785278, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.135751724243164, Accuracy: 0.625\n",
      "Batch: 115, Loss: 1.1603028774261475, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.1580222845077515, Accuracy: 0.638671875\n",
      "Batch: 117, Loss: 1.1342508792877197, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.1318186521530151, Accuracy: 0.6171875\n",
      "Batch: 119, Loss: 1.1641136407852173, Accuracy: 0.6259765625\n",
      "Batch: 120, Loss: 1.1639173030853271, Accuracy: 0.62890625\n",
      "Batch: 121, Loss: 1.153179407119751, Accuracy: 0.6318359375\n",
      "Batch: 122, Loss: 1.120898962020874, Accuracy: 0.640625\n",
      "Batch: 123, Loss: 1.0933144092559814, Accuracy: 0.6572265625\n",
      "Batch: 124, Loss: 1.2141375541687012, Accuracy: 0.6123046875\n",
      "Batch: 125, Loss: 1.173987627029419, Accuracy: 0.63671875\n",
      "Batch: 126, Loss: 1.1019728183746338, Accuracy: 0.65625\n",
      "Batch: 127, Loss: 1.2287635803222656, Accuracy: 0.6025390625\n",
      "Batch: 128, Loss: 1.1536189317703247, Accuracy: 0.6328125\n",
      "Batch: 129, Loss: 1.208409070968628, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.0896756649017334, Accuracy: 0.6396484375\n",
      "Batch: 131, Loss: 1.1686125993728638, Accuracy: 0.6298828125\n",
      "Batch: 132, Loss: 1.028625249862671, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.0901148319244385, Accuracy: 0.6396484375\n",
      "Batch: 134, Loss: 1.0501022338867188, Accuracy: 0.673828125\n",
      "Batch: 135, Loss: 1.0238878726959229, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.057784914970398, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.1065478324890137, Accuracy: 0.6435546875\n",
      "Batch: 138, Loss: 1.1764445304870605, Accuracy: 0.6142578125\n",
      "Batch: 139, Loss: 1.134640097618103, Accuracy: 0.630859375\n",
      "Batch: 140, Loss: 1.1942322254180908, Accuracy: 0.6142578125\n",
      "Batch: 141, Loss: 1.0531268119812012, Accuracy: 0.662109375\n",
      "Batch: 142, Loss: 1.120100975036621, Accuracy: 0.646484375\n",
      "Batch: 143, Loss: 1.166607141494751, Accuracy: 0.6298828125\n",
      "Batch: 144, Loss: 1.1678295135498047, Accuracy: 0.60546875\n",
      "Batch: 145, Loss: 1.222285509109497, Accuracy: 0.6123046875\n",
      "Batch: 146, Loss: 1.174053430557251, Accuracy: 0.619140625\n",
      "Batch: 147, Loss: 1.1757365465164185, Accuracy: 0.6240234375\n",
      "Batch: 148, Loss: 1.1573193073272705, Accuracy: 0.6416015625\n",
      "Batch: 149, Loss: 1.066420078277588, Accuracy: 0.6552734375\n",
      "Batch: 150, Loss: 1.0921530723571777, Accuracy: 0.65625\n",
      "Batch: 151, Loss: 1.0912411212921143, Accuracy: 0.642578125\n",
      "Batch: 152, Loss: 1.0957874059677124, Accuracy: 0.6484375\n",
      "Batch: 153, Loss: 1.0314793586730957, Accuracy: 0.6650390625\n",
      "Batch: 154, Loss: 1.0356507301330566, Accuracy: 0.66015625\n",
      "Batch: 155, Loss: 1.0594751834869385, Accuracy: 0.658203125\n",
      "Epoch 589/200\n",
      "Batch: 1, Loss: 1.1657520532608032, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 0.9947608113288879, Accuracy: 0.6748046875\n",
      "Batch: 3, Loss: 0.9709525108337402, Accuracy: 0.6845703125\n",
      "Batch: 4, Loss: 1.0004149675369263, Accuracy: 0.6572265625\n",
      "Batch: 5, Loss: 0.982117772102356, Accuracy: 0.6806640625\n",
      "Batch: 6, Loss: 1.0196751356124878, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 0.947088897228241, Accuracy: 0.69140625\n",
      "Batch: 8, Loss: 0.912525475025177, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 1.0015943050384521, Accuracy: 0.6669921875\n",
      "Batch: 10, Loss: 0.9558576345443726, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9224311709403992, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 0.9663141369819641, Accuracy: 0.6767578125\n",
      "Batch: 13, Loss: 1.024381160736084, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 0.9313247203826904, Accuracy: 0.6904296875\n",
      "Batch: 15, Loss: 0.9297900199890137, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 1.0168228149414062, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17, Loss: 1.039440393447876, Accuracy: 0.6728515625\n",
      "Batch: 18, Loss: 1.063971757888794, Accuracy: 0.6630859375\n",
      "Batch: 19, Loss: 1.1022008657455444, Accuracy: 0.638671875\n",
      "Batch: 20, Loss: 1.0753536224365234, Accuracy: 0.6484375\n",
      "Batch: 21, Loss: 1.0175602436065674, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.202408790588379, Accuracy: 0.619140625\n",
      "Batch: 23, Loss: 1.218292474746704, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.0835020542144775, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 1.0926682949066162, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.1220738887786865, Accuracy: 0.6220703125\n",
      "Batch: 27, Loss: 1.0992431640625, Accuracy: 0.6201171875\n",
      "Batch: 28, Loss: 1.0571823120117188, Accuracy: 0.6376953125\n",
      "Batch: 29, Loss: 1.075008749961853, Accuracy: 0.6337890625\n",
      "Batch: 30, Loss: 1.1285301446914673, Accuracy: 0.6298828125\n",
      "Batch: 31, Loss: 1.164308786392212, Accuracy: 0.62890625\n",
      "Batch: 32, Loss: 1.0074498653411865, Accuracy: 0.6650390625\n",
      "Batch: 33, Loss: 0.8981145620346069, Accuracy: 0.69921875\n",
      "Batch: 34, Loss: 1.0217101573944092, Accuracy: 0.666015625\n",
      "Batch: 35, Loss: 1.0770456790924072, Accuracy: 0.638671875\n",
      "Batch: 36, Loss: 1.1525559425354004, Accuracy: 0.62890625\n",
      "Batch: 37, Loss: 1.1762815713882446, Accuracy: 0.6142578125\n",
      "Batch: 38, Loss: 1.1697564125061035, Accuracy: 0.6318359375\n",
      "Batch: 39, Loss: 1.0404741764068604, Accuracy: 0.6552734375\n",
      "Batch: 40, Loss: 1.0963765382766724, Accuracy: 0.62890625\n",
      "Batch: 41, Loss: 1.047062873840332, Accuracy: 0.6494140625\n",
      "Batch: 42, Loss: 1.0186349153518677, Accuracy: 0.6708984375\n",
      "Batch: 43, Loss: 0.9901667237281799, Accuracy: 0.66015625\n",
      "Batch: 44, Loss: 1.057478666305542, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.9857320785522461, Accuracy: 0.671875\n",
      "Batch: 46, Loss: 1.1234464645385742, Accuracy: 0.63671875\n",
      "Batch: 47, Loss: 1.0760719776153564, Accuracy: 0.6611328125\n",
      "Batch: 48, Loss: 1.068922519683838, Accuracy: 0.6474609375\n",
      "Batch: 49, Loss: 1.079881191253662, Accuracy: 0.6640625\n",
      "Batch: 50, Loss: 1.1064672470092773, Accuracy: 0.6494140625\n",
      "Batch: 51, Loss: 1.1540501117706299, Accuracy: 0.609375\n",
      "Batch: 52, Loss: 1.1807861328125, Accuracy: 0.62109375\n",
      "Batch: 53, Loss: 1.1609612703323364, Accuracy: 0.6181640625\n",
      "Batch: 54, Loss: 1.1334409713745117, Accuracy: 0.6298828125\n",
      "Batch: 55, Loss: 1.118119239807129, Accuracy: 0.6337890625\n",
      "Batch: 56, Loss: 1.1316447257995605, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.0533361434936523, Accuracy: 0.6630859375\n",
      "Batch: 58, Loss: 1.0756101608276367, Accuracy: 0.6591796875\n",
      "Batch: 59, Loss: 1.0408287048339844, Accuracy: 0.658203125\n",
      "Batch: 60, Loss: 1.207091212272644, Accuracy: 0.6044921875\n",
      "Batch: 61, Loss: 1.112126350402832, Accuracy: 0.6455078125\n",
      "Batch: 62, Loss: 1.1245590448379517, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.0907773971557617, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.165360450744629, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.1315817832946777, Accuracy: 0.6171875\n",
      "Batch: 66, Loss: 1.07943856716156, Accuracy: 0.654296875\n",
      "Batch: 67, Loss: 1.149339199066162, Accuracy: 0.62890625\n",
      "Batch: 68, Loss: 1.1108031272888184, Accuracy: 0.64453125\n",
      "Batch: 69, Loss: 1.1094681024551392, Accuracy: 0.666015625\n",
      "Batch: 70, Loss: 1.1108152866363525, Accuracy: 0.6259765625\n",
      "Batch: 71, Loss: 1.099217414855957, Accuracy: 0.634765625\n",
      "Batch: 72, Loss: 1.1196019649505615, Accuracy: 0.640625\n",
      "Batch: 73, Loss: 1.1273337602615356, Accuracy: 0.626953125\n",
      "Batch: 74, Loss: 1.1007659435272217, Accuracy: 0.6337890625\n",
      "Batch: 75, Loss: 1.0510406494140625, Accuracy: 0.6650390625\n",
      "Batch: 76, Loss: 1.0262126922607422, Accuracy: 0.66015625\n",
      "Batch: 77, Loss: 1.0402048826217651, Accuracy: 0.6435546875\n",
      "Batch: 78, Loss: 1.0194785594940186, Accuracy: 0.6748046875\n",
      "Batch: 79, Loss: 1.0887598991394043, Accuracy: 0.6572265625\n",
      "Batch: 80, Loss: 1.1430071592330933, Accuracy: 0.62890625\n",
      "Batch: 81, Loss: 1.0792399644851685, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 1.0995512008666992, Accuracy: 0.6455078125\n",
      "Batch: 83, Loss: 1.1612001657485962, Accuracy: 0.623046875\n",
      "Batch: 84, Loss: 1.0309114456176758, Accuracy: 0.6533203125\n",
      "Batch: 85, Loss: 1.1779866218566895, Accuracy: 0.623046875\n",
      "Batch: 86, Loss: 1.105989933013916, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 1.1732063293457031, Accuracy: 0.6240234375\n",
      "Batch: 88, Loss: 1.1359857320785522, Accuracy: 0.6259765625\n",
      "Batch: 89, Loss: 1.104600191116333, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0836372375488281, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.0528382062911987, Accuracy: 0.6572265625\n",
      "Batch: 92, Loss: 1.108154296875, Accuracy: 0.6552734375\n",
      "Batch: 93, Loss: 1.1147245168685913, Accuracy: 0.65234375\n",
      "Batch: 94, Loss: 1.1483068466186523, Accuracy: 0.63671875\n",
      "Batch: 95, Loss: 1.1304819583892822, Accuracy: 0.6337890625\n",
      "Batch: 96, Loss: 1.190092921257019, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.159106731414795, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.122064232826233, Accuracy: 0.630859375\n",
      "Batch: 99, Loss: 1.0498478412628174, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.0997674465179443, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.0923588275909424, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.0964269638061523, Accuracy: 0.6396484375\n",
      "Batch: 103, Loss: 1.0851218700408936, Accuracy: 0.662109375\n",
      "Batch: 104, Loss: 1.097651481628418, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.2096171379089355, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.120957374572754, Accuracy: 0.673828125\n",
      "Batch: 107, Loss: 1.2016154527664185, Accuracy: 0.6240234375\n",
      "Batch: 108, Loss: 1.1384434700012207, Accuracy: 0.630859375\n",
      "Batch: 109, Loss: 1.1429463624954224, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.0967977046966553, Accuracy: 0.6455078125\n",
      "Batch: 111, Loss: 1.1033780574798584, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.0718297958374023, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.1169167757034302, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.0787285566329956, Accuracy: 0.646484375\n",
      "Batch: 115, Loss: 1.1268839836120605, Accuracy: 0.6357421875\n",
      "Batch: 116, Loss: 1.1253204345703125, Accuracy: 0.6123046875\n",
      "Batch: 117, Loss: 1.0532867908477783, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 1.1955852508544922, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.2087078094482422, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.265166163444519, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.184645652770996, Accuracy: 0.6279296875\n",
      "Batch: 122, Loss: 1.1356828212738037, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.12717604637146, Accuracy: 0.646484375\n",
      "Batch: 124, Loss: 1.1671671867370605, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.1674437522888184, Accuracy: 0.6181640625\n",
      "Batch: 126, Loss: 1.1972529888153076, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.2227611541748047, Accuracy: 0.6044921875\n",
      "Batch: 128, Loss: 1.1192935705184937, Accuracy: 0.6455078125\n",
      "Batch: 129, Loss: 1.1694364547729492, Accuracy: 0.6201171875\n",
      "Batch: 130, Loss: 1.0690336227416992, Accuracy: 0.662109375\n",
      "Batch: 131, Loss: 1.1933188438415527, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.019421100616455, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 1.1003003120422363, Accuracy: 0.6328125\n",
      "Batch: 134, Loss: 1.1183991432189941, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 0.9894266724586487, Accuracy: 0.6884765625\n",
      "Batch: 136, Loss: 1.041832685470581, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.0742387771606445, Accuracy: 0.6572265625\n",
      "Batch: 138, Loss: 1.180881142616272, Accuracy: 0.62109375\n",
      "Batch: 139, Loss: 1.0800995826721191, Accuracy: 0.6630859375\n",
      "Batch: 140, Loss: 1.1718236207962036, Accuracy: 0.630859375\n",
      "Batch: 141, Loss: 1.0885754823684692, Accuracy: 0.650390625\n",
      "Batch: 142, Loss: 1.139062762260437, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1552478075027466, Accuracy: 0.62109375\n",
      "Batch: 144, Loss: 1.1951260566711426, Accuracy: 0.60546875\n",
      "Batch: 145, Loss: 1.2474019527435303, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.126890778541565, Accuracy: 0.6416015625\n",
      "Batch: 147, Loss: 1.1423439979553223, Accuracy: 0.6494140625\n",
      "Batch: 148, Loss: 1.1432769298553467, Accuracy: 0.642578125\n",
      "Batch: 149, Loss: 1.0821635723114014, Accuracy: 0.6435546875\n",
      "Batch: 150, Loss: 1.064650058746338, Accuracy: 0.65234375\n",
      "Batch: 151, Loss: 1.1115303039550781, Accuracy: 0.6484375\n",
      "Batch: 152, Loss: 1.1145691871643066, Accuracy: 0.642578125\n",
      "Batch: 153, Loss: 1.0718472003936768, Accuracy: 0.6591796875\n",
      "Batch: 154, Loss: 1.09757399559021, Accuracy: 0.6376953125\n",
      "Batch: 155, Loss: 1.0121185779571533, Accuracy: 0.681640625\n",
      "Epoch 590/200\n",
      "Batch: 1, Loss: 1.2030823230743408, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 1.0494656562805176, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 0.9747780561447144, Accuracy: 0.666015625\n",
      "Batch: 4, Loss: 0.9824268817901611, Accuracy: 0.6708984375\n",
      "Batch: 5, Loss: 0.9876307845115662, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0043041706085205, Accuracy: 0.69140625\n",
      "Batch: 7, Loss: 1.0121939182281494, Accuracy: 0.68359375\n",
      "Batch: 8, Loss: 0.9476220607757568, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 0.984788179397583, Accuracy: 0.673828125\n",
      "Batch: 10, Loss: 0.9380548596382141, Accuracy: 0.6875\n",
      "Batch: 11, Loss: 0.9543439745903015, Accuracy: 0.681640625\n",
      "Batch: 12, Loss: 0.9702824950218201, Accuracy: 0.6787109375\n",
      "Batch: 13, Loss: 0.9623450040817261, Accuracy: 0.6796875\n",
      "Batch: 14, Loss: 0.9269826412200928, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.9658901691436768, Accuracy: 0.689453125\n",
      "Batch: 16, Loss: 0.9887820482254028, Accuracy: 0.693359375\n",
      "Batch: 17, Loss: 1.0402582883834839, Accuracy: 0.6650390625\n",
      "Batch: 18, Loss: 1.0786631107330322, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1477560997009277, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.055668592453003, Accuracy: 0.66015625\n",
      "Batch: 21, Loss: 1.0032708644866943, Accuracy: 0.669921875\n",
      "Batch: 22, Loss: 1.1599860191345215, Accuracy: 0.638671875\n",
      "Batch: 23, Loss: 1.1999253034591675, Accuracy: 0.603515625\n",
      "Batch: 24, Loss: 1.0334621667861938, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 1.1064256429672241, Accuracy: 0.6484375\n",
      "Batch: 26, Loss: 1.1671377420425415, Accuracy: 0.6240234375\n",
      "Batch: 27, Loss: 1.112377405166626, Accuracy: 0.6650390625\n",
      "Batch: 28, Loss: 1.011225700378418, Accuracy: 0.6669921875\n",
      "Batch: 29, Loss: 1.0406855344772339, Accuracy: 0.66015625\n",
      "Batch: 30, Loss: 1.1569160223007202, Accuracy: 0.6220703125\n",
      "Batch: 31, Loss: 1.1521363258361816, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 0.9994750022888184, Accuracy: 0.6728515625\n",
      "Batch: 33, Loss: 0.9276030659675598, Accuracy: 0.681640625\n",
      "Batch: 34, Loss: 1.0712289810180664, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 1.0371747016906738, Accuracy: 0.658203125\n",
      "Batch: 36, Loss: 1.11091947555542, Accuracy: 0.6396484375\n",
      "Batch: 37, Loss: 1.1660101413726807, Accuracy: 0.599609375\n",
      "Batch: 38, Loss: 1.1382112503051758, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.0342462062835693, Accuracy: 0.65625\n",
      "Batch: 40, Loss: 1.0886632204055786, Accuracy: 0.642578125\n",
      "Batch: 41, Loss: 1.076632022857666, Accuracy: 0.646484375\n",
      "Batch: 42, Loss: 1.0273091793060303, Accuracy: 0.662109375\n",
      "Batch: 43, Loss: 1.0282602310180664, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0350658893585205, Accuracy: 0.6513671875\n",
      "Batch: 45, Loss: 0.9596859216690063, Accuracy: 0.677734375\n",
      "Batch: 46, Loss: 1.0426702499389648, Accuracy: 0.666015625\n",
      "Batch: 47, Loss: 1.0794332027435303, Accuracy: 0.654296875\n",
      "Batch: 48, Loss: 1.1071326732635498, Accuracy: 0.658203125\n",
      "Batch: 49, Loss: 1.1049187183380127, Accuracy: 0.646484375\n",
      "Batch: 50, Loss: 1.111490249633789, Accuracy: 0.6357421875\n",
      "Batch: 51, Loss: 1.108670711517334, Accuracy: 0.6416015625\n",
      "Batch: 52, Loss: 1.191091775894165, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 1.1445255279541016, Accuracy: 0.6181640625\n",
      "Batch: 54, Loss: 1.1377451419830322, Accuracy: 0.6416015625\n",
      "Batch: 55, Loss: 1.0884947776794434, Accuracy: 0.650390625\n",
      "Batch: 56, Loss: 1.0528548955917358, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 1.091289758682251, Accuracy: 0.6455078125\n",
      "Batch: 58, Loss: 1.1256046295166016, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.0835531949996948, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.222659945487976, Accuracy: 0.6015625\n",
      "Batch: 61, Loss: 1.1265661716461182, Accuracy: 0.6318359375\n",
      "Batch: 62, Loss: 1.1294856071472168, Accuracy: 0.65625\n",
      "Batch: 63, Loss: 1.1941758394241333, Accuracy: 0.6123046875\n",
      "Batch: 64, Loss: 1.1680784225463867, Accuracy: 0.61328125\n",
      "Batch: 65, Loss: 1.160182237625122, Accuracy: 0.625\n",
      "Batch: 66, Loss: 1.1290735006332397, Accuracy: 0.6240234375\n",
      "Batch: 67, Loss: 1.1225526332855225, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.0794577598571777, Accuracy: 0.6640625\n",
      "Batch: 69, Loss: 1.209767460823059, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.128184199333191, Accuracy: 0.623046875\n",
      "Batch: 71, Loss: 1.0550888776779175, Accuracy: 0.6572265625\n",
      "Batch: 72, Loss: 1.1464272737503052, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.1594250202178955, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.0874230861663818, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.1526538133621216, Accuracy: 0.6220703125\n",
      "Batch: 76, Loss: 1.060549020767212, Accuracy: 0.64453125\n",
      "Batch: 77, Loss: 1.0535730123519897, Accuracy: 0.673828125\n",
      "Batch: 78, Loss: 1.0259144306182861, Accuracy: 0.677734375\n",
      "Batch: 79, Loss: 1.0986734628677368, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.097262978553772, Accuracy: 0.6416015625\n",
      "Batch: 81, Loss: 1.119404673576355, Accuracy: 0.6318359375\n",
      "Batch: 82, Loss: 1.0788205862045288, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.1652963161468506, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.0982513427734375, Accuracy: 0.6494140625\n",
      "Batch: 85, Loss: 1.148606300354004, Accuracy: 0.63671875\n",
      "Batch: 86, Loss: 1.1776158809661865, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.136101245880127, Accuracy: 0.634765625\n",
      "Batch: 88, Loss: 1.0954315662384033, Accuracy: 0.6455078125\n",
      "Batch: 89, Loss: 1.1463700532913208, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.0673738718032837, Accuracy: 0.6591796875\n",
      "Batch: 91, Loss: 1.068265676498413, Accuracy: 0.6494140625\n",
      "Batch: 92, Loss: 1.0905067920684814, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 1.0335237979888916, Accuracy: 0.662109375\n",
      "Batch: 94, Loss: 1.157300353050232, Accuracy: 0.6455078125\n",
      "Batch: 95, Loss: 1.0867702960968018, Accuracy: 0.654296875\n",
      "Batch: 96, Loss: 1.1611919403076172, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 1.0875070095062256, Accuracy: 0.6552734375\n",
      "Batch: 98, Loss: 1.0484071969985962, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.083178997039795, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.043292760848999, Accuracy: 0.6572265625\n",
      "Batch: 101, Loss: 1.0598549842834473, Accuracy: 0.6572265625\n",
      "Batch: 102, Loss: 1.136972188949585, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.1057974100112915, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.056209921836853, Accuracy: 0.6611328125\n",
      "Batch: 105, Loss: 1.173081398010254, Accuracy: 0.6220703125\n",
      "Batch: 106, Loss: 1.1472779512405396, Accuracy: 0.62890625\n",
      "Batch: 107, Loss: 1.163236379623413, Accuracy: 0.6357421875\n",
      "Batch: 108, Loss: 1.1343965530395508, Accuracy: 0.6279296875\n",
      "Batch: 109, Loss: 1.134314775466919, Accuracy: 0.6298828125\n",
      "Batch: 110, Loss: 1.1168584823608398, Accuracy: 0.642578125\n",
      "Batch: 111, Loss: 1.0867233276367188, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.0441842079162598, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.1048555374145508, Accuracy: 0.6416015625\n",
      "Batch: 114, Loss: 1.1728640794754028, Accuracy: 0.6123046875\n",
      "Batch: 115, Loss: 1.1310200691223145, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.162179708480835, Accuracy: 0.625\n",
      "Batch: 117, Loss: 1.1349587440490723, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.1743500232696533, Accuracy: 0.60546875\n",
      "Batch: 119, Loss: 1.208478331565857, Accuracy: 0.607421875\n",
      "Batch: 120, Loss: 1.308215618133545, Accuracy: 0.591796875\n",
      "Batch: 121, Loss: 1.1607508659362793, Accuracy: 0.6318359375\n",
      "Batch: 122, Loss: 1.1786636114120483, Accuracy: 0.6123046875\n",
      "Batch: 123, Loss: 1.1754406690597534, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.13274347782135, Accuracy: 0.625\n",
      "Batch: 125, Loss: 1.1348867416381836, Accuracy: 0.6162109375\n",
      "Batch: 126, Loss: 1.1454845666885376, Accuracy: 0.63671875\n",
      "Batch: 127, Loss: 1.2198368310928345, Accuracy: 0.611328125\n",
      "Batch: 128, Loss: 1.1783159971237183, Accuracy: 0.626953125\n",
      "Batch: 129, Loss: 1.121044635772705, Accuracy: 0.6484375\n",
      "Batch: 130, Loss: 1.112324595451355, Accuracy: 0.638671875\n",
      "Batch: 131, Loss: 1.1865864992141724, Accuracy: 0.5966796875\n",
      "Batch: 132, Loss: 1.0752899646759033, Accuracy: 0.673828125\n",
      "Batch: 133, Loss: 1.1381511688232422, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.0788664817810059, Accuracy: 0.66015625\n",
      "Batch: 135, Loss: 0.9748042821884155, Accuracy: 0.68359375\n",
      "Batch: 136, Loss: 1.048944115638733, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 1.0876948833465576, Accuracy: 0.6611328125\n",
      "Batch: 138, Loss: 1.1818811893463135, Accuracy: 0.6123046875\n",
      "Batch: 139, Loss: 1.1363697052001953, Accuracy: 0.638671875\n",
      "Batch: 140, Loss: 1.1801609992980957, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.0945301055908203, Accuracy: 0.6494140625\n",
      "Batch: 142, Loss: 1.1314016580581665, Accuracy: 0.6357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 1.1614303588867188, Accuracy: 0.6318359375\n",
      "Batch: 144, Loss: 1.2209663391113281, Accuracy: 0.62109375\n",
      "Batch: 145, Loss: 1.1865606307983398, Accuracy: 0.6123046875\n",
      "Batch: 146, Loss: 1.198784351348877, Accuracy: 0.6025390625\n",
      "Batch: 147, Loss: 1.1466219425201416, Accuracy: 0.6318359375\n",
      "Batch: 148, Loss: 1.127039909362793, Accuracy: 0.63671875\n",
      "Batch: 149, Loss: 1.1298099756240845, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.1073682308197021, Accuracy: 0.6396484375\n",
      "Batch: 151, Loss: 1.1535440683364868, Accuracy: 0.6376953125\n",
      "Batch: 152, Loss: 1.0868263244628906, Accuracy: 0.6435546875\n",
      "Batch: 153, Loss: 1.0802628993988037, Accuracy: 0.642578125\n",
      "Batch: 154, Loss: 1.1278321743011475, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.0625519752502441, Accuracy: 0.6484375\n",
      "Saved Weights at epoch 590 to file Weights_590.h5\n",
      "Epoch 591/200\n",
      "Batch: 1, Loss: 1.1692843437194824, Accuracy: 0.6484375\n",
      "Batch: 2, Loss: 0.9852762818336487, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.9488086700439453, Accuracy: 0.68359375\n",
      "Batch: 4, Loss: 1.0324375629425049, Accuracy: 0.6650390625\n",
      "Batch: 5, Loss: 0.9548467397689819, Accuracy: 0.6923828125\n",
      "Batch: 6, Loss: 0.9792672395706177, Accuracy: 0.6826171875\n",
      "Batch: 7, Loss: 0.9973351955413818, Accuracy: 0.67578125\n",
      "Batch: 8, Loss: 0.9849294424057007, Accuracy: 0.6689453125\n",
      "Batch: 9, Loss: 0.9878348112106323, Accuracy: 0.666015625\n",
      "Batch: 10, Loss: 0.9450737833976746, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 0.9307370185852051, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9930130839347839, Accuracy: 0.650390625\n",
      "Batch: 13, Loss: 1.029653549194336, Accuracy: 0.67578125\n",
      "Batch: 14, Loss: 0.9372820854187012, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.8779351711273193, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 0.9774823784828186, Accuracy: 0.67578125\n",
      "Batch: 17, Loss: 1.027787685394287, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.1039824485778809, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.09249746799469, Accuracy: 0.64453125\n",
      "Batch: 20, Loss: 1.0760078430175781, Accuracy: 0.67578125\n",
      "Batch: 21, Loss: 1.0625431537628174, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.2158539295196533, Accuracy: 0.607421875\n",
      "Batch: 23, Loss: 1.1699845790863037, Accuracy: 0.595703125\n",
      "Batch: 24, Loss: 1.089667797088623, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 1.2355780601501465, Accuracy: 0.59765625\n",
      "Batch: 26, Loss: 1.191659688949585, Accuracy: 0.611328125\n",
      "Batch: 27, Loss: 1.0634217262268066, Accuracy: 0.666015625\n",
      "Batch: 28, Loss: 1.0599489212036133, Accuracy: 0.6435546875\n",
      "Batch: 29, Loss: 1.056301236152649, Accuracy: 0.6591796875\n",
      "Batch: 30, Loss: 1.135649561882019, Accuracy: 0.6416015625\n",
      "Batch: 31, Loss: 1.1689635515213013, Accuracy: 0.6357421875\n",
      "Batch: 32, Loss: 1.039239764213562, Accuracy: 0.654296875\n",
      "Batch: 33, Loss: 1.0077388286590576, Accuracy: 0.6611328125\n",
      "Batch: 34, Loss: 1.105195164680481, Accuracy: 0.6435546875\n",
      "Batch: 35, Loss: 1.116577386856079, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.1230812072753906, Accuracy: 0.609375\n",
      "Batch: 37, Loss: 1.200746774673462, Accuracy: 0.6015625\n",
      "Batch: 38, Loss: 1.1233071088790894, Accuracy: 0.646484375\n",
      "Batch: 39, Loss: 1.0764678716659546, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.0895922183990479, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.0748543739318848, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 1.0440548658370972, Accuracy: 0.6494140625\n",
      "Batch: 43, Loss: 1.0261690616607666, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 1.011718988418579, Accuracy: 0.6708984375\n",
      "Batch: 45, Loss: 1.0104804039001465, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.0405123233795166, Accuracy: 0.6533203125\n",
      "Batch: 47, Loss: 1.0932259559631348, Accuracy: 0.65234375\n",
      "Batch: 48, Loss: 1.1165554523468018, Accuracy: 0.6201171875\n",
      "Batch: 49, Loss: 1.1255550384521484, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.1171413660049438, Accuracy: 0.6328125\n",
      "Batch: 51, Loss: 1.1593408584594727, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.2151074409484863, Accuracy: 0.59375\n",
      "Batch: 53, Loss: 1.139599084854126, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.0770419836044312, Accuracy: 0.65234375\n",
      "Batch: 55, Loss: 1.0993599891662598, Accuracy: 0.6357421875\n",
      "Batch: 56, Loss: 1.0737087726593018, Accuracy: 0.6494140625\n",
      "Batch: 57, Loss: 1.0509729385375977, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.1452494859695435, Accuracy: 0.6328125\n",
      "Batch: 59, Loss: 1.09937584400177, Accuracy: 0.6494140625\n",
      "Batch: 60, Loss: 1.2185171842575073, Accuracy: 0.5927734375\n",
      "Batch: 61, Loss: 1.1726205348968506, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.0791466236114502, Accuracy: 0.642578125\n",
      "Batch: 63, Loss: 1.1399343013763428, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.1484907865524292, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1249620914459229, Accuracy: 0.6357421875\n",
      "Batch: 66, Loss: 1.120330810546875, Accuracy: 0.642578125\n",
      "Batch: 67, Loss: 1.104753017425537, Accuracy: 0.646484375\n",
      "Batch: 68, Loss: 1.0709635019302368, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 1.124901533126831, Accuracy: 0.64453125\n",
      "Batch: 70, Loss: 1.1291368007659912, Accuracy: 0.630859375\n",
      "Batch: 71, Loss: 1.035585641860962, Accuracy: 0.6533203125\n",
      "Batch: 72, Loss: 1.095503330230713, Accuracy: 0.6376953125\n",
      "Batch: 73, Loss: 1.1336185932159424, Accuracy: 0.63671875\n",
      "Batch: 74, Loss: 1.1303788423538208, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.059220314025879, Accuracy: 0.669921875\n",
      "Batch: 76, Loss: 1.0662975311279297, Accuracy: 0.638671875\n",
      "Batch: 77, Loss: 1.0452888011932373, Accuracy: 0.673828125\n",
      "Batch: 78, Loss: 0.9968498349189758, Accuracy: 0.68359375\n",
      "Batch: 79, Loss: 1.0961880683898926, Accuracy: 0.658203125\n",
      "Batch: 80, Loss: 1.1193677186965942, Accuracy: 0.6318359375\n",
      "Batch: 81, Loss: 1.0796177387237549, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 1.0893572568893433, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 1.12997567653656, Accuracy: 0.6181640625\n",
      "Batch: 84, Loss: 1.103697419166565, Accuracy: 0.630859375\n",
      "Batch: 85, Loss: 1.1435985565185547, Accuracy: 0.6328125\n",
      "Batch: 86, Loss: 1.162172555923462, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.0930324792861938, Accuracy: 0.6396484375\n",
      "Batch: 88, Loss: 1.1237387657165527, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.1380422115325928, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.091193437576294, Accuracy: 0.63671875\n",
      "Batch: 91, Loss: 1.1189422607421875, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.0592050552368164, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 1.074502944946289, Accuracy: 0.658203125\n",
      "Batch: 94, Loss: 1.1574643850326538, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.099015235900879, Accuracy: 0.6494140625\n",
      "Batch: 96, Loss: 1.1672072410583496, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 1.1236287355422974, Accuracy: 0.6171875\n",
      "Batch: 98, Loss: 1.0723263025283813, Accuracy: 0.65234375\n",
      "Batch: 99, Loss: 1.0766537189483643, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.0042963027954102, Accuracy: 0.6611328125\n",
      "Batch: 101, Loss: 1.027791976928711, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 1.158919334411621, Accuracy: 0.6279296875\n",
      "Batch: 103, Loss: 1.0665457248687744, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.09333336353302, Accuracy: 0.6474609375\n",
      "Batch: 105, Loss: 1.130593180656433, Accuracy: 0.66015625\n",
      "Batch: 106, Loss: 1.1326018571853638, Accuracy: 0.6171875\n",
      "Batch: 107, Loss: 1.1866446733474731, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.0941932201385498, Accuracy: 0.6435546875\n",
      "Batch: 109, Loss: 1.154313325881958, Accuracy: 0.61328125\n",
      "Batch: 110, Loss: 1.1307467222213745, Accuracy: 0.6103515625\n",
      "Batch: 111, Loss: 1.1121976375579834, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.0433703660964966, Accuracy: 0.6611328125\n",
      "Batch: 113, Loss: 1.0956039428710938, Accuracy: 0.6298828125\n",
      "Batch: 114, Loss: 1.0972859859466553, Accuracy: 0.6357421875\n",
      "Batch: 115, Loss: 1.1368300914764404, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.183474063873291, Accuracy: 0.5986328125\n",
      "Batch: 117, Loss: 1.1285033226013184, Accuracy: 0.61328125\n",
      "Batch: 118, Loss: 1.1596946716308594, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.1921076774597168, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.1598832607269287, Accuracy: 0.62890625\n",
      "Batch: 121, Loss: 1.1531867980957031, Accuracy: 0.6162109375\n",
      "Batch: 122, Loss: 1.1758577823638916, Accuracy: 0.626953125\n",
      "Batch: 123, Loss: 1.1052759885787964, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.1913959980010986, Accuracy: 0.6259765625\n",
      "Batch: 125, Loss: 1.1251877546310425, Accuracy: 0.6513671875\n",
      "Batch: 126, Loss: 1.154261827468872, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127, Loss: 1.2463430166244507, Accuracy: 0.5927734375\n",
      "Batch: 128, Loss: 1.1611007452011108, Accuracy: 0.6416015625\n",
      "Batch: 129, Loss: 1.1674705743789673, Accuracy: 0.625\n",
      "Batch: 130, Loss: 1.1070835590362549, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1017935276031494, Accuracy: 0.63671875\n",
      "Batch: 132, Loss: 1.0288262367248535, Accuracy: 0.6630859375\n",
      "Batch: 133, Loss: 1.1196640729904175, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.0403106212615967, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 0.9861422777175903, Accuracy: 0.669921875\n",
      "Batch: 136, Loss: 1.112792730331421, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.1580755710601807, Accuracy: 0.6396484375\n",
      "Batch: 138, Loss: 1.174512505531311, Accuracy: 0.6005859375\n",
      "Batch: 139, Loss: 1.1519112586975098, Accuracy: 0.626953125\n",
      "Batch: 140, Loss: 1.2164075374603271, Accuracy: 0.609375\n",
      "Batch: 141, Loss: 1.1444381475448608, Accuracy: 0.62109375\n",
      "Batch: 142, Loss: 1.167343020439148, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.1378991603851318, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.2079873085021973, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.221360206604004, Accuracy: 0.6162109375\n",
      "Batch: 146, Loss: 1.1738049983978271, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.1739938259124756, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.1427826881408691, Accuracy: 0.640625\n",
      "Batch: 149, Loss: 1.1006313562393188, Accuracy: 0.6279296875\n",
      "Batch: 150, Loss: 1.0992043018341064, Accuracy: 0.6328125\n",
      "Batch: 151, Loss: 1.13949716091156, Accuracy: 0.646484375\n",
      "Batch: 152, Loss: 1.1003667116165161, Accuracy: 0.6484375\n",
      "Batch: 153, Loss: 1.0707063674926758, Accuracy: 0.6494140625\n",
      "Batch: 154, Loss: 1.053368330001831, Accuracy: 0.65625\n",
      "Batch: 155, Loss: 1.0660755634307861, Accuracy: 0.65625\n",
      "Epoch 592/200\n",
      "Batch: 1, Loss: 1.2047470808029175, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.082186222076416, Accuracy: 0.638671875\n",
      "Batch: 3, Loss: 1.0375806093215942, Accuracy: 0.654296875\n",
      "Batch: 4, Loss: 1.0138161182403564, Accuracy: 0.65625\n",
      "Batch: 5, Loss: 0.9627776741981506, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0672067403793335, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 0.9534422159194946, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.9902801513671875, Accuracy: 0.6884765625\n",
      "Batch: 9, Loss: 1.006749153137207, Accuracy: 0.6748046875\n",
      "Batch: 10, Loss: 0.89194256067276, Accuracy: 0.70703125\n",
      "Batch: 11, Loss: 0.9158978462219238, Accuracy: 0.701171875\n",
      "Batch: 12, Loss: 0.9715538620948792, Accuracy: 0.673828125\n",
      "Batch: 13, Loss: 1.0040593147277832, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 0.9254163503646851, Accuracy: 0.7119140625\n",
      "Batch: 15, Loss: 0.9232689738273621, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 0.963287353515625, Accuracy: 0.6787109375\n",
      "Batch: 17, Loss: 1.0000507831573486, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.0890742540359497, Accuracy: 0.6474609375\n",
      "Batch: 19, Loss: 1.1927299499511719, Accuracy: 0.62109375\n",
      "Batch: 20, Loss: 1.0620189905166626, Accuracy: 0.6689453125\n",
      "Batch: 21, Loss: 1.0346978902816772, Accuracy: 0.666015625\n",
      "Batch: 22, Loss: 1.1744542121887207, Accuracy: 0.6279296875\n",
      "Batch: 23, Loss: 1.2382237911224365, Accuracy: 0.6083984375\n",
      "Batch: 24, Loss: 1.0407702922821045, Accuracy: 0.66015625\n",
      "Batch: 25, Loss: 1.0910404920578003, Accuracy: 0.6435546875\n",
      "Batch: 26, Loss: 1.1197798252105713, Accuracy: 0.6298828125\n",
      "Batch: 27, Loss: 1.073480486869812, Accuracy: 0.6435546875\n",
      "Batch: 28, Loss: 1.0394078493118286, Accuracy: 0.63671875\n",
      "Batch: 29, Loss: 1.0444566011428833, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 1.0796337127685547, Accuracy: 0.658203125\n",
      "Batch: 31, Loss: 1.1763412952423096, Accuracy: 0.6123046875\n",
      "Batch: 32, Loss: 1.0425076484680176, Accuracy: 0.646484375\n",
      "Batch: 33, Loss: 0.9931914806365967, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.0196728706359863, Accuracy: 0.6728515625\n",
      "Batch: 35, Loss: 1.1007198095321655, Accuracy: 0.6396484375\n",
      "Batch: 36, Loss: 1.1069408655166626, Accuracy: 0.6376953125\n",
      "Batch: 37, Loss: 1.1927478313446045, Accuracy: 0.6142578125\n",
      "Batch: 38, Loss: 1.1094729900360107, Accuracy: 0.6328125\n",
      "Batch: 39, Loss: 1.0360455513000488, Accuracy: 0.6669921875\n",
      "Batch: 40, Loss: 1.036025047302246, Accuracy: 0.6650390625\n",
      "Batch: 41, Loss: 1.0643727779388428, Accuracy: 0.6416015625\n",
      "Batch: 42, Loss: 1.0153344869613647, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.0044431686401367, Accuracy: 0.673828125\n",
      "Batch: 44, Loss: 1.0265954732894897, Accuracy: 0.650390625\n",
      "Batch: 45, Loss: 1.0131585597991943, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.06252121925354, Accuracy: 0.63671875\n",
      "Batch: 47, Loss: 1.0609469413757324, Accuracy: 0.6591796875\n",
      "Batch: 48, Loss: 1.1075247526168823, Accuracy: 0.623046875\n",
      "Batch: 49, Loss: 1.13007390499115, Accuracy: 0.6455078125\n",
      "Batch: 50, Loss: 1.0909531116485596, Accuracy: 0.6494140625\n",
      "Batch: 51, Loss: 1.0773248672485352, Accuracy: 0.630859375\n",
      "Batch: 52, Loss: 1.1937440633773804, Accuracy: 0.6162109375\n",
      "Batch: 53, Loss: 1.1610772609710693, Accuracy: 0.61328125\n",
      "Batch: 54, Loss: 1.1555495262145996, Accuracy: 0.6240234375\n",
      "Batch: 55, Loss: 1.1371381282806396, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.0733497142791748, Accuracy: 0.646484375\n",
      "Batch: 57, Loss: 1.0648295879364014, Accuracy: 0.6533203125\n",
      "Batch: 58, Loss: 1.029249668121338, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 1.0570228099822998, Accuracy: 0.6708984375\n",
      "Batch: 60, Loss: 1.2047405242919922, Accuracy: 0.609375\n",
      "Batch: 61, Loss: 1.1723809242248535, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1210222244262695, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.0837695598602295, Accuracy: 0.6455078125\n",
      "Batch: 64, Loss: 1.1738433837890625, Accuracy: 0.6103515625\n",
      "Batch: 65, Loss: 1.1890790462493896, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.1224110126495361, Accuracy: 0.6376953125\n",
      "Batch: 67, Loss: 1.1240646839141846, Accuracy: 0.650390625\n",
      "Batch: 68, Loss: 1.0214130878448486, Accuracy: 0.671875\n",
      "Batch: 69, Loss: 1.1865553855895996, Accuracy: 0.62890625\n",
      "Batch: 70, Loss: 1.1003844738006592, Accuracy: 0.6611328125\n",
      "Batch: 71, Loss: 1.1062397956848145, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.1829222440719604, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.1040046215057373, Accuracy: 0.6484375\n",
      "Batch: 74, Loss: 1.0535908937454224, Accuracy: 0.6533203125\n",
      "Batch: 75, Loss: 1.1230063438415527, Accuracy: 0.6298828125\n",
      "Batch: 76, Loss: 1.0071747303009033, Accuracy: 0.6533203125\n",
      "Batch: 77, Loss: 1.0319023132324219, Accuracy: 0.662109375\n",
      "Batch: 78, Loss: 1.008847713470459, Accuracy: 0.6689453125\n",
      "Batch: 79, Loss: 1.106170415878296, Accuracy: 0.650390625\n",
      "Batch: 80, Loss: 1.0829792022705078, Accuracy: 0.6552734375\n",
      "Batch: 81, Loss: 1.0673116445541382, Accuracy: 0.63671875\n",
      "Batch: 82, Loss: 1.0585105419158936, Accuracy: 0.6552734375\n",
      "Batch: 83, Loss: 1.1413633823394775, Accuracy: 0.607421875\n",
      "Batch: 84, Loss: 1.1063809394836426, Accuracy: 0.6396484375\n",
      "Batch: 85, Loss: 1.1527326107025146, Accuracy: 0.640625\n",
      "Batch: 86, Loss: 1.0577402114868164, Accuracy: 0.64453125\n",
      "Batch: 87, Loss: 1.1151033639907837, Accuracy: 0.64453125\n",
      "Batch: 88, Loss: 1.1396852731704712, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.08778977394104, Accuracy: 0.6474609375\n",
      "Batch: 90, Loss: 1.0788846015930176, Accuracy: 0.6416015625\n",
      "Batch: 91, Loss: 1.0855894088745117, Accuracy: 0.65625\n",
      "Batch: 92, Loss: 1.067091464996338, Accuracy: 0.6494140625\n",
      "Batch: 93, Loss: 1.0580517053604126, Accuracy: 0.6708984375\n",
      "Batch: 94, Loss: 1.1262760162353516, Accuracy: 0.646484375\n",
      "Batch: 95, Loss: 1.1362340450286865, Accuracy: 0.6376953125\n",
      "Batch: 96, Loss: 1.1331753730773926, Accuracy: 0.650390625\n",
      "Batch: 97, Loss: 1.1108311414718628, Accuracy: 0.6318359375\n",
      "Batch: 98, Loss: 1.0631933212280273, Accuracy: 0.640625\n",
      "Batch: 99, Loss: 1.0804431438446045, Accuracy: 0.6474609375\n",
      "Batch: 100, Loss: 0.9745949506759644, Accuracy: 0.6904296875\n",
      "Batch: 101, Loss: 1.0836009979248047, Accuracy: 0.654296875\n",
      "Batch: 102, Loss: 1.136886477470398, Accuracy: 0.6142578125\n",
      "Batch: 103, Loss: 1.0758652687072754, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.137017011642456, Accuracy: 0.6171875\n",
      "Batch: 105, Loss: 1.143855333328247, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.1251156330108643, Accuracy: 0.6494140625\n",
      "Batch: 107, Loss: 1.213780164718628, Accuracy: 0.623046875\n",
      "Batch: 108, Loss: 1.132087230682373, Accuracy: 0.626953125\n",
      "Batch: 109, Loss: 1.1198413372039795, Accuracy: 0.6318359375\n",
      "Batch: 110, Loss: 1.1021244525909424, Accuracy: 0.650390625\n",
      "Batch: 111, Loss: 1.0383248329162598, Accuracy: 0.6455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 1.02332603931427, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.0909130573272705, Accuracy: 0.65234375\n",
      "Batch: 114, Loss: 1.1389319896697998, Accuracy: 0.6240234375\n",
      "Batch: 115, Loss: 1.1764662265777588, Accuracy: 0.6162109375\n",
      "Batch: 116, Loss: 1.145160436630249, Accuracy: 0.6220703125\n",
      "Batch: 117, Loss: 1.0993595123291016, Accuracy: 0.642578125\n",
      "Batch: 118, Loss: 1.1698400974273682, Accuracy: 0.6083984375\n",
      "Batch: 119, Loss: 1.165732979774475, Accuracy: 0.6337890625\n",
      "Batch: 120, Loss: 1.2195754051208496, Accuracy: 0.625\n",
      "Batch: 121, Loss: 1.1959586143493652, Accuracy: 0.62890625\n",
      "Batch: 122, Loss: 1.1897326707839966, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.1246137619018555, Accuracy: 0.642578125\n",
      "Batch: 124, Loss: 1.1798125505447388, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.1455039978027344, Accuracy: 0.630859375\n",
      "Batch: 126, Loss: 1.2053337097167969, Accuracy: 0.607421875\n",
      "Batch: 127, Loss: 1.2163127660751343, Accuracy: 0.6103515625\n",
      "Batch: 128, Loss: 1.163039207458496, Accuracy: 0.630859375\n",
      "Batch: 129, Loss: 1.1715539693832397, Accuracy: 0.6318359375\n",
      "Batch: 130, Loss: 1.1139470338821411, Accuracy: 0.6220703125\n",
      "Batch: 131, Loss: 1.2066640853881836, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.0158400535583496, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 1.114128828048706, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.0688261985778809, Accuracy: 0.6728515625\n",
      "Batch: 135, Loss: 1.0391695499420166, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.0591644048690796, Accuracy: 0.666015625\n",
      "Batch: 137, Loss: 1.111458420753479, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.2165117263793945, Accuracy: 0.5908203125\n",
      "Batch: 139, Loss: 1.1517785787582397, Accuracy: 0.625\n",
      "Batch: 140, Loss: 1.1783971786499023, Accuracy: 0.6171875\n",
      "Batch: 141, Loss: 1.0961506366729736, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.1074035167694092, Accuracy: 0.6318359375\n",
      "Batch: 143, Loss: 1.1798958778381348, Accuracy: 0.626953125\n",
      "Batch: 144, Loss: 1.1700413227081299, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.2367558479309082, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.1519581079483032, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.1476576328277588, Accuracy: 0.623046875\n",
      "Batch: 148, Loss: 1.1396441459655762, Accuracy: 0.630859375\n",
      "Batch: 149, Loss: 1.1687312126159668, Accuracy: 0.5986328125\n",
      "Batch: 150, Loss: 1.1188567876815796, Accuracy: 0.6328125\n",
      "Batch: 151, Loss: 1.1220800876617432, Accuracy: 0.62890625\n",
      "Batch: 152, Loss: 1.1379828453063965, Accuracy: 0.6123046875\n",
      "Batch: 153, Loss: 1.059020757675171, Accuracy: 0.6396484375\n",
      "Batch: 154, Loss: 1.09494948387146, Accuracy: 0.6474609375\n",
      "Batch: 155, Loss: 1.0624539852142334, Accuracy: 0.6455078125\n",
      "Epoch 593/200\n",
      "Batch: 1, Loss: 1.193467140197754, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 1.0453310012817383, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 1.02125883102417, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 0.9806392788887024, Accuracy: 0.6767578125\n",
      "Batch: 5, Loss: 0.9603286385536194, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.045973777770996, Accuracy: 0.6650390625\n",
      "Batch: 7, Loss: 0.9728530645370483, Accuracy: 0.6611328125\n",
      "Batch: 8, Loss: 0.9639863967895508, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 0.96127849817276, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 0.9322788119316101, Accuracy: 0.6865234375\n",
      "Batch: 11, Loss: 0.9403046369552612, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 1.018279790878296, Accuracy: 0.662109375\n",
      "Batch: 13, Loss: 0.9556184411048889, Accuracy: 0.68359375\n",
      "Batch: 14, Loss: 0.9283523559570312, Accuracy: 0.685546875\n",
      "Batch: 15, Loss: 0.895967960357666, Accuracy: 0.69921875\n",
      "Batch: 16, Loss: 0.9876259565353394, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 0.9893363118171692, Accuracy: 0.6796875\n",
      "Batch: 18, Loss: 1.0895497798919678, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.1635571718215942, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.0695686340332031, Accuracy: 0.6650390625\n",
      "Batch: 21, Loss: 1.0658011436462402, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.2164714336395264, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.2080249786376953, Accuracy: 0.623046875\n",
      "Batch: 24, Loss: 1.046288013458252, Accuracy: 0.6640625\n",
      "Batch: 25, Loss: 1.1102670431137085, Accuracy: 0.630859375\n",
      "Batch: 26, Loss: 1.1545590162277222, Accuracy: 0.6025390625\n",
      "Batch: 27, Loss: 1.0569974184036255, Accuracy: 0.6455078125\n",
      "Batch: 28, Loss: 1.0340089797973633, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.0900824069976807, Accuracy: 0.6416015625\n",
      "Batch: 30, Loss: 1.1135424375534058, Accuracy: 0.6484375\n",
      "Batch: 31, Loss: 1.1581006050109863, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.027207851409912, Accuracy: 0.6630859375\n",
      "Batch: 33, Loss: 1.0116240978240967, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.041868805885315, Accuracy: 0.6669921875\n",
      "Batch: 35, Loss: 1.075010061264038, Accuracy: 0.6298828125\n",
      "Batch: 36, Loss: 1.1595627069473267, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.2390398979187012, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.1797314882278442, Accuracy: 0.599609375\n",
      "Batch: 39, Loss: 1.039144515991211, Accuracy: 0.6630859375\n",
      "Batch: 40, Loss: 1.0921392440795898, Accuracy: 0.640625\n",
      "Batch: 41, Loss: 1.0141716003417969, Accuracy: 0.66796875\n",
      "Batch: 42, Loss: 1.0166676044464111, Accuracy: 0.65625\n",
      "Batch: 43, Loss: 1.0267654657363892, Accuracy: 0.6533203125\n",
      "Batch: 44, Loss: 0.9940118789672852, Accuracy: 0.6630859375\n",
      "Batch: 45, Loss: 1.0362238883972168, Accuracy: 0.642578125\n",
      "Batch: 46, Loss: 1.1166887283325195, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.087388515472412, Accuracy: 0.654296875\n",
      "Batch: 48, Loss: 1.0934462547302246, Accuracy: 0.630859375\n",
      "Batch: 49, Loss: 1.1208858489990234, Accuracy: 0.654296875\n",
      "Batch: 50, Loss: 1.1152222156524658, Accuracy: 0.625\n",
      "Batch: 51, Loss: 1.1130863428115845, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.17569899559021, Accuracy: 0.6416015625\n",
      "Batch: 53, Loss: 1.1181011199951172, Accuracy: 0.6357421875\n",
      "Batch: 54, Loss: 1.0792083740234375, Accuracy: 0.6533203125\n",
      "Batch: 55, Loss: 1.0668712854385376, Accuracy: 0.6572265625\n",
      "Batch: 56, Loss: 1.084604263305664, Accuracy: 0.6455078125\n",
      "Batch: 57, Loss: 1.0548927783966064, Accuracy: 0.6533203125\n",
      "Batch: 58, Loss: 1.0873606204986572, Accuracy: 0.638671875\n",
      "Batch: 59, Loss: 1.0869505405426025, Accuracy: 0.65234375\n",
      "Batch: 60, Loss: 1.188218116760254, Accuracy: 0.62890625\n",
      "Batch: 61, Loss: 1.084031105041504, Accuracy: 0.6298828125\n",
      "Batch: 62, Loss: 1.0862212181091309, Accuracy: 0.6455078125\n",
      "Batch: 63, Loss: 1.1638814210891724, Accuracy: 0.62109375\n",
      "Batch: 64, Loss: 1.185456395149231, Accuracy: 0.6123046875\n",
      "Batch: 65, Loss: 1.1464040279388428, Accuracy: 0.6181640625\n",
      "Batch: 66, Loss: 1.0991584062576294, Accuracy: 0.650390625\n",
      "Batch: 67, Loss: 1.1355457305908203, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0530524253845215, Accuracy: 0.6806640625\n",
      "Batch: 69, Loss: 1.1780602931976318, Accuracy: 0.6171875\n",
      "Batch: 70, Loss: 1.138293743133545, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.0693426132202148, Accuracy: 0.6357421875\n",
      "Batch: 72, Loss: 1.1126058101654053, Accuracy: 0.6455078125\n",
      "Batch: 73, Loss: 1.1346968412399292, Accuracy: 0.6337890625\n",
      "Batch: 74, Loss: 1.0801024436950684, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.0759798288345337, Accuracy: 0.6484375\n",
      "Batch: 76, Loss: 1.0601696968078613, Accuracy: 0.65625\n",
      "Batch: 77, Loss: 1.0220086574554443, Accuracy: 0.666015625\n",
      "Batch: 78, Loss: 1.0364705324172974, Accuracy: 0.662109375\n",
      "Batch: 79, Loss: 1.1098109483718872, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1259851455688477, Accuracy: 0.65234375\n",
      "Batch: 81, Loss: 1.0531575679779053, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 1.0486327409744263, Accuracy: 0.6689453125\n",
      "Batch: 83, Loss: 1.1171443462371826, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.075087070465088, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.1530201435089111, Accuracy: 0.619140625\n",
      "Batch: 86, Loss: 1.1002345085144043, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 1.077672004699707, Accuracy: 0.662109375\n",
      "Batch: 88, Loss: 1.1384048461914062, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.1068780422210693, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0300590991973877, Accuracy: 0.65625\n",
      "Batch: 91, Loss: 1.0578866004943848, Accuracy: 0.64453125\n",
      "Batch: 92, Loss: 1.1198763847351074, Accuracy: 0.646484375\n",
      "Batch: 93, Loss: 1.0636487007141113, Accuracy: 0.6572265625\n",
      "Batch: 94, Loss: 1.1418401002883911, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.2079238891601562, Accuracy: 0.6064453125\n",
      "Batch: 96, Loss: 1.1571290493011475, Accuracy: 0.6552734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 97, Loss: 1.1384756565093994, Accuracy: 0.6318359375\n",
      "Batch: 98, Loss: 1.0693914890289307, Accuracy: 0.650390625\n",
      "Batch: 99, Loss: 1.0411165952682495, Accuracy: 0.6708984375\n",
      "Batch: 100, Loss: 1.0517520904541016, Accuracy: 0.662109375\n",
      "Batch: 101, Loss: 1.0395832061767578, Accuracy: 0.654296875\n",
      "Batch: 102, Loss: 1.0938551425933838, Accuracy: 0.658203125\n",
      "Batch: 103, Loss: 1.1565265655517578, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.1074445247650146, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.109764814376831, Accuracy: 0.64453125\n",
      "Batch: 106, Loss: 1.145304560661316, Accuracy: 0.6328125\n",
      "Batch: 107, Loss: 1.2099037170410156, Accuracy: 0.603515625\n",
      "Batch: 108, Loss: 1.1017118692398071, Accuracy: 0.6376953125\n",
      "Batch: 109, Loss: 1.1333121061325073, Accuracy: 0.638671875\n",
      "Batch: 110, Loss: 1.1288584470748901, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.0905823707580566, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.0289760828018188, Accuracy: 0.658203125\n",
      "Batch: 113, Loss: 1.0760488510131836, Accuracy: 0.6552734375\n",
      "Batch: 114, Loss: 1.1569926738739014, Accuracy: 0.615234375\n",
      "Batch: 115, Loss: 1.133061170578003, Accuracy: 0.6376953125\n",
      "Batch: 116, Loss: 1.175894856452942, Accuracy: 0.6162109375\n",
      "Batch: 117, Loss: 1.1592036485671997, Accuracy: 0.6298828125\n",
      "Batch: 118, Loss: 1.1649961471557617, Accuracy: 0.6162109375\n",
      "Batch: 119, Loss: 1.1936815977096558, Accuracy: 0.609375\n",
      "Batch: 120, Loss: 1.1919487714767456, Accuracy: 0.61328125\n",
      "Batch: 121, Loss: 1.1636182069778442, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.208774447441101, Accuracy: 0.609375\n",
      "Batch: 123, Loss: 1.0467380285263062, Accuracy: 0.6728515625\n",
      "Batch: 124, Loss: 1.1500000953674316, Accuracy: 0.62890625\n",
      "Batch: 125, Loss: 1.142797589302063, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.1874934434890747, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.1398555040359497, Accuracy: 0.6357421875\n",
      "Batch: 128, Loss: 1.1090455055236816, Accuracy: 0.634765625\n",
      "Batch: 129, Loss: 1.160757303237915, Accuracy: 0.6015625\n",
      "Batch: 130, Loss: 1.1049091815948486, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 1.1419326066970825, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 0.9940500259399414, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 1.1061831712722778, Accuracy: 0.64453125\n",
      "Batch: 134, Loss: 1.1231225728988647, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.0052188634872437, Accuracy: 0.67578125\n",
      "Batch: 136, Loss: 1.0863195657730103, Accuracy: 0.6513671875\n",
      "Batch: 137, Loss: 1.0959792137145996, Accuracy: 0.6611328125\n",
      "Batch: 138, Loss: 1.1608763933181763, Accuracy: 0.6220703125\n",
      "Batch: 139, Loss: 1.1389656066894531, Accuracy: 0.6552734375\n",
      "Batch: 140, Loss: 1.1466575860977173, Accuracy: 0.626953125\n",
      "Batch: 141, Loss: 1.153764247894287, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.1379756927490234, Accuracy: 0.638671875\n",
      "Batch: 143, Loss: 1.121020793914795, Accuracy: 0.634765625\n",
      "Batch: 144, Loss: 1.1301690340042114, Accuracy: 0.6328125\n",
      "Batch: 145, Loss: 1.1951853036880493, Accuracy: 0.607421875\n",
      "Batch: 146, Loss: 1.1726200580596924, Accuracy: 0.6337890625\n",
      "Batch: 147, Loss: 1.1323046684265137, Accuracy: 0.6416015625\n",
      "Batch: 148, Loss: 1.1669584512710571, Accuracy: 0.6240234375\n",
      "Batch: 149, Loss: 1.137978434562683, Accuracy: 0.6171875\n",
      "Batch: 150, Loss: 1.097226619720459, Accuracy: 0.6435546875\n",
      "Batch: 151, Loss: 1.1051361560821533, Accuracy: 0.623046875\n",
      "Batch: 152, Loss: 1.0900341272354126, Accuracy: 0.64453125\n",
      "Batch: 153, Loss: 1.1106785535812378, Accuracy: 0.619140625\n",
      "Batch: 154, Loss: 1.0429128408432007, Accuracy: 0.6611328125\n",
      "Batch: 155, Loss: 1.0459721088409424, Accuracy: 0.6650390625\n",
      "Epoch 594/200\n",
      "Batch: 1, Loss: 1.1747230291366577, Accuracy: 0.666015625\n",
      "Batch: 2, Loss: 1.0604792833328247, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 1.0661565065383911, Accuracy: 0.646484375\n",
      "Batch: 4, Loss: 1.053342580795288, Accuracy: 0.634765625\n",
      "Batch: 5, Loss: 0.9718567728996277, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0493454933166504, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 0.9921091198921204, Accuracy: 0.6708984375\n",
      "Batch: 8, Loss: 0.9835984706878662, Accuracy: 0.697265625\n",
      "Batch: 9, Loss: 0.9432348012924194, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9084482192993164, Accuracy: 0.705078125\n",
      "Batch: 11, Loss: 0.893925666809082, Accuracy: 0.697265625\n",
      "Batch: 12, Loss: 0.9767544269561768, Accuracy: 0.6865234375\n",
      "Batch: 13, Loss: 1.0055029392242432, Accuracy: 0.6611328125\n",
      "Batch: 14, Loss: 0.9274046421051025, Accuracy: 0.697265625\n",
      "Batch: 15, Loss: 0.9615792036056519, Accuracy: 0.689453125\n",
      "Batch: 16, Loss: 1.0109306573867798, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 1.0202521085739136, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.1286866664886475, Accuracy: 0.6181640625\n",
      "Batch: 19, Loss: 1.1556882858276367, Accuracy: 0.6220703125\n",
      "Batch: 20, Loss: 1.0590850114822388, Accuracy: 0.6669921875\n",
      "Batch: 21, Loss: 1.0443434715270996, Accuracy: 0.654296875\n",
      "Batch: 22, Loss: 1.196831226348877, Accuracy: 0.6181640625\n",
      "Batch: 23, Loss: 1.1970274448394775, Accuracy: 0.615234375\n",
      "Batch: 24, Loss: 1.0545525550842285, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.1052900552749634, Accuracy: 0.64453125\n",
      "Batch: 26, Loss: 1.1399990320205688, Accuracy: 0.6376953125\n",
      "Batch: 27, Loss: 1.0943603515625, Accuracy: 0.6337890625\n",
      "Batch: 28, Loss: 1.021460771560669, Accuracy: 0.67578125\n",
      "Batch: 29, Loss: 1.000878095626831, Accuracy: 0.6826171875\n",
      "Batch: 30, Loss: 1.1266220808029175, Accuracy: 0.619140625\n",
      "Batch: 31, Loss: 1.1524490118026733, Accuracy: 0.6318359375\n",
      "Batch: 32, Loss: 1.0035369396209717, Accuracy: 0.6845703125\n",
      "Batch: 33, Loss: 0.9615039825439453, Accuracy: 0.6669921875\n",
      "Batch: 34, Loss: 1.0171386003494263, Accuracy: 0.671875\n",
      "Batch: 35, Loss: 1.0344353914260864, Accuracy: 0.6689453125\n",
      "Batch: 36, Loss: 1.1255338191986084, Accuracy: 0.6298828125\n",
      "Batch: 37, Loss: 1.175868272781372, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.1392021179199219, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 1.0386109352111816, Accuracy: 0.6474609375\n",
      "Batch: 40, Loss: 1.0154732465744019, Accuracy: 0.6611328125\n",
      "Batch: 41, Loss: 1.1101391315460205, Accuracy: 0.64453125\n",
      "Batch: 42, Loss: 1.0009657144546509, Accuracy: 0.671875\n",
      "Batch: 43, Loss: 1.0695375204086304, Accuracy: 0.64453125\n",
      "Batch: 44, Loss: 0.9891968965530396, Accuracy: 0.67578125\n",
      "Batch: 45, Loss: 1.0569489002227783, Accuracy: 0.6572265625\n",
      "Batch: 46, Loss: 1.0476096868515015, Accuracy: 0.666015625\n",
      "Batch: 47, Loss: 1.0690182447433472, Accuracy: 0.6640625\n",
      "Batch: 48, Loss: 1.1269437074661255, Accuracy: 0.64453125\n",
      "Batch: 49, Loss: 1.121385097503662, Accuracy: 0.634765625\n",
      "Batch: 50, Loss: 1.0412280559539795, Accuracy: 0.662109375\n",
      "Batch: 51, Loss: 1.0690938234329224, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.2075912952423096, Accuracy: 0.6064453125\n",
      "Batch: 53, Loss: 1.180159330368042, Accuracy: 0.5908203125\n",
      "Batch: 54, Loss: 1.1178576946258545, Accuracy: 0.6240234375\n",
      "Batch: 55, Loss: 1.0370917320251465, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.0829235315322876, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.0543911457061768, Accuracy: 0.66796875\n",
      "Batch: 58, Loss: 1.0457197427749634, Accuracy: 0.6533203125\n",
      "Batch: 59, Loss: 1.0352710485458374, Accuracy: 0.6455078125\n",
      "Batch: 60, Loss: 1.2113571166992188, Accuracy: 0.62109375\n",
      "Batch: 61, Loss: 1.1231974363327026, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.0883071422576904, Accuracy: 0.6328125\n",
      "Batch: 63, Loss: 1.1451284885406494, Accuracy: 0.6259765625\n",
      "Batch: 64, Loss: 1.1334311962127686, Accuracy: 0.6103515625\n",
      "Batch: 65, Loss: 1.1922352313995361, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.1023914813995361, Accuracy: 0.65234375\n",
      "Batch: 67, Loss: 1.109968900680542, Accuracy: 0.646484375\n",
      "Batch: 68, Loss: 1.022130012512207, Accuracy: 0.673828125\n",
      "Batch: 69, Loss: 1.1376391649246216, Accuracy: 0.646484375\n",
      "Batch: 70, Loss: 1.142594337463379, Accuracy: 0.6318359375\n",
      "Batch: 71, Loss: 1.1308495998382568, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 1.1276626586914062, Accuracy: 0.6396484375\n",
      "Batch: 73, Loss: 1.1428589820861816, Accuracy: 0.630859375\n",
      "Batch: 74, Loss: 1.072108268737793, Accuracy: 0.6591796875\n",
      "Batch: 75, Loss: 1.0917408466339111, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.0800261497497559, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.0529727935791016, Accuracy: 0.6650390625\n",
      "Batch: 78, Loss: 1.0275171995162964, Accuracy: 0.6669921875\n",
      "Batch: 79, Loss: 1.0850720405578613, Accuracy: 0.6396484375\n",
      "Batch: 80, Loss: 1.1828734874725342, Accuracy: 0.615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 1.0761616230010986, Accuracy: 0.662109375\n",
      "Batch: 82, Loss: 1.0790454149246216, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.24600350856781, Accuracy: 0.6044921875\n",
      "Batch: 84, Loss: 1.0717425346374512, Accuracy: 0.6552734375\n",
      "Batch: 85, Loss: 1.1257600784301758, Accuracy: 0.6328125\n",
      "Batch: 86, Loss: 1.0630993843078613, Accuracy: 0.6494140625\n",
      "Batch: 87, Loss: 1.1580150127410889, Accuracy: 0.6181640625\n",
      "Batch: 88, Loss: 1.1218000650405884, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.057463526725769, Accuracy: 0.662109375\n",
      "Batch: 90, Loss: 1.0805292129516602, Accuracy: 0.646484375\n",
      "Batch: 91, Loss: 1.050873041152954, Accuracy: 0.646484375\n",
      "Batch: 92, Loss: 1.068820595741272, Accuracy: 0.6513671875\n",
      "Batch: 93, Loss: 1.098225474357605, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.1741584539413452, Accuracy: 0.6220703125\n",
      "Batch: 95, Loss: 1.1225630044937134, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.1942939758300781, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.1574152708053589, Accuracy: 0.6279296875\n",
      "Batch: 98, Loss: 1.0708215236663818, Accuracy: 0.6357421875\n",
      "Batch: 99, Loss: 1.1117591857910156, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 1.0227982997894287, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.0743998289108276, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.1325619220733643, Accuracy: 0.640625\n",
      "Batch: 103, Loss: 1.1078124046325684, Accuracy: 0.64453125\n",
      "Batch: 104, Loss: 1.0707852840423584, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.1273322105407715, Accuracy: 0.6298828125\n",
      "Batch: 106, Loss: 1.188364028930664, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.1775236129760742, Accuracy: 0.634765625\n",
      "Batch: 108, Loss: 1.1269893646240234, Accuracy: 0.6357421875\n",
      "Batch: 109, Loss: 1.1594414710998535, Accuracy: 0.6142578125\n",
      "Batch: 110, Loss: 1.1101181507110596, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.0717170238494873, Accuracy: 0.650390625\n",
      "Batch: 112, Loss: 1.0576814413070679, Accuracy: 0.6513671875\n",
      "Batch: 113, Loss: 1.1058930158615112, Accuracy: 0.6318359375\n",
      "Batch: 114, Loss: 1.1462935209274292, Accuracy: 0.623046875\n",
      "Batch: 115, Loss: 1.1760698556900024, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1784119606018066, Accuracy: 0.595703125\n",
      "Batch: 117, Loss: 1.1318352222442627, Accuracy: 0.6103515625\n",
      "Batch: 118, Loss: 1.1700749397277832, Accuracy: 0.6171875\n",
      "Batch: 119, Loss: 1.187333583831787, Accuracy: 0.61328125\n",
      "Batch: 120, Loss: 1.2497384548187256, Accuracy: 0.595703125\n",
      "Batch: 121, Loss: 1.072333812713623, Accuracy: 0.650390625\n",
      "Batch: 122, Loss: 1.1492562294006348, Accuracy: 0.6103515625\n",
      "Batch: 123, Loss: 1.0730477571487427, Accuracy: 0.6533203125\n",
      "Batch: 124, Loss: 1.150394082069397, Accuracy: 0.640625\n",
      "Batch: 125, Loss: 1.0682318210601807, Accuracy: 0.6318359375\n",
      "Batch: 126, Loss: 1.1532649993896484, Accuracy: 0.6435546875\n",
      "Batch: 127, Loss: 1.1894361972808838, Accuracy: 0.6171875\n",
      "Batch: 128, Loss: 1.1477036476135254, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.155691146850586, Accuracy: 0.6142578125\n",
      "Batch: 130, Loss: 1.0734357833862305, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.1802793741226196, Accuracy: 0.6064453125\n",
      "Batch: 132, Loss: 1.0332952737808228, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 1.0885730981826782, Accuracy: 0.6533203125\n",
      "Batch: 134, Loss: 1.0934302806854248, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 0.9992493391036987, Accuracy: 0.65625\n",
      "Batch: 136, Loss: 1.086290717124939, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.126206636428833, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 1.1904726028442383, Accuracy: 0.60546875\n",
      "Batch: 139, Loss: 1.1829726696014404, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.130832314491272, Accuracy: 0.630859375\n",
      "Batch: 141, Loss: 1.1203675270080566, Accuracy: 0.6318359375\n",
      "Batch: 142, Loss: 1.1323318481445312, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1748400926589966, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.2024593353271484, Accuracy: 0.62890625\n",
      "Batch: 145, Loss: 1.236494779586792, Accuracy: 0.587890625\n",
      "Batch: 146, Loss: 1.1644779443740845, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.17969810962677, Accuracy: 0.6123046875\n",
      "Batch: 148, Loss: 1.1433842182159424, Accuracy: 0.6357421875\n",
      "Batch: 149, Loss: 1.0548250675201416, Accuracy: 0.6533203125\n",
      "Batch: 150, Loss: 1.1321508884429932, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.1280250549316406, Accuracy: 0.634765625\n",
      "Batch: 152, Loss: 1.1074519157409668, Accuracy: 0.642578125\n",
      "Batch: 153, Loss: 1.0885283946990967, Accuracy: 0.6474609375\n",
      "Batch: 154, Loss: 1.0644636154174805, Accuracy: 0.6455078125\n",
      "Batch: 155, Loss: 1.0476422309875488, Accuracy: 0.654296875\n",
      "Epoch 595/200\n",
      "Batch: 1, Loss: 1.196265697479248, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.0657994747161865, Accuracy: 0.6630859375\n",
      "Batch: 3, Loss: 1.0588515996932983, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 1.0263155698776245, Accuracy: 0.6396484375\n",
      "Batch: 5, Loss: 0.9975411891937256, Accuracy: 0.6865234375\n",
      "Batch: 6, Loss: 1.0165629386901855, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 0.9551504850387573, Accuracy: 0.6826171875\n",
      "Batch: 8, Loss: 0.9689486026763916, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 0.9545348286628723, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9329515695571899, Accuracy: 0.6865234375\n",
      "Batch: 11, Loss: 0.9403588175773621, Accuracy: 0.662109375\n",
      "Batch: 12, Loss: 0.935434103012085, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 1.014420986175537, Accuracy: 0.6513671875\n",
      "Batch: 14, Loss: 0.9019985198974609, Accuracy: 0.7236328125\n",
      "Batch: 15, Loss: 0.8984618782997131, Accuracy: 0.708984375\n",
      "Batch: 16, Loss: 0.9616692662239075, Accuracy: 0.697265625\n",
      "Batch: 17, Loss: 1.0257086753845215, Accuracy: 0.666015625\n",
      "Batch: 18, Loss: 1.1119385957717896, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.2329890727996826, Accuracy: 0.611328125\n",
      "Batch: 20, Loss: 1.0522994995117188, Accuracy: 0.673828125\n",
      "Batch: 21, Loss: 1.021836519241333, Accuracy: 0.6630859375\n",
      "Batch: 22, Loss: 1.2063391208648682, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.210448980331421, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.0682164430618286, Accuracy: 0.66015625\n",
      "Batch: 25, Loss: 1.1049060821533203, Accuracy: 0.6474609375\n",
      "Batch: 26, Loss: 1.1234982013702393, Accuracy: 0.650390625\n",
      "Batch: 27, Loss: 1.0996038913726807, Accuracy: 0.63671875\n",
      "Batch: 28, Loss: 0.9941880702972412, Accuracy: 0.6796875\n",
      "Batch: 29, Loss: 0.9805738925933838, Accuracy: 0.6787109375\n",
      "Batch: 30, Loss: 1.13080894947052, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.1361223459243774, Accuracy: 0.6279296875\n",
      "Batch: 32, Loss: 1.0342073440551758, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 0.9448342323303223, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.10155189037323, Accuracy: 0.642578125\n",
      "Batch: 35, Loss: 1.1170973777770996, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.157813310623169, Accuracy: 0.6064453125\n",
      "Batch: 37, Loss: 1.1216857433319092, Accuracy: 0.6298828125\n",
      "Batch: 38, Loss: 1.1484392881393433, Accuracy: 0.63671875\n",
      "Batch: 39, Loss: 1.0252546072006226, Accuracy: 0.66796875\n",
      "Batch: 40, Loss: 1.0537326335906982, Accuracy: 0.640625\n",
      "Batch: 41, Loss: 1.0989553928375244, Accuracy: 0.62890625\n",
      "Batch: 42, Loss: 1.0836236476898193, Accuracy: 0.638671875\n",
      "Batch: 43, Loss: 1.0387787818908691, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0263967514038086, Accuracy: 0.6552734375\n",
      "Batch: 45, Loss: 1.0300588607788086, Accuracy: 0.650390625\n",
      "Batch: 46, Loss: 1.0661633014678955, Accuracy: 0.65625\n",
      "Batch: 47, Loss: 1.0619301795959473, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0792971849441528, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.1227355003356934, Accuracy: 0.6455078125\n",
      "Batch: 50, Loss: 1.099802017211914, Accuracy: 0.646484375\n",
      "Batch: 51, Loss: 1.1214878559112549, Accuracy: 0.64453125\n",
      "Batch: 52, Loss: 1.1737349033355713, Accuracy: 0.6171875\n",
      "Batch: 53, Loss: 1.1274932622909546, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.1325347423553467, Accuracy: 0.6298828125\n",
      "Batch: 55, Loss: 1.0580346584320068, Accuracy: 0.65625\n",
      "Batch: 56, Loss: 1.0614031553268433, Accuracy: 0.66015625\n",
      "Batch: 57, Loss: 1.0744019746780396, Accuracy: 0.6455078125\n",
      "Batch: 58, Loss: 1.0686125755310059, Accuracy: 0.6416015625\n",
      "Batch: 59, Loss: 1.0631210803985596, Accuracy: 0.650390625\n",
      "Batch: 60, Loss: 1.1791315078735352, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.0898480415344238, Accuracy: 0.626953125\n",
      "Batch: 62, Loss: 1.091713547706604, Accuracy: 0.6357421875\n",
      "Batch: 63, Loss: 1.128126621246338, Accuracy: 0.6259765625\n",
      "Batch: 64, Loss: 1.127863883972168, Accuracy: 0.6376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 65, Loss: 1.1173889636993408, Accuracy: 0.6376953125\n",
      "Batch: 66, Loss: 1.0494158267974854, Accuracy: 0.666015625\n",
      "Batch: 67, Loss: 1.1190130710601807, Accuracy: 0.63671875\n",
      "Batch: 68, Loss: 1.0624616146087646, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 1.1332550048828125, Accuracy: 0.634765625\n",
      "Batch: 70, Loss: 1.1804478168487549, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.1035277843475342, Accuracy: 0.6416015625\n",
      "Batch: 72, Loss: 1.1816375255584717, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.141385555267334, Accuracy: 0.6494140625\n",
      "Batch: 74, Loss: 1.078108549118042, Accuracy: 0.6494140625\n",
      "Batch: 75, Loss: 1.0787502527236938, Accuracy: 0.63671875\n",
      "Batch: 76, Loss: 1.008453369140625, Accuracy: 0.666015625\n",
      "Batch: 77, Loss: 1.0601850748062134, Accuracy: 0.6513671875\n",
      "Batch: 78, Loss: 1.0455818176269531, Accuracy: 0.6513671875\n",
      "Batch: 79, Loss: 1.1071457862854004, Accuracy: 0.6552734375\n",
      "Batch: 80, Loss: 1.1665279865264893, Accuracy: 0.61328125\n",
      "Batch: 81, Loss: 1.074947714805603, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 1.0987193584442139, Accuracy: 0.646484375\n",
      "Batch: 83, Loss: 1.1235601902008057, Accuracy: 0.642578125\n",
      "Batch: 84, Loss: 1.036653757095337, Accuracy: 0.6533203125\n",
      "Batch: 85, Loss: 1.1231292486190796, Accuracy: 0.6337890625\n",
      "Batch: 86, Loss: 1.1040778160095215, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 1.1038414239883423, Accuracy: 0.6640625\n",
      "Batch: 88, Loss: 1.1277233362197876, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.0885415077209473, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.0075536966323853, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.1066609621047974, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.077290415763855, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 1.0614075660705566, Accuracy: 0.6748046875\n",
      "Batch: 94, Loss: 1.0979430675506592, Accuracy: 0.6474609375\n",
      "Batch: 95, Loss: 1.13144850730896, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.174979567527771, Accuracy: 0.625\n",
      "Batch: 97, Loss: 1.1543688774108887, Accuracy: 0.6142578125\n",
      "Batch: 98, Loss: 1.0413625240325928, Accuracy: 0.6494140625\n",
      "Batch: 99, Loss: 1.0567080974578857, Accuracy: 0.6630859375\n",
      "Batch: 100, Loss: 1.0372018814086914, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.0108017921447754, Accuracy: 0.666015625\n",
      "Batch: 102, Loss: 1.1129090785980225, Accuracy: 0.66015625\n",
      "Batch: 103, Loss: 1.1800990104675293, Accuracy: 0.6181640625\n",
      "Batch: 104, Loss: 1.0452778339385986, Accuracy: 0.6650390625\n",
      "Batch: 105, Loss: 1.1418769359588623, Accuracy: 0.638671875\n",
      "Batch: 106, Loss: 1.1630247831344604, Accuracy: 0.6181640625\n",
      "Batch: 107, Loss: 1.209189534187317, Accuracy: 0.6044921875\n",
      "Batch: 108, Loss: 1.133224368095398, Accuracy: 0.6240234375\n",
      "Batch: 109, Loss: 1.101957082748413, Accuracy: 0.6298828125\n",
      "Batch: 110, Loss: 1.1364378929138184, Accuracy: 0.626953125\n",
      "Batch: 111, Loss: 1.0535492897033691, Accuracy: 0.6494140625\n",
      "Batch: 112, Loss: 1.058016300201416, Accuracy: 0.66015625\n",
      "Batch: 113, Loss: 1.0232912302017212, Accuracy: 0.6591796875\n",
      "Batch: 114, Loss: 1.0983328819274902, Accuracy: 0.62109375\n",
      "Batch: 115, Loss: 1.161057949066162, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.1850972175598145, Accuracy: 0.6171875\n",
      "Batch: 117, Loss: 1.1229047775268555, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.2207491397857666, Accuracy: 0.603515625\n",
      "Batch: 119, Loss: 1.1636028289794922, Accuracy: 0.623046875\n",
      "Batch: 120, Loss: 1.218754529953003, Accuracy: 0.6123046875\n",
      "Batch: 121, Loss: 1.1101653575897217, Accuracy: 0.6484375\n",
      "Batch: 122, Loss: 1.1775362491607666, Accuracy: 0.59765625\n",
      "Batch: 123, Loss: 1.1682844161987305, Accuracy: 0.6298828125\n",
      "Batch: 124, Loss: 1.1235296726226807, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.1306915283203125, Accuracy: 0.63671875\n",
      "Batch: 126, Loss: 1.1549742221832275, Accuracy: 0.6298828125\n",
      "Batch: 127, Loss: 1.268911361694336, Accuracy: 0.580078125\n",
      "Batch: 128, Loss: 1.210823893547058, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.1725959777832031, Accuracy: 0.615234375\n",
      "Batch: 130, Loss: 1.1043870449066162, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.165075659751892, Accuracy: 0.615234375\n",
      "Batch: 132, Loss: 1.0197203159332275, Accuracy: 0.6748046875\n",
      "Batch: 133, Loss: 1.1024246215820312, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.0312411785125732, Accuracy: 0.6787109375\n",
      "Batch: 135, Loss: 0.9854786396026611, Accuracy: 0.6923828125\n",
      "Batch: 136, Loss: 1.0247843265533447, Accuracy: 0.6611328125\n",
      "Batch: 137, Loss: 1.1404855251312256, Accuracy: 0.6328125\n",
      "Batch: 138, Loss: 1.209395408630371, Accuracy: 0.6044921875\n",
      "Batch: 139, Loss: 1.1068657636642456, Accuracy: 0.64453125\n",
      "Batch: 140, Loss: 1.1811374425888062, Accuracy: 0.62890625\n",
      "Batch: 141, Loss: 1.1173126697540283, Accuracy: 0.646484375\n",
      "Batch: 142, Loss: 1.1806402206420898, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.154655933380127, Accuracy: 0.619140625\n",
      "Batch: 144, Loss: 1.231007695198059, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.2379164695739746, Accuracy: 0.60546875\n",
      "Batch: 146, Loss: 1.1373956203460693, Accuracy: 0.638671875\n",
      "Batch: 147, Loss: 1.149219036102295, Accuracy: 0.62890625\n",
      "Batch: 148, Loss: 1.1814485788345337, Accuracy: 0.6259765625\n",
      "Batch: 149, Loss: 1.1712793111801147, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.0728455781936646, Accuracy: 0.626953125\n",
      "Batch: 151, Loss: 1.1261239051818848, Accuracy: 0.626953125\n",
      "Batch: 152, Loss: 1.1564576625823975, Accuracy: 0.61328125\n",
      "Batch: 153, Loss: 1.0411806106567383, Accuracy: 0.6591796875\n",
      "Batch: 154, Loss: 1.0666574239730835, Accuracy: 0.662109375\n",
      "Batch: 155, Loss: 1.0581778287887573, Accuracy: 0.6484375\n",
      "Epoch 596/200\n",
      "Batch: 1, Loss: 1.1417286396026611, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 1.0667357444763184, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 1.022581934928894, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 1.0031695365905762, Accuracy: 0.671875\n",
      "Batch: 5, Loss: 0.9577205181121826, Accuracy: 0.68359375\n",
      "Batch: 6, Loss: 1.025155782699585, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 1.0138331651687622, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 0.9680995345115662, Accuracy: 0.69921875\n",
      "Batch: 9, Loss: 0.995913028717041, Accuracy: 0.6923828125\n",
      "Batch: 10, Loss: 0.9273462295532227, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 0.922160267829895, Accuracy: 0.6943359375\n",
      "Batch: 12, Loss: 1.0035450458526611, Accuracy: 0.65625\n",
      "Batch: 13, Loss: 1.0161224603652954, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 0.919972836971283, Accuracy: 0.716796875\n",
      "Batch: 15, Loss: 0.9339430332183838, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 0.9473917484283447, Accuracy: 0.6953125\n",
      "Batch: 17, Loss: 1.0367329120635986, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.0981502532958984, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.1811716556549072, Accuracy: 0.60546875\n",
      "Batch: 20, Loss: 1.0832188129425049, Accuracy: 0.6591796875\n",
      "Batch: 21, Loss: 1.0512773990631104, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1555097103118896, Accuracy: 0.6162109375\n",
      "Batch: 23, Loss: 1.1742424964904785, Accuracy: 0.6171875\n",
      "Batch: 24, Loss: 1.0357353687286377, Accuracy: 0.6552734375\n",
      "Batch: 25, Loss: 1.0669806003570557, Accuracy: 0.650390625\n",
      "Batch: 26, Loss: 1.132007360458374, Accuracy: 0.61328125\n",
      "Batch: 27, Loss: 1.0293934345245361, Accuracy: 0.650390625\n",
      "Batch: 28, Loss: 1.0423216819763184, Accuracy: 0.658203125\n",
      "Batch: 29, Loss: 1.0037580728530884, Accuracy: 0.6708984375\n",
      "Batch: 30, Loss: 1.1187500953674316, Accuracy: 0.646484375\n",
      "Batch: 31, Loss: 1.152449607849121, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.0607736110687256, Accuracy: 0.654296875\n",
      "Batch: 33, Loss: 0.9715484380722046, Accuracy: 0.693359375\n",
      "Batch: 34, Loss: 1.0377907752990723, Accuracy: 0.6748046875\n",
      "Batch: 35, Loss: 1.0976123809814453, Accuracy: 0.6328125\n",
      "Batch: 36, Loss: 1.1422035694122314, Accuracy: 0.609375\n",
      "Batch: 37, Loss: 1.141123652458191, Accuracy: 0.626953125\n",
      "Batch: 38, Loss: 1.177389144897461, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.0527528524398804, Accuracy: 0.6650390625\n",
      "Batch: 40, Loss: 1.046520471572876, Accuracy: 0.6630859375\n",
      "Batch: 41, Loss: 1.0516573190689087, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 1.0200119018554688, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.0220274925231934, Accuracy: 0.6630859375\n",
      "Batch: 44, Loss: 1.044779658317566, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 0.9618051052093506, Accuracy: 0.6845703125\n",
      "Batch: 46, Loss: 1.0874814987182617, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.0286732912063599, Accuracy: 0.666015625\n",
      "Batch: 48, Loss: 1.110142707824707, Accuracy: 0.619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 49, Loss: 1.0783724784851074, Accuracy: 0.6328125\n",
      "Batch: 50, Loss: 1.0651262998580933, Accuracy: 0.646484375\n",
      "Batch: 51, Loss: 1.1002376079559326, Accuracy: 0.64453125\n",
      "Batch: 52, Loss: 1.1553735733032227, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.1391761302947998, Accuracy: 0.62890625\n",
      "Batch: 54, Loss: 1.101385474205017, Accuracy: 0.642578125\n",
      "Batch: 55, Loss: 1.138203740119934, Accuracy: 0.6240234375\n",
      "Batch: 56, Loss: 1.0442534685134888, Accuracy: 0.66015625\n",
      "Batch: 57, Loss: 1.0567835569381714, Accuracy: 0.6728515625\n",
      "Batch: 58, Loss: 1.1302169561386108, Accuracy: 0.6337890625\n",
      "Batch: 59, Loss: 1.0437252521514893, Accuracy: 0.662109375\n",
      "Batch: 60, Loss: 1.1907525062561035, Accuracy: 0.6142578125\n",
      "Batch: 61, Loss: 1.0833300352096558, Accuracy: 0.630859375\n",
      "Batch: 62, Loss: 1.1090426445007324, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.0861601829528809, Accuracy: 0.640625\n",
      "Batch: 64, Loss: 1.1909596920013428, Accuracy: 0.611328125\n",
      "Batch: 65, Loss: 1.1490845680236816, Accuracy: 0.6279296875\n",
      "Batch: 66, Loss: 1.1036545038223267, Accuracy: 0.65234375\n",
      "Batch: 67, Loss: 1.0764079093933105, Accuracy: 0.63671875\n",
      "Batch: 68, Loss: 1.0499571561813354, Accuracy: 0.6708984375\n",
      "Batch: 69, Loss: 1.1205811500549316, Accuracy: 0.62890625\n",
      "Batch: 70, Loss: 1.120970368385315, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.1545367240905762, Accuracy: 0.61328125\n",
      "Batch: 72, Loss: 1.1159625053405762, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.1218563318252563, Accuracy: 0.6357421875\n",
      "Batch: 74, Loss: 1.061147689819336, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.0790486335754395, Accuracy: 0.6533203125\n",
      "Batch: 76, Loss: 1.0845847129821777, Accuracy: 0.654296875\n",
      "Batch: 77, Loss: 1.0327156782150269, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.011890172958374, Accuracy: 0.66015625\n",
      "Batch: 79, Loss: 1.0816439390182495, Accuracy: 0.640625\n",
      "Batch: 80, Loss: 1.1628882884979248, Accuracy: 0.609375\n",
      "Batch: 81, Loss: 1.0675920248031616, Accuracy: 0.658203125\n",
      "Batch: 82, Loss: 1.10072922706604, Accuracy: 0.638671875\n",
      "Batch: 83, Loss: 1.1816980838775635, Accuracy: 0.619140625\n",
      "Batch: 84, Loss: 1.0839951038360596, Accuracy: 0.642578125\n",
      "Batch: 85, Loss: 1.1313525438308716, Accuracy: 0.6162109375\n",
      "Batch: 86, Loss: 1.1193995475769043, Accuracy: 0.6484375\n",
      "Batch: 87, Loss: 1.161207675933838, Accuracy: 0.630859375\n",
      "Batch: 88, Loss: 1.1577295064926147, Accuracy: 0.6357421875\n",
      "Batch: 89, Loss: 1.0931196212768555, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0618022680282593, Accuracy: 0.6416015625\n",
      "Batch: 91, Loss: 1.083447813987732, Accuracy: 0.6552734375\n",
      "Batch: 92, Loss: 1.0950641632080078, Accuracy: 0.650390625\n",
      "Batch: 93, Loss: 1.034462332725525, Accuracy: 0.6689453125\n",
      "Batch: 94, Loss: 1.152538776397705, Accuracy: 0.6396484375\n",
      "Batch: 95, Loss: 1.1244581937789917, Accuracy: 0.634765625\n",
      "Batch: 96, Loss: 1.207669734954834, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.131077527999878, Accuracy: 0.6259765625\n",
      "Batch: 98, Loss: 1.0440176725387573, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.0378851890563965, Accuracy: 0.6494140625\n",
      "Batch: 100, Loss: 1.0251083374023438, Accuracy: 0.6552734375\n",
      "Batch: 101, Loss: 1.1159287691116333, Accuracy: 0.62890625\n",
      "Batch: 102, Loss: 1.1488306522369385, Accuracy: 0.634765625\n",
      "Batch: 103, Loss: 1.1196261644363403, Accuracy: 0.6455078125\n",
      "Batch: 104, Loss: 1.1300519704818726, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.2087374925613403, Accuracy: 0.607421875\n",
      "Batch: 106, Loss: 1.190885305404663, Accuracy: 0.6025390625\n",
      "Batch: 107, Loss: 1.2017242908477783, Accuracy: 0.6025390625\n",
      "Batch: 108, Loss: 1.1137741804122925, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1474653482437134, Accuracy: 0.6279296875\n",
      "Batch: 110, Loss: 1.1326520442962646, Accuracy: 0.6201171875\n",
      "Batch: 111, Loss: 1.1601800918579102, Accuracy: 0.6044921875\n",
      "Batch: 112, Loss: 1.061206579208374, Accuracy: 0.65625\n",
      "Batch: 113, Loss: 1.0879122018814087, Accuracy: 0.64453125\n",
      "Batch: 114, Loss: 1.1059209108352661, Accuracy: 0.6396484375\n",
      "Batch: 115, Loss: 1.1765124797821045, Accuracy: 0.6123046875\n",
      "Batch: 116, Loss: 1.105741024017334, Accuracy: 0.6376953125\n",
      "Batch: 117, Loss: 1.1272156238555908, Accuracy: 0.6259765625\n",
      "Batch: 118, Loss: 1.183412790298462, Accuracy: 0.6240234375\n",
      "Batch: 119, Loss: 1.2132827043533325, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.2825884819030762, Accuracy: 0.5888671875\n",
      "Batch: 121, Loss: 1.1871817111968994, Accuracy: 0.6103515625\n",
      "Batch: 122, Loss: 1.1422505378723145, Accuracy: 0.6318359375\n",
      "Batch: 123, Loss: 1.1214545965194702, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.1155860424041748, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.146742343902588, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.1532379388809204, Accuracy: 0.6298828125\n",
      "Batch: 127, Loss: 1.2296159267425537, Accuracy: 0.6064453125\n",
      "Batch: 128, Loss: 1.1533716917037964, Accuracy: 0.619140625\n",
      "Batch: 129, Loss: 1.123708963394165, Accuracy: 0.623046875\n",
      "Batch: 130, Loss: 1.0814189910888672, Accuracy: 0.6513671875\n",
      "Batch: 131, Loss: 1.2191829681396484, Accuracy: 0.587890625\n",
      "Batch: 132, Loss: 1.0401113033294678, Accuracy: 0.669921875\n",
      "Batch: 133, Loss: 1.1015045642852783, Accuracy: 0.646484375\n",
      "Batch: 134, Loss: 1.0533931255340576, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 0.9934014081954956, Accuracy: 0.6845703125\n",
      "Batch: 136, Loss: 1.047903299331665, Accuracy: 0.66796875\n",
      "Batch: 137, Loss: 1.1183006763458252, Accuracy: 0.6748046875\n",
      "Batch: 138, Loss: 1.2812485694885254, Accuracy: 0.5810546875\n",
      "Batch: 139, Loss: 1.173109769821167, Accuracy: 0.634765625\n",
      "Batch: 140, Loss: 1.2206249237060547, Accuracy: 0.607421875\n",
      "Batch: 141, Loss: 1.1134939193725586, Accuracy: 0.6533203125\n",
      "Batch: 142, Loss: 1.151593804359436, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.1124881505966187, Accuracy: 0.6376953125\n",
      "Batch: 144, Loss: 1.1502341032028198, Accuracy: 0.619140625\n",
      "Batch: 145, Loss: 1.2424969673156738, Accuracy: 0.5966796875\n",
      "Batch: 146, Loss: 1.2054470777511597, Accuracy: 0.6123046875\n",
      "Batch: 147, Loss: 1.1491246223449707, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1514836549758911, Accuracy: 0.623046875\n",
      "Batch: 149, Loss: 1.1883697509765625, Accuracy: 0.595703125\n",
      "Batch: 150, Loss: 1.0676493644714355, Accuracy: 0.64453125\n",
      "Batch: 151, Loss: 1.0830655097961426, Accuracy: 0.658203125\n",
      "Batch: 152, Loss: 1.1632318496704102, Accuracy: 0.603515625\n",
      "Batch: 153, Loss: 1.1204195022583008, Accuracy: 0.630859375\n",
      "Batch: 154, Loss: 1.0406944751739502, Accuracy: 0.6591796875\n",
      "Batch: 155, Loss: 1.07309889793396, Accuracy: 0.6513671875\n",
      "Epoch 597/200\n",
      "Batch: 1, Loss: 1.164658546447754, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 0.9963701963424683, Accuracy: 0.6748046875\n",
      "Batch: 3, Loss: 1.0323679447174072, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 1.0197445154190063, Accuracy: 0.6650390625\n",
      "Batch: 5, Loss: 0.964606523513794, Accuracy: 0.6943359375\n",
      "Batch: 6, Loss: 1.066462755203247, Accuracy: 0.6591796875\n",
      "Batch: 7, Loss: 0.9769960641860962, Accuracy: 0.671875\n",
      "Batch: 8, Loss: 0.9494715332984924, Accuracy: 0.6787109375\n",
      "Batch: 9, Loss: 0.9951913356781006, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 0.9917460680007935, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 0.9535219669342041, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 0.9633995294570923, Accuracy: 0.6669921875\n",
      "Batch: 13, Loss: 0.9927393794059753, Accuracy: 0.6748046875\n",
      "Batch: 14, Loss: 0.9783766269683838, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.896054208278656, Accuracy: 0.6962890625\n",
      "Batch: 16, Loss: 1.0362884998321533, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 1.054530382156372, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.0582809448242188, Accuracy: 0.6484375\n",
      "Batch: 19, Loss: 1.1477408409118652, Accuracy: 0.6201171875\n",
      "Batch: 20, Loss: 1.0605416297912598, Accuracy: 0.6728515625\n",
      "Batch: 21, Loss: 1.0613057613372803, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.1814606189727783, Accuracy: 0.6083984375\n",
      "Batch: 23, Loss: 1.1748769283294678, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.0912272930145264, Accuracy: 0.63671875\n",
      "Batch: 25, Loss: 1.073203206062317, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.1033439636230469, Accuracy: 0.619140625\n",
      "Batch: 27, Loss: 1.0583947896957397, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 0.9855769872665405, Accuracy: 0.6748046875\n",
      "Batch: 29, Loss: 1.0191073417663574, Accuracy: 0.6591796875\n",
      "Batch: 30, Loss: 1.1109085083007812, Accuracy: 0.6455078125\n",
      "Batch: 31, Loss: 1.1466665267944336, Accuracy: 0.6357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 0.9928346276283264, Accuracy: 0.6669921875\n",
      "Batch: 33, Loss: 0.947582483291626, Accuracy: 0.677734375\n",
      "Batch: 34, Loss: 1.0070366859436035, Accuracy: 0.6728515625\n",
      "Batch: 35, Loss: 1.1003811359405518, Accuracy: 0.6328125\n",
      "Batch: 36, Loss: 1.1147570610046387, Accuracy: 0.625\n",
      "Batch: 37, Loss: 1.1920289993286133, Accuracy: 0.61328125\n",
      "Batch: 38, Loss: 1.1520650386810303, Accuracy: 0.62109375\n",
      "Batch: 39, Loss: 0.9903583526611328, Accuracy: 0.6630859375\n",
      "Batch: 40, Loss: 1.1140371561050415, Accuracy: 0.6494140625\n",
      "Batch: 41, Loss: 1.09128737449646, Accuracy: 0.6435546875\n",
      "Batch: 42, Loss: 1.033752202987671, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.074465036392212, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0395829677581787, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 0.972449779510498, Accuracy: 0.6728515625\n",
      "Batch: 46, Loss: 1.0619574785232544, Accuracy: 0.654296875\n",
      "Batch: 47, Loss: 1.1492486000061035, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.108124017715454, Accuracy: 0.6357421875\n",
      "Batch: 49, Loss: 1.120901107788086, Accuracy: 0.6298828125\n",
      "Batch: 50, Loss: 1.1267744302749634, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.1072673797607422, Accuracy: 0.6357421875\n",
      "Batch: 52, Loss: 1.1624590158462524, Accuracy: 0.6376953125\n",
      "Batch: 53, Loss: 1.147951602935791, Accuracy: 0.6162109375\n",
      "Batch: 54, Loss: 1.096280574798584, Accuracy: 0.64453125\n",
      "Batch: 55, Loss: 1.0655019283294678, Accuracy: 0.6640625\n",
      "Batch: 56, Loss: 1.0397329330444336, Accuracy: 0.671875\n",
      "Batch: 57, Loss: 1.0752537250518799, Accuracy: 0.64453125\n",
      "Batch: 58, Loss: 1.1233210563659668, Accuracy: 0.6298828125\n",
      "Batch: 59, Loss: 1.0482275485992432, Accuracy: 0.658203125\n",
      "Batch: 60, Loss: 1.1723027229309082, Accuracy: 0.6240234375\n",
      "Batch: 61, Loss: 1.0708692073822021, Accuracy: 0.6455078125\n",
      "Batch: 62, Loss: 1.050814151763916, Accuracy: 0.65234375\n",
      "Batch: 63, Loss: 1.108436107635498, Accuracy: 0.6484375\n",
      "Batch: 64, Loss: 1.1951072216033936, Accuracy: 0.6103515625\n",
      "Batch: 65, Loss: 1.176308035850525, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.0635350942611694, Accuracy: 0.6748046875\n",
      "Batch: 67, Loss: 1.1662704944610596, Accuracy: 0.609375\n",
      "Batch: 68, Loss: 1.0706819295883179, Accuracy: 0.6650390625\n",
      "Batch: 69, Loss: 1.178447961807251, Accuracy: 0.6123046875\n",
      "Batch: 70, Loss: 1.112004041671753, Accuracy: 0.6474609375\n",
      "Batch: 71, Loss: 1.1489431858062744, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.1265132427215576, Accuracy: 0.615234375\n",
      "Batch: 73, Loss: 1.1450330018997192, Accuracy: 0.6103515625\n",
      "Batch: 74, Loss: 1.0252752304077148, Accuracy: 0.6650390625\n",
      "Batch: 75, Loss: 1.054328203201294, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.033543586730957, Accuracy: 0.6611328125\n",
      "Batch: 77, Loss: 1.0129649639129639, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0616915225982666, Accuracy: 0.6533203125\n",
      "Batch: 79, Loss: 1.0201115608215332, Accuracy: 0.6630859375\n",
      "Batch: 80, Loss: 1.0957512855529785, Accuracy: 0.640625\n",
      "Batch: 81, Loss: 1.0859873294830322, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.0777406692504883, Accuracy: 0.6728515625\n",
      "Batch: 83, Loss: 1.1658298969268799, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.0871659517288208, Accuracy: 0.6455078125\n",
      "Batch: 85, Loss: 1.1049813032150269, Accuracy: 0.6318359375\n",
      "Batch: 86, Loss: 1.053739309310913, Accuracy: 0.6533203125\n",
      "Batch: 87, Loss: 1.1367343664169312, Accuracy: 0.6162109375\n",
      "Batch: 88, Loss: 1.1203110218048096, Accuracy: 0.63671875\n",
      "Batch: 89, Loss: 1.1667959690093994, Accuracy: 0.6328125\n",
      "Batch: 90, Loss: 1.037718415260315, Accuracy: 0.6484375\n",
      "Batch: 91, Loss: 1.118930697441101, Accuracy: 0.6357421875\n",
      "Batch: 92, Loss: 1.0874402523040771, Accuracy: 0.669921875\n",
      "Batch: 93, Loss: 1.065545678138733, Accuracy: 0.6572265625\n",
      "Batch: 94, Loss: 1.167813777923584, Accuracy: 0.6435546875\n",
      "Batch: 95, Loss: 1.0932788848876953, Accuracy: 0.646484375\n",
      "Batch: 96, Loss: 1.0812759399414062, Accuracy: 0.6640625\n",
      "Batch: 97, Loss: 1.1231729984283447, Accuracy: 0.634765625\n",
      "Batch: 98, Loss: 1.0622882843017578, Accuracy: 0.64453125\n",
      "Batch: 99, Loss: 1.1170704364776611, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.0273590087890625, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.105008840560913, Accuracy: 0.662109375\n",
      "Batch: 102, Loss: 1.1325603723526, Accuracy: 0.6357421875\n",
      "Batch: 103, Loss: 1.1550228595733643, Accuracy: 0.6220703125\n",
      "Batch: 104, Loss: 1.0970531702041626, Accuracy: 0.6494140625\n",
      "Batch: 105, Loss: 1.1714046001434326, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.1008070707321167, Accuracy: 0.6416015625\n",
      "Batch: 107, Loss: 1.185911774635315, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.144853115081787, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.1406645774841309, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.1307487487792969, Accuracy: 0.62109375\n",
      "Batch: 111, Loss: 1.0339901447296143, Accuracy: 0.6689453125\n",
      "Batch: 112, Loss: 1.0073843002319336, Accuracy: 0.671875\n",
      "Batch: 113, Loss: 1.114871621131897, Accuracy: 0.6240234375\n",
      "Batch: 114, Loss: 1.1368739604949951, Accuracy: 0.61328125\n",
      "Batch: 115, Loss: 1.181807041168213, Accuracy: 0.609375\n",
      "Batch: 116, Loss: 1.1255145072937012, Accuracy: 0.626953125\n",
      "Batch: 117, Loss: 1.163853406906128, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 1.191775918006897, Accuracy: 0.609375\n",
      "Batch: 119, Loss: 1.1736648082733154, Accuracy: 0.5986328125\n",
      "Batch: 120, Loss: 1.2155259847640991, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.140566349029541, Accuracy: 0.6240234375\n",
      "Batch: 122, Loss: 1.181251049041748, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.172584056854248, Accuracy: 0.6337890625\n",
      "Batch: 124, Loss: 1.2067137956619263, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.1689900159835815, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.1976511478424072, Accuracy: 0.6171875\n",
      "Batch: 127, Loss: 1.2539194822311401, Accuracy: 0.5947265625\n",
      "Batch: 128, Loss: 1.1614710092544556, Accuracy: 0.6220703125\n",
      "Batch: 129, Loss: 1.165210247039795, Accuracy: 0.62890625\n",
      "Batch: 130, Loss: 1.1834297180175781, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.1622161865234375, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.0595836639404297, Accuracy: 0.65625\n",
      "Batch: 133, Loss: 1.1188583374023438, Accuracy: 0.6162109375\n",
      "Batch: 134, Loss: 1.1239005327224731, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.041438341140747, Accuracy: 0.658203125\n",
      "Batch: 136, Loss: 1.0408949851989746, Accuracy: 0.65625\n",
      "Batch: 137, Loss: 1.1053416728973389, Accuracy: 0.65234375\n",
      "Batch: 138, Loss: 1.187483310699463, Accuracy: 0.62109375\n",
      "Batch: 139, Loss: 1.1378861665725708, Accuracy: 0.6298828125\n",
      "Batch: 140, Loss: 1.2504909038543701, Accuracy: 0.5986328125\n",
      "Batch: 141, Loss: 1.1441588401794434, Accuracy: 0.6376953125\n",
      "Batch: 142, Loss: 1.1418336629867554, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.158747673034668, Accuracy: 0.634765625\n",
      "Batch: 144, Loss: 1.2138748168945312, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.1791679859161377, Accuracy: 0.62109375\n",
      "Batch: 146, Loss: 1.1696884632110596, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.1636121273040771, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.206380844116211, Accuracy: 0.6064453125\n",
      "Batch: 149, Loss: 1.1389849185943604, Accuracy: 0.62109375\n",
      "Batch: 150, Loss: 1.1379398107528687, Accuracy: 0.61328125\n",
      "Batch: 151, Loss: 1.0999974012374878, Accuracy: 0.6416015625\n",
      "Batch: 152, Loss: 1.1117738485336304, Accuracy: 0.6279296875\n",
      "Batch: 153, Loss: 1.1141345500946045, Accuracy: 0.6201171875\n",
      "Batch: 154, Loss: 1.0568110942840576, Accuracy: 0.6669921875\n",
      "Batch: 155, Loss: 1.0292165279388428, Accuracy: 0.666015625\n",
      "Epoch 598/200\n",
      "Batch: 1, Loss: 1.1803604364395142, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 1.032699704170227, Accuracy: 0.666015625\n",
      "Batch: 3, Loss: 0.954801619052887, Accuracy: 0.685546875\n",
      "Batch: 4, Loss: 0.9733335971832275, Accuracy: 0.6796875\n",
      "Batch: 5, Loss: 0.9956940412521362, Accuracy: 0.6669921875\n",
      "Batch: 6, Loss: 1.0154131650924683, Accuracy: 0.6787109375\n",
      "Batch: 7, Loss: 0.9839062690734863, Accuracy: 0.666015625\n",
      "Batch: 8, Loss: 0.9699808359146118, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9410171508789062, Accuracy: 0.7080078125\n",
      "Batch: 10, Loss: 0.9407241344451904, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 0.9419751763343811, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.928199827671051, Accuracy: 0.697265625\n",
      "Batch: 13, Loss: 1.051701545715332, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 0.951593279838562, Accuracy: 0.6982421875\n",
      "Batch: 15, Loss: 0.9333617091178894, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 0.983756959438324, Accuracy: 0.6767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17, Loss: 0.9996829032897949, Accuracy: 0.6845703125\n",
      "Batch: 18, Loss: 1.054484486579895, Accuracy: 0.6435546875\n",
      "Batch: 19, Loss: 1.140424132347107, Accuracy: 0.6181640625\n",
      "Batch: 20, Loss: 1.0610032081604004, Accuracy: 0.6455078125\n",
      "Batch: 21, Loss: 1.04660165309906, Accuracy: 0.6796875\n",
      "Batch: 22, Loss: 1.1450661420822144, Accuracy: 0.6357421875\n",
      "Batch: 23, Loss: 1.215915560722351, Accuracy: 0.6142578125\n",
      "Batch: 24, Loss: 1.120859146118164, Accuracy: 0.630859375\n",
      "Batch: 25, Loss: 1.1258783340454102, Accuracy: 0.6376953125\n",
      "Batch: 26, Loss: 1.0962110757827759, Accuracy: 0.630859375\n",
      "Batch: 27, Loss: 1.135056972503662, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.0031147003173828, Accuracy: 0.6748046875\n",
      "Batch: 29, Loss: 0.9981949925422668, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.091799259185791, Accuracy: 0.630859375\n",
      "Batch: 31, Loss: 1.1257908344268799, Accuracy: 0.6396484375\n",
      "Batch: 32, Loss: 0.9934868812561035, Accuracy: 0.673828125\n",
      "Batch: 33, Loss: 0.9305770397186279, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.06721031665802, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 1.0813844203948975, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.1436190605163574, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1777243614196777, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.154189109802246, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.0427296161651611, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.0133265256881714, Accuracy: 0.6767578125\n",
      "Batch: 41, Loss: 1.0611406564712524, Accuracy: 0.662109375\n",
      "Batch: 42, Loss: 1.0076708793640137, Accuracy: 0.671875\n",
      "Batch: 43, Loss: 1.04330313205719, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 0.9896419048309326, Accuracy: 0.6884765625\n",
      "Batch: 45, Loss: 0.9907745718955994, Accuracy: 0.6689453125\n",
      "Batch: 46, Loss: 1.072439193725586, Accuracy: 0.640625\n",
      "Batch: 47, Loss: 1.0748966932296753, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.030151128768921, Accuracy: 0.6669921875\n",
      "Batch: 49, Loss: 1.1236202716827393, Accuracy: 0.626953125\n",
      "Batch: 50, Loss: 1.0985801219940186, Accuracy: 0.642578125\n",
      "Batch: 51, Loss: 1.1106687784194946, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.193887710571289, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1315768957138062, Accuracy: 0.6376953125\n",
      "Batch: 54, Loss: 1.0631115436553955, Accuracy: 0.65234375\n",
      "Batch: 55, Loss: 1.0617798566818237, Accuracy: 0.65625\n",
      "Batch: 56, Loss: 1.0436081886291504, Accuracy: 0.6611328125\n",
      "Batch: 57, Loss: 1.0709114074707031, Accuracy: 0.658203125\n",
      "Batch: 58, Loss: 1.034661054611206, Accuracy: 0.669921875\n",
      "Batch: 59, Loss: 1.0477871894836426, Accuracy: 0.662109375\n",
      "Batch: 60, Loss: 1.1931302547454834, Accuracy: 0.6083984375\n",
      "Batch: 61, Loss: 1.1459728479385376, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.1299433708190918, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.0964268445968628, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.2086505889892578, Accuracy: 0.6025390625\n",
      "Batch: 65, Loss: 1.1672519445419312, Accuracy: 0.63671875\n",
      "Batch: 66, Loss: 1.217421531677246, Accuracy: 0.623046875\n",
      "Batch: 67, Loss: 1.1171882152557373, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 0.9947744607925415, Accuracy: 0.6865234375\n",
      "Batch: 69, Loss: 1.1373357772827148, Accuracy: 0.630859375\n",
      "Batch: 70, Loss: 1.1826272010803223, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.1439440250396729, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.122231364250183, Accuracy: 0.63671875\n",
      "Batch: 73, Loss: 1.1534464359283447, Accuracy: 0.6083984375\n",
      "Batch: 74, Loss: 1.0599944591522217, Accuracy: 0.6484375\n",
      "Batch: 75, Loss: 1.1201484203338623, Accuracy: 0.6357421875\n",
      "Batch: 76, Loss: 1.067251443862915, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.0576577186584473, Accuracy: 0.646484375\n",
      "Batch: 78, Loss: 1.0458958148956299, Accuracy: 0.65625\n",
      "Batch: 79, Loss: 1.087300181388855, Accuracy: 0.6435546875\n",
      "Batch: 80, Loss: 1.1362043619155884, Accuracy: 0.6181640625\n",
      "Batch: 81, Loss: 1.0607519149780273, Accuracy: 0.6513671875\n",
      "Batch: 82, Loss: 1.1007802486419678, Accuracy: 0.65625\n",
      "Batch: 83, Loss: 1.1046335697174072, Accuracy: 0.6484375\n",
      "Batch: 84, Loss: 1.1041278839111328, Accuracy: 0.640625\n",
      "Batch: 85, Loss: 1.169527292251587, Accuracy: 0.6328125\n",
      "Batch: 86, Loss: 1.1035447120666504, Accuracy: 0.62890625\n",
      "Batch: 87, Loss: 1.1274263858795166, Accuracy: 0.6328125\n",
      "Batch: 88, Loss: 1.088367223739624, Accuracy: 0.65625\n",
      "Batch: 89, Loss: 1.1249172687530518, Accuracy: 0.6337890625\n",
      "Batch: 90, Loss: 1.0618937015533447, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.094362497329712, Accuracy: 0.650390625\n",
      "Batch: 92, Loss: 1.077688455581665, Accuracy: 0.66015625\n",
      "Batch: 93, Loss: 1.1082124710083008, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.120510458946228, Accuracy: 0.640625\n",
      "Batch: 95, Loss: 1.1663835048675537, Accuracy: 0.619140625\n",
      "Batch: 96, Loss: 1.1675660610198975, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.1100051403045654, Accuracy: 0.6220703125\n",
      "Batch: 98, Loss: 1.0871093273162842, Accuracy: 0.634765625\n",
      "Batch: 99, Loss: 1.1215016841888428, Accuracy: 0.6298828125\n",
      "Batch: 100, Loss: 0.9865502119064331, Accuracy: 0.6884765625\n",
      "Batch: 101, Loss: 1.0374013185501099, Accuracy: 0.6689453125\n",
      "Batch: 102, Loss: 1.1389858722686768, Accuracy: 0.6044921875\n",
      "Batch: 103, Loss: 1.0980497598648071, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.1050087213516235, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.1186962127685547, Accuracy: 0.6494140625\n",
      "Batch: 106, Loss: 1.1406152248382568, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.167271375656128, Accuracy: 0.625\n",
      "Batch: 108, Loss: 1.0727430582046509, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.163703441619873, Accuracy: 0.603515625\n",
      "Batch: 110, Loss: 1.0638461112976074, Accuracy: 0.65234375\n",
      "Batch: 111, Loss: 1.0995196104049683, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.0755008459091187, Accuracy: 0.638671875\n",
      "Batch: 113, Loss: 1.1059235334396362, Accuracy: 0.6533203125\n",
      "Batch: 114, Loss: 1.1950535774230957, Accuracy: 0.59765625\n",
      "Batch: 115, Loss: 1.1146202087402344, Accuracy: 0.6474609375\n",
      "Batch: 116, Loss: 1.1314465999603271, Accuracy: 0.6318359375\n",
      "Batch: 117, Loss: 1.1479284763336182, Accuracy: 0.625\n",
      "Batch: 118, Loss: 1.118839979171753, Accuracy: 0.62109375\n",
      "Batch: 119, Loss: 1.188633680343628, Accuracy: 0.6298828125\n",
      "Batch: 120, Loss: 1.2288377285003662, Accuracy: 0.607421875\n",
      "Batch: 121, Loss: 1.1440930366516113, Accuracy: 0.646484375\n",
      "Batch: 122, Loss: 1.1689425706863403, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.1409049034118652, Accuracy: 0.6328125\n",
      "Batch: 124, Loss: 1.1395201683044434, Accuracy: 0.62890625\n",
      "Batch: 125, Loss: 1.1110541820526123, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.222504734992981, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.2446869611740112, Accuracy: 0.583984375\n",
      "Batch: 128, Loss: 1.1125773191452026, Accuracy: 0.63671875\n",
      "Batch: 129, Loss: 1.237044334411621, Accuracy: 0.5927734375\n",
      "Batch: 130, Loss: 1.0755574703216553, Accuracy: 0.6474609375\n",
      "Batch: 131, Loss: 1.1298792362213135, Accuracy: 0.630859375\n",
      "Batch: 132, Loss: 1.0604453086853027, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.0869245529174805, Accuracy: 0.630859375\n",
      "Batch: 134, Loss: 1.103049635887146, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 0.9738584160804749, Accuracy: 0.68359375\n",
      "Batch: 136, Loss: 1.069515585899353, Accuracy: 0.6591796875\n",
      "Batch: 137, Loss: 1.129252314567566, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.2194535732269287, Accuracy: 0.6044921875\n",
      "Batch: 139, Loss: 1.1259348392486572, Accuracy: 0.6279296875\n",
      "Batch: 140, Loss: 1.2316572666168213, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.1175596714019775, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.1634860038757324, Accuracy: 0.6328125\n",
      "Batch: 143, Loss: 1.1061286926269531, Accuracy: 0.6513671875\n",
      "Batch: 144, Loss: 1.1876989603042603, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.227721929550171, Accuracy: 0.6015625\n",
      "Batch: 146, Loss: 1.1542593240737915, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.0906513929367065, Accuracy: 0.6337890625\n",
      "Batch: 148, Loss: 1.1153010129928589, Accuracy: 0.6435546875\n",
      "Batch: 149, Loss: 1.1159405708312988, Accuracy: 0.63671875\n",
      "Batch: 150, Loss: 1.1123992204666138, Accuracy: 0.6376953125\n",
      "Batch: 151, Loss: 1.1499831676483154, Accuracy: 0.6357421875\n",
      "Batch: 152, Loss: 1.0960466861724854, Accuracy: 0.634765625\n",
      "Batch: 153, Loss: 1.0179070234298706, Accuracy: 0.6650390625\n",
      "Batch: 154, Loss: 1.0730763673782349, Accuracy: 0.6591796875\n",
      "Batch: 155, Loss: 1.048346996307373, Accuracy: 0.662109375\n",
      "Epoch 599/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 1.1808602809906006, Accuracy: 0.6630859375\n",
      "Batch: 2, Loss: 1.0092004537582397, Accuracy: 0.66015625\n",
      "Batch: 3, Loss: 1.0440261363983154, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 1.0487593412399292, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 0.9900948405265808, Accuracy: 0.6796875\n",
      "Batch: 6, Loss: 1.0350961685180664, Accuracy: 0.677734375\n",
      "Batch: 7, Loss: 0.9961830377578735, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9595046043395996, Accuracy: 0.689453125\n",
      "Batch: 9, Loss: 0.9380656480789185, Accuracy: 0.701171875\n",
      "Batch: 10, Loss: 0.9442752599716187, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 0.9277525544166565, Accuracy: 0.685546875\n",
      "Batch: 12, Loss: 0.9769247770309448, Accuracy: 0.6884765625\n",
      "Batch: 13, Loss: 0.9903974533081055, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 0.9383800625801086, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.9271251559257507, Accuracy: 0.681640625\n",
      "Batch: 16, Loss: 0.9924988746643066, Accuracy: 0.671875\n",
      "Batch: 17, Loss: 1.030712604522705, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.0981589555740356, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.1609302759170532, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0930230617523193, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.0269451141357422, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 1.1357591152191162, Accuracy: 0.6259765625\n",
      "Batch: 23, Loss: 1.2197585105895996, Accuracy: 0.607421875\n",
      "Batch: 24, Loss: 1.0131945610046387, Accuracy: 0.6708984375\n",
      "Batch: 25, Loss: 1.1231359243392944, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.159462809562683, Accuracy: 0.6259765625\n",
      "Batch: 27, Loss: 1.0367710590362549, Accuracy: 0.658203125\n",
      "Batch: 28, Loss: 0.9999457597732544, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.0328969955444336, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.166394591331482, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.1680324077606201, Accuracy: 0.615234375\n",
      "Batch: 32, Loss: 0.9883829355239868, Accuracy: 0.669921875\n",
      "Batch: 33, Loss: 0.9703367948532104, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.1013529300689697, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.0847141742706299, Accuracy: 0.6220703125\n",
      "Batch: 36, Loss: 1.1423406600952148, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.1601601839065552, Accuracy: 0.6220703125\n",
      "Batch: 38, Loss: 1.1070318222045898, Accuracy: 0.630859375\n",
      "Batch: 39, Loss: 1.0216889381408691, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.032618761062622, Accuracy: 0.654296875\n",
      "Batch: 41, Loss: 1.1240906715393066, Accuracy: 0.6416015625\n",
      "Batch: 42, Loss: 1.007407546043396, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.0306568145751953, Accuracy: 0.6640625\n",
      "Batch: 44, Loss: 1.0641181468963623, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.0422418117523193, Accuracy: 0.662109375\n",
      "Batch: 46, Loss: 1.0728744268417358, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.0856000185012817, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0851030349731445, Accuracy: 0.65234375\n",
      "Batch: 49, Loss: 1.15065598487854, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.116607904434204, Accuracy: 0.6455078125\n",
      "Batch: 51, Loss: 1.0700007677078247, Accuracy: 0.6474609375\n",
      "Batch: 52, Loss: 1.1562952995300293, Accuracy: 0.6416015625\n",
      "Batch: 53, Loss: 1.121166467666626, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.0931830406188965, Accuracy: 0.640625\n",
      "Batch: 55, Loss: 1.0731654167175293, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.061190128326416, Accuracy: 0.6650390625\n",
      "Batch: 57, Loss: 1.024393916130066, Accuracy: 0.6591796875\n",
      "Batch: 58, Loss: 1.0618512630462646, Accuracy: 0.6552734375\n",
      "Batch: 59, Loss: 1.0339912176132202, Accuracy: 0.6845703125\n",
      "Batch: 60, Loss: 1.20770263671875, Accuracy: 0.60546875\n",
      "Batch: 61, Loss: 1.1049752235412598, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.085094928741455, Accuracy: 0.6708984375\n",
      "Batch: 63, Loss: 1.1411420106887817, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.0902419090270996, Accuracy: 0.640625\n",
      "Batch: 65, Loss: 1.1048619747161865, Accuracy: 0.646484375\n",
      "Batch: 66, Loss: 1.1306270360946655, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.1125658750534058, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.0424842834472656, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.1538190841674805, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.1417746543884277, Accuracy: 0.642578125\n",
      "Batch: 71, Loss: 1.0956048965454102, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.1862956285476685, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.1520686149597168, Accuracy: 0.642578125\n",
      "Batch: 74, Loss: 1.0604604482650757, Accuracy: 0.669921875\n",
      "Batch: 75, Loss: 1.116640567779541, Accuracy: 0.62890625\n",
      "Batch: 76, Loss: 1.046036958694458, Accuracy: 0.6640625\n",
      "Batch: 77, Loss: 1.031415343284607, Accuracy: 0.6552734375\n",
      "Batch: 78, Loss: 1.0249782800674438, Accuracy: 0.6533203125\n",
      "Batch: 79, Loss: 1.090393304824829, Accuracy: 0.662109375\n",
      "Batch: 80, Loss: 1.1820082664489746, Accuracy: 0.6083984375\n",
      "Batch: 81, Loss: 1.0714110136032104, Accuracy: 0.6591796875\n",
      "Batch: 82, Loss: 1.0988574028015137, Accuracy: 0.642578125\n",
      "Batch: 83, Loss: 1.2061444520950317, Accuracy: 0.609375\n",
      "Batch: 84, Loss: 1.0608524084091187, Accuracy: 0.6435546875\n",
      "Batch: 85, Loss: 1.1632384061813354, Accuracy: 0.6396484375\n",
      "Batch: 86, Loss: 1.0908520221710205, Accuracy: 0.6279296875\n",
      "Batch: 87, Loss: 1.0949243307113647, Accuracy: 0.6416015625\n",
      "Batch: 88, Loss: 1.1440776586532593, Accuracy: 0.650390625\n",
      "Batch: 89, Loss: 1.0728310346603394, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.0715177059173584, Accuracy: 0.654296875\n",
      "Batch: 91, Loss: 1.0867830514907837, Accuracy: 0.6572265625\n",
      "Batch: 92, Loss: 1.1189756393432617, Accuracy: 0.642578125\n",
      "Batch: 93, Loss: 1.1259870529174805, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.126451015472412, Accuracy: 0.6376953125\n",
      "Batch: 95, Loss: 1.1310832500457764, Accuracy: 0.6513671875\n",
      "Batch: 96, Loss: 1.1205847263336182, Accuracy: 0.650390625\n",
      "Batch: 97, Loss: 1.0960524082183838, Accuracy: 0.6435546875\n",
      "Batch: 98, Loss: 1.0395936965942383, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.027569055557251, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.0691440105438232, Accuracy: 0.662109375\n",
      "Batch: 101, Loss: 1.0617356300354004, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 1.1594029664993286, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.0800813436508179, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.0968230962753296, Accuracy: 0.65625\n",
      "Batch: 105, Loss: 1.1488240957260132, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.1244540214538574, Accuracy: 0.638671875\n",
      "Batch: 107, Loss: 1.2289797067642212, Accuracy: 0.6123046875\n",
      "Batch: 108, Loss: 1.1137144565582275, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.1192141771316528, Accuracy: 0.6484375\n",
      "Batch: 110, Loss: 1.114023208618164, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.0883147716522217, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.062524437904358, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.1331058740615845, Accuracy: 0.623046875\n",
      "Batch: 114, Loss: 1.147749662399292, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.152019739151001, Accuracy: 0.626953125\n",
      "Batch: 116, Loss: 1.1514570713043213, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.1047919988632202, Accuracy: 0.6162109375\n",
      "Batch: 118, Loss: 1.1334539651870728, Accuracy: 0.6328125\n",
      "Batch: 119, Loss: 1.197076678276062, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.1883834600448608, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.1630539894104004, Accuracy: 0.625\n",
      "Batch: 122, Loss: 1.2017228603363037, Accuracy: 0.619140625\n",
      "Batch: 123, Loss: 1.0676910877227783, Accuracy: 0.6640625\n",
      "Batch: 124, Loss: 1.1276365518569946, Accuracy: 0.619140625\n",
      "Batch: 125, Loss: 1.09788179397583, Accuracy: 0.6484375\n",
      "Batch: 126, Loss: 1.2153483629226685, Accuracy: 0.619140625\n",
      "Batch: 127, Loss: 1.1359930038452148, Accuracy: 0.630859375\n",
      "Batch: 128, Loss: 1.1698509454727173, Accuracy: 0.6279296875\n",
      "Batch: 129, Loss: 1.1624634265899658, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.1250677108764648, Accuracy: 0.625\n",
      "Batch: 131, Loss: 1.1748844385147095, Accuracy: 0.6220703125\n",
      "Batch: 132, Loss: 1.0213160514831543, Accuracy: 0.6650390625\n",
      "Batch: 133, Loss: 1.1044397354125977, Accuracy: 0.6220703125\n",
      "Batch: 134, Loss: 1.1228822469711304, Accuracy: 0.6484375\n",
      "Batch: 135, Loss: 0.9867931604385376, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.0464706420898438, Accuracy: 0.6533203125\n",
      "Batch: 137, Loss: 1.1251507997512817, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 1.1533621549606323, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.1510006189346313, Accuracy: 0.6279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 1.199577808380127, Accuracy: 0.611328125\n",
      "Batch: 141, Loss: 1.1058237552642822, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.168969750404358, Accuracy: 0.6279296875\n",
      "Batch: 143, Loss: 1.1108264923095703, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.20560884475708, Accuracy: 0.609375\n",
      "Batch: 145, Loss: 1.2294319868087769, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.1742007732391357, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.1564247608184814, Accuracy: 0.62109375\n",
      "Batch: 148, Loss: 1.1341989040374756, Accuracy: 0.634765625\n",
      "Batch: 149, Loss: 1.1679315567016602, Accuracy: 0.6005859375\n",
      "Batch: 150, Loss: 1.078961730003357, Accuracy: 0.6552734375\n",
      "Batch: 151, Loss: 1.1160227060317993, Accuracy: 0.6201171875\n",
      "Batch: 152, Loss: 1.1080522537231445, Accuracy: 0.6298828125\n",
      "Batch: 153, Loss: 1.0357420444488525, Accuracy: 0.63671875\n",
      "Batch: 154, Loss: 1.097446322441101, Accuracy: 0.66015625\n",
      "Batch: 155, Loss: 1.0416538715362549, Accuracy: 0.6552734375\n",
      "Epoch 600/200\n",
      "Batch: 1, Loss: 1.1291522979736328, Accuracy: 0.658203125\n",
      "Batch: 2, Loss: 1.0271563529968262, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.9735443592071533, Accuracy: 0.6884765625\n",
      "Batch: 4, Loss: 1.0422718524932861, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 1.0277915000915527, Accuracy: 0.67578125\n",
      "Batch: 6, Loss: 1.0175786018371582, Accuracy: 0.6796875\n",
      "Batch: 7, Loss: 0.9617339372634888, Accuracy: 0.69140625\n",
      "Batch: 8, Loss: 0.9580506086349487, Accuracy: 0.6943359375\n",
      "Batch: 9, Loss: 0.92772376537323, Accuracy: 0.703125\n",
      "Batch: 10, Loss: 0.9138256311416626, Accuracy: 0.701171875\n",
      "Batch: 11, Loss: 0.9492279291152954, Accuracy: 0.6845703125\n",
      "Batch: 12, Loss: 0.9684786796569824, Accuracy: 0.6865234375\n",
      "Batch: 13, Loss: 0.9748823642730713, Accuracy: 0.67578125\n",
      "Batch: 14, Loss: 0.9703806042671204, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.8773596286773682, Accuracy: 0.71875\n",
      "Batch: 16, Loss: 1.0403752326965332, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 0.9641417264938354, Accuracy: 0.6787109375\n",
      "Batch: 18, Loss: 1.0930836200714111, Accuracy: 0.6513671875\n",
      "Batch: 19, Loss: 1.1290135383605957, Accuracy: 0.6328125\n",
      "Batch: 20, Loss: 1.0363765954971313, Accuracy: 0.6796875\n",
      "Batch: 21, Loss: 1.045150876045227, Accuracy: 0.6630859375\n",
      "Batch: 22, Loss: 1.1964809894561768, Accuracy: 0.611328125\n",
      "Batch: 23, Loss: 1.1995432376861572, Accuracy: 0.599609375\n",
      "Batch: 24, Loss: 1.0645580291748047, Accuracy: 0.6533203125\n",
      "Batch: 25, Loss: 1.0619103908538818, Accuracy: 0.650390625\n",
      "Batch: 26, Loss: 1.1305218935012817, Accuracy: 0.63671875\n",
      "Batch: 27, Loss: 1.08634614944458, Accuracy: 0.6513671875\n",
      "Batch: 28, Loss: 1.0662553310394287, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.005340814590454, Accuracy: 0.6875\n",
      "Batch: 30, Loss: 1.1147528886795044, Accuracy: 0.65234375\n",
      "Batch: 31, Loss: 1.1217286586761475, Accuracy: 0.619140625\n",
      "Batch: 32, Loss: 1.0215001106262207, Accuracy: 0.669921875\n",
      "Batch: 33, Loss: 0.9208037853240967, Accuracy: 0.69140625\n",
      "Batch: 34, Loss: 1.0577037334442139, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 1.0665113925933838, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.1251769065856934, Accuracy: 0.6162109375\n",
      "Batch: 37, Loss: 1.148018479347229, Accuracy: 0.6171875\n",
      "Batch: 38, Loss: 1.116786241531372, Accuracy: 0.625\n",
      "Batch: 39, Loss: 1.0212998390197754, Accuracy: 0.66796875\n",
      "Batch: 40, Loss: 1.0453475713729858, Accuracy: 0.662109375\n",
      "Batch: 41, Loss: 1.1090881824493408, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 0.9409370422363281, Accuracy: 0.6923828125\n",
      "Batch: 43, Loss: 0.9939520359039307, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 1.028804898262024, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 1.0427991151809692, Accuracy: 0.6689453125\n",
      "Batch: 46, Loss: 1.1249418258666992, Accuracy: 0.6171875\n",
      "Batch: 47, Loss: 1.0370664596557617, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.0639817714691162, Accuracy: 0.6474609375\n",
      "Batch: 49, Loss: 1.1048870086669922, Accuracy: 0.65234375\n",
      "Batch: 50, Loss: 1.1200207471847534, Accuracy: 0.6474609375\n",
      "Batch: 51, Loss: 1.1033694744110107, Accuracy: 0.62890625\n",
      "Batch: 52, Loss: 1.2077100276947021, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.1502817869186401, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.0946695804595947, Accuracy: 0.6484375\n",
      "Batch: 55, Loss: 1.0830585956573486, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.0655533075332642, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 1.035672903060913, Accuracy: 0.669921875\n",
      "Batch: 58, Loss: 1.0852134227752686, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 1.058682918548584, Accuracy: 0.6640625\n",
      "Batch: 60, Loss: 1.1707457304000854, Accuracy: 0.6318359375\n",
      "Batch: 61, Loss: 1.1331562995910645, Accuracy: 0.623046875\n",
      "Batch: 62, Loss: 1.100801944732666, Accuracy: 0.6533203125\n",
      "Batch: 63, Loss: 1.1200172901153564, Accuracy: 0.6435546875\n",
      "Batch: 64, Loss: 1.1441823244094849, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.1571733951568604, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.0567219257354736, Accuracy: 0.6552734375\n",
      "Batch: 67, Loss: 1.142112374305725, Accuracy: 0.6259765625\n",
      "Batch: 68, Loss: 1.0774078369140625, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.1310511827468872, Accuracy: 0.63671875\n",
      "Batch: 70, Loss: 1.1113067865371704, Accuracy: 0.6416015625\n",
      "Batch: 71, Loss: 1.0956816673278809, Accuracy: 0.6435546875\n",
      "Batch: 72, Loss: 1.1732807159423828, Accuracy: 0.6142578125\n",
      "Batch: 73, Loss: 1.1370115280151367, Accuracy: 0.6171875\n",
      "Batch: 74, Loss: 1.0744167566299438, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.056748390197754, Accuracy: 0.650390625\n",
      "Batch: 76, Loss: 1.0265177488327026, Accuracy: 0.66796875\n",
      "Batch: 77, Loss: 1.0340218544006348, Accuracy: 0.6474609375\n",
      "Batch: 78, Loss: 1.0368022918701172, Accuracy: 0.658203125\n",
      "Batch: 79, Loss: 1.1065776348114014, Accuracy: 0.65234375\n",
      "Batch: 80, Loss: 1.0365259647369385, Accuracy: 0.6669921875\n",
      "Batch: 81, Loss: 1.0856181383132935, Accuracy: 0.6357421875\n",
      "Batch: 82, Loss: 1.0531702041625977, Accuracy: 0.6689453125\n",
      "Batch: 83, Loss: 1.1319218873977661, Accuracy: 0.625\n",
      "Batch: 84, Loss: 1.0889391899108887, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.151437520980835, Accuracy: 0.6376953125\n",
      "Batch: 86, Loss: 1.0333949327468872, Accuracy: 0.666015625\n",
      "Batch: 87, Loss: 1.0929539203643799, Accuracy: 0.6611328125\n",
      "Batch: 88, Loss: 1.084267020225525, Accuracy: 0.6513671875\n",
      "Batch: 89, Loss: 1.094979166984558, Accuracy: 0.6640625\n",
      "Batch: 90, Loss: 1.0753259658813477, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.1118369102478027, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.1566718816757202, Accuracy: 0.6357421875\n",
      "Batch: 93, Loss: 1.0952647924423218, Accuracy: 0.654296875\n",
      "Batch: 94, Loss: 1.1239280700683594, Accuracy: 0.650390625\n",
      "Batch: 95, Loss: 1.1335418224334717, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.1620535850524902, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.1653960943222046, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.1043992042541504, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.0828399658203125, Accuracy: 0.65234375\n",
      "Batch: 100, Loss: 1.0225610733032227, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.0522761344909668, Accuracy: 0.66015625\n",
      "Batch: 102, Loss: 1.1502680778503418, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.134635329246521, Accuracy: 0.6494140625\n",
      "Batch: 104, Loss: 1.0796077251434326, Accuracy: 0.658203125\n",
      "Batch: 105, Loss: 1.1594390869140625, Accuracy: 0.6171875\n",
      "Batch: 106, Loss: 1.1342873573303223, Accuracy: 0.626953125\n",
      "Batch: 107, Loss: 1.1684534549713135, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.1636912822723389, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.1698040962219238, Accuracy: 0.623046875\n",
      "Batch: 110, Loss: 1.1458357572555542, Accuracy: 0.61328125\n",
      "Batch: 111, Loss: 1.0541582107543945, Accuracy: 0.6494140625\n",
      "Batch: 112, Loss: 1.0634994506835938, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.094624400138855, Accuracy: 0.6396484375\n",
      "Batch: 114, Loss: 1.1200602054595947, Accuracy: 0.6376953125\n",
      "Batch: 115, Loss: 1.1547062397003174, Accuracy: 0.6328125\n",
      "Batch: 116, Loss: 1.1154876947402954, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.1266212463378906, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 1.174483060836792, Accuracy: 0.625\n",
      "Batch: 119, Loss: 1.2060391902923584, Accuracy: 0.6064453125\n",
      "Batch: 120, Loss: 1.2135162353515625, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.1629122495651245, Accuracy: 0.6220703125\n",
      "Batch: 122, Loss: 1.1943426132202148, Accuracy: 0.615234375\n",
      "Batch: 123, Loss: 1.1668118238449097, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.1809747219085693, Accuracy: 0.6328125\n",
      "Batch: 125, Loss: 1.1578888893127441, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 126, Loss: 1.1894124746322632, Accuracy: 0.6220703125\n",
      "Batch: 127, Loss: 1.2320829629898071, Accuracy: 0.609375\n",
      "Batch: 128, Loss: 1.1977229118347168, Accuracy: 0.6162109375\n",
      "Batch: 129, Loss: 1.1407842636108398, Accuracy: 0.634765625\n",
      "Batch: 130, Loss: 1.0863466262817383, Accuracy: 0.6416015625\n",
      "Batch: 131, Loss: 1.1738256216049194, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.0025285482406616, Accuracy: 0.6787109375\n",
      "Batch: 133, Loss: 1.085023283958435, Accuracy: 0.6435546875\n",
      "Batch: 134, Loss: 1.0652027130126953, Accuracy: 0.6669921875\n",
      "Batch: 135, Loss: 1.0520658493041992, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.1032373905181885, Accuracy: 0.634765625\n",
      "Batch: 137, Loss: 1.1023484468460083, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.1233372688293457, Accuracy: 0.630859375\n",
      "Batch: 139, Loss: 1.2269806861877441, Accuracy: 0.6259765625\n",
      "Batch: 140, Loss: 1.1779290437698364, Accuracy: 0.623046875\n",
      "Batch: 141, Loss: 1.0432325601577759, Accuracy: 0.65625\n",
      "Batch: 142, Loss: 1.12892484664917, Accuracy: 0.6435546875\n",
      "Batch: 143, Loss: 1.1193881034851074, Accuracy: 0.6337890625\n",
      "Batch: 144, Loss: 1.1931524276733398, Accuracy: 0.623046875\n",
      "Batch: 145, Loss: 1.1870777606964111, Accuracy: 0.625\n",
      "Batch: 146, Loss: 1.2097656726837158, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1773600578308105, Accuracy: 0.634765625\n",
      "Batch: 148, Loss: 1.1792784929275513, Accuracy: 0.625\n",
      "Batch: 149, Loss: 1.1234784126281738, Accuracy: 0.6337890625\n",
      "Batch: 150, Loss: 1.1334388256072998, Accuracy: 0.630859375\n",
      "Batch: 151, Loss: 1.1274795532226562, Accuracy: 0.623046875\n",
      "Batch: 152, Loss: 1.116990327835083, Accuracy: 0.6181640625\n",
      "Batch: 153, Loss: 1.0621356964111328, Accuracy: 0.654296875\n",
      "Batch: 154, Loss: 1.1245906352996826, Accuracy: 0.62890625\n",
      "Batch: 155, Loss: 1.0970194339752197, Accuracy: 0.615234375\n",
      "Saved Weights at epoch 600 to file Weights_600.h5\n"
     ]
    }
   ],
   "source": [
    "training_model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
