{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module generates notes for a midi file using the\n",
    "    trained neural network \"\"\"\n",
    "import pickle\n",
    "from music21 import instrument, note, stream, chord, converter,midi, duration,volume\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation, Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"DataX/\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = 'DataX/Model_Weights/'\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "  \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add((Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for pg2\n",
    "def generate_sequence(epoch_num, initial_index, seq_length):\n",
    "    padder = int(seq_length * 0.2)\n",
    "    seq_length += padder\n",
    "    with open(os.path.join(data_directory, charIndex_json)) as f:\n",
    "        char_to_index = json.load(f)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    unique_chars = len(index_to_char)\n",
    "    \n",
    "    model = make_model(unique_chars)\n",
    "    model.load_weights(model_weights_directory + \"Weights_{}.h5\".format(epoch_num))\n",
    "     \n",
    "    sequence_index = [initial_index]\n",
    "    \n",
    "    for _ in range(seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(unique_chars), size = 1, p = predicted_probs)\n",
    "\n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "    output_sequence = [index_to_char[c] for c in sequence_index]\n",
    "    output_sequence = output_sequence[padder:]\n",
    "    return output_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize(seq_len):\n",
    "    # randomize duration and velocity\n",
    "    mu, sigma = 1, 0.15 # mean and standard deviation\n",
    "    duration_list = np.random.normal(mu, sigma, seq_len)\n",
    "    mu, sigma = 75, 11 \n",
    "    velocity_list = np.random.normal(mu, sigma, seq_len)\n",
    "    velocity_list = [int(i) for i in velocity_list]\n",
    "    return duration_list, velocity_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_chord(vel,seq_len):\n",
    "    # randomize the velocity for each value in chord\n",
    "    mu, sigma = vel, 3 # mean and standard deviation\n",
    "    velocity_list = np.random.normal(mu, sigma, seq_len)\n",
    "    velocity_list = [int(i) for i in velocity_list]\n",
    "    return velocity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    # get a list of the indexes of all chords\n",
    "    l_chords = []\n",
    "    for i in range(len(prediction_output)):\n",
    "        if ('.' in prediction_output[i]) or prediction_output[i].isdigit():\n",
    "            l_chords.append(i)       \n",
    "    print(\"l_chords\",l_chords)\n",
    "    last_chord = None\n",
    "    \n",
    "    duration_list, velocity_list = humanize(len(prediction_output))\n",
    "    \n",
    "    \n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for i in range(len(prediction_output)):\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in prediction_output[i]) or prediction_output[i].isdigit():\n",
    "            notes_in_chord = prediction_output[i].split('.')\n",
    "            notes_in_chord = [int(i) for i in notes_in_chord]\n",
    "            soprano = max(notes_in_chord)\n",
    "            notes = []   \n",
    "            chord_vel = humanize_chord(velocity_list[i],len(notes_in_chord))\n",
    "            if i != l_chords[-1]:\n",
    "                # when the current chord is not the last chord\n",
    "                curr_idx = l_chords.index(i)\n",
    "                time = (l_chords[curr_idx+1] - i) * 0.5\n",
    "                if time > 2:\n",
    "                    time = 2\n",
    "                \n",
    "                for current_note in notes_in_chord:\n",
    "                    if current_note != soprano:\n",
    "                        new_note = note.Note(current_note,quarterLength=time)\n",
    "                    else:\n",
    "                        new_note = note.Note(current_note)\n",
    "                    new_note.volume = volume.Volume(velocity=random.choice(chord_vel))\n",
    "                    new_note.storedInstrument = instrument.Piano()   # change the instrument\n",
    "                    notes.append(new_note)\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                output_notes.append(new_chord)\n",
    "                \n",
    "            else:\n",
    "                last_chord = copy.deepcopy(notes_in_chord)\n",
    "                continue\n",
    "                          \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(prediction_output[i],quarterLength=duration_list[i])\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "#             new_note.storedInstrument = instrument.Vocalist()\n",
    "            new_note.volume = volume.Volume(velocity=velocity_list[i])\n",
    "\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "        \n",
    "    \n",
    "    if last_chord is not None:\n",
    "        for current_note in last_chord:\n",
    "            new_note = note.Note(current_note)\n",
    "#             new_note.storedInstrument = instrument.Piano()   \n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes,quarterLength=1)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "        \n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    # generate function for pg1\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    # get output sequence\n",
    "    initial_index = np.random.randint(low=1, high=n_vocab-1, size=1)\n",
    "    # epoch_num: identify the model to be loaded\n",
    "    # initial_index: randomize starting index\n",
    "    # seq_length: length of output\n",
    "    output_sequence = generate_sequence(epoch_num=320, initial_index=initial_index[0], seq_length=400)\n",
    "    return output_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_sequence = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = midi.MidiFile()\n",
    "mf.open('test_output.mid')\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = midi.translate.midiFileToStream(mf)\n",
    "s.show('midi')\n",
    "# this midi player shows little variation in velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Data source] \"Giovanni Pierluigi da Palestrina\" *ChoralWiki.* \n",
    "    <br>http://www1.cpdl.org/wiki/index.php/Giovanni_Pierluigi_da_Palestrina <br>\n",
    "2. [LSTM model] Gaurav Sharma. \"Music Generation Using Deep Learning.\" *Medium.*\n",
    "    <br>https://medium.com/datadriveninvestor/music-generation-using-deep-learning-85010fb982e2?<br>\n",
    "3. [Data processing] Sigurður Skúli. \"How to Generate Music using a LSTM Neural Network in Keras\" *Medium.*\n",
    "    <br>https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5<br>\n",
    "4. [WebScraper] Samridha Shretha. *Github.*\n",
    "    <br>https://github.com/SamSamhuns/musical_python/blob/master/scrap_midi/scrap_freemidi_org.py<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
