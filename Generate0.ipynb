{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module generates notes for a midi file using the\n",
    "    trained neural network \"\"\"\n",
    "import pickle\n",
    "from music21 import instrument, note, stream, chord, converter,midi, duration,volume\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation, Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"DataX/\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = 'DataX/Model_Weights/'\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "  \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add((Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for pg2\n",
    "def generate_sequence(epoch_num, initial_index, seq_length):\n",
    "    padder = int(seq_length * 0.2)\n",
    "    seq_length += padder\n",
    "    with open(os.path.join(data_directory, charIndex_json)) as f:\n",
    "        char_to_index = json.load(f)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    unique_chars = len(index_to_char)\n",
    "    \n",
    "    model = make_model(unique_chars)\n",
    "    model.load_weights(model_weights_directory + \"Weights_{}.h5\".format(epoch_num))\n",
    "     \n",
    "    sequence_index = [initial_index]\n",
    "    \n",
    "    for _ in range(seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(unique_chars), size = 1, p = predicted_probs)\n",
    "\n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "    output_sequence = [index_to_char[c] for c in sequence_index]\n",
    "    output_sequence = output_sequence[padder:]\n",
    "    return output_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize(seq_len):\n",
    "    # randomize duration and velocity\n",
    "    mu, sigma = 1, 0.15 # mean and standard deviation\n",
    "    duration_list = np.random.normal(mu, sigma, seq_len)\n",
    "    mu, sigma = 75, 11 \n",
    "    velocity_list = np.random.normal(mu, sigma, seq_len)\n",
    "    velocity_list = [int(i) for i in velocity_list]\n",
    "    return duration_list, velocity_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_chord(vel,seq_len):\n",
    "    # randomize the velocity for each value in chord\n",
    "    mu, sigma = vel, 3 # mean and standard deviation\n",
    "    velocity_list = np.random.normal(mu, sigma, seq_len)\n",
    "    velocity_list = [int(i) for i in velocity_list]\n",
    "    return velocity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    # get a list of the indexes of all chords\n",
    "    l_chords = []\n",
    "    for i in range(len(prediction_output)):\n",
    "        if ('.' in prediction_output[i]) or prediction_output[i].isdigit():\n",
    "            l_chords.append(i)       \n",
    "    print(\"l_chords\",l_chords)\n",
    "    last_chord = None\n",
    "    \n",
    "    duration_list, velocity_list = humanize(len(prediction_output))\n",
    "    \n",
    "    \n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for i in range(len(prediction_output)):\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in prediction_output[i]) or prediction_output[i].isdigit():\n",
    "            notes_in_chord = prediction_output[i].split('.')\n",
    "            notes_in_chord = [int(i) for i in notes_in_chord]\n",
    "            soprano = max(notes_in_chord)\n",
    "            notes = []   \n",
    "            chord_vel = humanize_chord(velocity_list[i],len(notes_in_chord))\n",
    "            if i != l_chords[-1]:\n",
    "                # when the current chord is not the last chord\n",
    "                curr_idx = l_chords.index(i)\n",
    "                time = (l_chords[curr_idx+1] - i) * 0.5\n",
    "                if time > 2:\n",
    "                    time = 2\n",
    "                \n",
    "                for current_note in notes_in_chord:\n",
    "                    if current_note != soprano:\n",
    "                        new_note = note.Note(current_note,quarterLength=time)\n",
    "                    else:\n",
    "                        new_note = note.Note(current_note)\n",
    "                    new_note.volume = volume.Volume(velocity=random.choice(chord_vel))\n",
    "                    new_note.storedInstrument = instrument.Piano()   # change the instrument\n",
    "                    notes.append(new_note)\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                output_notes.append(new_chord)\n",
    "                \n",
    "            else:\n",
    "                last_chord = copy.deepcopy(notes_in_chord)\n",
    "                continue\n",
    "                          \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(prediction_output[i],quarterLength=duration_list[i])\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "#             new_note.storedInstrument = instrument.Vocalist()\n",
    "            new_note.volume = volume.Volume(velocity=velocity_list[i])\n",
    "\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "        \n",
    "    \n",
    "    if last_chord is not None:\n",
    "        for current_note in last_chord:\n",
    "            new_note = note.Note(current_note)\n",
    "#             new_note.storedInstrument = instrument.Piano()   \n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes,quarterLength=1)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "        \n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    # generate function for pg1\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes_given', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "    print(n_vocab)\n",
    "\n",
    "    # get output sequence\n",
    "    initial_index = np.random.randint(low=1, high=n_vocab-1, size=1)\n",
    "    # epoch_num: identify the model to be loaded\n",
    "    # initial_index: randomize starting index\n",
    "    # seq_length: length of output\n",
    "    output_sequence = generate_sequence(epoch_num=320, initial_index=initial_index[0], seq_length=400)\n",
    "    return output_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "output_sequence = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_chords []\n"
     ]
    }
   ],
   "source": [
    "create_midi(output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv11993'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv11993');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf = midi.MidiFile()\n",
    "mf.open('test_output.mid')\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = midi.translate.midiFileToStream(mf)\n",
    "s.show('midi')\n",
    "# this midi player shows little variation in velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Data source] \"Giovanni Pierluigi da Palestrina\" *ChoralWiki.* \n",
    "    <br>http://www1.cpdl.org/wiki/index.php/Giovanni_Pierluigi_da_Palestrina <br>\n",
    "2. [LSTM model] Gaurav Sharma. \"Music Generation Using Deep Learning.\" *Medium.*\n",
    "    <br>https://medium.com/datadriveninvestor/music-generation-using-deep-learning-85010fb982e2?<br>\n",
    "3. [Data processing] Sigurður Skúli. \"How to Generate Music using a LSTM Neural Network in Keras\" *Medium.*\n",
    "    <br>https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5<br>\n",
    "4. [WebScraper] Samridha Shretha. *Github.*\n",
    "    <br>https://github.com/SamSamhuns/musical_python/blob/master/scrap_midi/scrap_freemidi_org.py<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
